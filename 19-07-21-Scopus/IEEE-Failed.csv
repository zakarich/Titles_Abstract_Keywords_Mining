Document Title,Author Keywords,Abstract,Publication Year,Authors,Start Page,End Page,Pages count,Article Citation Count,DOI,Link,Document Identifier,Publisher
Automatic Machine Translation of Poetry and a Low-Resource Language Pair,automatic machine translation;statistical and neural machine translation;quality evaluation;automatic metrics;natural language processing;low-resource;Croatian,"Automatic machine translation is gaining more and more attention in a particular segment of the research community that treats various topics from artificial intelligence, natural language processing, computational linguistics, machine learning and data science. Machine translation is a complex task in which a computer is utilised for the purpose of translating from source to one or more target languages without human involvement, or with a minimum of interventions. In general, machine translation could be implemented in higher education and academic curricula in a variety of possible fields and applications. Although there are several approaches to machine translation, two are dominant today - statistical and neural machine translation. Both are being used in this research in form of two online machine translation systems. The aim of this paper is to examine the usability of machine translation for poetry and a low-resource language pair, such as Croatian-German. The authors chose to use a data set that contained the works of a relevant contemporary poet of the Croatian language and the translations of his poems in German that were conducted by two professional literary translators. The paper demonstrates the effectiveness of machine translation of poetry with regard to special automatic quality metrics.",2020,A. A. Deshmukh; R. Prasad,1034,1039,6,,10.23919/MIPRO48935.2020.9245342,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9245342,IEEE Conferences,IEEE
Human Quality Evaluation of Machine-Translated Poetry,automatic machine translation;machine translation quality evaluation;human evaluation;domainspecific evaluation;natural language processing,"The quality of literary translation was from the beginning of literacy an important factor in publishing and, as a consequence, in research and education. The quality of literary text translation is of utmost significance for researchers and students, especially in higher education. Only complete and high-standard translations are believed to be necessary for the use in the evaluation and study of style and concepts of a given author or a literary genre. This quality verification applies even more to machine translation in general, due to the fact that such translations are deemed subpar and unsuitable for further dissemination and examination. The need for human quality evaluation of machine-translated text is therefore highly emphasised, since human translations are considered to be the â€œgold standardâ€? and reference translations in the machine translation process. The aim of this paper is to explore, on the example of a data set consisting of poems written by a relevant contemporary Croatian poet, the effectiveness of applying machine translation on the Croatian-German language pair in the domain of poetry, with regard to human judgment of machine translation quality. Human evaluation in this paper is conducted by taking into account two machine translation quality criteria - adequacy and fluency, after which an inter-rater agreement analysis is performed.",2020,A. A. Suryani; D. H. Widyantoro; A. Purwarianti; Y. Sudaryat,1040,1045,6,,10.23919/MIPRO48935.2020.9245436,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9245436,IEEE Conferences,IEEE
A Summary and Comparative Study of Different Metrics for Machine Translation Evaluation,Machine Translation;MT Evaluation;Automatic Evaluation Metrics,"Assessment of the Translation done by machines has always been a major topic of interest for the Natural Language Researchers. Every day, a new translator is out there in the market claiming to be the best one. But to challenge such claims, one needs to have a powerful assessment tool that can judge the output of any translator on different parameters like fluency of the language, adequacy as well as the accuracy of the output generated. In this paper, we have discussed the major issues with the algorithms used for the evaluation of Machine translation. We have also presented a brief description and comparative study of different metrics used to evaluate the outcome of a machine translator over English to Hindi Language parallel sentences.",2018,A. A. Zhivotova; V. D. Berdonosov; E. V. Redkolis,55,60,6,1,10.1109/CONFLUENCE.2018.8442777,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8442777,IEEE Conferences,IEEE
Statistical machine translation of Croatian weather forecast: How much data do we need?,statistical machine translation;Croatian language;English language;automatic evaluation;manual evaluation,"This research is a first step towards a system for translating Croatian weather forecast into multiple languages. This steps deals with the Croatian-English language pair. The parallel corpus consists of a one-year sample of the weather forecasts for the Adriatic consisting of 7,893 sentence pairs. Evaluation is performed by best known automatic evaluation measures BLUE, NIST and METEOR, as well as by evaluating manually a sample of 200 translations. In this research we have shown that with a small-sized training set and the state-of-the art Moses system, decoding can be done with 96% accuracy concerning adequacy and fluency. Additional improvement is to be expected by increasing the training set size.",2010,Ã–. Åžahin; A. KurtoÄŸlu; G. Ercan,91,96,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5546371,IEEE Conferences,IEEE
Syntax Rectification of Speech Using Neural Machine Translation,Automatic Speech Recognition;Neural Machine Translation;Sequence to Sequence;Deep Recurrent Neural Networks,Speech Recognition is the identification of speech and conversion of the audio signals into textual data. The process of Speech Recognition has been accelerated with advancements in computing and progress in the development of Deep Learning. The mathematics behind Speech Recognition stems from Hidden Markov Models and has evolved into its more advanced form - End to End Speech Recognition. The aim of this paper is to focus on the syntax correction of speech in English language which will make use of Sequence to Sequence Models. The paper will delineate three major domains of grammatical correction of speech which will be achieved through real time interaction with the user.,2018,A. Boni; A. Zorat,306,311,6,,10.1109/I-SMAC.2018.8653676,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653676,IEEE Conferences,IEEE
A hybrid approach for Hindi-English machine translation,Machine Translation;Hindi-English Machine Translation;Example Based Machine Translation;Statistical Based Machine Translation;Ruled Based Machine Translation;Hybrid Machine Translation,"In this paper, an extended combined approach of phrase based statistical machine translation (SMT), example based MT (EBMT) and rule based MT (RBMT) is proposed to develop a novel hybrid data driven MT system capable of outperforming the baseline SMT, EBMT and RBMT systems from which it is derived. In short, the proposed hybrid MT process is guided by the rule based MT after getting a set of partial candidate translations provided by EBMT and SMT subsystems. Previous works have shown that EBMT systems are capable of outperforming the phrase-based SMT systems and RBMT approach has the strength of generating structurally and morphologically more accurate results. This hybrid approach increases the fluency, accuracy and grammatical precision which improve the quality of a machine translation system. A comparison of the proposed hybrid machine translation (HTM) model with renowned translators i.e. Google, BING and Babylonian is also presented which shows that the proposed model works better on sentences with ambiguity as well as comprised of idioms than others.",2017,A. de Gispert; J. B. Marino,389,394,6,14,10.1109/ICOIN.2017.7899465,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899465,IEEE Conferences,IEEE
A web based Punjabi to Hindi Statistical Machine Translation System,Machine Translation (MT);Statistical Machine Translation (SMT);Natural Language Processing (NLP);Punjabi;Hindi;transliteration and translation,"Machine translation (MT) system translates one natural language into another language with the help of computers. MT is a key application in the field of natural language processing. In proposed system, Statistical Machine Translation (SMT) approach has been used for developing Punjabi to Hindi Machine Translation System. In SMT, every sentence in the target language i.e. Hindi is a translation of the source language i.e. Punjabi with some probability and the best translation will be of high probability which the system will attain in the form of sentence. The key activities involved during translation process are pre-processing, translation engine and post processing. Unigram algorithm, N-Gram string matching algorithm etc formed the basis for solving these issues. The accuracy of the system has been evaluated using subjective tests i.e. intelligibility test and accuracy test. A proposed system is found to perform better than the existing system.",2015,A. de Pierrefeu; T. LÃ¶fstedt; C. Laidi; F. Hadj-Selem; M. Leboyer; P. Ciuciu; J. Houenou; E. Duchesnay,1,6,6,1,10.1109/RAECS.2015.7453298,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7453298,IEEE Conferences,IEEE
Evaluating English to Arabic machine translators,Automatic Evaluation of Machine Translation;Arabic MT;English MT;statistical MT;BLEU,"Location and language have now less impact as barriers for the expansion and the spread of information around the world. Machine translators achieve such a tedious task of translation among languages in quick and reliable manners. However, if compared with human translation, issues related to semantic meanings may always arise. Different machine translators may differ in their effectiveness, and they can be evaluated either by humans or through the use of automatic methods. In this study, we attempt to evaluate the effectiveness of two popular Machine Translation (MT) systems (Google Translate and Babylon machine translation systems) to translate sentences from English to Arabic, where an automatic evaluation method called Bilingual Evaluation Understudy (BLEU) is used. Our preliminary tests indicated that Google Translate system is more effective in translating English sentences into Arabic in comparison with the Babylon MT system.",2013,A. Deniz; H. E. Kiziloz,1,6,6,3,10.1109/AEECT.2013.6716439,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716439,IEEE Conferences,IEEE
Can we beat google translate?,automatic evaluation;BLEU;F-measure;Google Translate;NIST;PER;reference set;SMT (statistical machine translation);TER;translation evaluation;WER,"This paper presents a machine translation evaluation study for Croatian-English language pair. In-domain and out-of-domain translations from Croatian into English have been obtained from Google Translate, our own statistical machine translation system LegTran, and from a professional translator. These translations have been evaluated by six different automatic metrics. The gains obtained from increasing the number of reference translations have been explored and measured. System level correlation between automatic evaluation metrics is given and the significance of the results is discussed. Bootstrapping, approximate randomization and the sign test have been used for confidence intervals and hypothesis testing.",2012,A. Dubbaka; A. Gopalan,381,386,6,,10.2498/iti.2012.0411,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6308037,IEEE Conferences,IEEE
Automatic Machine Translation for Bangla and English Resolving Ambiguities,Ambiguities;bilingual;dialect;machine translation approaches;natural language;Stanford POS tagger,"The strategic borderless knowledge sharing and development of communication interacts with dialects. Significant factors such as education, medical, business, research and others are vastly diffused over the world based on various lingoes. Bilingual or multilingual expression is the standard of having unknown/new linguistic along with its resources. The initial endeavor of the study is to implement the MT (machine translation) approaches for English to Bangla language processing and vice-versa. The emphasis of the study is the distinct ambiguities are identified along with their best solutions. Certain machine translation approaches such as word-to-word, direct, transfer, interlingua, corpus-based and statistical translation are surviving and, few of them are deployed in this Smart Natural Language Processing (SNLP) for dispatching the source to the target language and vice-versa. Two different dictionaries (bilingual and monolingual) are developed for the execution process. An eminent resource Stanford POS Tagger (as a toolkit) is used for identifying the grammatical structure of the source (English) dialect. This research also focuses on output acquiring through performance analyzing of different translation models.",2021,A. Gorthi; R. Jain; N. Dimitrova,27,32,6,,10.1109/ICREST51555.2021.9331085,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331085,IEEE Conferences,IEEE
An empirical study on English to Hindi E-contents Machine Translation through multi engines,Example Based Machine Translation;Multi Engine Machine Translation;Machine Translation;Rule Based Machine Translation;Statistical Machine Translation,Empirical study presented here about the comparative view of translations through freely available English to Hindi machine translation engines. The selected Machine Translation engines are compared for computer science related text domain. The objective is to present the comparison amongst eight selected machine translation engines based on various comparison criteria. Three different English source text of computer science domain have randomly picked and translated those with eight selected engines. The outputs produced by different selected engines are compared on the basis of comparison criteria. The best fluent translation has been judged by expert human translator and assumed this translation as required quality translation of respective source text. This empirical study will be helpful in designing of Multi Engine Machine Translation architecture for domain specific English to Hindi language pair.,2014,A. H. Imam; M. R. Mahmud Arman; S. H. Chowdhury; K. Mahmood,1,6,6,3,10.1109/ICRITO.2014.7014735,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014735,IEEE Conferences,IEEE
Neural Machine Translation for Cebuano to Tagalog with Subword Unit Translation,neural machine translation;recurrent neural network;subword unit translation;natural language processing,"The Philippines is an archipelago composed of 7, 641 different islands with more than 150 different languages. This linguistic differences and diversity, though may be seen as a beautiful feature, have contributed to the difficulty in the promotion of educational and cultural development of different domains in the country. An effective machine translation system solely dedicated to cater Philippine languages will surely help bridge this gap. In this research work, a never before applied approach for language translation to a Philippine language was used for a Cebuano to Tagalog translator. A Recurrent Neural Network was used to implement the translator using OpenNMT sequence modeling tool in TensorFlow. The performance of the translation was evaluated using the BLEU Score metric. For the Cebuano to Tagalog translation, BLEU produced a score of 20.01. A subword unit translation for verbs and copyable approach was performed where commonly seen mistranslated words from the source to the target were corrected. The BLEU score increased to 22.87. Though slightly higher, this score still indicates that the translation is somehow understandable but is not yet considered as a good translation.",2018,A. Hermanto; T. B. Adji; N. A. Setiawan,328,333,6,,10.1109/IALP.2018.8629153,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629153,IEEE Conferences,IEEE
A Survey of Machine Translation Approaches for Konkani to English,Natural Language Processing;Machine Translation;Rule-Based Machine Translation;Statistical Machine Translation;Neural-Based Machine Translation;Hybrid-Based Machine Translation,"Machine Translation is a popular field in computer science. It's also a key part in the field of Natural Language Processing. Since India is a country where multiple languages are spoken there is a need for Language Translation. In this paper, we present a survey of several research works and the machine translation approaches mentioned in them. We begin with some well-established methodologies and further delve into more recent and hybrid techniques which are still in the state of improvement. We also compare these papers using several parameters such as the tools & technologies, datasets, advantages, disadvantages, and accuracy. We propose a machine translation model based on Statistical Machine Translation that will help us to translate from the Indian regional language Konkani to English and vice versa.",2020,A. Hossny; K. Shaalan; A. Fahmy,1,6,6,,10.1109/ic-ETITE47903.2020.110,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9077842,IEEE Conferences,IEEE
Dynamic Machine Translation of Croatian Academic Web Sites,web sites translation;machine translation;Domain Translator,"Web sites internationalization of Croatian web sites is a problem remained from the beginnings of web. In most cases, only some general information that are rarely changed are available in foreign languages, and the reason for that is the lack of human resources to make translations, as well as the need of software adaptations to support multilingualism. This paper analyses some lexical characteristics of the selected Croatian academic web sites, compared with some other, like daily newspapers and culinary web sites in order to find out their suitability for machine translation. The findings are compared to the actual state of our dynamic translation system for web contents, named as Domain Translator.",2019,A. Kaur; J. Rani,637,642,6,,10.23919/MIPRO.2019.8756643,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756643,IEEE Conferences,IEEE
Evaluation of the Validity of Back-Translation as a Method of Assessing the Accuracy of Machine Translation,machine translation;back translation;multilingual communication,"Inaccurate translation prevents effective communication between individuals and leads to misunderstandings. Back-translation is a process used to check the accuracy of a sentence by translating it to the checker's native language. We believe that there is a positive correlation between the accuracy of sentences translated to a target language and that of back-translated sentences. Some studies have discussed the validity of back-translation from the standpoint of the performance evaluation of machine translation systems and concluded that back-translation was unsuitable for checking translation accuracy. However, this result has been derived from the process of verification of whether there was a positive correlation between the accuracy of target-translated sentences and that of back-translated sentences. This mode of verification is not suitable to human verification of back-translation. In this paper, we verified the validity of back-translation from the standpoint of a human checker. We focused on differences that tend to occur between checkers, and determined whether there were differences between target- and back-translated sentences. Our study's contribution can be summarized as follows: (1) we examined the co-occurrence rate of each evaluated value in the same sentence and revealed possible differences in evaluated values between checkers, and (2) we defined an acceptable range of accuracy mismatch based on these differences. Moreover, we revealed how the rate of accuracy mismatch changes with the extension of the acceptable range, which can be different for different purposes. Our results enable people to judge whether they can use back-translation for their purposes.",2015,A. Kaur; V. Goyal,145,150,6,1,10.1109/Culture.and.Computing.2015.35,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433246,IEEE Conferences,IEEE
Survey on Neural Machine Translation for multilingual translation system,Recurrent Neural Networks;Long Short-Term Memory;Machine Translation;Neural Machine Translation;Attention;sequence to sequence,"Neural Machine Translation (NMT) has provided promising results in the field of machine translation in recent times. As compared to the previously used rule-based methods or Statistical Machine Translation (SMT), NMT outperforms SMT in quite a few linguist categories. In this paper, we analyze various models, approaches and frameworks used in NMT to find an efficient method to create a translation system and to achieve accurate translation between Indian languages and English.",2019,A. Lucas; J. Hermiz; J. Labuzetta; Y. Arabadzhi; N. Karanjia; V. Gilja,443,448,6,2,10.1109/ICCMC.2019.8819788,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8819788,IEEE Conferences,IEEE
Evaluation of Arabic to English Machine Translation Systems,Machine Translation;Google translation;BLEU;Story Understanding;Arabic Text;Evaluation of Machine Translation,"Arabic machine translation has an important role in most NLP tasks. Many machine translation systems that support Arabic exist already; however the quality of the translation needs to be improved. In this paper, we review different research approaches for Arabic-to-English machine translation. The approaches use various evaluation methods, datasets, and tools to measure their performance. Moreover, this paper sheds light on several methods and assessment efforts, and future ideas to improve the machine translation quality of Arabic-to-English. The review results depict three major findings; first neural machine translation approaches outperform other approaches in many aspects. Second, the recently emerging attention-based approach is being useful to improve the performance of neural machine translation for all languages. Third, the translation performance quality depends on the quality of the dataset, well-behaved aligned corpus, and the evaluation technique used.",2020,A. M. Abualkishik; K. Omar,185,190,6,,10.1109/ICICS49469.2020.239518,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079094,IEEE Conferences,IEEE
"Statistical Machine Learning for Transliteration: Transliterating names between Sinhala, Tamil and English",statistical machine translation;transliteration;naive bayes;sinhala;tamil,"In this paper, we focus on building models for transliteration of personal names between the primary languages of Sri Lanka-namely Sinhala, Tamil and English. Currently, a Rule-based system has been used to transliterate names between Sinhala and Tamil. However, we found that it fails in several cases. Further, there were no systems available to transliterate names to English. In this paper, we present a hybrid approach where we use machine learning and statistical machine translation to do the transliteration. We built a parallel trilingual corpus of personal names. Then we trained a machine learner to classify names based on the ethnicity as we found it is an influencing factor in transliteration. Then we took the transliteration as a translation problem and applied statistical machine translation to generate the most probable transliteration for personal names. The system shows very promising results compared with the existing rule-based system. It gives a BLEU score of 89 in all the test cases and produces the top BLEU score of 93.7 for Sinhala to English transliteration.",2019,A. M. Khan; A. Khan,244,249,6,,10.1109/IALP48816.2019.9037651,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037651,IEEE Conferences,IEEE
Transliteration and Byte Pair Encoding to Improve Tamil to Sinhala Neural Machine Translation,neural machine translation;transliteration;byte pair encoding;sinhala;tamil,"Neural Machine Translation (NMT) is the current state-of-the-art machine translation technique. However, applicability of NMT for language pairs that have high morphological variations is still debatable. Lack of language resources, especially a sufficiently large parallel corpus causes additional issues, which leads to very poor translation performance, when NMT is applied to languages with high morphological variations. In this paper, we present three techniques to improve domain-specific NMT performance of the under-resourced language pair Sinhala and Tamil that have high morphological variations. Out of these three techniques, transliteration is a novel approach to improve domain-specific NMT performance for language pairs such as Sinhala and Tamil that share a common grammatical structure and have moderate lexical similarity. We built the first transliteration system for Sinhala to English and Tamil to English, which provided an accuracy of 99.6%, when tested with the parallel corpus we used for NMT training. The other technique we employed is Byte Pair Encoding (BPE), which is a technique that has been used to achieve open vocabulary translation with a fixed vocabulary of subword symbols. Our experiments show that while the translation based on independent BPE models and pure transliteration perform moderately, integrating transliteration to build a joint BPE model for the aforementioned language pair increases the translation quality by 1.68 BLEU score.",2018,A. Megerdoumian; S. Khadivi,390,395,6,3,10.1109/MERCon.2018.8421939,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421939,IEEE Conferences,IEEE
Confidence Modeling for Neural Machine Translation,machine translation;confidence estimation,"Current methods of neural machine translation output incorrect sentences together with sentences translated correctly. Consequently, users of neural machine translation algorithms do not have a way to check which outputted sentences have been translated correctly without employing an evaluation method. Therefore, we aim to define the confidence values in neural machine translation models. We suppose that setting a threshold to limit the confidence value would allow correctly translated sentences to exceed the threshold; thus, only clearly translated sentences would be outputted. Hence, users of such a translation tool can obtain a particular level of confidence in the translation correctness. We propose some indices; sentence log-likelihood, minimum variance, and average variance. After that, we calculated the correlation between each index and bilingual evaluation score (BLEU) to investigate the appropriateness of the defined confidence indices. As a result, sentence log-likelihood and average variance calculated by probability have a weak correlation with the BLEU score. Furthermore, when we set each index as the threshold value, we could obtain high quality translated sentences instead of outputting all translated sentences which include a wide range of quality sentences like previous work.",2019,A. O'Shea; G. Lightbody; G. Boylan; A. Temko,349,354,6,,10.1109/IALP48816.2019.9037709,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037709,IEEE Conferences,IEEE
A Corpus Based N-gram Hybrid Approach of Bengali to English Machine Translation,Natural Language Processing (NLP);Machine Translation (MT);Hybrid Machine Translation (HMT);Bengali to English Translation;N-gram model;Bilingual corpus,"Machine translation means automatic translation which is performed using computer software. There are several approaches to machine translation, some of them need extensive linguistic knowledge while others require enormous statistical calculations. This paper presents a hybrid method, integrating corpus based approach and statistical approach for translating Bengali sentences into English with the help of N-gram language model. The corpus based method finds the corresponding target language translation of sentence fragments, selecting the best match text from the bilingual corpus to acquire knowledge while the N-gram model rearranges the sentence constituents to get an accurate translation without employing external linguistic rules. A variety of Bengali sentences, including various structures and verb tenses are considered to translate through the new system. The performance of the proposed system is evaluated in terms of adequacy, fluency, WER, and BLEU score. The assessment scores are compared with other conventional approaches as well as with Google Translate, a well-known free machine translation service by Google. It has been found that experimental results of the work provide higher scores over Google Translate and other methods with less computational cost.",2018,A. Pramodya; R. Pushpananda; R. Weerasinghe,1,6,6,1,10.1109/ICCITECHN.2018.8631938,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8631938,IEEE Conferences,IEEE
Automatic Acquisition of Semantic Elements Based on Statistical Decomposition,Machine Translation;semantic element;automatic acquisition;statistical decomposition,"The implement of machine translation system based on semantic element (SE) requires a large scale semantic element base. An automatic acquisition method for SEs based on statistical decomposition was proposed in this paper. Firstly, .analogical decomposition was applied to decompose abandonable SE and two conditions are found to assure the correctness of decomposition. Secondly, three statistics were designed, namely parameter index, translation index and language model index, to measure the rationality of analogical decomposition. Finally, multi-attribute decision making values for the above three statistics were prioritized to choose the best decomposition. Abandonable SE could be decomposed iteratively thereafter. Experimental results show that the accuracy has reached around 60%.",2008,A. R. Atmadja; A. Purwarianti,76,81,6,,10.1109/WSCS.2008.15,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4570820,IEEE Conferences,IEEE
Increasing SMT and NMT Performance by Corpus Extension with Free Online Machine Translation Services,Corpus Extension;Statistical Machine Translation;Neural Machine Translation;Under-Resourced Languages;ASEAN-MT Performance,"In machine translation, parallel corpora of source-target language pair are essential to improve the performance of the translation. However, the existing parallel corpora for the low resource language is not sufficient to improve the quality of the translation. In this paper, we explore the role of corpus extension by using the three freely available online machine translation services; â€œGoogle Translateâ€?, â€œSYSTRAN Translateâ€? and â€œYandex Translateâ€? for English and Thai language pair. We compare three statistical and neural machine translation performances between the original ASEAN-MT corpus, and their extended version, which double the original size of the ASEAN-MT. The results showed that, for SMT models, extended Thai corpus can help improve the translation performance for th-en translation up to 2.6% and the extended English corpus can do so significantly for en-th translation up to 4.2%. While for the NMT model, the extended Thai corpus can improve the translation performance up to 5.5%.",2020,A. Rashid; A. Do-Omri; M. A. Haidar; Q. Liu; M. Rezagholizadeh,212,217,6,,10.1109/ICAIT51105.2020.9261772,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261772,IEEE Conferences,IEEE
Image Semantic Extraction Using Latent Semantic Indexing on Image Retrieval Automatic-Annotation,Content-based image retrieval;automatic annotation;statistical machine translation;latent semantic indexing,"This research proposed a new method Latent Semantic Indexing to overcome semantic problem on image retrieval based on automatic image annotation. Statistical machine translation used to automatically annotates the image. This approach considers image annotation as the translation of image regions to words, similar to the translation of text from one language to another. The ""lexicon"" for the translation is learned from large annotated image collections, which consist of images that are associated with text. Images are segmented into regions with grid segmentation. A pre-specified feature vector represents each region. The regions then clustered into a finite set of blobs. The correspondences between the blobs and the words are learned using Expectation Maximization algorithm. These correspondences are used to predict words associated with whole images (auto-annotation). The auto-annotation performance is evaluated using Normalized Score (ENS) algorithm. The experimental results show that the average precision of clause queries achieved best result than word queries, 0.544 and 0.251 for clause queries and word queries respectively. The proposed method of latent semantic indexing succeeds to exploit semantic value of automatic-annotation-based image retrieval.",2009,A. Senapati; U. Garain,283,288,6,,10.1109/SoCPaR.2009.64,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370355,IEEE Conferences,IEEE
Rule Based Machine Translation System from English to Tamil,Machine Translation;Syntax Based Approach;Lexicon;PoS;Parse;Paninian grammar,"The main goal of this research is to develop English-Tamil machine translation system using rule-based approaches. For rule based approach, considering the structural difference between English and Tamil languages, syntax transfer based methodology is adopted for translation. This translation engine is a parser, which analyzes the source text, and the corresponding target structure is generated through the transfer lexicon. Morphological generator for Tamil is required to generate the proper Tamil sentence.",2014,A. Tomar; J. Bodhankar; P. Kurariya; P. Anarase; P. Jain; A. Lele; H. Darbari; V. C. Bhavsar,158,163,6,2,10.1109/WCCCT.2014.50,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755127,IEEE Conferences,IEEE
Study on machine translation approaches for Indian languages and their challenges,Source language;Target language;Machine Translation;computational linguistics,"This survey mainly focuses on the developments of machine translation for the Indian languages. The survey throws a light on rule-based approach, empirical based approach and hybrid based approaches for machine translation. Every approach has its own advantages and disadvantages. Machine Translation (MT) is a process which translates from one language to another language. Due to rapid globalisation there is an increased data over the web machine translation plays a very important role to reduce the language barrier between different regions. In a country like India with 22 official languages shows a high attention for the translation. This paper focuses on the different MT systems for Indian languages and also their challenges.",2016,A. Zifan; P. Liatsis,262,267,6,3,10.1109/ICEECCOT.2016.7955227,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7955227,IEEE Conferences,IEEE
On evaluation of interactive-predictive machine translation: Practical problems and suggestions,Statistical Machine Translation;Interactive-Predictive Machine Translation;Machine Translation Evaluation;Computer-Assisted Translation,"This paper first gives an overview on interactive-predictive machine translation systems. In such systems, the human translator translates the text while the machine provides completion to it. The user is given options to accept either the entire or a part of the suggested completion. Moreover, the user is also permitted to skip the suggestions and continue typing. Thereafter, we focus on TransType2 project, its architecture, and its evaluation methods. Furthermore we analyze the user log files of the last TransType2 Evaluation round. Eventually, according to the obtained analysis results, TransType2 project deliverables, and reports of human translators, we recommend several new features and adjustments to the current evaluation methodology of interactive-predictive machine translation systems. These new methods take advantage of the existing systems, add evaluation methods to them and modify them to result in qualified systems.",2010,Aye Thida Win,568,573,6,1,10.1109/ISTEL.2010.5734089,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734089,IEEE Conferences,IEEE
Neural Machine Translation: English to Hindi,Machine Translation (MT);Neural Machine Translation (NMT);BLEU score;Attention Mechanism,"Machine Translation (MT) attempts to minimize the communication gap among people from various linguistic backgrounds. Automatic translation between pair of different natural languages is the task of MT mechanism, wherein Neural Machine Translation (NMT) attract attention because it offers reasonable translation accuracy in case of the context analysis and fluent translation. In this paper, two different NMT systems are carried out, namely, NMT-1 relies on the Long Short Term Memory (LSTM) based attention model and NMT-2 depends on the transformer model in the context of English to Hindi translation. System results are evaluated using Bilingual Evaluation Understudy (BLEU) metric. The average BLEU scores of NMT-1 system are 35.89 (Test-Set-1), 19.91 (Test-Set-2) and NMT-2 system are 34.42 (Test-Set-1), 24.74 (Test-Set-2) respectively. The results show better performance than existing NMT systems.",2019,B. Buz; T. GÃ¼ngÃ¶r,1,6,6,2,10.1109/CICT48419.2019.9066238,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9066238,IEEE Conferences,IEEE
Preprocessors in NLP applications: In the context of English to Malayalam Machine Translation,preprocessor;machine translation;AnglaBharati,"Preprocessing the input text is an essential component in a Natural Language Processing (NLP) system. We are discussing the relevance of the preprocessors in the context of Machine Translation system developed by us based on AnglaBharati Technology. Whenever we come across with text for translation we encounter with the special formats in an input text and getting its appropriate translation is a difficult task. Sometimes they may not have definite grammatical structure and may not be able to handle using a language rule. This paper present a strategy to identify the special formats in English text like date, currency, number, time, quotes, acronym, parenthesis, etc for a rule based English Malayalam Machine Aided Translation system. AnglaBharati is a pattern directed rule based system with context free grammar like structure for English which generates a pseudo target for group of Indian languages. Preprocessor is one of the main modules in this translation System. Here it manipulates the English input text to produce an input which is more suitable for an engine to generate appropriate translation. Extensive research is carried out in this area to disambiguate and process the input text in order to get more suitable output from the translation engine.",2012,B. Ko; H. Byun,221,226,6,5,10.1109/INDCON.2012.6420619,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6420619,IEEE Conferences,IEEE
Japanese-Thai machine translation with generalized patterns,Japanese;Thai;Machine Translation;Pattern Based;Generalized Pattern,"Nowadays, most of modern approaches to machine translation are statistical-based method. However, its performance depends on the size of training corpus. This paper presents a pattern based method using small data to translate Japanese sentences into Thai language. We created 2,214 pair-patterns of Japanese and Thai and evaluated 3,107 sentences by using F-measure, PER and BLEU-score. The experiment confirms the effectiveness of the method introduced in this paper.",2012,B. Lu; B. K. Tsou,987,992,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6530478,IEEE Conferences,IEEE
Automatic Meta-evaluation of Low-Resource Machine Translation Evaluation Metrics,Automatic Meta-evaluation;Limited ORANGE;BLEUS;ROUGE-L;ROUGE-S,"Meta-evaluation is a method to assess machine translation (MT) evaluation metrics according to certain theories and standards. This paper addresses an automatic meta-evaluation method of machine translation evaluation based on ORANGE- Limited ORANGE, which is applied in low-resource machine translation evaluation. It is adopted when the resources are limited. And take the three n-gram-based metrics - BLEUS, ROUGE-L and ROUGE-S for experiment, which is called horizontal comparison. Also, vertical comparison is used to compare the different forms of the same evaluation metric. Compared with the traditional human method, this method can evaluate metrics automatically without extra human involvement except for a set of references. It only needs the average rank of the references, and will not be influenced by the subjective factors. And it costs less and expends less time than the traditional one. It is good for the machine translation system parameter optimization and shortens the system development period. In this paper, we use this automatic meta-evaluation method to evaluate BLEUS, ROUGE-L, ROUGE-S and their different forms based on Cilin on the Russian-Chinese dataset. The result shows the same as that of the traditional human meta-evaluation. In this way, the consistency and effectiveness of Limited ORANGE are verified.",2019,B. Ribeiro; H. Pereira; R. Almeida; A. Ferreira; L. Martins; C. Quaresma; P. Vieira,136,141,6,,10.1109/IALP48816.2019.9037658,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037658,IEEE Conferences,IEEE
Automatic translation of Arabic queries for bilingual information retrieval,systems of multilingual information retrieval;machine translation;lexical disambiguation;semantic and conceptual indexing;contextual relationships;matching;automatic evaluation metrics,"In this paper, we present an automatic query translation in Arabic for information retrieval. This system, implements a method for lexical disambiguation of terms in a query. To choose the best sense, each term of the query is projected on the French EuroWordNet and we extract his related concepts in order to form a semantic network. In a second time using the same type of network, but by integrating LSI (Latent Semantic Index), and extraction of contextual hidden links between the concepts of the list (listSRF). This list extracted by the automatic alignment by Mkalign tool's, from the knowledge base defined by the Monde Diplomatic parallel corpus. This tool will allow us to map between the relevant sentences in Arabic identified in our previous work with French sentences to build a listSRF. This list forms the basis of the lexical disambiguation method. Finally, we propose a mechanism for selecting the best sense of the ambiguous term of the query, based on the matching between each network corresponds to a word in the query with the network listSRF to extract an adequate sense with the highest degree of similarity. An evaluation and comparison are conducted to measure the quality of our translation system.",2013,B. Soewito; A. K. Satyadhana; Raymond; S. Maria,1,6,6,,10.1109/ICTA.2013.6815308,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815308,IEEE Conferences,IEEE
Open morphological machine translation: Bangla to English,Machine Translation (MT);Source Sentence (SS);Target Sentence (TS);Syntactic Transfer,The increase of Internet users all over the world and the subsequent growth of available multilingual information on the Web have brought new challenges to machine translation systems. It is really difficult to build up a complete Machine Translation System for natural languages. This paper represents a new solution that can be useful for building a MT system for converting the Bangla sentences into English sentences. In this paper we deal with the root word of Bangla sentence. We show here how to use the root word to translate the Bangla sentence into English Sentence. We deal here first to find out the root word from the database. Here is also an alternative to use the morphological analyzing. After that we define the parts of speech of that sentence. Then we detect the proper grammatical structure of that sentence. Then we find the grammar for the targeted language. The system will be able to translate error-free and ambiguous sentences correctly and will indicate if there is any error. Hopefully this paper will be helpful for the MT researchers to build and efficient MT System for Bangla Language.,2010,B. Wei; S. Lu; L. Mou; H. Zhou; P. Poupart; G. Li; Z. Jin,460,465,6,3,10.1109/CISIM.2010.5643495,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643495,IEEE Conferences,IEEE
A semi-automatic extraction of the SERB in machine translation based on SL,machine translation based on SL;Semantic Element;SERB;SER pattern match algorithm;SE pruning algorithm,"Machine translation based on semantic language (SL) should include a large scale semantic element representation base (SERB), which needs to be extracted from corpus automatically or at least semi-automatically. This paper presents a practical and efficient semi-automatic method to build a SERB from parallel corpus. This method processes the basic characters in both Chinese sentences and English sentences directly, instead of using Chinese word segmentation. First, a preliminary SERB is built. Then some semantic elements (SEs) are picked up by SER pattern match algorithm from the SERB and some of them are pruned by SE pruning algorithm. Last, the SEs are reconstructed to build some SE trees and new SEs and the SEs whose parameter vector categories need to be modified are put forward to users to examine and the correct SEs are appended to the SERB. Thus the SERB is built up. The correctness of the SEs in SERB can be guaranteed.",2005,B. Zhou; S. F. Chen; Y. Gao,398,403,6,,10.1109/NLPKE.2005.1598770,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1598770,IEEE Conferences,IEEE
A Review of Statistical and Neural Network Based Hybrid Machine Translators,Machine translation;Hybrid Machine Translator;Statistical Machine Translation;Neural Machine Translation,"Machine Translation has become one of the top research interests for a few years. Compared to others, statistical and neural network approaches toward machine translation are performing the best. However, both approaches have advantages over one another. In recent years, few researchers have conducted experiments to create hybrid machine translation systems that combine the strength of statistical and neural network approach to produce a better translation. In this paper, we review all of these research methodologies, datasets, evaluation scores and point out their shortcomings.",2018,Bing Xiang; Yonggang Deng; Yuqing Gao,1,6,6,,10.1109/ICBSLP.2018.8554792,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554792,IEEE Conferences,IEEE
English to Urdu: Optimizing Sequence Learning in Neural Machine Translation,Neural machine translation;Convolutional English to Urdu Translation;Machine Translation;Encoder-Decoder,"Neural machine translation is a new approach for machine translation, which translates source language sentences into the target language. Source to target words mapping is the key task of attention mechanism in neural machine translation. The number of attention-based seq2seq encoder-decoder models have been proposed in the literature. But these models have a nonlinearity problem with attention in English to Urdu translation. A seq2seq encoder-decoder model named Convolutional English to Urdu Translation (CEUT) has been proposed in this paper. The model reduces nonlinearity in attention word mapping and achieves 29.94 BLEU score in English to Urdu translation.",2020,C. A. Hammerschmidt; S. Garcia; S. Verwer; R. State,1,6,6,,10.1109/iCoMET48670.2020.9074098,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074098,IEEE Conferences,IEEE
Handling incomplete verb conjugations of telugu in machine translation,incomplete transitive Telugu conjugations;conjugation handling;Machine Translation;Morphological Analysis,"Various types of Telugu verbs like transitive, intransitive, reflexive, causative, negative, interrogative, passive, etc., can be conjugated grammatically to their complete or incomplete forms as required. Only incomplete transitive verbs and their conjugations were considered for handling in Machine Translation in this paper. The role of conjugations is very crucial in interpreting context since tense and mood of the context depends on them. Different categories of incomplete transitive conjugations and the ways of handling them are discussed in detail in this paper. For analysis, identification and extraction of root verb or headword verb from conjugations, a Morphological Analysis System (MAS) was developed in the process of Machine Translation (MT). MT has been done using Telugu as Source Language (SL) and Sanskrit as Target Language (TL).",2017,C. Cargile; G. Santhanakrishnan; A. Olmsted,92,97,6,,10.1109/ICBDACI.2017.8070815,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070815,IEEE Conferences,IEEE
"A machine translation framework for translating Bangla assertive, interrogative and imperative sentences into English",Machine translation;context sensitive grammar;parsing;transfer;generation,"This paper proposes a technique to translate Bangla sentence into corresponding English sentence using context sensitive grammar rules. A set of context sensitive grammar rules is proposed to translate Bangla sentences including assertive, interrogative and imperative sentences. The proposed rules are developed based on the mood or intonation of sentences rather than structure of the sentences. Machine translation system works with three major steps: parsing, transfer and generation. We propose algorithms for these three major stages. The evaluation result reveals that the proposed machine translation system can translate Bangla sentences into English with 83% accuracy and gives better accuracy compare to the Google translator for some selected sentences.",2015,C. Ling; L. Yue; J. Gao,1,6,6,5,10.1109/ICEEICT.2015.7307534,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307534,IEEE Conferences,IEEE
"An empirical machine translation framework for translating bangla imperative, optative and exclamatory sentences into English",Machine Translation;context sensitive grammar;parsing;transfer;generation,"A set of Context Sensitive Grammar (CSG) rules to translate Bangla imperative, optative and exclamatory sentences into English are introduced in this paper. In this paper, sentences are considered according to the function and purpose of the user rather than structure of the sentence. Three algorithms are implemented to complete major three steps of machine translation system (i.e., parsing, transfer and generation). The experimental results shows that the performance of the proposed machine translation framework is quite appeasement and efficiency is compared with Google Translator for some selected sentences which are quite satisfactory.",2016,C. M. Gevaert; C. Persello; S. O. Elberink; G. Vosselman; R. Sliuzas,932,937,6,2,10.1109/ICIEV.2016.7760137,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7760137,IEEE Conferences,IEEE
How Does Machine Translated User Interface Affect User Experience? A Study on Android Apps,User Experience;Machine Translation;Android Apps;User Interface,"For global-market-oriented software applications, it is required that their user interface be translated to local languages so that users from different areas in the world can use the software. A long-term practice in software industry is to hire professional translators or translation companies to perform the translation. However, due to the large number of user-interface labels and target languages, this is often too expensive for software providers, especially cost-sensitive providers such as personal developers of mobile apps. As natural language processing and machine techniques advance, more mature machine translation techniques are providing a cheap though imperfect alternative, and the Google Translation service has already been widely used for translating websites and apps. However, the effect of lower translation quality on user experience has not been well studied yet. In this paper, we present a user study on 6 popular Android apps, which involves 24 participants performing tasks on app variants with 4 different translation quality levels and 2 target languages: Spanish and Chinese. From our study, we acquire the following 3 major findings, including (1) compared with original versions, machine translated versions of apps have similar task completion rate and efficiency on most studied apps; (2) machine translated versions have more tasks completed with flaws such unnecessary steps and missed optional steps, and (3) users are not satisfied with the GUI of machine translated versions and the two major complaints are misleading labels of input boxes, and unclear translation of items in option lists.",2017,C. M. Jin; Z. Omar; M. H. Jaward,430,435,6,1,10.1109/ESEM.2017.58,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170130,IEEE Conferences,IEEE
Machine Translation of LATEX Based Mathematical Equations to Spoken Mathematics,Phrase-based Statistical Machine Translation (PBSMT);Ripple Down Rules (RDR);Weighted Finite State Transducers (WFST),"This paper describes the machine translation of LATEX encoded mathematical equations to spoken mathematical sentences. A LATEX- Spoken math parallel corpus (5,600 sentences) was developed. In this paper, the 10-fold cross-validation experiments were carried out by applying Phrase-based Statistical Machine Translation (PBSMT), Weighted Finite-State Transducers (WFST) and Ripple Down Rules (RDR) based tagging approaches. The BLEU, RIBES, F1 and WER evaluation scoring metrics are used for measuring translation performance. The experimental results show that the PBSMT approach achieved the highest translation performance for LATEX mathematical equations to spoken mathematical sentences translation. Moreover, we found that the translation performance of RDR approach is comparable with PBSMT.",2020,C. Mermer; M. Saraclar; R. Sarikaya,1,6,6,,10.1109/ICSEC51790.2020.9375339,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9375339,IEEE Conferences,IEEE
Impact of corpus size and quality on English-Bangla statistical Machine Translation system,Natural Language Processing;Parallel Corpus;Phrase-Based Machine Translation;Statistical machine translation,"Statistical machine translation (SMT) evolves with the motivation of translating a text from source language to target language which employs the machine learning technique to a parallel corpus for producing a translation system exclusively automatic. We have developed Anubad[26], a phrase-based Bangla to English SMT on the top of the SMT model proposed in [1] which is publicly available on www.anubad.com. As the most challenging task for SMT system development is the designing of large parallel corpora as the translation quality significantly depends upon the corpus dimension and quality, Bangla parallel corpus suffers the same problem and fails to provide a standard translation till now. In this paper, through simulations, we provide a guideline for developing an English-Bangla bilingual corpus. Although in a phrase-based Statistical Machine Translation systems, more training data is generally better outcome, however, we deflect from this notion and according to our experimental results, we observed that quality of good corpus could significantly improve the Bangla to English translation quality. We have found better translation quality by employing our techniques and achieved effective improvements on NIST and BLEU scores.",2011,C. Moulin; Kenji Sugawara; Shigeru Fujita; L. Wouters; Yusuke Manabe,566,571,6,3,10.1109/ICCITechn.2011.6164853,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164853,IEEE Conferences,IEEE
Machine Translation of Arabic Language: Challenges and Keys,Natural Language processing; word sense disambiguation; machine translation; analysis; synthesis; permutations; mapping,"The morphologically rich Arabic language continues to present challenges to Arabic Word Sense Disambiguation researchers. The challenges are quite clear when one compares the gradually emerging Arabic to English Machine Translation with the rapidly developing Machine Translations available today. The lagging of the former may be attributed to two reasons. The first is the impenetrability of some Arabic words, which puzzles their decomposition into morphemes. The second is the incompatibility of existing machine-translation techniques with the Arabic language. The degree of difficulty can easily be observed by checking the results of any artless round-trip machine translation of arbitrary Arabic texts. Even the most advanced technologies that are available today are challenged. Regardless of whether the round trip is Arabicto- English-to-Arabic or English-to-Arabic-to-English, the inevitable outcome will be disenchanting. This leads to an even more disappointing conclusion. That is, as long as no drastic improvements are made, one must not take output of any machine translation of Arabic as orthodox. Yet another disappointing fact is that most of the intelligent machines are built to produce woodenly literal or paraphrased translations. This paper proposes a framework for a biphasic Arabic translation process. Besides, the paper recommends the all-inclusive Holey Quran's English translation as the most reliable benchmark for Arabic to English Translations.",2014,C. N. Vanitha; V. N. Jeevaa; S. P. Shriman,111,116,6,3,10.1109/ISMS.2014.25,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280889,IEEE Conferences,IEEE
Mobile-Based Translation System for Cebuano Language with Object Detection for Travel Assistance using Neural Machine Translation,Neural Machine Translation;BLEU Score;Mobile-Based;Language Model;Object Detection,"The Philippines as an archipelagic nation has the numerous number of dialects per island that hampers local tourist communication. Cebu is one of the top tourist destinations by locals also has a vast language hurdle compared to other local dialects. Because of huge language differences of native Cebuano and Filipino speakers, travelers in Cebu often experience difficulty in expressing their needs and requests to the island locals. The solution is a mobile-based translation system with object detection for travel assistance. The system uses Neural Machine Translation to translate Filipino to Cebuano language and vice versa based on the user's keyboard input, extracted text strings from a detected image, and the detected object itself. The Filipino-Cebuano model obtained 31.1 BLEU score, while the Cebuano-Filipino model obtained 31.6 BLEU score.",2019,C. Nilubol; Q. H. Pham; R. M. Mersereau; M. J. T. Smith; M. A. Clements,523,528,6,,10.1109/ICOIACT46704.2019.8938565,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938565,IEEE Conferences,IEEE
Statistical machine translation,Machine Translation (MT);Phrase Based Statistical Machine Translation (PBSMT);language modeling;word alignment,"Translation of natural language text using statistical machine translation (SMT) is a supervised machine learning problem. SMT algorithms are trained to learn how to translate by providing many translations produced by human language experts. The field SMT has gained momentum in recent three decades. New techniques are constantly introduced by the researchers. This is survey paper presenting an introduction of the recent developments in the field. The paper also describes the recent research for word alignment and language modelling problems in the translation process. An overview of these two sub problems is enlisted. Along the way, some challenges in machine translation are presented.",2017,C. Park; C. Lee; Y. Yang; H. Lim,62,67,6,1,10.1109/ICISIM.2017.8122149,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8122149,IEEE Conferences,IEEE
A Study on an Effect of Using Deep Learning in Thai-English Machine Translation Processes,Deep Learning;Neural Machine Translation;Thai-English translation,"Deep learning has been used in many fields including natural language processing. This paper aims to study the effect of applying deep learning in machine translation processes including word segmentation and translation model generation. We compare the results of the process from traditional statistical method and deep learning and analyze the difference. From experiment, the results indicated that the processes from deep learning obtained higher score in overall. Word segmentation from Bidirectional neural network yielded 0.861 f1 score which was higher than standard n-gram based system for 0.081. The translation results within dataset show that the neural-network-based translation got the best BLEU score in average for 0.43 in which are higher than the traditional statistical approach for 0.16. The result analysis indicates that the neural-network-based translation can translate better for Thai sentences containing unknown words and those with numerical classifier expression.",2019,C. Park; S. Won,1,6,6,,10.1109/iSAI-NLP48611.2019.9045115,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045115,IEEE Conferences,IEEE
Template-based model for Mongolian - Chinese machine translation,machine translation;template extraction;template translation;combine system,"Mongolian-Chinese statistical machine translation (SMT) system has its limitation because of the significant syntax differences, complex Mongolian morphology and scarce resource of parallel corpus. Template-based machine translation (TBMT) can produce high accuracy and good syntax structure translations with a relative small corpus. Therefore, SMT systems can combine with TBMT system to get better translations. We built a Mongolian-Chinese TBMT system including a template extraction model and a template translation model. We proposed a novel method of aligning and abstracting static words from bilingual parallel examples to extracts templates automatically. We also proposed a method to filter out low quality TBMT translations to enhance the combined systems. Moreover, we applied lemmatization and latinization to address the problem data sparsity and fuzzy match. Experimentally, the translation of TBMT outperformed the baselines of phrase-based SMT system and hierarchical phrase-based SMT system. The combined system of the TBMT and the SMT systems also performed better than the baselines. Besides, the coverage can satisfy the combined systems.",2015,C. Park; Y. Yang; C. Lee; H. Lim,352,357,6,1,10.1109/TAAI.2015.7407090,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407090,IEEE Conferences,IEEE
Experiment on a phrase-based statistical machine translation using PoS Tag information for Sundanese into Indonesian,phrase-based machine translation;translation model;language model;PoS Tag;bleu score,"This paper discusses the problem of Sundanese into Indonesian text translation, as one of low-resource language pair translation. The number of parallel corpus gives a significant impact on a statistical machine translation. Whereas to date, there are no Sundanese to Indonesian parallel corpus that ready to use. It is, therefore, we apply the PoS Tag rather than only surface form in the translation model to get a better translation result. This experiment was done to get an early result in Sundanese to Indonesian text translation and to identify problems arise on it. The result shows that the model using surface form and PoS Tag was slightly outperformed the model using only surface form. However, there are some problems faced in this experiment which are the large number of OOV caused by the limited number of parallel corpus and unproper phrase translation caused by some noise in the parallel corpus such as typos and inconsistency writing a word in Sundanese corpus.",2015,C. Pluempitiwiriyawej; P. Chaicharoen; T. Chayanopparat; T. Wongprajan,1,6,6,2,10.1109/ICITSI.2015.7437678,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437678,IEEE Conferences,IEEE
Improving Phrase-Based Statistical Machine Translation with Preprocessing Techniques,Statistical Machine Translation;Preprocessing techniques;Sinhala to Tamil translation;Chunking;Segmentation;Natural language Processing,"This work presents an improvement to phrase-based statistical machine translation models which incorporates linguistic knowledge, namely parts-of-speech information and preprocessing techniques. Any Statistical Machine Translation (SMT) System needs large parallel corpora for exact performance. So, non-availability of corpora limits the success achievable in machine translation to and from those languages. In this study, we choose Sinhala to Tamil translation which gains importance since both of them are acknowledged as official languages of Sri Lanka and also resource-poor languages. Even though findings presented here is for Sinhala to Tamil translation, the concept of pre-processing is language neutral and can be transcended to any other language pair with different parameters. To overcome the translation challenges in traditional SMT, preprocessing techniques are used. Preprocessing described in the research is related to generating phrasal units, Parts of Speech (POS) integration and segmentation. At the end, automatic evaluation of the system is performed by using BLEU as evaluation metrics. We observed all preprocessing techniques outperform the baseline system. The best performance is reported with PMI based chunking for Sinh ala to Tamil translation. We could improve performance by 12% BLEU (3.56) using a small Sinhala to Tamil corpus with the help of proposed PMI based preprocessing. Notably, this increase is significantly higher compared to the increase shown by prior approaches for the same language pair.",2018,C. R. Hema; M. P. Paulraj; S. Yaacob; A. H. Adom; R. Nagarajan,322,327,6,,10.1109/IALP.2018.8629203,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629203,IEEE Conferences,IEEE
Exploring Neural Machine Translation for Sinhala-Tamil Languages Pair,Neural Machine Translation (NMT);Out-Of-Vocabulary (OOV);Low Resourced Translation Sinhala-Tamil,"In the face of rapid globalization, the concept of translation performs the most important role in continuing the existence of native languages. Most of the research on Natural Language Processing in Neural Machine Translation has achieved an impressive result through parallel corpus dataset. Low resourced languages confront low performance due to the lack of parallel corpus data. Creating parallel corpus for language pair is more expensive and needs the persons who are expert knowledge for both languages. In this research, we present the availability of developing the translator for Sinhala-Tamil languages pair using monolingual corpus dataset. In this paper, the Byte Pair Encoding (BPE) is applied for overcoming the Out-Of-Vocabulary (OOV) problem in both Sinhala and Tamil languages. Our first part of the research is using monolingual word embedding approach for developing the translation in between Sinhala-Tamil language pair only using monolingual corpora. The second part of the research we use both parallel and monolingual corpus data with transformer architecture. The BLEU score and the synonyms analysis are used to evaluate the approach we suggested.",2020,C. S. Eke; E. Jammeh; X. Li; C. Carroll; S. Pearson; E. Ifeachor,202,207,6,,10.1109/ICTer51097.2020.9325466,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325466,IEEE Conferences,IEEE
Design of Long Sentence Split Translation Model based on Support Vector Machine,Support vector machine;Long sentence decomposing type;Translation model;Constraint parameter,"Aiming at the problem of high translation misalignment rate due to the ambiguity of semantics in statistical translation methods, this paper proposes a long-sentence translation model based on support vector machines. Firstly, the translation words to be disassembled in long sentences are processed, and the semantic registration process based on support vector machine is set up to calculate the utilization rate of different semantic elements in the language evaluation set, which is used as the information label to construct the language evaluation set model. On this basis, the support vector machine analysis factor is calculated, and the support vector machine analysis factor is used as the constraint parameter to extract the feature information of the long sentence decomposing type to construct the translation model. The experimental results show that the model has the lowest inaccuracy rate of 0.01, which proves that the model has accurate translation effect.",2020,C. Tillmann; T. Zhang,143,148,6,,10.1109/IAAI51705.2020.9332815,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332815,IEEE Conferences,IEEE
Sinhala and English Document Alignment using Statistical Machine Translation,Document alignment;Comparable Corpora;Machine Translation;Sinhala;Transliteration,"Document alignment is the process of identifying documents that have the same content in different languages. Document alignment is a very useful prerequisite for creating parallel corpora to be used in Machine Translation (MT). Hybrid document alignment techniques are commonly used, where a set of heuristics are used along with an existing MT system. In these systems, first all the target documents are translated into source language using an existing MT system. Candidate pairs are identified using a heuristics such as web domain or published date. Similarity of these candidate pairs is calculated using a similarity calculation algorithm. Heuristics are used either to reduce the candidate pair count or to improve the accuracy of alignment. However, the considered heuristics are dependent on the selected document sources. In this paper, we present a hybrid document alignment system for Sinhala and English, where a set of source-independent heuristics is used on the output of an MT system. In addition, we demonstrate how transliteration between Sinhala and English is exploited to improve the performance of the document alignment process.",2020,C. Wang; T. BÃ¤ck; H. H. Hoos; M. Baratchi; S. Limmer; M. Olhofer,29,34,6,,10.1109/ICTer51097.2020.9325462,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325462,IEEE Conferences,IEEE
Improving Quality of Machine Translation Using Text Rewriting,Machine Translation;Text Rewriting;NER;Statistical Machine Translation,"Machine Translation may be defined as the task of transformation of source text from one language to another. In the following paper, we have discussed the improvement in quality of Machine Translation (MT) using Source text Rewriting. We have performed English to Hindi translation on our MT system and also translation of rewritten English text to Hindi and then compared their performances and evaluated MT system based on 11 features sets as well as using automatic evaluation metrics such as BLEU, METEOR and F-Measure. We found that the performance of MT improved by using Text Rewriting approach.",2016,C. Wirth; J. FÃ¼rnkranz,22,27,6,3,10.1109/CICT.2016.14,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546568,IEEE Conferences,IEEE
English to Turkish Example-Based Machine Translation with Synchronous SSTC,Machine Translation;Example Based Machine Translation;Synchronous SSTC,"Example based machine translation (EBMT) is a corpus-based method which is based on using previously translated text. In this project, English to Turkish EBMT system has been developed which uses the Synchronous SSTC for the representation of the sentences in the parallel corpora. This method proves to be effective especially in structurally different languages such as English and Turkish.",2008,C. Wu; L. Sun; Z. Q. Zhou,674,679,6,2,10.1109/ITNG.2008.64,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492559,IEEE Conferences,IEEE
Machine translation from English to Malayalam using transfer approach,domain specific RBMT;machine translation;transfer rules,"A machine translation system converts text from a natural language to other while abiding to the syntax and semantics of the latter. The area of interest here is a Rule Based machine translation system that translates text from English to Malayalam using transfer approach. The system is designed to translate sentences from cricket domain related articles. The purpose behind making the system domain specific is to improve translation quality of sentences in the chosen domain. Our system depends on Stanford parser in the preprocessing stage. The input English sentence is tokenized, and parsed with the help of Stanford parser, and a parse tree is generated. According to the rules structured for the target language the source parse tree is reordered to produce the target parse tree. The words in target tree are mapped with bilingual English - Malayalam dictionary to obtain output Malayalam words. The system also maintains a separate verb dictionary that holds English verb in root form and its Malayalam meaning with 9 different inflections. Morphological generation phase provides necessary inflections for Malayalam words and thereby creates meaningful translations. The domain specific translation system was able to achieve correct translation results for about 86% of test sets.",2015,C. Zhang; G. Zhou; X. Gao,1565,1570,6,6,10.1109/ICACCI.2015.7275836,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275836,IEEE Conferences,IEEE
Korean-English named entity alignment for machine translation of digital TV closed caption,Closed Caption;Machine Translation;Digital TV;multilingual Named Entity;Translingual Equivalence,"We present a Korean to English machine translation system of closed captions for digital television. Named entities (NEs) convey important information of news articles and drama scripts. So, correct translation of NEs is indispensable for effective comprehension of TV programs. In order to achieve more accurate translation results, we adopted English and Korean NEs alignment into the base MT system. The resources for NEs and their translingual equivalences are acquired from the Web by an intelligent Web crawler. With these integrated approaches, we could raise the translation accuracy on average by 0.60 (mean opinion score) higher than the base MT system",2006,D. Danopoulos; C. Kachris; D. Soudris,6,1722,6,,10.1109/ICACT.2006.206319,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1625924,IEEE Conferences,IEEE
Phrase-level English to Sinhala machine translation with multi-agent approach,Machine Translation;Multi-Agent Systems;Sinhala Language,"Translating phrases including noun phrases, verb phrases, and preposition phrases has been identified as a key subtask of machine translation. Various techniques have been used to translate source language phrases into target language phrases including rule-based and machine-learning techniques. These phrase-level machine translation techniques have considerably increased the quality of the machine translation. However, human translation is considered as the perfect language translation so far. In view of this, we propose a novel approach to machine translation that is inspired by phrase-based and multi-agent approaches. The approach is stimulated by the fact that how humans translate a sentence with psycholinguistic parsing. The approach has been tested with a multi-agent system named EnSiMaS that translates an English sentence into Sinhala. The EnSiMaS has been implemented through the MaSMT framework. This paper presents how English phrases are translated to Sinhala through the multi-agent approach. Each English phrase in the input sentence is assigned as an agent. According to the availability of the Sinhala words, phrase agents are capable of generating multiple Sinhala phrases with support of the Sinhala morphological and semantic system. These agents consider the structure of the phrase, semantic features of the words, and thematic roles of the existing phrase to generate the Sinhala translation. Further, phrase agents are capable of classifying each generated Sinhala phrase according to its context and usage. Communicating with other related agents, phrase agents identify the most suitable Sinhala phrase form generated Sinhala phrases. The system has been tested with the different types of phrases and the successful results were obtained.",2017,D. Genzel; A. C. Popat; N. Spasojevic; M. Jahr; A. Senior; E. Ie; F. Y. Tang,1,6,6,,10.1109/ICIINFS.2017.8300419,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8300419,IEEE Conferences,IEEE
The impact of reference normalization on automatic MT evaluation,Reference Normalization;Machine Translation;Automatic Evaluation;Farsi Language,"Automatic methods for MT evaluation are often depends on high quality data as references that allow the comparison between automatic and human translations. However, independently produced human translations are necessarily different not only in the choice of words but also in word orthography and writing style. This inconsistency between references texts can negatively influence the quality of automatic evaluation of machine translation especially in high morphological language such as Farsi. In this paper, we study the effect of character and word-level reference preprocessing schemes for Farsi on quality of machine translation evaluation. For this purpose, we experimentally look into their impact on three established evaluation measures. Our results show that reference normalization results in a significant increase in Automatic MT Evaluation scores.",2012,D. Hakkani-TÃ¼r; G. Tur; R. Iyer; L. Heck,811,816,6,,10.1109/ISTEL.2012.6483097,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483097,IEEE Conferences,IEEE
Neural Machine Translation from Jordanian Dialect to Modern Standard Arabic,Neural Machine Translation;Jordanian Dialect;Deep Learning;RNN;MSA,"The development of cultures and societies all over the world was the first reason for the emergence of many different languages and dialects that differ from each other based on the geographical location of these communities, whether in the Arab countries or Western or other parts of the world. Due to these differences, there is a need to translate these dialects between each other to facilitate their understanding and handling by people who will use them from other communities. The tremendous technological advancement and the flourishing of the era of Deep Learning, has led to the emergence of so-called neural machine translation (NMT), which has significantly facilitated the translation process compared to other methods. In this paper, we present a framework to translate the Jordanian dialect into Modern Standard Arabic (MSA) using Deep Learning, in particular, the RNN encoder-decoder model, which provided good results on the level of our manually created dataset. The conducted experiments using this model were divided into two parts: word level and sentence level, and the results were as follows: loss equals 0.8 and accuracy equals 91.3% when using the model for word to word translation; and loss value equals 3.33 and accuracy equals 63.2% when using the model for sentence translation. These are very encouraging results in this largely unexplored topic.",2020,D. J. Makris; N. Papadakis,173,178,6,1,10.1109/ICICS49469.2020.239505,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079061,IEEE Conferences,IEEE
Neural Machine Translation for the Bangla-English Language Pair,Machine Translation;Bangla-to-English;Neural Machine Translation;Transformer;Bidirectional LSTM,"Due to the rapid advancement of different neural network architectures, the task of automated translation from one language to another is now in a new era of Machine Translation (MT) research. In the last few years, Neural Machine Translation (NMT) architectures have proven to be successful for resource-rich languages, trained on a large dataset of translated sentences, with variations of NMT algorithms used to train the model. In this study, we explore different NMT algorithms - Bidirectional Long Short Term Memory (LSTM) and Transformer based NMT, to translate the Bangla to English language pair. For the experiments, we used different datasets and our experimental results outperform the existing performance by a large margin on different datasets. We also investigated the factors affecting the data quality and how they influence the performance of the models. It shows a promising research avenue to enhance NMT for the Bangla-English language pair.",2019,D. Kelly; S. McLoone; T. Dishongh,1,6,6,,10.1109/ICCIT48885.2019.9038381,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9038381,IEEE Conferences,IEEE
English to Japanese spoken lecture translation system by using DNN-HMM and phrase-based SMT,automatic speech recognition;statistical machine translation;classroom lecture;DNN-HMM;phrase-based translation,"This paper presents our scheme to translate spoken English lectures into Japanese that consists of an English automatic speech recognition system (ASR) that utilizes a deep neural network (DNN) and an English to Japanese phrase-based statistical machine translation system (SMT). We utilized an existing Wall Street Journal corpus for our acoustic model and adapted it with MIT OpenCourseWare lectures whose transcriptions we also utilized to create our language model. For the parallel corpus of our SMT system, we used TED Talks and Japanese News Article Alignment Data. Our ASR system achieved a word error rate (WER) of 21.0%, and our SMT system achieved a 3-gram base bilingual evaluation understudy (BLEU) of 16.8 for text input and 14.6 for speech input, respectively. These scores outperformed our previous system : WER = 32.1% and BLEU = 11.0.",2015,D. Luo; S. Shi; R. Su; H. Huang,1,6,6,2,10.1109/ICAICTA.2015.7335357,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335357,IEEE Conferences,IEEE
Issues in parsing for Machine Aided Translation from English to Hindi,Natural Language Processing;Machine Translation;Multi-lingual Machine Translation;Parsers;Word Sense Disambiguation;Text Mining,"Resolving cases of ambiguity due to differences in the syntactic form of grammatical rules in source and target languages is a major challenge in the development of a Machine Aided Translation (MAT) system. The primary focus in this paper is laid on translation of text from English to Hindi, one among the most popular Indian languages. Producing an unambiguous parse tree is an extremely difficult task considering Indian languages as the target language because of their free order nature. This paper presents a sub-model of a parser identifies the syntactical elements in English sentences and suggests its Hindi translation taking in to account various grammatical forms of Hindi. Thus this parser would focus on the grammatical structure of the statement especially those of gender, karaka (case) and context. Here we use the Subject-Verb-Object approach to break down the sentences.",2011,D. Manoj Kumar; K. Bavanraj; S. Thavananthan; G. M. A. S. Bastiansz; S. M. B. Harshanath; J. Alosious,754,759,6,3,10.1109/WICT.2011.6141341,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141341,IEEE Conferences,IEEE
Improving Chinese-English patent machine translation using sentence segmentation,Machine Translation;sentence segmentation;semantic features;main verb;long NP,"This paper presents a method using sentence segmentation to improve the performance of Chinese-English patent machine translation. In this method, long Chinese sentence was segmented into separated short sentences using some features from the Hierarchical Network of Concepts theory (HNC theory). Some semantic features are introduced, including main verb of CSC (Eg), main verb of CSP (Egp), long NPs and conjunctions. The main purpose of segmentation algorithm is to detect if one CSC can or cannot be a separate sentence. The segmentation method was integrated with a rule-base MT system. The sequence of these short translations was adjusted and the different ways of expressions in both Chinese and English languages also were in consideration. From the result of the experiments, we can see that the performance of the Chinese-English patent translation was improved effectively. Our method had been integrated into an online patent MT system running in SIPO.",2010,D. Munkova; M. Munk,1,6,6,3,10.1109/NLPKE.2010.5587855,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587855,IEEE Conferences,IEEE
AnglaBharati to AnglaMalayalam: An Experience with English to Indian Language Machine Translation,Machine Translation;AnglaBharati;Text Generator,AnglaBharati is English to Indian Language pattern based interligual Machine Aided Translation (MAT) System developed by IIT Kanpur. Basically it is meant for English to Indo-Aryan language family Machine Translation (MT). In this paper we describe the way in which the system customized for Dravidian languages also. There are many features which are common in both language families and also we found some dissimilarity among Dravidian families also. We will focus on the changes that are incorporated in the translation system for customization.,2014,D. N. Chuong; P. Seresangtakul,282,287,6,3,10.1109/IC3I.2014.7019748,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7019748,IEEE Conferences,IEEE
Neural Machine Translation on scarce-resource condition: A case-study on Persian-English,neural machine translation;cost function;alignment model;text preprocessing,"Neural Machine Translation (NMT) is a new approach for Machine Translation (MT), and due to its success, it has absorbed the attention of many researchers in the field. In this paper, we study NMT model on Persian-English language pairs, to analyze the model and investigate the appropriateness of the model for scarce-resourced scenarios, the situation that exist for Persian-centered translation systems. We adjust the model for the Persian language and find the best parameters and hyper parameters for two tasks: translation and transliteration. We also apply some preprocessing task on the Persian dataset which yields to increase for about one point in terms of BLEU score. Also, we have modified the loss function to enhance the word alignment of the model. This new loss function yields a total of 1.87 point improvements in terms of BLEU score in the translation quality.",2017,D. P. Tuan; D. P. Ngoc,1485,1490,6,,10.1109/IranianCEE.2017.7985278,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985278,IEEE Conferences,IEEE
Neural Machine Translation for English to Hindi,Cognitive linguistics;Neural Machine Translation;Long and Short Term Memory;Indian Languages,"Language translation is one task in which machine is definitely lagging behind the cognitive powers of human beings. Statistical Machine Translation is one of the conventional ways of solving the problem of machine translation. This method requires huge data sets and performs well on similar grammar structured language pairs. In recent years, Neural Machine Translation (NMT) has emerged as an alternate way of addressing the same issue. In this paper, we explore different configurations for setting up a Neural Machine Translation System for Indian language Hindi. We have experimented with eight different architecture combinations of NMT for English to Hindi and compared our results with conventional machine translation techniques. We have also observed in this work that NMT requires very less amount of data size for training and thus exhibits satisfactory translation for few thousands of training sentences as well.",2018,D. P. Yadav; A. Sharma; M. Singh; A. Goyal,1,6,6,7,10.1109/INFRKM.2018.8464781,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464781,IEEE Conferences,IEEE
POS-based reordering rules for Indonesian-Korean statistical machine translation,statistical machine translation;POS tag;reordering rules;verb formation;word alignment,"In SMT system, reordering problem is one of the most important and difficult problems to solve. The problem becomes definitely serious due to the different grammatical pattern between source and target language. The previous research about reordering model in SMT use the distortion-based reordering approach. However, this approach is not suitable for Indonesian-Korean translation. The main reason is because the word order between Indonesian and Korean are mostly reversed. Therefore, in this study, we develop a source-side reordering rules by using POS tag and word alignment information. This technique is promising to solve the reordering problem based on the experimental result. By applying 130 reordering rules in ID-KR and 50 reordering rules for KR-ID translation, the quality of translation in term of BLEU score increases 1.25% for ID-KR translation and 0.83% for KR-ID translation. Besides, combining this reordering rules with Korean verb formation rules for ID-KR translation can increase the BLEU score from 38.07 to 49.46 (in 50 simple sentences evaluation).",2017,D. Pesu; Z. Q. Zhou; J. Zhen; D. Towey,1,6,6,,10.1109/ICEEI.2017.8312383,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8312383,IEEE Conferences,IEEE
An evaluation methodology for English to Sinhala machine translation,Machine Translation;Sinhala;Evaluation,"This paper presents evaluation methodology for English to Sinhala machine translation system. The English to Sinhala machine translation system has been developed by using Multi Agent Approach and powered through the concept of ""Varanegeema"". Translation system works through the communication among nine agents namely English Morphological Analyzer Agent, English Parser Agent, English to Sinhala Base Word Translator Agent, Sinhala Morphological Generator Agent, Sinhala Parser agent, Transliteration agent, Intermediate Editor agent, Message Space Agent and Request agent. The evaluation was conducted through three steps. As the first step, evaluation was conducted through the white box testing approach and tested each module in the machine translation system through the developed testing tools. Then, evaluated the system performance and calculated the error rate through the result of the evaluation test bed. Finally, Intelligibility and the Accuracy test will be conducted through the human support. The experimental result shows 89% accuracy of the overall system and 7.2% word error rate and the 5.4% sentence error rate. Details of the evaluation and results are given in the paper.",2010,D. RadoÅ¡eviÄ‡; A. Bernik; J. DobÅ¡a; M. KaniÅ¡ki; N. Mrvac,31,36,6,3,10.1109/ICIAFS.2010.5715630,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715630,IEEE Conferences,IEEE
State-of-the-art English to Persian Statistical Machine Translation system,Parallel Corpus;Statistical Machine Translation;MaxEnt Classifier;Hybrid Machine Translation,"Comparison of several kinds of English-Persian Statistical Machine Translation systems is reported in this paper. A large parallel corpus containing about 6 million tokens on each side has been developed for training the proposed SMT system. In development of the parallel corpus, a noisy filtering system based on MaxEnt classifier has been innovated to distinguish between correct and incorrect sentence pairs. By using the generated parallel corpus, a variety of SMT systems on English to Persian languages has been developed. Several variations on SMT, such as hybrid MT or statistical post editing MT has been proposed in this paper. The whole systems were tested on two different types of test set, one extracted randomly from parallel corpus and the other containing formal English sentences extracted from English learning book. The results shows hybrid system of SMT augmented by a rule based detection of English phrasal verb and Persian compound verb improves the baseline significantly. Also, state-of-the-art results on English-Persian translation are obtained by Verb-aware SMT with respect to BLEU measure.",2012,D. RavÃ¬; C. Wong; F. Deligianni; M. Berthelot; J. Andreu-Perez; B. Lo; G. Yang,174,179,6,6,10.1109/AISP.2012.6313739,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6313739,IEEE Conferences,IEEE
Phoneme strings based machine transliteration,machine transliteration;combined transliteration system;Conditional Random Fields;phoneme strings,"Transliteration is always used to translate source names with approximate equivalence of pronunciation into target language. Current direct orthographical mapping (DOM) approach does segmentation and alignment on the basis of the single syllable. However it is hard to break down English names into constituent parts according to their corresponding single Chinese characters. This document proposes an approach of segmentation and alignment on the unit of phoneme strings in transliteration between English and Chinese. To lessen the calculation of model training on whole corpus, we split the training data into several pools stochastically and each is used to train a model. The final results of transliteration are arranged according to the decoding probability of each model, called combined model. The combined machine transliteration system between English and Chinese performs remarkably well on the shared task of NEWS2011.",2011,D. S. Ganesh; S. M. Tamilarasan; J. Bodhankar,304,309,6,,10.1109/NLPKE.2011.6138214,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138214,IEEE Conferences,IEEE
Improving Neural Machine Translation with Neural Sentence Rewriting,Neural Machine Translation;Sentence Rewriting,"A complex expression is more difficult for machine translation than a simplified sentence. One efficient method to handle this problem is to rewrite the source text into a simplified version before translation while keeping its meaning. In this paper, we propose a novel method to automatically rewrite source sentences based on neural machine translation. We propose a round-trip machine translation method to automatically generate a large amount of high quality rewritten pairs from bilingual corpus and then build an end-to-end sentence rewriting system based on neural network. Experimental results on Chinese-English IWSLT translation tasks show that our method leads to significant improvements over a strong baseline system.",2018,D. Sudarsan; P. Vijayakumar; S. Biju; S. Sanu; S. K. Shivadas,147,152,6,1,10.1109/IALP.2018.8629254,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629254,IEEE Conferences,IEEE
A Survey of Machine Translation Techniques and Systems for Indian Languages,Natural language processing;Learning systems;Statistical Machine Translation,"Machine Translation pertains to translation of one natural language to other by using automated computing. The main objective is to fill the language gap between two different languages speaking people, communities or countries. In India, we have multiple and hugely diverse languages and scripts, hence scope and need of language translation is immense. In this paper, we focus on the current scenario of research in machine translation in India. We have reviewed various important Machine Translation Systems (MTS) and presented preliminary comparison of the core methodology as used by them.",2015,D. V. Sindhu; B. M. Sagar,676,681,6,19,10.1109/CICT.2015.123,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078789,IEEE Conferences,IEEE
Machine Translation Using Improved Attention-based Transformer with Hybrid Input,Neural Machine Translation;Self-Attention;Multi-Head Attention;Encoder-Decoder,"Machine Translation (MT) refers to the automated software-based translation of natural language text. The embedded complexities and incompatibilities of natural languages have made MT a daunting task facing numerous challenges, especially when it is to be compared to a manual translation. With the emergence of deep-learning AI approaches, the Neural Machine Translation (NMT) has pushed MT results closer to human expectations. One of the newest deep learning approaches is the sequence-to-sequence approach based on Recurrent Neural Networks (RNN), complex convolutions, and transformers, and employing encoders/decoder pairs. In this study, an attention-based deep learning architecture is proposed for MT, with all layers focused exclusively on multi-head attention and based on a transformer that includes multi-layer encoders/decoders. The main contributions of the proposed model lie in the weighted combination of layers' primary input and output of the previous layers, feeding into the next layer. This mechanism results in a more accurate transformation compared to non-hybrid inputs. The model is evaluated using two datasets for German/English translation, the WMT'14 dataset for training, and the newstest'2012 dataset for testing. The experiments are run on GPD-equipped Google Colab instances and the results show an accuracy of 36.7 BLEU, a 5% improvement over the previous work without the hybrid-input technique.",2020,D. Wu,52,57,6,,10.1109/ICWR49608.2020.9122317,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122317,IEEE Conferences,IEEE
Syntax-aware Transformer Encoder for Neural Machine Translation,Neural Machine Translation;dependency parsing;POS Tagging,"Syntax has been shown a helpful clue in various natural language processing tasks including previous statistical machine translation and recurrent neural network based machine translation. However, since the state-of-the-art neural machine translation (NMT) has to be built on the Transformer based encoder, few attempts are found on such a syntax enhancement. Thus in this paper, we explore effective ways to introduce syntax into Transformer for better machine translation. We empirically compare two ways, positional encoding and input embedding, to exploit syntactic clues from dependency tree over source sentence. Our proposed methods have a merit keeping the architecture of Transformer unchanged, thus the efficiency of Transformer can be kept. The experimental results on IWSLT' 14 German-to-English and WMT14 English-to-German show that our method can yield advanced results over strong Transformer baselines.",2019,D. Ze-ya; Z. Han-fen; Z. Quan; M. Jian-ming; C. Yu-huan,396,401,6,,10.1109/IALP48816.2019.9037672,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037672,IEEE Conferences,IEEE
Two Effective Approaches to Data Reduction for Neural Machine Translation: Static and Dynamic Sentence Selection,machine translation;data reduction;NMT,"In this paper, we aim at data reduction for neural machine translation (NMT): selecting a subset from a very large training corpus and training NMT on this subset so as to reduce training time while meantime achieving the same or even higher translation quality. We propose two effective approaches to achieve this goal: a static sentence selection method that selects sentences into a subset before training according to their sentence embeddings, and a dynamic sentence selection method that dynamically selects sentences into epoch during training based on their training cost. We examine the effect of an n-gram based traditional data reduction method originally proposed for statistical machine translation (SMT) on NMT and compare the two proposed approaches against the traditional method. Experiments on the United Nations Parallel Corpus show that the best of the two proposed approaches can reduce training time by half and at the same time achieve improvements in translation quality with up to +0.79 BLEU.",2018,D. Zhang; L. Yao; Y. Wang; X. Zhu,159,164,6,,10.1109/IALP.2018.8629243,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629243,IEEE Conferences,IEEE
Enhancing Machine Translation by Integrating Linguistic Knowledge in the Word Alignment Module,Machine Translation;Morphosyntactic analysis;Word alignment;heuristics alignment methods;English language;Arabic language,"The word alignment process, which is a critical step in statistical translation systems (SMT), has been suggested by several researchers as a promising track for enhancing neural translation system (NMT) performance in low-resource environments. Furthermore, given the negative impact on English/Arabic machine translation quality arising from the morphological richness and complexity of the Arabic language compared to the English language, we assessed in this study the relevance of the integration of morphosyntactic characteristics during the alignment phase. Indeed, we have enriched parallel corpora by morphosyntactic features such as stems, lemmas, roots, and POS tags; yet we have developed new SMT systems embedding one of these features in the word alignment phase. The test results proved the interest to use these features and highlighted the most relevant morphosyntactic information to the translation system.",2020,E. A. M. Odijk,1,6,6,,10.1109/ISCV49265.2020.9204328,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204328,IEEE Conferences,IEEE
Improve User Experience on Web for Machine Translation System Using Storm,NLP;Machine Translation;Storm Framework;Stream Processing;Interactive Response;Throughput;Performance,"A transfer based Machine Translation (MT) system is a large complex functional application where the job completion time is proportional to job size. When these applications are deployed on web with increasing translation load web user experience degrades. The end user has to wait unusually longer to get his first visible response. Generic layer 3 load balancing techniques does not help to improve the response time as each job is assigned similar compute resources irrespective of job size. This paper presents an engineering approach to deploy MT system on cloud platform using Storm, a distributed computing framework. This scheme, by utilizing the inherent parallelism of a functional application, not only reduces the job completion time considerably but it, also as a web application, gives very good user experience, viz., the first visible response time within an acceptable time limit, and the subsequent responses well before the user finishes perusing the preceding response. Using Storm framework a translation job is split into multiple job partitions and is streamed into the storm cluster such that first job partitions of all jobs are processed before the second partitions, i.e., All nth partitions of all jobs are processed before (n+1)th partitions. Thus machine translation system is able to produce translation output as a continuous stream, sentence by sentence, as soon as each sentence gets translated. The system maintains flow rate of translated sentences stream high enough so that the next translated sentence is produced well before the end user finishes reading the previous sentence, thereby providing very good user experience. There is a class of natural language processing (NLP) applications, viz., machine translation systems, text to speech systems, speech recognition systems, etc., that are functional in nature, and this engineering approach would be equally applicable to them as well.",2014,E. Ã–zkan; G. Ercan,243,248,6,1,10.1109/BDCloud.2014.88,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7034793,IEEE Conferences,IEEE
Experiment on English-Thai Machine Translation via Text Understanding Based on Mental Image Directed Semantic Theory,natural language understanding;cross-language paraphrase;machine translation;mental-image description language,"This paper describes an original methodology for cross-language paraphrase via intermediate semantic expression in a knowledge representation language called Mental-image Description Language (Lmd) and its application to an experimental system for English-Thai translation. This system interprets English text into Lmd expression to understand it and interprets the understanding result into Thai text without using any syntactic information of the input English text. That is, the system performs free translation, namely, generates target language texts only from intermediate semantic representations of source language texts. It works as one kind of inter-lingual machine translation system but actually is a subsystem of our natural language understanding system to paraphrase an input text in another language. Some experimental results were evaluated by several native Thai speakers with good knowledge of English, which gave a good perspective to our future work on this system.",2018,E. Barshan; P. Fieguth,202,207,6,,10.1109/ICAwST.2018.8517252,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517252,IEEE Conferences,IEEE
An approach to Lao-English rule based machine translation,Machine translation;RBMT;Transfer-based,"This paper presents an approach to Lao-English rule based machine translation. In our approach, we start by modifying the Lao word segmented algorithm to mark the name entities part, which will be reordered according to its type later. Then, using the transfer-based strategy, the sentence is analyzed to build the source dependency structure, which is then transferred to the target dependency structure. The target text is then generated according to its attribute information. The machine translation performance obtained from the proposed method, in BLEU, METEOR, ROUGE-L, was 0.5920, 0.5482 and 0.8586, respectively. These results are better than those achieved by Google Translate.",2015,E. Besler; Y. C. Wang; A. V. Sahakian,93,98,6,2,10.1109/KST.2015.7051459,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051459,IEEE Conferences,IEEE
Automated Translation Machines: Challenges and a Proposed Solution,machine translation;ambiguity;natural language processing,"Automated translation (MT) tools have become an urgent need in a multilingual environment. Although there are any available tools on the market, unfortunately, a robust MT tool is still a dream. This purpose of this paper is to discuss challenging issues in MT tool developments, the state of art of he MT tools and propose a framework for a semantic-based translation. The focus of this paper is English to Arabic translation MT.",2011,E. Dunne; A. Santorelli; B. McGinley; M. Oâ€™Halloran; E. Porter,77,82,6,4,10.1109/ISMS.2011.74,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730324,IEEE Conferences,IEEE
Nested Template-based Model for Chinese-Japanese Machine Translation,Natural Language Processing;Machine Translation;Levenshtein Distance;Nested Template,"Template-based Machine Translation model has been adopted in practical translation systems. In order to build a practical Chinese-Japanese Machine Translation system, we continue to extend Template-based Model. In order to make Template-based Model more practical and specific, original Template is divided into Template for sentences and Template for phrases to build nested Template-based Machine Translation Model. The existing scope and definition of the variable for original Template-based Model is also extended. From the experiment results, Template-based model is not only effective but also feasible and with considerable precision for Chinese Japanese Machine Translation. The Template-based model can even translate long sentences with complex structure.",2011,E. Hosogai; T. Mukai; S. Jung; Y. Kowase; A. Bossard; Y. Xu; M. Ishikawa; K. Kaneko,161,166,6,,10.1109/CSE.2011.39,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062868,IEEE Conferences,IEEE
Si-Ta: Machine Translation of Sinhala and Tamil Official Documents,Machine Translation;SMT;Moses;Sinhala;Tamil,"Although Sri Lanka is a multi-ethnic country with Sinhala and Tamil being the official languages, most of the population is familiar with only one of these languages. This results in a lack of Sinhala-Tamil translators, which in turn has an impact on the government agencies that are required to issue official government documents in both languages. Although Machine Translation can be considered as a possible solution, available translation systems for this language pair have a poor performance, mainly because they do not focus on official government documents. This paper presents Si-Ta, the first Machine Translation system for Sinhala and Tamil official government documents. Si-Ta uses a Statistical Machine Translation engine, and provides a user-friendly web interface. Results show that Si-Ta can be used to eliminate the need for manual translators, if the only requirement is to understand the document received in the source language. In other words, current version of Si-Ta is capable of translating without loss of semantics at a level that is enough for any common target language reader to understand the message in source language.",2018,E. K. Vellingiriraj; M. Balamurugan; P. Balasubramanie,1,6,6,2,10.1109/NITC.2018.8550069,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550069,IEEE Conferences,IEEE
Parallel Attention Mechanisms in Neural Machine Translation,"machine translation, transformer, attention","Recent papers in neural machine translation have proposed the strict use of attention mechanisms over previous standards such as recurrent and convolutional neural networks (RNNs and CNNs). We propose that by running traditionally stacked encoding branches from encoder-decoder attention-focused architectures in parallel, that even more sequential operations can be removed from the model and thereby decrease training time. In particular, we modify the recently published attention-based architecture called Transformer by Google, by replacing sequential attention modules with parallel ones, reducing the amount of training time and substantially improving BLEU scores at the same time. Experiments over the English to German and English to French translation tasks show that our model establishes a new state of the art.",2018,E. Saquete; P. Martinez-Barco; R. Munoz; M. Negri; M. Speranza; R. Sprugnoli,547,552,6,,10.1109/ICMLA.2018.00088,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614113,IEEE Conferences,IEEE
A new verb based approach for English to Bangla machine translation,Rule based Machine Translation;Natural Language Processing;English to Bangla;Human Language Technology,"This paper proposes verb based machine translation (VBMT), a new approach of machine translation (MT) from English to Bangla (EtoB). For translation, it simplifies any form (i.e. simple, complex, compound, active and passive form) of English sentence into the simplest form of English sentence i.e. subject plus verb plus object. When compared with existing rule based EtoB MT schemes, VBMT doesn't employ exclusive or individual structural rules of various English sentences; it only detects the main verb from any form of English sentence and then transforms it into the simplest form of English sentence. Thus VBMT can translate from EtoB very simply, correctly and efficiently. Rule based EtoB MT is tough because it requires the matching of sentences with the stored rules. Moreover, many existing EtoB MT schemes which deploy rules are almost inefficient to translate complex or complicated sentences because it is difficult to match them with well-established rules of English grammar. VBMT is efficient because after identifying the main verb of any form of English sentence, it binds the remaining parts of speech (POS) as subject and object. VBMT has been successfully implemented for the MT of Assertive, Interrogative, Imperative, Exclamatory, Active-Passive, Simple, Complex, and Compound form of English sentences applicable in both desktop and mobile applications.",2014,E. Shaabani; S. Khadivi,1,6,6,8,10.1109/ICIEV.2014.6850684,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6850684,IEEE Conferences,IEEE
Fusion of Image-text attention for Transformer-based Multimodal Machine Translation,Multimodal Machine Translation;Image-text attention;Transformer-based;Self-attention.,"In recent years, multimodal machine translation has become one of the hot research topics. In this paper, a machine translation model based on self-attention mechanism is extended for multimodal machine translation. In the model, an Image-text attention layer is added in the end of encoder layer to capture the relevant semantic information between image and text words. With this layer of attention, the model can capture the different weights between the words that is relevant to the image or appear in the image, and get a better text representation that fuses these weights, so that it can be better used for decoding of the model. Experiments are carried out on the original English-German sentence pairs of the multimodal machine translation dataset, Multi30k, and the Indonesian-Chinese sentence pairs which is manually annotated by human. The results show that our model performs better than the text-only transformer-based machine translation model and is comparable to most of the existing work, proves the effectiveness of our model.",2019,E. Vidal; F. Casacuberta; L. Rodriguez; J. Civera; C. D. M. Hinarejos,199,204,6,,10.1109/IALP48816.2019.9037732,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037732,IEEE Conferences,IEEE
Automatic Extraction of Equations in Medieval Arabic Algebra,Arabic;Natural Language Processing (NLP);Machine Translation;Medieval mathematics;Dictionary Approach;Rule-based Machine Translation (MT),"In medieval Arabic, no symbols are used to express mathematical problems and solutions. Instead, specific Arabic terms are used to describe mathematical processes. Nevertheless, a close examination of the text styles and how information is encoded into natural language phrases reveals that the notations contain no ambiguity, which makes it possible to formulate the problem and solve it. In this paper, we explore the idea of automatically generating modern symbolic mathematical equations from natural language medieval Arabic Algebra texts. We will describe a simple machine translation system using Rule-based Machine Translation (MT) with Dictionary Approach in order to translate medieval verbal equation to a modern equation. We construct a new dataset from scratch to facilitate our study, as there is no previously published similar dataset. Our system was able to achieve correct translation results for cubic equations with 100% accuracy, and quartic, quintic equations with 96.66% and 94.01%, respectively.",2018,E. Yulianti; M. Adriani; H. M. Manurung; I. Budi; A. N. Hidayanto,1,6,6,,10.1109/AICCSA.2018.8612830,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8612830,IEEE Conferences,IEEE
Character Decomposition for Japanese-Chinese Character-Level Neural Machine Translation,decomposition;neural machine translation;Japanese-Chinese;character-level;LSTM;encoder;decoder,"After years of development, Neural Machine Translation (NMT) has produced richer translation results than ever over various language pairs, becoming a new machine translation model with great potential. For the NMT model, it can only translate words/characters contained in the training data. One problem on NMT is handling of the low-frequency words/characters in the training data. In this paper, we propose a method for removing characters whose frequencies of appearance are less than a given minimum threshold by decomposing such characters into their components and/or pseudo-characters, using the Chinese character decomposition table we made. Experiments of Japanese-to-Chinese and Chinese-to-Japanese NMT with ASPEC-JC (Asian Scientific Paper Excerpt Corpus, Japanese-Chinese) corpus show that the BLEU scores, the training time and the number of parameters are varied with the number of the given minimum thresholds of decomposed characters.",2019,F. Bunyak; N. Shiraishi; K. Palaniappan; T. E. Lever; L. Avivi-Arber; K. Takahashi,35,40,6,,10.1109/IALP48816.2019.9037677,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037677,IEEE Conferences,IEEE
A System Architecture to Support Cost-Effective Transcription and Translation of Large Video Lecture Repositories,Language Technologies;Machine Translation;Automatic Speech Recognition;Massive Adaptation;Intelligent Interaction;Education;Video Lectures;Multilingualism;Accessibility;Opencast Matterhorn,"Online video lecture repositories are rapidly growing and becoming established as fundamental knowledge assets. However, most lectures are neither transcribed nor translated because of the lack of cost-effective solutions that can give accurate enough results. In this paper, we describe a system architecture that supports the cost-effective transcription and translation of large video lecture repositories. This architecture has been adopted in the EU project transLectures and is now being tested on a repository of more than 9000 video lectures at the Universitat Politecnica de Valencia. Following a brief description of this repository and of the transLectures project, we describe the proposed system architecture in detail. We also report empirical results on the quality of the transcriptions and translations currently being maintained and steadily improved.",2013,F. Calefato; F. Lanubile; P. Minervini,3994,3999,6,2,10.1109/SMC.2013.682,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722435,IEEE Conferences,IEEE
Neural Machine Translation with Dynamic Selection Network,neural machine translation;context gate;dynamic vocabulary,"Neural Machine Translation (NMT) has made remarkable progress in recent years, and the attention mechanism has become the dominant approach with the state-of-the-art records in many language pairs. However, the attention based NMT models have two shortcomings: First, due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations. Second, with the extensive application of NMT model in empirical research, its long-term weaknesses in dealing with scarce and extra vocabulary have become increasingly prominent. To address this problem, we employ our dynamic selection network which consists of context gate that dynamically controls the amount of information flowing from the source and target contexts, and dynamic vocabulary that additionally considers copying words directly from the source. Experiments are conducted on three machine translation tasks, English-to-German IWLST 2014, English-to-Vietnamese IWLST 2015 and Turkish-to-English WMT 2017. Experiments show that the proposed model outperforms the traditional NMT model with a large margin.",2018,F. Calefato; F. Lanubile; R. Prikladnicki,1986,1991,6,,10.1109/CompComm.2018.8781050,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8781050,IEEE Conferences,IEEE
Identification of V+N compound nouns in Chinese-English machine translation based on rules in patent texts,V+N compound nouns;identification;rule based;machine translation,"We address the problem of exclusion of verbs in sentences which are not predicates in Machine Translation and V+N compound nouns are the most apparent phenomena. We propose several identification rules based on HNC theory to lower the error rate of predicate-identification and verb-translation. Result is got by testing in existing MT system, which has a precision of 83.22% and a recall of 65.56%. And the result is valid to the identification and translation of Eigen Chunk1.",2012,F. Calefato; F. Lanubile; T. Conte; R. Prikladnicki,1485,1490,6,1,10.1109/CCIS.2012.6664632,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664632,IEEE Conferences,IEEE
Communication between deaf and hearing children using statistical machine translation,Persian sign language;children communications;statistical machine translation;sign language,"Communication with hearing people society is an important problem for deaf people. Because they are not learned the valid rules of spoken language that hearing people use them. We therefor prepare an efficient corpus and apply it to Moses Machine Translation to simplify these communications. We choose communications between children because they use e-communications more than adults. All of the systems that automatically process sign language corpus rely on appropriate data. So our corpus with a limited set of words and with specific subject is the first Persian corpus containing Persian language, PL, and Persian sign language, PSL, based on the domain of children conversations. At the first step raw data are pre-processed which provides necessary information for translation. These data are statistic information extracted of sentences. After getting important data from initial sentences, the corpus is applied for training of Moses machine translation. Beside on the main goal of this system, we can educate deaf people the valid Persian grammar that is a problem for deaf people in school and society. In this paper we compare our results with the results taken from Moses decoder in other spoken languages that indicate our purpose is applicable in real world.",2015,F. Chung; Z. Deng; S. Wang,1,6,6,,10.1109/PRIA.2015.7161632,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7161632,IEEE Conferences,IEEE
A novel word reordering method for statistical machine translation,statistical machine translation;reordering;dependency parsing,"Word order differences between source and target languages pose a serious challenge to statistical machine translation (SMT). Pre-ordering, an approach that reorders source words into a target-word-like order as a preprocessing step, has been shown effective in handling word order between different languages and improving translation performance of SMT. In this paper, we propose a novel word reordering method based on the pre-ordering framework. Instead of using a supervised parser trained on a monolingual treebank, our method extracts bilingual structural information for reordering from automatically wordaligned sentence pairs into dependency-tree-like structures, then learns a reordering model by training a dependency parser on this extracted pseudo-treebank. Experiment results show that our pre-ordering method is effective in permuting source words to resemble word order of the target language, and improving translation quality.",2015,F. Han; J. Mu; L. Tian; M. Luo; Z. Qiu; D. Zhang,843,848,6,1,10.1109/FSKD.2015.7382052,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382052,IEEE Conferences,IEEE
Analysis on bilingual machine translation systems for English and Tamil,Statistical machine translation;IBM models;BLEU score,"Language in any form is the fundamental requirement to communicate and interact within the human society. In this globalization era, we interact with people from different regions and linguistic backgrounds as per our interest in social, cultural, economical, educational and professional domain. It is quite tough, rather impossible to know all the languages. Thus we need a computerized approach to convert one natural language to another as per the necessity. In this paper, we discuss statistical machine translation for the languages Tamil and English limited to travel domain. The system aims to translate from English to Tamil and vice versa. GIZA++ tool is used for training the statistical models. The performance of the system is analyzed based on various performance metrics like BLEU score and TER.",2016,F. Mandita; T. Anwar; Hermawan; G. Kusnanto; W. E. S. Yudha; A. Hermanto; Supangat,245,250,6,4,10.1109/ICCPEIC.2016.7557203,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557203,IEEE Conferences,IEEE
Trends and Advances in Neural Machine Translation,Neural Networks;Machine translation;Recurrent neural network;Deep Learning,"In the time of globalization, there is a requirement for conquering the language barrier and interfacing with an ever-increasing number of individuals. The value of speaking to customers in their language is tangible with retention and engagement rates up over 70% when there are effective localization workflows in place. To do this, integrating Neural Machine Translation into traditional localization workflows is an efficient way. In this paper, we break down different models, approaches, inception, principle development, and structures utilized in NMT to discover a productive strategy to make a translation system and identifying the advances and imperfections of the equivalent. It also talks about evolution of various NMT techniques leading to the current methodologies and numerous challenges which could be taken further for future research trends and improvements carried on them.",2020,F. Maurer; B. Donyanavard; A. M. Rahmani; N. Dutt; A. Herkersdorf,1,6,6,,10.1109/INOCON50539.2020.9298373,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298373,IEEE Conferences,IEEE
Statistical Machine Translation Approach for Lexical Normalization on Indonesian Text,Lexical normalization;Indonesian;machine translation;social media,"Lexical normalization is an important task to be performed on noisy data, such as social media posts, before using the data for further analysis. We examine the potential of Statistical Machine Translation (SMT) for normalization of Indonesian text using the translation unit on both phrase and character levels. We also used an external corpus to generate additional language model data and pre-normalization rules to enhance the SMT system. The result shows the SMT systems on both phrase and character levels are outperforming various baseline in Word Error Rate (WER) score and Bilingual Understudy Evaluation (BLEU) score. This research also demonstrates the effect of using an external language model and applying pre-normalization rules can further enhance the effectiveness of SMT systems in normalizing Indonesian text.",2020,F. Oliveira; F. Wong; K. Leong; C. Tong; M. Dong,288,293,6,,10.1109/IALP51396.2020.9310508,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310508,IEEE Conferences,IEEE
Reranking machine translation hypotheses with structured and web-based language models,Statistical machine translation;N-best reranking;structured language model;web-based language modeling;smoothing,"In this paper, we investigate the use of linguistically motivated and computationally efficient structured language models for reranking N-best hypotheses in a statistical machine translation system. These language models, developed from constraint dependency grammar parses, tightly integrate knowledge of words, morphological and lexical features, and syntactic dependency constraints. Two structured language models are applied for N-best rescoring, one is an almost-parsing language model, and the other utilizes more syntactic features by explicitly modeling syntactic dependencies between words. We also investigate effective and efficient language modeling methods to use N-grams extracted from up to 1 teraword of web documents. We apply all these language models for N-best re-ranking on the NIST and DARPA GALE program1 2006 and 2007 machine translation evaluation tasks and find that the combination of these language models increases the BLEU score up to 1.6% absolutely on blind test sets.",2007,F. Oliveira; F. Wong; S. Chao; P. Fong,159,164,6,2,10.1109/ASRU.2007.4430102,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4430102,IEEE Conferences,IEEE
An Effective Neural Machine Translation for English to Hindi Language,Machine Translation;Encoder;Decoder;Attention;Long short-term memory;Bilingual evaluation understudy (BLEU) and Recurrent Neural Network,"Machine translation involves the conversion of text from one language to the other language. In the world of web, a huge number of resources are made available in English. Many of the people are not familiar with this global language. Manually transmuting them into native languages such as Hindi (Indian National language) is a tedious task. In such scenarios, automatic machine translation is an efficient approach. In our work, 8 advanced architectures have been experimented and contrasted their efficiencies. Six different Indian languages such as Hindi, Bengali, Gujarati, Malayalam, Tamil and Telugu is worked on. How BLEU varies with the usage of Word embedding technique have been clearly shown.. Encoder to decoder networks are found fine for short sentences. But if the length of the sentence exceeds 20, then attention architecture is suitable. The 4 Layer Bi-directional LSTM is a great choice in these networks to achieve higher BLEU is also observed. In our work, CFILT, UFAL, ILCC datasets have been considered and achieved a BLEU score of 21.97.",2020,F. Ren; J. Zhu; H. Wang,209,214,6,,10.1109/ICOSEC49089.2020.9215347,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9215347,IEEE Conferences,IEEE
Integration of Bilingual Lists for Domain-Specific Statistical Machine Translation for Sinhala-Tamil,"statistical machine translation;Sinhala, Tamil;low-resourced;terminology integration","Availability of quality parallel data is a major requirement to build a reasonably well performing statistical machine translation (SMT) system. Thus, developing a decent SMT system for a low-resourced language pair like Sinhala and Tamil that does not have a large parallel corpus is rather challenging. Past research for other different language pairs has shown that different terminology/bilingual list integration methodologies can be used to improve the quality of SMT systems, for domain-specific SMT in particular. In this paper, we explore if this can be effective for Sinhala-Tamil machine translation for the domain of official government documents. We evaluate the impact of three types of bilingual lists, namely, a list of government organizations and official designations, a glossary related to government administration and operations, and a general bilingual dictionary, based on four different methodologies (three static and one dynamic). Out of four, one methodology gave notable improvements for all three types of list over the baseline.",2018,F. Ren; J. Zhu; H. Wang,538,543,6,3,10.1109/MERCon.2018.8421901,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421901,IEEE Conferences,IEEE
"Statistical Machine Translation, Ripple Down Rules and Hidden Markov Model for Burmese Romanization",Statistical Machine Translation (SMT);Phrase-based SMT;Hierarchical Phrase-based SMT;Operation Sequence Model;Ripple Down Rules;Hidden Markov Model;Burmese Romanization,"Burmese Romanization is the phonetic translation of Burmese (Myanmar) language into their phonetic Latin script. Burmese Romanization is aimed the reader who is unfamiliar with the Burmese script to pronounce the Burmese language reasonably accurately. We developed a 15K Burmese Romanization parallel corpus based on the practical usage of several Romanizations of native Myanmar people. The experiments were performed using different SMT approaches (PBSMT, HPBSMT, OSM), Ripple Down Rules (RDR) and Hidden Markov Model (HMM) approaches to the task of Burmese Romanization. The results show that the OSM approach achieves the highest performance in Burmese to Romanized Burmese direction. On the other hand, HMM approach gives the highest results in Romanized Burmese to Burmese.",2020,F. Sugaya; K. Yasuda; T. Takezawa; S. Yamamoto,99,104,6,,10.1109/ICAIT51105.2020.9261807,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261807,IEEE Conferences,IEEE
An experiment on Japanese-Uighur statistical machine translation with increased corpus,Statistical machine translation (SMT);Phrase-Based approach;Japanese;Uyghur (Uighur),"In this paper, we present the results of our work on the development of a phrase-based statistical machine translation system from Japanese to Uyghur - an agglutinative language with productive inflectional and derivational morphology. We experiment with different morpheme-level representations for Japanese-Uyghur parallel texts. We improve from our baseline 2.61 BLEU points for our phrase-based baseline model to 7.03 BLEU points for an improvement of 4.42 points.",2014,F. Wang; W. Chen; Z. Yang; X. Zhang; S. xu; B. Xu,490,495,6,,10.1109/ICCI-CC.2014.6921504,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921504,IEEE Conferences,IEEE
EasyTalk: A Translator for Sri Lankan Sign Language using Machine Learning and Artificial Intelligence,machine learning;image processing;low-resolution image recognition;convolutional neural networks;natural language processing;real-time translation;semantic analysis;text to speech conversion,"Sign language is used by the hearing-impaired and inarticulate community to communicate with each other. But not all Sri Lankans are aware of the sign language or verbal languages and a translation is required. The Sri Lankan Sign Language is tightly bound to the hearing-impaired and inarticulate. The paper presents EasyTalk, a sign language translator which can translate Sri Lankan Sign Language into text and audio formats as well as translate verbal language into Sri Lankan Sign Language which would benefit them to express their ideas. This is handled in four separate components. The first component, Hand Gesture Detector captures hand signs using pre-trained models. Image Classifier component classifies and translates the detected hand signs. The Text and Voice Generator component produces a text or an audio formatted output for identified hand signs. Finally, Text to Sign Converter works on converting an entered English text back into the sign language based animated images. By using these techniques, EasyTalk can detect, translate and produce relevant outputs with superior accuracy. This can result in effective and efficient communication between the community with differently-abled people and the community with normal people.",2020,F. Wong; F. Oliveira; S. Chao; F. Sun,506,511,6,,10.1109/ICAC51239.2020.9357154,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357154,IEEE Conferences,IEEE
Design of Online Proofreading System for Business English Translation Based on Machine Vision,machine vision;business English;online proofreading;system design,"The translation work of business English is becoming more and more complicated, and the accuracy of translation cannot be maintained at a high level. Therefore, it is necessary to use an online proofreading system to make up for the lack of English translation software. However, due to the traditional online proofreading system, the design of the translation logic is relatively fragmented, resulting in the constant changes in the proofreading node layout and affecting the proofreading results. Therefore, an online proofreading system for business English translation based on machine vision is designed. In terms of hardware, connect a new type of single-chip microcomputer in the system and redesign the control circuit. On the software side, it calculates vocabulary similarity by tracking business English vocabulary; calculating semantic similarity based on content characteristics, and designing the system's online proofreading logic based on machine vision theory, and then resetting the system's online intelligent proofreading method. Experimental results: Compared with the system under the traditional design, the proofreading node of the design system deployment and control has a certain regularity. After proofreading the English translation, the accuracy of the translated content has been greatly improved.",2020,F. Wong; K. K. Leung,155,160,6,,10.1109/IAAI51705.2020.9332885,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332885,IEEE Conferences,IEEE
Towards the design of automatic translation system from Arabic Sign Language to Arabic text,Arabic Sign Language;Annotation System;Sign language automatic translation systems,"Automatic translation from or to sign language by recognizing patterns to produce a written text by using an annotated sign language corpus or any other tools of grammatical structure, syntactic rules, synthesis specifically for Arabic Sign Language. Arabic Sign Language still lack exhaustive scientific studies of their grammatical structure, morphology and syntactic rules, as well as the rules that govern the construction of sentences in this language. Such studies are necessary for the development and evolution of any sign language. In addition, the lack of tools that help researchers in studying Arabic Sign Language is another obstacle. In this paper we will show the importance of a system that would help to represent and translate Sign Language to a written text. In this context, we present a new proposal for the way towards the establishment of a system for the automated translation of the Arabic sign language into written text based on creation an annotated Arabic Sign Language corpus. This new proposed scheme can be useful for learning, teaching or studying for people who suffer from hearing difficulty. We also propose some rules which help developing Sign Language automatic translation systems.",2017,F. Y. Putri; D. Hoesen; D. P. Lestari,325,330,6,1,10.1109/ICICI.2017.8365365,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365365,IEEE Conferences,IEEE
The Design of Web Based Machine Translation Server Based on Grid Infrastructure,machine translation;network based;grid infrastructure,"This paper presents the research work in designing the architecture of translation server of Internet based machine translation system by using the infrastructure of grid. Where the translation server is able to access a LAN (or WAN) whose spare computing resources could be employed to accomplish the massive translation works generated by overwhelming user requests. According to the characteristics of different analytical tasks in a translation system, the whole process can be factorized into a series of tasks, where some computational tasks can be decomposed into highly independent and making the processing highly parallelizable. Two different configurations of distributed tasks over the network environment have been constructed in our current study.",2008,Francisco Oliveira; Fai Wong; Yiping Li; Jie Zheng,713,718,6,1,10.1109/NCM.2008.35,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4624233,IEEE Conferences,IEEE
Computational model of grammar for English to Sinhala Machine Translation,Machine Translation;Context-free grammar;Sinhala Languages;Conjugation,Development of the computational model of grammar for highly inflected language is a complex task and it is also essential to develop rule-based machine translation systems. This paper presents a computational model of grammar for Sinhala language by considering the Morphology and the Syntax of the Sinhala language. Finite State Transducers (FST) and Context-free grammar (CFG) have been used to describe the computational grammar for Sinhala. The grammar has been tested through the English to Sinhala Machine Translation System. The translation system successfully translates English sentences with simple or complex subjects and objects with most commonly used patterns of the tenses including active and passive voice forms.,2011,G. Adachi; T. Furuhashi; Y. Uchikawa,26,31,6,7,10.1109/ICTer.2011.6075022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6075022,IEEE Conferences,IEEE
Statistical Machine Translation as a Language Model for Handwriting Recognition,handwriting recognition;machine translation,"When performing handwriting recognition on natural language text, the use of a word-level language model (LM) is known to significantly improve recognition accuracy. The most common type of language model, the n-gram model, decomposes sentences into short, overlapping chunks. In this paper, we propose a new type of language model which we use in addition to the standard n-gram LM. Our new model uses the likelihood score from a statistical machine translation system as a reranking feature. In general terms, we automatically translate each OCR hypothesis into another language, and then create a feature score based on how ""difficult"" it was to perform the translation. Intuitively, the difficulty of translation correlates with how well-formed the input sentence is. In an Arabic handwriting recognition task, we were able to obtain an 0.4% absolute improvement to word error rate (WER) on top of a powerful 5-gram LM.",2012,G. Correia; R. CortesÃ£o,291,296,6,5,10.1109/ICFHR.2012.273,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424408,IEEE Conferences,IEEE
Sense disambiguation of simple prepositions in English to Kannada Machine Translation,Dictionary;Kannada postpositions;Machine Translation;Prepositions;Rule file;WordNet,"The preposition sense disambiguation is a critical task in any reliable Machine Translation (MT) system. The pervasive use of preposition or its equivalent in most of the languages makes it a crucial element during translation. Unlike English, there is no concept of preposition in Kannada. English prepositions are translated to Kannada by attaching appropriate inflections to the head noun of the prepositional phrase. Further post-positional words may also appear in Kannada translation for some prepositions. The choice of the appropriate post-positional word depends on the WordNet synset information of the head noun. The paper proposes an algorithm to disambiguate sense of a simple preposition in English to Kannada MT. It uses properties of the head noun and complement of the preposition for disambiguation. To the best of our knowledge, this is the first attempt towards introducing an algorithm to disambiguate sense of the preposition during English to Kannada MT. Experiments were conducted and the result obtained has been described. The performance of an algorithm is proved to be reliable and scalable.",2012,G. Costagliola; S. Orefice; G. Polese; G. Tortora; M. Tucci,203,208,6,2,10.1109/ICDSE.2012.6282320,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6282320,IEEE Conferences,IEEE
Neural machine translation research based on the semantic vector of the tri-lingual parallel corpus,Neural Machine Translation;Tri-lingual Parallel Corpus;Semantic Vector,"RNN Encoder-Decoder and attentional mechanism have lately been used to improve neural machine translation (NMT) on bilingual parallel corpus. In this paper, we propose tri-lingual NMT. Based on the Encoder-Decoder and attentional mechanism, we translate source language to target language, meanwhile translate another parallel source language to target language. We provides two approaches called splicing-model and similarity-model. Both of the approaches are in order to enhance the semantic representation of input sequences. Our experiments on the IWSLT 2012 Chinese to Japanese translation and English to Japanese tasks show that both of the methods provide a comparable or substantial improvement over the bilingual parallel corpus.",2016,G. Dhopavkar; M. Kshirsagar,69,74,6,3,10.1109/ICMLC.2016.7860879,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860879,IEEE Conferences,IEEE
Topic adaptation for Statistical Machine Translation,statistical machine translation;topic adaptation;topic models;sparse features;phrase table;topical similarity;domain adaptation,We present new ways for Farsi to English topic adaptation for statistical machine translation. We incorporate topic in the phrase table in the form of sparse phrasal features and make use of sparse lexical features by determining the topic distribution of source sentences in the development and test corpus. These sparse features cover a lot of source to target topic related translations. We also develop systems with features that measure the topical similarity of the source sentence and each hypothesis. These features include features based on distributional profiles and two types of features which make use of bilingual topic models to measure the similarity of the source sentence and the hypothesis using topic vectors in source and target languages. Domain and topic adaptation is also combined to improve the translation quality. Different experiments are carried out on Farsi to English Verbmobil and CNN datasets. BLEU score shows up to 2.0 improvement on Verbmobil dataset. Up to 1.17 BLEU improvement and several individual translation corrections are observed in CNN dataset.,2017,G. Dimauro; V. Di Nicola; V. Bevilacqua; D. Caivano; F. Girardi,2147,2152,6,,10.1109/IranianCEE.2017.7985416,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985416,IEEE Conferences,IEEE
Word sense disambiguation system for Myanmar word in support of Myanmar-English machine translation,Word Sense Disambiguation;machine translation;Myanmar-English parallel corpus,"Word Sense Disambiguation (WSD) has always been a key problem in Natural Language Processing. WSD is defined as the task of finding the correct sense of a word in a specific context. It is an intermediate task essential to many natural language processing problems, including machine translation, information retrieval and speech processing. There is not any cited work for resolving ambiguity of words in Myanmar language. In this paper, we propose an approach to solve the ambiguity of Myanmar words for Myanmar-English machine translation. Our approach is based on Nearest Neighbor Cosine classifier to disambiguate ambiguous words with part-of-speech `noun' and `verb', which uses topical feature that represent co-occurring words in bag-of-word feature. The system uses Myanmar-English parallel corpus as training data. The proposed system can improve the translation accuracy for Myanmar-English machine translation system.",2011,G. Flach; M. Holzapfel; C. Just; A. Wachtler; M. Wolff,2835,2840,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060465,IEEE Conferences,IEEE
Encoding-Decoding Methods for Neural Machine Translation,Neural Machine Translation;Encoding;Decoding;Natural Language Processing,"Deep Learning techniques have significant progress in the last few years. Different designs and methods of the model have experimented to enhance the performance in various domains of Natural Language Processing (NLP). Machine Translation is a domain of NLP. In this paper, we have reviewed different Encoding-Decoding methods for Neural Machine Translation(NMT). We also, compare these various methods and put forward a past, present and future of Neural Machine Translation.",2019,G. Kikui; S. Yamamoto; T. Takezawa; E. Sumita,1454,1459,6,,10.1109/ICICICT46008.2019.8993143,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8993143,IEEE Conferences,IEEE
Vietnamese-Thai machine translation using rule-based,Thai-Vietnamese;machine translation;rule-based,This paper presents a rule-based Vietnamese-Thai machine translation (VTMT) system. Vietnamese text is input and segmented to a set of sentences through the use of punctuation marks. The output sentence is segmented into a sequence of words using a longest syllable matching algorithm together with named entity recognition (NER) rules. Segmented words will seek corresponding Thai words from the Vietnamese-Thai lexicon. Vietnamese to Thai transcription rules will be used to transcribe unknown words and recognized name entity words. The system will analyze the source sentence structure in order to generate the output Thai sentences. The translation accuracy obtained from the proposed system was 77.15%; which is better than the results achieved through the popular website Google Translate.,2017,G. Kumar; M. Post; D. Povey; S. Khudanpur,187,192,6,,10.1109/KST.2017.7886094,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886094,IEEE Conferences,IEEE
A Simple but Effective Way to Improve the Performance of RNN-Based Encoder in Neural Machine Translation Task,"neural machine translation, recurrent neural network, attention mechanism, deep learning","Armed with attention mechanism, the recurrent neural network-based encoder-decoder model (or sequence to sequence model) has become the standard architecture to tackle many sequence Nature Language Processing (NLP) tasks. With regard to the neural machine translation (NMT) tasks, our paper proposed a new architecture to proficiently mines the ability of attention mechanism and stacked recurrent neural networks. As a lot of work has given proved that each layer of the stacked recurrent neural networks learns different aspects of a sequence. That means the information represented by each layer is important in terms of the translation task. However, usually, most work just simply adopt stacked recurrent neural networks as a whole part as the encoder or decoder and then combined them with the attention mechanism. While our work creatively uses the attention mechanism to explore each layer of the encoder. In this way, many aspects of the sequence could be learned. For example, linguistic features and semantics information of a word in a sentence could be clearly captured and finally influences the generation of the current translation word. Experiments have shown the effectiveness of our model and an average of 5.67 points BLEU scores were promoted.",2019,G. Li; X. Li; B. Xu,416,421,6,,10.1109/DSC.2019.00069,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923783,IEEE Conferences,IEEE
English-Vietnamese machine translation model based on sequence to sequence algorithm,sequence to sequence;attention algorithm;machine translation,"Machine translation is a task in natural language processing that uses computers to convert between different languages. This article introduces an original seq2seq model experiment on the English-Vietnamese data set. By adding the attention mechanism and comparing the results of the model, we find that the attention mechanism can greatly promote machine translation. Using seq2seq and attention mechanism models to achieve the basic functions of the machine model, and has outstanding performance in the experimental results. Using multi-bleu-perl to analyze, the results show that the attention mechanism shows good performance on Vietnamese machine translation tasks.",2020,G. M. Witter,1086,1091,6,,10.1109/ITOEC49072.2020.9141548,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141548,IEEE Conferences,IEEE
Translating unknown words using WordNet and IPA-based-transliteration,Machine Translation;Example-Based Machine Translation;Transliteration;WordNet,"Due to small available English-Bangla parallel corpus, Example-Based Machine Translation (EBMT) system has high probability of handling unknown words. To improve translation quality for Bangla language, we propose a novel approach for EBMT using WordNet and International-Phonetic-Alphabet(IPA)-based transliteration. Proposed system first tries to find semantically related English words from WordNet for the unknown word. From these related words, we choose the semantically closest related word whose Bangla translation exists in English-Bangla dictionary. If no Bangla translation exists, the system uses IPA-based-transliteration. For proper nouns, the system uses Akkhor transliteration mechanism. We implemented the proposed approach in EBMT, which improved the quality of good translation by 16 points.",2011,G. R. Tahir; S. Asghar; N. Masood,481,486,6,2,10.1109/ICCITechn.2011.6164838,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164838,IEEE Conferences,IEEE
The construction of Chinese-English lexical knowledge base for machine translation,Chinese-English lexical knowledge base;HNC theory;semantic distance calculation;machine translation;relational database,"The Chinese-English lexical knowledge base based on HNC is an important component of the HNC knowledge base system. As a new stage of the HNC natural language processing, the building of the knowledge base needs a deep development of the association between the target language and the source language in the concept of space. In this paper, the Chinese-English lexical knowledge base model based on the HNC theory is first put forward to provide an effective reference database for the machine translation based on the semantic content, and two examples are provided to introduce its application in the semantic distance calculation and the Chinese-English machine translation. This supplies a gap in the research about the bilingual knowledge database of the HNC theory system.",2011,G. Raboshchuk; C. Nadeu; P. JanÄ?oviÄ?; A. P. Lilja; M. KÃ¶KÃ¼Er; B. MuÃ±oz Mahamud; A. Riverola De Veciana,73,78,6,1,10.1109/SoCPaR.2011.6089098,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6089098,IEEE Conferences,IEEE
An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via Neural Machine Translation,neural machine translation;bug-fixes,"Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. We mine millions of bug-fixes from the change histories of GitHub repositories to extract meaningful examples of such bug-fixes. Then, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. Our model is able to fix hundreds of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9% of the cases.",2018,G. Sarker,832,837,6,5,10.1145/3238147.3240732,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000077,IEEE Conferences,IEEE
English to Persian machine translation exploiting semantic word sense disambiguation,English to Persian Machine Translation;Word Sense Disambiguation;semantic WSD,"PEnT1 is an automatic English to Persian text translator. It translates simple English sentences into Persian, exploiting a combination of rule based and semantic approaches. It covers all the twelve tenses in English in both passive and active verbs for indicative, negative, interrogative sentences. In this paper, introducing PEnT1, we propose a new WSD method by presenting a hybrid measure to score different senses of a word. We also discuss prototyping some linguistic resources to test our methods.",2009,G. Xie; X. Hei; H. Mochizuki; S. Takahashi; H. Nakamura,253,258,6,2,10.1109/CSICC.2009.5349401,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349401,IEEE Conferences,IEEE
Query rewriting using statistical machine translation,Statistic Machine Translation;Query Rewriting;CTR-Recall;BLEU;Information Retrieval,"In the area of Information Retrieval, user queries often mismatch the documents users exactly want. We regard this problem as a Query Rewriting task from user queries to document space. Using query logs containing query-keywords-CTR pairs, we trained a state-of-the-art statistical machine translation model to translate the user query to keywords of a web document. Using this method we successfully built the Â¿lecical gapÂ¿ between user queries and document keywords, and got the keywords as rewritings of the queries. We separately use BLUE and CTR-Recall as optimization target to complete eight comparable experiments. CTR-Recall is presented by us as an optimization target and evaluation indicator. It shows that if forcing the same word to be aligned in word alignment and using BLEU as optimization target we get both the best CTR-Recall and BLEU. At the same time using CTR-Recall as optimization target we get both the best CTR-Recall and BLEU too.",2013,G. Yammine; E. Wige; F. Simmet; D. Niederkorn; A. Kaup,814,819,6,,10.1109/ICMLC.2013.6890396,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6890396,IEEE Conferences,IEEE
A Morphological Analyzer to Enable English to Sinhala Machine Translation,Morphological analysis;Machine translation,"Morphological analysis plays a key role in effective functioning of a parser of any machine translation system. Further, morphological analyzers are useful as supportive software tools to coin terms for a given language. This paper reports on the first morphological analysis system for Sinhala language. This comes out as a major step in the development of a Sinhala parser for machine translation from English to Sinhala. The paper describes how the morphological analyzer can detect grammatical information of a given Sinhala word, and generation of all possible forms of the given word. It is also presented how a language specialist can use our system to device Sinhala terms that are agreeable with Sinhala grammar. The system has been developed with the use of SWI-Prolog, and to runs on Windows and Linux.",2006,G. Yang; J. Deng; G. Pang; H. Zhang; J. Li; B. Deng; Z. Pang; J. Xu; M. Jiang; P. Liljeberg; H. Xie; H. Yang,21,26,6,10,10.1109/ICINFA.2006.374146,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4250236,IEEE Conferences,IEEE
Approaches to improving corpus quality for statistical machine translation,Data selection;Noise filter;Corpus optimization;Statistical machine translation,"The performance of a statistical machine translation (SMT) system heavily depends on the quantity and quality of the bilingual language resource. However, the pervious work mainly focuses on the quantity and tries to collect more bilingual data. In this paper, we aim to optimize the bilingual corpus to improve the performance of the translation system. We propose methods to process the bilingual language data by filtering noise and selecting more informative sentences from the training corpus and the development corpus. The experimental results show that we can obtain a competitive performance using less data compared with using all available data.",2010,G. Yuan; Q. Zeng; H. Duan; W. Guo; W. Ni; N. Xie,3293,3298,6,1,10.1109/ICMLC.2010.5580699,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580699,IEEE Conferences,IEEE
Enhancing the Quality of Phrase-Table in Statistical Machine Translation for Less-Common and Low-Resource Languages,statistical machine translation;phrase-table;vector representation similarity;extend dictionary,"The phrase-table plays an important role in traditional phrase-based statistical machine translation (SMT) system. During translation, a phrase-based SMT system relies heavily on phrase-table to generate outputs. In this paper, we propose two methods for enhancing the quality of phrase-table. The first method is to recompute phrase-table weights by using vector representations similarity. The remaining method is to enrich the phrase-table by integrating new phrase-pairs from an extended dictionary and projections of word vector presentations on the target-language space. Our methods produce an attainment of up to 0.21 and 0.44 BLEU scores on in-domain and cross-domain (Asian Language Treebank - ALT) English - Vietnamese datasets respectively.",2018,G. Zhang; Y. Gao; D. Ji; X. Ren,165,170,6,,10.1109/IALP.2018.8629188,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629188,IEEE Conferences,IEEE
An Information Extraction Approach to English-Vietnamese Weather Bulletins Machine Translation,information extraction;machine translation;knowledge acquisition,"In this paper, we present our method of using information extraction techniques to tackle the task of automatically translating English weather bulletins to Vietnamese. It is simple yet effective in satisfying the constraints of low processing power and storage space for the deployment on an embedded system. Experimental results are very promising with the F-measure going up to 96% for extracting relevant information from the weather bulletins.",2009,H. Bing,161,166,6,,10.1109/ACIIDS.2009.90,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5175986,IEEE Conferences,IEEE
An Arabic WordNet enrichment approach using machine translation and external linguistic resources,Arabic WordNet;princeton WordNet;AWN anrichment;WordNet concepts alignment;machine translation;wikipedia;ranking metric;dictionaries,"The development of Arabic WordNet (AWN) has provided the Arabic Natural Language Processing (NLP) community with a lexical resource. However, due to the considerable lack of AWN Synsets compared to other WordNets, the use of this resource in Arabic NLP applications cannot be considered as an option yet. In this paper, we propose an automatic approach for AWN enrichment, based on three features: (1) the translation of Princeton WordNet (PWN) words and their direct Hypernyms; (2) an automatic validation of the hypernymy relation that is suggested as existing between words using Wikipedia articles; and (3) the integration of validated Synsets in AWN including their definitions, examples and synonyms that get extracted using dictionaries and other resources. The proposed approach has been implemented and a preliminary evaluation shows that the obtained results are promising.",2018,H. Haddad; H. Fadaei; H. Faili,1,6,6,,10.1109/ICNLSP.2018.8374385,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374385,IEEE Conferences,IEEE
Incremental translation using hierarchichal phrase-based translation system,Statistical Machine Translation (SMT);Incremental Decoding;Hierarchical Phrase-based Translation (Hiero);Left-to-Right Decoding,"Hierarchical phrase-based machine translation [1] (Hiero) is a prominent approach for Statistical Machine Translation usually comparable to or better than conventional phrase-based systems. But Hiero typically uses the CKY decoding algorithm which requires the entire input sentence before decoding begins, as it produces the translation in a bottom-up fashion. Left-to-right (LR) decoding [2] is a promising decoding algorithm for Hiero that produces the output translation in left to right order. In this paper we focus on simultaneous translation using the Hiero translation framework. In simultaneous translation, translations are generated incrementally as source language speech input is processed. We propose a novel approach for incremental translation by integrating segmentation and decoding in LR-Hiero. We compare two incremental decoding algorithms for LR-Hiero and present translation quality scores (BLEU) and the latency of generating translations for both decoders on audio lectures from the TED collection.",2014,H. Hassan; K. Sima'an; A. Way,71,76,6,,10.1109/SLT.2014.7078552,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078552,IEEE Conferences,IEEE
Improving the quality of MT output using novel name entity translation scheme,machine translation;machine transliteration;name entity translation;n-gram probability;syllabification,"Name Entity Translation has become a challenge for the machine translators as it has become a cardinal part of Natural Language Processing Applications. Name Entity comprises of two subtasks i.e. they can either be translated or transliterated with the help of syllabification. This paper describes the translation and transliteration of name entities from English to Punjabi using statistical rule based approach. Various rules are constructed with the help of syllabification approach. We are transliterating the name entities by applying the syllabification algorithm. Name entities involved in our experiment are: Proper name, Location name, Organization name and miscellaneous. Transliteration of name entities is obtained with the help of Probability calculation. We have calculated N-Gram probabilities for all the syllables on the basis of relative frequency. For the purpose of probability calculation we have used a statistical machine translation toolkit MOSES.",2013,H. Htun; Y. K. Thu; N. N. Oo; T. Supnithi,1548,1553,6,2,10.1109/ICACCI.2013.6637410,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6637410,IEEE Conferences,IEEE
Automatic Generation of an Operational CSP-Z Specification from an Abstract Temporal^Z Specification,automatic translation;abstract specification;TemporalZ;CSP-Z;operational specification,"Formal methods can be useful in developing distributed systems, in particular when critical applications are being developed. In this context, the purpose of this work is to define an automatic translation from an abstract formal specification using TemporalZ into an operational specification using CSP-Z in order to address the gap between the abstract design languages and their implementation. Our objective consists in, first, to generate a CSP-Z specification from a Z specification by defining a list of translation rules. Second, we suggest an extension of these rules in order to take into consideration the specific concepts of a TemporalZ specification as an integration of Z and LTL. This translation is supported and implemented by the ANTLR tool. Finally, we illustrate this work by translating an air traffic control system which is specified in TemporalZ with the ForMAAD method.",2012,H. Huang; P. Kharazmi; D. I. McLean; H. Lui; Z. J. Wang; T. K. Lee,248,253,6,1,10.1109/COMPSACW.2012.53,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6341583,IEEE Conferences,IEEE
Elimination of Machine Translation Errors in English Language Transformation,in-depth learning;English;language transformation;translation error elimination;semantics,"To improve the level of automation and intelligence of English language transformation in machine translation, a method of machine translation error elimination based on deep learning and feature extraction of language transformation error is proposed. The semantic correlation detection model of error exclusion in English language conversion translation is constructed by using the differentiated semantic modification method, and the semantic tree of error exclusion in English language transformation translation is built by means of grammar analysis. The semantic similarity feature of English language transformation is extracted. According to the different combinations of semantic similarity, the semantic allocation and machine translation error feature analysis in English language transformation are carried out. The tree topic word list of English language conversion is established by means of deep learning method, and the sentence structure of English language transformation is adjusted according to the semantic modification target in the tree topic word list. In order to eliminate the errors in translation of English language conversion and the registration of topic words, the optimal semantic correlation feature of each clause is calculated, and the deep learning algorithm is used to automatically optimize the errors in translation of English language conversion. The simulation results show that the accuracy of the proposed approach is high and the relevance of translation calibration is strong.",2019,H. Kong; B. Gu; P. Gu; J. Su; G. Liu,642,647,6,,10.1109/ICMTMA.2019.00147,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8858751,IEEE Conferences,IEEE
Automatic Extraction of Chinese/Japanese Translation Patterns Using Prefix Span,translation pattern;Prefix Span;Chinese;Japanese,"In late years, a large number of translation patterns are required for the pattern based machine translation. We propose an efficient method to extract the Japanese/Chinese translation patterns from the corpora using Prefix Span. They performed chunking on the sentence pairs of the parallel corpora, collected the candidate translation patterns from them using Prefix Span, and narrow down the candidates using two criteria: the point wise mutual information (PMI) and the degree of confidence for the threshold values. The proposed method achieved precision 85% when the PMI is 1.0 and the degree of confidence is 0.15.",2011,H. Lin; Y. Chen; N. Damdinsuren; T. Tan; T. Liu; J. Y. Chiang,139,144,6,,10.1109/TAAI.2011.31,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120733,IEEE Conferences,IEEE
Does joint decoding really outperform cascade processing in English-to-Chinese transliteration generation? The role of syllabification,Transliteration;syllabification;joint decoding;statistical machine translation;log-linear model,"Transliteration is a challengeable task aimed at converting a proper name into another language with phonetic equivalence. Since the conversion relates to the phonetic aspect of a text, syllabification is considered a major factor affecting the performance of a transliteration system. In grapheme-based approaches, there are two routines to transliterate, one is to perform in a pipeline of separate syllabification and other components in generation process step by step, the other is to synchronously segment syllables and generating transliteration options. Usually, joint decoding outperforms the cascade processing in many natural language processing missions, however, syllabification is a special component in transliteration task. Thus in this paper, we investigate the two routines with a systematic analysis and compare their results to illustrate the strength of syllabification. A phrase-based statistical machine translation framework for joint decoding and a conditional random field syllabification system are used in this work for our investigation, which shows a different scenario on the issue of joint decoding versus cascade processing in transliteration.",2010,H. M. Djamel; N. Bensaou,3323,3328,6,,10.1109/ICMLC.2010.5580674,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580674,IEEE Conferences,IEEE
Features of Accuracy Mismatch between Back-Translated Sentences and Target-Translated Sentences,multilingual communication;machine translation;back-translation,"In communication using a machine translation, inaccurate translation prevents effective communication between individuals and leads to misunderstandings. Back-translation is used to check the accuracy of a sentence translated to a native language. For back-translation to be used as a method for checking the accuracy of a translated sentence, it has to satisfy the following conditions: There must be a positive correlation between the accuracy of sentences translated to an intermediate language and that of back-translated sentences, and there can be no significant difference between them. From the results of our verification, we found that back-translation satisfies these conditions. However, we found that accuracy mismatch case 1, which means that a back-translated sentence is accurate but the translated sentence is inaccurate, occurred although the number of such accuracy mismatch cases was small. Accuracy mismatch case 1 can lead to serious problems in communication. In this paper, we discuss the causes of accuracy mismatch case 1. We find that there are six features of accuracy mismatch between a back-translated sentence and its target-translated sentence.",2011,H. Nieto-Chaupis,63,68,6,,10.1109/Culture-Computing.2011.20,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103211,IEEE Conferences,IEEE
Sinhala to English Language Translator,English;Sinhala language;transfer based machine translation;translator,"This paper describes a machine translation system that is capable of translating a grammatically correct Sinhala sentence in to its corresponding English sentence. This is the first Sinhala to English machine translation system, which comes with features such as an inbuilt keyboard, an inbuilt dictionary, an integrated word processor based on Unicode fonts, a grammar tool, a Sinhalese grammar checker, an add word tool, and a debugging tool. With the expansion of the world, English has become an important language that people should learn, as the majority of the worldwide population understand and carry out their day-to-day work in English. In addressing this need, we thought of taking up the challenge of building, a Sinhala to English language translator. To build this system, we used the transfer-based machine translation approach, which is a rule-based approach. At present, the system has achieved a success rate of 75% with a corpus of 150 sentences.",2008,H. Phan; H. A. Nguyen; N. M. Tran; L. H. Truong; A. T. Nguyen; T. N. Nguyen,419,424,6,3,10.1109/ICIAFS.2008.4783983,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4783983,IEEE Conferences,IEEE
Context Based MTS for Translating Gujarati Trigram and Bigram Idioms to English,Trigram;English;Gujarati;Idiom;Machine Translation System (MTS),"Gujarati language is the official language of the state of Gujarat located on the western region of India. Machine Translation System (MTS) translates text from one language to other language. Based on our review, we found that very few machine translation systems are available that converts Gujarati text into English language. This paper focuses on the translation of Gujarati trigram idioms. Idiom is defined as a token-sequence whose meaning is different from the literal meaning of the individual tokens. The proposed Gujarati to English Idioms translator accurately translates the trigram and bigram idioms. We have created the corpus of nearly 3000 n-gram idioms and from this corpus we have found nearly 890 trigram idioms and 1735 bigram idioms. This paper studies the translation of trigram and bigram idioms.",2020,H. S. Sreedeepa; S. M. Idicula,1,6,6,,10.1109/INCET49848.2020.9154112,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154112,IEEE Conferences,IEEE
Introduction of Phrase Structures into the Example-Based Machine Translation System,inflectional word classes;machine grammar;morphological analysis;semantic syntactic- analysis;formal model of syntax;phrase structure;generalized syntagms,"The formal model of the syntax structure of texts based on representations of phrase structures as generalized syntagms and methods of their automatic construction are described. A new solution to a number of current problems of automatic processing of text information in the field of information search and machine translation, as well as an approach to the problem of unification of syntax structures of sentences and phrase structures constituting the sentences has been proposed. Declarative tools which are a complex of dictionaries and grammatical tables in machine form were created on the basis of large-scale studies of extensive volumes of scientific and technical texts using linguistic and statistical methods.",2019,H. Sun; R. Wang; K. Chen; M. Utiyama; E. Sumita; T. Zhao,445,450,6,,10.1109/CSCI49370.2019.00087,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071405,IEEE Conferences,IEEE
Hindi-English speech-to-speech translation system for travel expressions,Speech-to-Speech Translation System;HMM based speech recognition;Statistical Machine Translation;HMM based speech synthesis system,"Speech-to-speech translation system enables in translation of speech signals in a source language A to target language B. A good speech-to-speech translation (S2ST) system can be characterized by its ability to keep intact the fluency and meaning of the original speech input. An S2ST system to enable translation between Hindi and English is the main idea of the proposed work. A preliminary dataset concentrating on basic travel expressions in both the languages considered is used for this work. In order to develop a successful S2ST system three subsystems are required namely, automatic speech recognition (ASR) system, machine translation (MT) system and text-to-speech synthesis (TTS) system. Hidden Markov models based ASR system is developed for both the languages and their performances are analyzed based on the word error rate (WER). The MT subsystem makes use of the statistical machine translation (SMT) approach for the purpose of translating the text between the two languages involved. The SMT makes use of IBM alignment models and language models to enable proper translation. The performance of MT is analyzed based on translated edit rate (TER) and analysis of the translation table. HMM-based speech synthesis system (HTS) is used to synthesize the translated text. Performance of the synthesizer is analyzed based on mean opinion score (MOS) from a group of listeners.",2015,H. Yoon; J. Li,250,255,6,2,10.1109/ICCPEIC.2015.7259472,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7259472,IEEE Conferences,IEEE
Automatic Patterns Acquisition and Evaluation for Web-Based Terminology Translation,Pattern acquisition;Automatic evaluation;Web-based;Terminology translation,"To find the translation of a given terminology from web without dictionary is an interesting and challengeable work. The existing methods based on pattern mainly consist of two steps: (1) learn patterns from a training set, and (2) find the candidate terms and score them. However, there are two main deficiencies in the existing works: (1) the amount and reliability of patterns are restricted by the training set, and (2) the methods for scoring patterns and candidate terminologies are too simplified. We present a new method that needs only a pair of terminologies for training to acquire the initial patterns. Patterns acquisition and patterns evaluation are performed automatically when an appropriate candidate terminology is selected for a user's query. We also improve the method of scoring the candidate terminologies by applying heuristic rules. The experiment results show that our method is better than the existing technologies.",2007,H. Yu; H. Luo; Y. Yi; F. Cheng,4124,4129,6,,10.1109/ICMLC.2007.4370868,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370868,IEEE Conferences,IEEE
Gender aware spoken language translation applied to English-Arabic,Speaker Gender;Unbiased Translation;Gender Aware Translation;Gender Agreement Neural Machine Translation System,"Spoken Language Translation (SLT) is becoming more widely used and becoming a communication tool that helps in crossing language barriers. One of the challenges of SLT is the translation from a language without gender agreement to a language with gender agreement such as English to Arabic. In this paper, we introduce an approach to tackle such limitation by enabling a Neural Machine Translation system to produce gender-aware unbiased translation. We show that NMT system can model the speaker/listener gender information to produce gender-aware translation that reduces the bias effect resulting from having training data dominated by particular gender forms. We propose a method to generate data used in adapting a NMT system to produce gender-aware and unbiased translation. The proposed approach can achieve significant improvement of the translation quality by 2 BLEU points.",2018,H. Yuehong; W. Chunyu,1,6,6,1,10.1109/ICNLSP.2018.8374387,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374387,IEEE Conferences,IEEE
Subjective and objective evaluation of English to Urdu Machine translation,BLEU;GTM;METEOR and ATEC,"Machine translation is research based area where evaluation is very important phenomenon for checking the quality of MT output. The work is based on the evaluation of English to Urdu Machine translation. In this research work we have evaluated the translation quality of Urdu language which has been translated by using different Machine Translation systems like Google, Babylon and Ijunoon. The evaluation process is done by using two approaches - Human evaluation and Automatic evaluation. We have worked for both the approaches where in human evaluation emphasis is given to scales and parameters while in automatic evaluation emphasis is given to some automatic metric such as BLEU, GTM, METEOR and ATEC.",2013,I. McLoughlin; H. Zhang; Z. Xie; Y. Song; W. Xiao,1520,1525,6,,10.1109/ICACCI.2013.6637405,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6637405,IEEE Conferences,IEEE
A novel dependency based word-level reordering model for phrased-based translation,Statistical Machine Translation;Phrase Based SMT;Reordering Model;Head-modifier,"Phrase based statistic MT (SMT) is an important milestone in MT. However, the translation model in the phrase based SMT is structure free which limits its reordering capacity to some extent. In order to enhance the reordering capacity of phrase based SMT, in this paper we propose a head-modifier relation based reordering model, which exploits the way how to utilize the structured linguistic analysis information in source language. Within very small size of reordering model, we enhance the performance of the phrase based SMT significantly.",2010,J. A. Hurt; G. J. Scott; D. T. Anderson; C. H. Davis,1,6,6,,10.1109/NLPKE.2010.5587829,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587829,IEEE Conferences,IEEE
Semantic translation error rate for evaluating translation systems,Automated Metric;Statistical Machine Translation,"In this paper, we introduce a new metric which we call the semantic translation error rate, or STER, for evaluating the performance of machine translation systems. STER is based on the previously published translation error rate (TER) (Snover et al., 2006) and METEOR (Banerjee and Lavie, 2005) metrics. Specifically, STER extends TER in two ways: first, by incorporating word equivalence measures (WordNet and Porter stemming) standardly used by METEOR, and second, by disallowing alignments of concept words to non-concept words (aka stop words). We show how these features make STER alignments better suited for human-driven analysis than standard TER. We also present experimental results that show that STER is better correlated to human judgments than TER. Finally, we compare STER to METEOR, and illustrate that METEOR scores computed using the STER alignments have similar statistical properties to METEOR scores computed using METEOR alignments.",2007,J. Cao; K. Zhang; H. Yong; X. Lai; B. Chen; Z. Lin,390,395,6,2,10.1109/ASRU.2007.4430144,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4430144,IEEE Conferences,IEEE
Phrase-Based Named Entity Transliteration on Myanmar-English Terminology Dictionary,Myanmar;named entity;transliteration;Phrasebased statistical machine translation (PBSMT);language model,"Named entity (NE) transliteration is mainly a phonetically based transcription of names across languages using different writing systems. For the Myanmar language, robust transliteration of named entities is still a challenging task, because of the complex writing system and the lack of data. The Myanmar NE transliteration dictionary has so far developed over 135,255 NE instance pairs of western person, organization and place names. We apply statistical experiments on Phrase-based statistical machine translation (PBSMT) model using 2-Grams, 3-Grams, 4-Grams, 5-Grams and 6-Grams language models in decoding. Different units in the Myanmar script, i.e., characters and syllables are compared. We perform experiments on 1,000 test data set and 1,000 development data set of our proposed dictionary and measure the performance of our system applying bilingual evaluation understudy (BLEU) score. We discuss detailed observations of our experiments in this paper. According to the evaluations, we got the significant results on syllable unit for Myanmar (Myan) to English (Eng) transliteration direction with 89.3% BLEU score and on character unit for English (Eng) to Myanmar (Myan) transliteration direction with 82.0% BLEU score.",2020,J. Chatterjee; A. Saxena; G. Vyas,38,43,6,,10.1109/O-COCOSDA50338.2020.9295015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295015,IEEE Conferences,IEEE
Improved Reordering Rules for Hierarchical Phrase-Based Translation,statistical machine translation;hierarchical phrase-based translation;hierarchical rules;reordering,"Hierarchical phrase-based translation model has been proven to be a simple and powerful machine translation model. However, due to the computational complexity constraints, the extraction and use of hierarchical rules are usually restricted under certain limits, and these limits could have a negative impact on the performance of the translation model, especially for reordering. This paper presents a solution to improve the reordering of hierarchical phrase-based translation model. We propose a two-step method to extract improved reordering rules with less limits. These reordering rules help both local and non-local reordering, and could be incorporated to a hierarchical phrase-based translation system easily. Experiments show that our approach achieves statistically significant improvements over the baseline system in Chinese-English translation.",2009,J. Chung; F. Hsu; C. Lu; H. Lee; J. Ho,65,70,6,1,10.1109/IALP.2009.22,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380772,IEEE Conferences,IEEE
Machine Translation Effect on Communication: What Makes It Difficult to Communicate through Machine Translation?,computer supported intercultural collaboration;multilingual communication;communication analysis,"Intercultural collaboration facilitated by machine translation has gradually spread in various settings. Still, little is known as for the practice of machine-translation mediated communication. This paper investigates how machine translation affects intercultural communication in practice. Based on communication in which multilingual communication system is applied, we identify four communication types and its' influences on stakeholders' communication process, especially focusing on establishment and maintenance of common ground. Different from our expectation that quality of machine translation results determines communication process largely, our data indicates communication relies more on a dynamic process where participants establish common ground than on reproducibility and grammatical accuracy.",2011,J. Du; P. Yu,110,115,6,,10.1109/Culture-Computing.2011.28,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103219,IEEE Conferences,IEEE
Automatic text recognition in natural scene and its translation into user defined language,text detection;text localization;binarization;segmentation;fuzzy logic,"In recent year's availability of economical image capturing devices in low cost products like mobile phones has led a significant attention of researchers to the problem of recognizing text in images. Recognition of scene text is a challenging problem compared to the recognition of printed documents. In this work a novel approach is proposed to recognize text in complex background natural scene, word formation from recognized text, spelling checking and word translation into user defined language and finally overlay translated word onto the image. The proposed approach is robust to different kinds of text appearances, including font size, font style, color, and background. Combining the respective strengths of different complementary techniques and overcoming their shortcomings, the proposed method uses efficient character detection and localization technique and multiclass classifier to recognize the text accurately. The proposed approach successfully recognizes text on natural scene images and does not depend on a particular alphabet, text background. It works with a wide variety in size of characters and can handle up to 20 degree skewness efficiently.",2014,J. -J. Sun; S. Sun; Y. P. Chen; L. Jiang; J. Hu,324,329,6,1,10.1109/PDGC.2014.7030764,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030764,IEEE Conferences,IEEE
Analysis on Multilingual Discussion for Wikipedia Translation,Wikipedia Translation;Multilingual communication;Machine Translation;Multilingual Liquid Threads,"In current Wikipedia translation activities, most translation tasks are performed by bilingual speakers who have high language skills and specialized knowledge of the articles. Unfortunately, compared to the large amount of Wikipedia articles, the number of such qualified translators is very small. Thus the success of Wikipedia translation activities hinges on the contributions from non-bilingual speakers. In this paper, we report on a study investigating the effects of introducing a machine translation mediated BBS that enables monolinguals to collaboratively translate Wikipedia articles using their mother tongues. From our experiment using this system, we found out that users made high use of the system and communicated actively across different languages. Furthermore, most of such multilingual discussions seemed to be successful in transferring knowledge between different languages. Such success appeared to be made possible by a distinctive communication pattern which emerged as the users tried to avoid misunderstandings from machine translation errors. These findings suggest that there is a fair chance of non-bilingual speakers being capable of effectively contributing to Wikipedia translation activities with the assistance of machine translation.",2011,J. Jimenez; A. Martin; V. Uc; A. Espinosa,104,109,6,1,10.1109/Culture-Computing.2011.27,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103218,IEEE Conferences,IEEE
Pattern matching for automatic sign language translation system using LabVIEW,Image processing;LabVIEW;pattern matching;sign language,"This paper presents an automatic sign language translator, which is able to translate Malaysian sign language using pattern-matching algorithm. The sign language translator is a vision-based system where the image of the sign is captured by a camera, processed and translated into English by the computer. This sign language translator is able to recognize alphabets (A-Z), numbers (0-9), finger spelling, words (13 words) and sentences. Alphabets, numbers and fingers are categorized under static signs while words and sentences are known as dynamic signs where the signs involve motion. Static signs are recognised by matching positions of each fingertip with the database while the recognition of dynamic signs is performed by comparing the trajectory of the motion. The accuracy for static sign is 97.79% while the accuracy for dynamic sign is 80.38%.",2007,J. L. Bruse; M. A. Zuluaga; A. Khushnood; K. McLeod; H. N. Ntsinjana; T. -Y. Hsia; M. Sermesant; X. Pennec; A. M. Taylor; S. Schievano,660,665,6,4,10.1109/ICIAS.2007.4658470,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658470,IEEE Conferences,IEEE
Speech-to-speech translation humanoid robot in doctor's office,Speech-to-Speech Translation;Humanoid Robot;Medical Service Robot;Machine Translation,"This paper illustrates the implementation of a speech-to-speech translation humanoid robot in the domain of medical care. At this stage, the proposed system is a one-way translation that is designed to help English speaking patients describe their symptoms to Korean doctors or nurses. A humanoid robot is useful because it can be extended to reach out to people in need first and may substitute the role of human workers, unlike laptops or tablets. The system consists of three main parts - speech recognition, English-Korean translation, and Korean speech generation. It utilizes CMU Sphinx-4 as a speech recognition tool. English-Korean translation in this system is based on the rule-based translation. The success rate of the translation shows reliable results from an experiment with a closed scenario.",2015,J. Li; L. Ke; Q. Du; X. Ding; X. Chen; D. Wang,484,489,6,2,10.1109/ICARA.2015.7081196,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081196,IEEE Conferences,IEEE
Consolidation based speech translation,Speech Consolidation;Machine translation;Chinese broadcast news speech;Chinese-English translation,"To alleviate the degradation of the performance of speech translation, this paper proposes a new approach to translate ASR results through consolidation which extracts meaningful phrases and remove redundant and irrelevant information caused by speaker's disfluency and recognition errors. The speech translation results via consolidation are partial translation and can not be directly compared with gold standards in which all words are translated. We would like to propose a new evaluation framework for partial translation by comparing with the most similar set of words extracted from a word network created by merging gradual summarizations of the gold standard translation. Chinese broadcast news speech in RT04 were recognized, consolidated and then translated. The performance of MT results was evaluated using BLEU. We propose information preservation accuracy (IPAccy) and meaning preservation accuracy (MPAccy) for consolidation and consolidation-based MT.",2007,J. Qiang; X. Wu,380,385,6,,10.1109/ASRU.2007.4430142,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4430142,IEEE Conferences,IEEE
A novel approach for proper name transliteration verification,component;translteration;machine translation;cross lingual IR,"Proper name transliteration, the pronunciation based translation of a proper name, is important to many multilingual natural language processing task, such as Statistical Machine Translation (SMT) and Cross Lingual Information Retrieval (CLIR). This task is extremely challenging due to the pronunciation difference between the source and target language. A given proper name can lead to many different transliterations. In the past, research efforts had demonstrated a 30-50% error using top-1 reference for transliteration. This error leads to performance degradation for many applications. In this paper, a novel approach to verify a given proper name transliteration pair using a discrete variant Hidden Markov Model (HMM) alignment is proposed. The state emission probabilities are derived from SMT phrase tables. The proposed method yields an Equal Error Rate (EER) of 3.73% on a 300 matched and 1000 unmatched name pairs test set. By comparison, the commonly used SMT framework yields 6.5% EER under the best configuration. The widely used edit distance approach has an EER of 22%. Our new method achieves high accuracy and low complexity, and provides an alternative for name transliteration in CLIR and other cross lingual natural language applications such as word alignment and machine translation.",2010,J. Qu; Y. Lu,89,94,6,,10.1109/ISCSLP.2010.5684842,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5684842,IEEE Conferences,IEEE
Integration Algorithm of English-Chinese Word Segmentation and Alignment,Word segmentation;word alignment;word similarity;example-based machine translation,"This paper proposes an integration algorithm of English-Chinese word segmentation and alignment. In this algorithm, bilingual word segmentation and alignment work synchronously and interactively. Given sentence-aligned bitext, it cannot only use bilingual word alignment's information to guide resolving word segmentation ambiguities, but also avoid the errors of word segmentation from being transferred into word alignment. Experimental result shows that it distinctly improves accuracy of both word segmentation and alignment",2006,J. Rhinelander; P. X. Liu,4105,4110,6,1,10.1109/ICMLC.2006.258869,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028790,IEEE Conferences,IEEE
Neuro-FGA Based Machine Translation System for Sanskrit to Hindi Language,MTS;GA;Fuzzy Rule Based System;Rule Optimization;Neural Network,"Today is the era of technology and in this various automated systems are used for different purposes. Machine translation systems (MTSs) are also very popular now-a-days and it is used for both personal and professional works. As it is on high demand so these systems needs to be very effective in terms of their performance. For this, a number of MTSs were proposed for different languages. Here in this paper, a new hybrid MTS is proposed to achieve optimal performance based on Neural and Genetic Algorithm (GA) based Fuzzy inference System. In this hybrid system, fuzzy is used for rule generation where GA helps to optimize the rules generated by fuzzy and collaboratively it is known as GA based Fuzzy inference System (FGA) then neural is used to train the system and then it will be matched with the rules generated by FGA for translation. The translation of the Sanskrit to Hindi language is done by using this proposed MTS and its performance is analyzed on the basis of different parameters.",2019,J. Singh; S. Pote; A. Karhe; A. Agrawal,1,6,6,,10.1109/CISCT46613.2019.9008136,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008136,IEEE Conferences,IEEE
Language translation of web-based content,Machine Translation (MT);Cross-Language Information Retrieval (CLIR) [1];Computer-Aided Translation (CAT);International Organization for Standardization (ISO),"Machine Translation (MT) software today provides adequate conversion of foreign languages to one's native tongue; however, dialects, slang, and character conversion errors result in partially successful translations. For an accurate translation, a native speaker is often required to correct the translation by using sentence structure and word use cues to capture the true meaning. MT character conversion from Cyrillic, Asian, and Arabic languages to western characters induce errors in the translated text which can change the meaning or result in characters being associated together that do not form words. The authors present a solution using open source MT and the International Organization for Standardization (ISO) character mapping. The solution provides proper character conversion to achieve greater translation accuracy for web-based content.",2012,J. Srivastava; S. Sanyal,40,45,6,1,10.1109/NAECON.2012.6531026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531026,IEEE Conferences,IEEE
Time Series Neural Networks for Real Time Sign Language Translation,"Sign Language Translation, Computer Vision, Long Short Term Memory Networks, Neural Machine Translation, Attention Neural Networks, Deep Neural Networks, American Sign Language","Sign language is the primary mode of communication for the hearing and speech impaired and there is a need for systems to translate sign languages to spoken languages. Prior research has been focused on providing glove based solutions which are intrusive and expensive. We propose a sign language translation system based solely on visual cues and deep learning for accurate translation. Our system applies Computer Vision and Neural Machine Translation for American Sign Language (ASL) gloss recognition and translation respectively. In this paper, we show that an end to end neural network system is not only capable of recognition of individual ASL glosses but also translation of continuous sign language videos into complete English sentences, making it an effective and practical tool for sign language communication.",2018,J. Su; J. Zeng; D. Xiong; Y. Liu; M. Wang; J. Xie,243,248,6,1,10.1109/ICMLA.2018.00043,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614068,IEEE Conferences,IEEE
Korean-Chinese statistical translation model,Statistical Machine Translation;Korean-Chinese;Factored Translation Model,"Korean and Chinese belong to different language families and there are very few researches on statistical machine translation between them. The word order of these two languages is quite different. Korean is considered as a morphologically rich language when compared to Chinese. Hence, in translating Korean into Chinese, more linguistic knowledge is required to achieve a better translation result. This paper presents a Korean to Chinese machine translation system by incorporating different linguistic data of Korean into the translation model. A state-of-the-art factored translation model is employed to verify the goodness of the proposed approach, which is efficient not only for the European languages, but also for Korean and Chinese. Experimental results demonstrate the solid evidence that the proposed method is able to achieve a better performance by integrating different types of linguistic information.",2012,J. Sukharev; L. Zhukov; A. Popescul,767,772,6,1,10.1109/ICMLC.2012.6359022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359022,IEEE Conferences,IEEE
Automatic Generation of Program Comments Based on Problem Statements for Computational Thinking,Programming Learning;Comment Generating;Neural Machine Translation;Encoder-Decoder Translation Model;Seq2Seq;TF-IDF,"To support the understanding of programs and understanding of procedures, we think need to automatically generate comments from source code. As a method, we learn the source code and comment pair by Encoder-Decoder translation model using LSTM, thereby generating comments of the source code that was the target of learning. Though, since it is difficult to increase the amount of learning data when generating comment for problem description, generated comments have some incorrect word for problem sentence. We use program problem sentence to generate comments for source code more suitable for users.",2019,J. Tian; P. Cheng; Z. Chen; M. Li; H. Hu; Y. Li; B. Vucetic,629,634,6,1,10.1109/IIAI-AAI.2019.00132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8992608,IEEE Conferences,IEEE
History attention for source-target alignment in neural machine translation,NMT;Attention;History Attention;Gate,"Attention mechanism has enhanced state-of-the-art Neural Machine Translation (NMT) by focusing on parts of the source sentence when predicting each target word. However we find that most of the attention context vector calculation is directly dependent on the current decoder hidden state. It tends to ignore past translated information, which often leads to over-translation and under-translation. When target sentence is very long, or the words relation inside the sentence are not tight, for example, there are some separators in the sentence, the model can get wrong translation. Aiming to solve these problems, in this paper, we propose a history attention structure that takes advantage of translated information. This architecture easily captures history information, helps model alleviate the memory vanishing problem introduced by long sentences and avoid focusing on one local part. In experiments, we show our history attention with gate improves translation quality.",2018,J. Zhang; T. Matsumoto,619,624,6,,10.1109/ICACI.2018.8377531,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377531,IEEE Conferences,IEEE
A Lightweight Transformer with Convolutional Attention,neural machine translation;Transformer;CNN;Muti-head attention,"Neural machine translation (NMT) goes through rapid development because of the application of various deep learning techs. Especially, how to construct a more effective structure of NMT attracts more and more attention. Transformer is a state-of-the-art architecture in NMT. It replies on the self-attention mechanism exactly instead of recurrent neural networks (RNN). The Multi-head attention is a crucial part that implements the self-attention mechanism, and it also dramatically affects the scale of the model. In this paper, we present a new Multi-head attention by combining convolution operation. In comparison with the base Transformer, our approach can reduce the number of parameters effectively. And we perform a reasoned experiment. The result shows that the performance of the new model is similar to the base model.",2020,Jiajie Lu; Canlin Li; Chao Yin; Lizhuang Ma,1,6,6,,10.1109/iCAST51195.2020.9319489,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319489,IEEE Conferences,IEEE
Research on Katakana phrase translation based on bi-directional integration,Katakana;Bi-directional Integration;Phrase-based Statistical Machine Translation,"In order to solve the problem of Katakana reduced to English in Japanese-English translation, we employ the phrase-based statistical machine translation model to perform Katakana phrase (or word) translation from Japanese to English. The Katakana phrase is segmented into words by CRF, and then Japanese-English and English-Japanese bi-directional integration translation is carried out on those segmented results. The translated results of all the segmented words are comprehensively scored to obtain the best English phrase translation result. The experimental results indicate that the Katakana phrase translation precision reaches 76%, effectively addresses the problem of the Katakana reduced to English.",2009,Jun-Wei Bao; De-Qvan Zheng; Bing Xu; Tie-Jun Zhao,1,6,6,1,10.1109/NLPKE.2009.5313753,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313753,IEEE Conferences,IEEE
Marathi - English Named Entities Forward MachineTransliteration Using Linguistic and Metrical Approach,Machine Transliteration;Named Entities;Pure and full Consonant;Rule Based Approach;Metrical Approach,"Machine transliteration is required in machine translation to transliterate words which are not present in dictionary such as names of persons, locations, cities and villages, names of roads and building etc. It is noticed that the machine transliteration is less studied for the language pair Marathi-English. Most of the present research in this area is done by using linguistic rule based and grapheme/phoneme based statistical approaches with the help of machine learning tools. This paper proposes Marathi to English forward machine transliteration of named entities of Indian-origin using hybrid approach which is the combination of linguistic rules and metrical approach. Proposed rule-based transliteration method uses phoneme model of the machine transliteration which uses the phonetic mapping between the source language Marathi written using Devanagari script and target language English written using Roman script. The key concept of this method is schwa deletion based on the stress of syllable after phonetic mapping. This approach requires full consonant based input and uses syllable based metrical approach for schwa deletion. Metrical approach works on stress of syllable whether it is unstressed or stressed in the given named entity. The experimental result showed that the absolute performance of the proposed method is high as compare to existing grapheme based approaches.",2017,K. Ahkouk; M. Machkour,1,6,6,1,10.1109/ICCUBEA.2017.8463731,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463731,IEEE Conferences,IEEE
Innovative algorithms for Parts of Speech Tagging in hindi-english machine translation language,component;formatting Hindi tokenizer;Conditional Random Fields;Parts of Speech Tagger,"In this paper we develop and evaluate Parts Of Speech Tagging algorithm for parsing the Hindi text in Unicode format, it verifies the Hindi text according to the correct grammar. The accuracy for only Parts of Speech Tagging 93.6% window-3, 93.96% window-2 and 92.09% window-1. Accuracy of word with Parts of Speech Tagging for window-1- 94.45%, window-2- 95.17% and window-3- 94.75%. The accuracy for Parts of Speech Tagging was achieved by Conditional Random Fields algorithm.",2015,K. Ahkouk; M. Machkour; M. Ennaji; B. Erraha; J. Antari,709,714,6,2,10.1109/ICGCIoT.2015.7380555,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380555,IEEE Conferences,IEEE
Rule based personal references resolution in pashto discourse for better machine translation,Discourse (DC);Pronouns;Pashto;Anaphora Resolution;Algorithm,"Pashto is one of the richest languages of the world and consists of a large number of personal pronouns that are categorized into strong, weak and directional pronouns. In this paper a computational approach for resolving these pronouns is proposed and an algorithm is developed. This algorithm is the combination of two sub-algorithms that resolves these pronouns. The algorithm has been tested on real world text taken from novels and stories which showed 78% accuracy.",2008,K. Alden; J. Cosgrove; M. Coles; J. Timmis,1,6,6,2,10.1109/ICEE.2008.4553941,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4553941,IEEE Conferences,IEEE
Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to Formal Language with Iterative Forward-Translation,style-transfer;Indonesian;machine translation;colloquial;semi-supervised;natural language processing,"In its daily use, the Indonesian language is riddled with informality, that is, deviations from the standard in terms of vocabulary, spelling, and word order. On the other hand, current available Indonesian NLP models are typically developed with the standard Indonesian in mind. In this work, we address a style-transfer from informal to formal Indonesian as a low resource machine translation problem. We build a new dataset of parallel sentences of informal Indonesian and its formal counterpart. We benchmark several strategies to perform style transfer from informal to formal Indonesian. We also explore augmenting the training set with artificial forward-translated data. Since we are dealing with an extremely low-resource setting, we find that a phrase-based machine translation approach outperforms the Transformer-based approach. Alternatively, a pre-trained GPT-2 fined-tuned to this task performed equally well but costs more computational resource. Our findings show a promising step towards leveraging machine translation models for style transfer. Our code and data are available in https://github.com/haryoa/stif-indonesia.",2020,K. Bacha; M. Zrigui,310,315,6,,10.1109/IALP51396.2020.9310459,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310459,IEEE Conferences,IEEE
An Analysis of Multi-language Simultaneous Display in the Translation System,machine-translate;rewrite;language-grid,"It is assumed that Japanese can analogize the meaning of original text if they read the original text according to the commonality of written expressions, such as the commonality of Kanji and Chinese characters in case of Chinese-Japanese translations. In this study, participants rewrote translated sentences while viewing simultaneously the original sentences written in Chinese and the translated sentences into Japanese by Language Grid as a machine translation service. We analyzed how chat between a Japanese rewrite worker and Chinese participant was affected when the original sentences and machine-translated text were simultaneously displayed during the rewriting work. Additionally, we analyzed and evaluated the effect of the simultaneous display on the rewritten translated text. We found that the simultaneous display affects the rewriting work such that it is possible to analogize the meaning of the original text. Furthermore, the simultaneous display improved the translation quality of the rewritten translated text.",2017,K. Bantupalli; Y. Xie,666,671,6,,10.1109/COMPSAC.2017.50,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8030009,IEEE Conferences,IEEE
Semantic based orthographic with prepositional phrase for English-Tamil translation,Rule-Based Machine Translation;POS Tagging;Word Reordering;PENN Tree;Prepositions;Orthographic,"Machine translation quality has improved substantially in recent years. Many researchers have contributed and developed quite good algorithms, frameworks and models for various languages. Processing of natural language involves various levels, complexities, ambiguities arise at each of those levels. Some pragmatic and semantic approaches can be used to tackle these issues. Generally, prepositions are plays sound role in meaningful translation for any languages. While translating from English to Tamil, preposition in English sentences should be translated to postposition to have meaningful sentences. Thus the prepositional phase errors and orthographic errors are the major issue in machine translation. The main goal of this paper is to improve the translation quality. To achieve the goal, we use some semantic rule to correct the prepositional and orthographic errors in this English-Tamil translation. The proposed approach takes as input an English sentence containing a preposition and the correct postposition and correct spelling in Tamil for that particular sentence context as output. The rules are evaluated with corpus data and the performance is good. The outcomes of the results are compared with Google Translate.",2012,K. Bhattacharjee; S. K. S; S. Mehta; A. Kumar; R. Mehta; D. Pandya; P. Chaudhari; D. Verma,1,6,6,2,10.1109/IHCI.2012.6481845,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6481845,IEEE Conferences,IEEE
Web-based English-Sinhala translator in action,machine translation;morphological analysis;natural language processing;sinhala language,"Machine translation has been a potential solution for addressing the language barrier. In line with this, we have developed English to Sinhala machine translation system that can be accessed through the Internet. The translation system runs on a Web sever and can be accessed by an ordinary Web client. The core of the translation system contains seven modules, namely, English Morphological analyzer, English parser, Translator, Sinhala Morphological generator, Sinhala parser, Transliteration module and three Lexicon Databases. This core system has already been tested and used on standalone machines. The current project has extended the core system with the use of Prolog Server Pages to provide online access thereby opening the service to a wider audience.",2008,K. Chen; R. Wang; M. Utiyama; E. Sumita; T. Zhao,80,85,6,2,10.1109/ICIAFS.2008.4783963,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4783963,IEEE Conferences,IEEE
Intent transfer in speech-to-speech machine translation,Speech Translation;Prominence;Focus;Speech Synthesis;Cross-lingual Transfer,"This paper presents an approach for transfer of speaker intent in speech-to-speech machine translation (S2SMT). Specifically, we describe techniques to retain the prominence patterns of the source language utterance through the translation pipeline and impose this information during speech synthesis in the target language. We first present an analysis of word focus across languages to motivate the problem of transfer. We then propose an approach for training an appropriate transfer function for intonation on a parallel speech corpus in the two languages within which the translation is carried out. We present our analysis and experiments on Englishâ†”Portuguese and Englishâ†”German language pairs and evaluate the proposed transformation techniques through objective measures.",2012,K. Chen; T. Zhao; M. Yang; L. Liu; A. Tamura; R. Wang; M. Utiyama; E. Sumita,153,158,6,7,10.1109/SLT.2012.6424214,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424214,IEEE Conferences,IEEE
Intelligent Data Mining for Translator Correctness Prediction,Machine Learning;Predictive Analytics;Translation Accuracy;Yandex;Google;Live Translation;Multilingual Chatter,"This paper presents a new approach to predictive data analytics, called Radius of Neighbors (RN), and its mobile application, a multilingual RN-Chatter, devoted to improve communication among people, speaking different languages. RN is a modeless method of unsupervised machine learning, what makes it a fairly simple but effective way of analyzing big amounts of data while keeping acceptable speed of execution and taking up little run-time space. In the first preparatory stage of our research, we discovered that RN gives better results than well-known K-Nearest Neighbors (KNN) in some cases. We then extended our research to simulating the adjustments of floating radiuses, various volumes of the training data sets and ups and downs of the dimensions to tune RN for its optimum accuracy. We took experimental approach of not only extending the number of dimensions, but, instead, shrinking and modifying them in order to keep the predicted value' neighbors close by.",2016,K. Cui; F. Han; P. Wang,394,399,6,5,10.1109/BigDataSecurity-HPSC-IDS.2016.19,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502322,IEEE Conferences,IEEE
Text to speech synthesis system for English to Malayalam translation,Machine Translation System;Text to Speech synthesis;Speech recognition;Articulatory synthesis;Formant synthesis;Concatenation,"Speech recognition and Speech synthesis are the two emerging technologies in the communication field. Speech recognition is a system which generates text for the given speech, while a speech synthesizer is a system that should be able to read any text aloud. Research is conducting all over the world, to develop an efficient text to speech synthesis (TTS) system for minority languages. India has the largest democracy system in the world, also known as land of unity in diversity and has more than 22 official languages. It becomes difficult to understand the English and the other European languages to common people. This works aims to help people to translate English text to their own language and implement a TTS for the minority language, Malayalam. It is achieved by combining both Machine Translation and TTS. When an English text is given, it is translated to Malayalam with the help of a parser, using grammatical rules, applying morphology and a bilingual dictionary. From each of the translated Malayalam text, syllables are separated. A good number of syllables are recorded and stored in the syllable corpus. Syllables are concatenated to generate a synthesized Malayalam speech. Machine translation of English to Malayalam text is tested and achieved 73 percentage accuracy. For the TTS system, accuracy is verified by checking the naturalness and intelligibility. 87 percentages of the sentences are uttered correctly.",2016,K. Cui; Y. Du,1,6,6,,10.1109/ICETT.2016.7873642,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873642,IEEE Conferences,IEEE
Sentiment Polarity in Translation,sentiment polarity;machine translation;sentiment transfer;language barriers,"Previous year, many researchers have been sentiment analysis on many focus languages. They analyzed and categorizing opinions expressed in a text. People express their opinions and feeling on social media as a daily routine. For sentiment analysis work, data plays an important role. Thus, social media become interested platform for opinion mining. On the other hand, low resource languages face less of sentiment resources (such as sentiment lexicon, corpus) than English language. It is needed to overcome language barriers and realize a sentiment platform capable of scoring in different languages when global opinion is need to decide something. In this paper, the expectations and limitations of machine translation in sentiment polarity task for Myanmar language is presented. We experiment with comments of particular news and general news that are expressed in social media news pages. Results show that sentiment transfer can be successful through human translation. This also demonstrates that translation from Myanmar to English has a significant effect on the preservation of sentiment by using translation engine. This happens primarily due to nature of Language but the results show that machine translation quality plays the important role in this work.",2020,K. Dabre; S. Dholay,1,6,6,,10.1109/ICCA49400.2020.9022831,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022831,IEEE Conferences,IEEE
Grammar-based and example-based techniques in machine translation from English to Arabic,MT;Agreement;Word reorder;Rule-Based;Example-based;Hybrid-based;OAK Parser,"In the modern world, there is an increased need for language translation. This paper presents English to Arabic approach for translating well-structured English sentences into well-structured Arabic sentences, using a grammar-based and example-translation techniques to handle the problems of ordering and agreement. This technique combines rule-based MT (RBMT) and example-based MT (EBMT) which is called hybrid-based MT (HERBMT). The proposed methodology is flexible and scalable. The main advantages of HERBMT are that it combines the advantages of RBMT and EBMT, and it can be applied to other languages with minor modifications. EBMT extracts an example of target language sentences that are analogous to input source language sentences. The extraction of appropriate translated sentences is preceded by an analysis stage for the decomposition of input sentences into appropriate fragments. RBMT is used when examples of the source language to be translated into the target language are not found in the machine database. The OAK Parser is used to analyze the input English text to get the part of speech (POS) for each word in the text as a pre-translation process. A major design goal of this system is that it will be used as a stand-alone tool, and can be integrated with a general machine translation system for English sentences. The evaluation is carried out on 250 independent test suites, and the analysis indicates that HERBMT achieved good performance with an average of 97.2% precision.",2013,K. Dixit; A. S. Jalal,1,6,6,,10.1109/ICT4M.2013.6518910,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6518910,IEEE Conferences,IEEE
Probabilistic language model for template messaging based on Bi-gram,Language Model;Machine Translation;N-gram;Probability distribution table (PDT);Statistical Machine Translation (SMT);Text Normalization,"This paper reports the benefits of Probabilistic language modeling in template messaging domain. Through a Statistical Machine Translation (SMT) sentences written with short forms, misspelled words and chatting slang can be corrected. Given a source-language (e.g., Short message) sentence, the problem of machine translation is to automatically produce a target-language (e.g., Long form English) translation, to be used by the young generation for messaging. The main goal behind this project is to analyze the improvement in efficiency as the size of bilingual corpus increases. Machine learning and translation systems, dictionary and textbook preparations, patent and reference searches, and various information retrieval systems are the main applications of the project.",2012,K. Griffith; J. Kalita,196,201,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6215598,IEEE Conferences,IEEE
Influence of PoS on the accuracy translation from Indonesian to interlingua,Machine Translation;Part of Speech;Interlingua,"Part of speech (PoS) is the classification of words according to form, function, and meaning. POS tagging is an important problem and is the first step in natural language processing. POS tagging directly affect the accuracy on the next steps in the processing of natural language like syntax parsing, ambiguity of the word, and machine translation In general, machine translation can be divided into three strategic approaches: direct system, transfer systems, and Interlingua system. This study will use a systems approach Interlingua referring to rule-based systems that can be used for purposes that are more universal. In Interlingua system, translated into the native language of interpretation of meaning such as predicate calculus or minimal recursion semantics. The methodology used in this study consisted of several steps: conduct analysis Interlingua representation that refers to the role of semantics for the preparation phase of the PoS and the rules of production and translation, Conduct Indonesian grammar, prepare for PoS Indonesian Interlingua Machine Translation, Constructing rule-production rule which refers to the Indonesian grammar and translation, which refers to the rules of predicate logic, the last stage is to conduct the evaluation. The evaluation was done by implementing software that uses Syntax-Directed Translation Scheme (SDTS) method. The software serves as to translate sentences Indonesian to Interlingua. Experiments conducted with the same sentences but use a different PoS. From the results of research conducted, defining the right PoS can affect the accuracy of the translation from Indonesian to Interlingua represented in the form of predicate calculus.",2011,K. K. Yadav; U. C. Jaiswal,1,6,6,,10.1109/ICEEI.2011.6021737,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021737,IEEE Conferences,IEEE
Relative clause based text simplification for improved English to Hindi translation,Machine Translation;Text Simplification;Relative Clause identification;Computational Intelligence,"Language translation is one of the most research and development oriented topic in today's world because of its increasing demand and application. Knowledge of grammar structure of source and target languages is must for translating one language to other. Clauses are an integral part of any language and helps in constructing complex sentences in different contexts. This complication leads to a low score of translation in almost every machine translation engine existing in the world. In this work, we are focusing on relative clause identification and extraction for text simplification. The generated simple sentences are then fed to the existing translation engines for translation. Link Parser based parsing techniques are used to parse the sentence tree. In this work we have focused on achieving better quality of English-Hindi translations. The proposed approach is tested manually on a sufficiently large dataset and shows promising and better translation score than the conventional approaches.",2015,K. Kim; Y. Hong; Y. Han,1479,1484,6,4,10.1109/ICACCI.2015.7275821,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275821,IEEE Conferences,IEEE
Syntax based machine translation using blended methodology,Synchronous Tree Substitution Grammar (STSG);Reordering;Grammar Rules;Blended approach;Syntax based Translation;Lexicon;Bilingual Corpus,"The basic concept of machine translation is to translate one human language to another human language. Many translation systems have been built using different approaches which have different accuracy levels. In this paper, a work is being proposed for Syntax Based Machine Translation System from English to Hindi language. The Syntax Based Machine Translation System has the goal of incorporating an explicit representation of syntax into the statistical systems, to get the best out of the two worlds. The approach used in this translation system is a Blended approach i.e. statistical approach along with the Rule-based approach with the intention to get more accurate translation. Incorporating the idea of Synchronous Tree Substitution Grammar (STSG), it has been tried to parallel generate English and Hindi rules dynamically, which leads to final translated Hindi text. A parallel aligned text corpora of English and Hindi is being used as Database of the system, which is limited and hence limits the translation. Further, the system undergoes through various stages of Preprocessing, Source language analysis and then source to target language analysis to get the translation. The user has provision to select the best suitable translation according to him. This paper proposes the working strategy of how translation is being carried out from English to Hindi and the accuracy level that it achieved.",2016,K. Knight; D. Marcu,242,247,6,,10.1109/NGCT.2016.7877422,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877422,IEEE Conferences,IEEE
Automatic Sign Language Translation to Improve Communication,sign language;sign language recognition;translation;deaf;hearing disabilities;accessibility;inclusion,"Over the last years, there has been an increase in hearing-impaired students who use sign language as their main form of communication attending higher education institutions around the world. The knowledge that their comprehension of texts is reduced due to sentence structure differences causes a need for more solutions to improve communication and support students in environments where they are unable to be accompanied by sign interpreters. This article details the improvements and current structure of the VirtualSign platform, a bidirectional sign language to text translation tool that has been in development since 2015. The platform is divided into two main parts, sign to text and text to sign, and both components are described and explained. The solution has received positive feedback on several tests and a pilot experiment, and is being developed with partnerships with sign interpreters from six different European countries. Some planned improvements and future functionalities for the tool are also mentioned and detailed.",2019,K. Kolthoff,937,942,6,2,10.1109/EDUCON.2019.8725244,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725244,IEEE Conferences,IEEE
TREF - TRanslation Enhancement Framework for Japanese-English,Machine Translation;Syntactical Analysis;Sequence Alignment,"We present a method for improving existing statistical machine translation methods using an knowledge-base compiled from a bilingual corpus as well as sequence alignment and pattern matching techniques from the area of machine learning and bioinformatics. An alignment algorithm identifies similar sentences, which are then used to construct a better word order for the translation. Our preliminary test results indicate a significant improvement of the translation quality.",2010,K. Lingam; E. R. Lakshmi; L. R. Theja,541,546,6,1,10.1109/IMCSIT.2010.5679926,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679926,IEEE Conferences,IEEE
An unsupervised boosting technique for refiningword alignment,word alignment;boosting;statistical machine translation;mobile speech-to-speech translation,"Translation rules extracted from automatic word alignment form the basis of statistical machine translation (SMT) systems. An unsupervised expectation-maximization (EM) algorithm is typically used to obtain a word alignment from parallel corpora. Being statistically-driven, the alignments produced by this technique are often erroneous. In this paper, we propose an unsupervised boosting strategy for refining automatic word alignment with the goal of improving SMT performance. The proposed approach results in fewer unaligned words, a significant reduction in the number of extracted translation phrase pairs, a corresponding improvement in SMT decoding speed, and a consistent improvement in translation accuracy, as measured by BLEU, across multiple language pairs and test sets. The reduction in storage and processing requirements coupled with improved accuracy make the proposed technique ideally suited for interactive translation services, facilitating applications such as mobile speech-to-speech translation.",2010,K. M. Iftekharuddin,177,182,6,1,10.1109/SLT.2010.5700847,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5700847,IEEE Conferences,IEEE
Building a Filipino Colloquialism Translator Using Sequence-to-Sequence Model,Machine Translation;Statistical;Sequence-to-Sequence model;RNN;Filipino Colloquialism,"Colloquialism in the Philippines has been prominently used in day-to-day conversations. Its vast emergence is evident especially on social media platforms but poses issues in terms of understandability to certain groups. For this research, machine translators have been implemented to fill in that gap. The translators cover Filipino Textspeak or Shortcuts, Swardspeak or Gay-lingo, Conyo, and Datkilab - implemented on Tensorflow library and Moses tool. Implementing in Tensorflow achieved 85.88 BLEU score when evaluated to the training data and 14.67 to the test data, while Moses garnered 95.27 BLEU score on training data and 79.91 on test data. Analyses on both implementations include advantages and disadvantages in using each one. Through the analyses and development of this research, it is recommended to implement the following in the future: addition of colloquialism samples, experimentation on sequence-to-sequence configurations, applying Graphical User Interface (GUI) to the translators, implementing the translators to Natural Language Processing (NLP) tools, and to deploy the translators as a web application.",2018,K. Mokhtar; S. S. Bukhari; A. Dengel,2199,2204,6,,10.1109/TENCON.2018.8650118,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8650118,IEEE Conferences,IEEE
Divide and Translate Legal Text Sentence by Using Its Logical Structure,phrase-based machine translation;logical structure of legal text sentence;CRFs,"Translating legal text is generally considered to be difficult because legal text has some characteristics that make it different from other daily-use documents and legal text is usually long and complicated. In order boost the legal text translation quality, splitting an input sentence becomes mandatory. In this paper, we propose a novel method based on the logical structure of legal text sentence for dividing and translating legal text. We use a statistical learning method-Conditional Random Fields (CRFs) with rich linguistic information to recognize the logical structure of legal text sentence. We adapt the logical structure of legal text sentence to divide the sentence. By doing so, translation quality improves. Our experiments show that our approach can achieve better result for both Japanese-English and English-Japanese legal text translation by BLEU, NIST and TER score.",2012,K. N. Acheampong; W. Tian,18,23,6,,10.1109/KICSS.2012.19,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405605,IEEE Conferences,IEEE
Evaluation of Rewriting Service in Language Translation Web Services Workflow,intercultural collaboration;machine translation;language grid;web service,"We discuss here the complementarity effect of rewriting services in a language-translation Web service work-flow. The communication mediated by the machine translation service includes mistranslations and changed meanings, which are caused by the quality of the machine translation. To reduce these problems, we propose service reallocation and assemblage of the rewriting service by humans at each stage of the workflow. We set up two rewriting service allocation patterns: 1) a reallocation pattern as a previous rewriting process, and 2) a reallocation pattern as a follow-on rewriting process, for workflows consisting only of machine translations. A team of human judges provide multiple assessments of adequacy and fluency of sample sentences that are translated from English to Japanese using each pattern. Results indicated that the Japanese rewriting task as a follow-on rewriting service provided greater fluency than an English rewriting task as a previous rewriting service, with nearly equal adequacy.",2013,K. Nishimura; H. Kawanami; H. Saruwatari; K. Shikano,21,26,6,2,10.1109/CultureComputing.2013.12,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680325,IEEE Conferences,IEEE
PACT - Programming Assistant ChaTbot,chatbot;neural machine translation;generative model;encoder-decoder,"Programmers face situations where they have to rely on messy documentation, other developers and online search for basic programming commands and queries when they encounter any new programming environment. This leads to the waste of time of developers and decreases productivity. In this paper, we present, â€œPACTâ€?, a chat bot which assists the programmers with basic programming queries that they face when they are new to a programming environment. We use Neural Machine Translation architecture to generate coherent, non-rule based responses to a programmer's query. The data that is fed to the neural machine translation model is collected from websites like StackOverflow, technical sub-reddits and technical StackExchanges.",2019,K. Priyadharshini,131,136,6,,10.1109/ICCT46177.2019.8969070,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969070,IEEE Conferences,IEEE
Improved Graph-Based Bilingual Corpus Selection with Sentence Pair Ranking for Statistical Machine Translation,SMT;Ranking;Corpus Selection;Graph,"In statistical machine translation, the number of sentence pairs in the bilingual corpus is very important to the quality of translation. However, when the quantity reaches some extent, enlarging corpus has less effect on the translation, whereas increasing greatly the time and space complexity to building translation systems, which hinders the development of statistical machine translation. In this paper, we propose several ranking approaches to measure the quantity of information of each sentence pair, and apply them into a graph-based bilingual corpus selection framework to form an improved corpus selection approach, which now considers the difference of the initial quantities of information between the sentence pairs. Our experiments in a Chinese-English translation task show that, selecting only 50% of the whole corpus via the graph-based selection approach as training set, we can obtain the near translation result with the one using the whole corpus, and we obtain better results than the baselines after using the IDF-related ranking approach.",2011,K. Saija; S. Sangeetha; V. Shah,446,451,6,1,10.1109/ICTAI.2011.73,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103363,IEEE Conferences,IEEE
Rule base to resolve translation problems due to differences in gender properties in sibling language pair Gujarati-Hindi,empirical rules;rule base;sibling language;machine translation,"GH-MAP is a rule based token mapping system for translation between sibling language pair Gujarati-Hindi. However, with this rule bases it is not possible to obtain 'most' appropriate translation in certain cases of post positions markers, pronouns, adjectives and adverbs, where post position markers, pronouns, adjectives and adverbs are under the influence of grammatical properties of other elements of the sentence. The translation problem of current GH-MAP has been resolved by enriching GH-MAP with special empirical rules, formed based on observed patterns. These empirical rules help GH-MAP to obtain more appropriate translation. The revamped GH-MAP has been evaluated on 332 Hindi sentences. It has proved the importance of empirical rules by achieving 4% improvement over an existing GH-MAP.",2010,K. Saito; E. Yamamoto; M. Ueno; K. Kanzaki; H. Isahara,776,781,6,2,10.1109/ICCCT.2010.5640439,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5640439,IEEE Conferences,IEEE
Query Translation for Cross-Language Information Retrieval by Parsing Constraint Synchronous Grammar,Cross-Language Information Retrieval;Machine translation;Constraint synchronous grammar,"With the availability of large amounts of multilingual documents, cross-language information retrieval (CLIR) has become an active research area in recent years. However, researchers often face with the problem of inherent ambiguities involved in natural languages. Moreover, this task is even more challenging for processing the Chinese language because word boundaries are not defined in the sentence. This paper presents a Chinese-Portuguese query translation for CLIR based on a machine translation (MT) system that parses constraint synchronous grammar (CSG). Unlike traditional transfer-based MT architectures, this model only requires a set of CSG rules for modeling syntactic structures of two languages simultaneously to perform the translation. Moreover, CSG can be used to remove different levels of disambiguation as the parsing processes in order to generate a translation with quality.",2007,K. Singvongsa; P. Seresangtakul,4003,4008,6,2,10.1109/ICMLC.2007.4370846,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370846,IEEE Conferences,IEEE
An efficient approach to rule redundancy reduction in hierarchical phrase-based translation,Statistical machine translation;hierarchical phrase;redundancy;rift,"Hierarchical phrase-based machine translation model is a popular syntax model that makes use of the expressive power of synchronous context-free grammars (SCFG) to address the reordering problem in statistical machine translation. The model, however, generally suffers from a great amount of redundancy in the extracted translation rules. In this paper, we re-introduce the concept of rift into the rule extraction procedure to force the rules with reordering power to concentrate on where reordering has actually happened. Our approach brings a dramatic reduction in the training time and the number of the rules, with only minor sacrifice in translation quality.",2008,K. Soleymanzadeh; B. KaraoÄŸlan; S. K. Metin; T. KiÅŸla,1,6,6,,10.1109/NLPKE.2008.4906773,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906773,IEEE Conferences,IEEE
Automatic speech recognition of the Mixtec language: An ubiquitous computing application,Ubiquitous Computing;Mixtec Language;Automatic Speech Recognition,"In this work we present the implementation by means of ubiquitous computing of an Automatic Speech Recognizer (ASR) for the Mixtec language. This is proposed as a key development for future speech translation systems between the Mixtec and the Spanish languages in remote communities. The core of the ASR system was built with Hidden Markov Models (HMMs) and the management of its resources was performed with an interface developed with MATLAB. The interface was integrated with scripts that allowed remote access to the ASR by means of the MLConnect for Android devices with Wi-Fi connection. Experiments performed with a smartphone and a tablet PC, both inside a building, showed fast accessibility and word recognition accuracies over 92% for non-native speakers.",2013,K. Terui; R. Hishiyama,98,103,6,,10.1109/CONIELECOMP.2013.6525767,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525767,IEEE Conferences,IEEE
Automatic translation of text phrases into vector images for crisis communication,Global communication;image analysis;information management;information systems;picture archiving and communication systems;semantic Web;social network services,"Our contribution to the discipline of Information Systems consists in an attempt to develop a first technical approach for the automatic translation of series of syntagms (text phrases) into â€œSignagramsâ€?, to improve the management of multilingual information. We develop a new software that provides an instant translation of a written text into signagrams to allow access to information on some topic among national and international users. The signagram is the unit for signage. As an example, we adapt the software to the situation of emergency, where government units have to respond and give instructions to the population. We construct a first ontology for the situation of emergency that we link to the dictionary for signagrams. The translation software is developed in Java. We then test technically the translation method.",2015,K. Vijayanand; S. I. Choudhury; P. Ratna,119,124,6,1,10.1109/ISEI.2015.7358733,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358733,IEEE Conferences,IEEE
Segmenting Long Sentence Pairs for Statistical Machine Translation,segmentation;long sentences;semantics guided;Poisson distributed length ratio;length normalization,"In phrase-based statistical machine translation, the knowledge about phrase translation and phrase reordering is learned from the bilingual corpora. However, words may be poorly aligned in long sentence pairs in practice, which will then do harm to the following steps of the translation, such as phrase extraction, etc. A possible solution to this problem is segmenting long sentence pairs into shorter ones. In this paper, we present an effective approach to segmenting sentences based on the modified IBM translation model 1. We find that by taking into account the semantics of some words, as well as the length ratio of source and target sentences, the segmentation result is largely improved. We also discuss the effect of length factor to the segmentation result. Experiments show that our approach can improve the BLEU score of a phrase-based translation system by about 0.5 points.",2009,K. Wu; X. Wang; A. Aw,53,58,6,2,10.1109/IALP.2009.20,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380801,IEEE Conferences,IEEE
Combining a large sentiment lexicon and machine learning for subjectivity classification,Subjectivity classification;Ensemble techniques;Supervised approaches;Machine learning,"Most previous work on subjectivity/sentiment classification bases on either machine learning techniques (such as SVM, Maximum Entropy, Naive Bayes, etc.) or general sentiment lexicons. This paper presents a novel approach to combine a large sentiment lexicon and machine learning techniques for opinion analysis: 1) a large sentiment lexicon is automatically adjusted according to training data; 2) machine learning techniques are used to learn models on training data; 3) the results given by machine learning classifiers and the supervised lexicon-based classifier are combined to get better results. The experiments with the NTCIR data show that our approach significantly outperforms the baselines on subjectivity classification, i.e. the adjusted large sentiment lexicon shows good performance and its combination with machine learning techniques shows further improvement.",2010,K. Zeng; I. Paik,3311,3316,6,12,10.1109/ICMLC.2010.5580672,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580672,IEEE Conferences,IEEE
Developing a Statistical Turkish Sign Language Translation System for Primary School Students,Natural Language Processing;Statistical Machine Translation;Sign Language;Turkish,"As the access to information in the education domain increases, new technologies are developing for school children. However, deaf and dumb children still have limited access to the information, especially in their school lives. One of the most important reasons for this problem is the lack of studies in the Sign Language domain. In this paper, we propose a novel method for translation from Turkish to Turkish Sign Language for primary school students using the statistical machine translation approach. To the best of our approach, this is the first work that applies statistical translation to Turkish Sign Language. A parallel corpus is compiled from the books published by Ministry of National Education of Turkey. The results of the system were tested using different evaluation metrics. We observe that the results obtained are motivating for new studies.",2019,Kui Wu; Xuancong Wang; Nina Zhou; AiTi Aw; Haizhou Li,1,6,6,,10.1109/INISTA.2019.8778246,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778246,IEEE Conferences,IEEE
An improvement of translation quality with adding key-words in parallel corpus,Parallel corpus;Statistical machine translation,"In this paper, we propose a new approach to improve the translation quality by adding the Key-Words of a sentence to the parallel corpus. The main idea of the approach is to find the key-words of sentences that cannot be properly translated by the model, and then put it or them in the training corpus in a separated line as a sentence. During our experiment, we use two statistical machine translation (SMT) systems, word-based SMT (ISI-rewrite) and phrase-based SMT (Moses), and a small parallel corpus (4,000 sentences) to check our assumption. To our glad, we get a better BLEU score than the original parallel text. It can improve about 6% in word-based SMT (isi-rewrite) and 4% in phrased-based SMT (Moses). At last we build a 120,000 English-Chinese parallel corpus in this way.",2010,L. C. Galea; A. F. Smeaton,1273,1278,6,,10.1109/ICMLC.2010.5580888,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580888,IEEE Conferences,IEEE
Monotonic filter for hierarchical translation models,Statistical machine translation;Hierarchical rules filtering;Filtered rule extraction;Phrase decomposition pattern,"The model size and decoding time are known issues in statistical machine translation. Especially, monotonic words order of language pairs makes the size of hierarchical models huge. Considering this fact, the rule extraction method of phrase-boundary model was changed to extract less number of rules. This paper proposes this rule extraction method as a general filter for hierarchical models. Named as monotonic filter, this filter reduces the extracted rules from phrase pairs decomposable to monotonic aligned subphrases. We apply the monotonic filter on the hierarchical phrase-based, SAMT and phrase-boundary models. Our experiments are performed in translations from Persian, German and French to English as the source and target languages with low, medium and high monotonic word order respectively. The reduction amount of the monotonic filter for the model size and decoding time is up to about 70% and 80% respectively, in most cases with no tangible impact on the translation quality.",2016,L. Capra,19,24,6,1,10.1109/ICCKE.2016.7802109,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7802109,IEEE Conferences,IEEE
Statistical-based machine translation for prepositional phrase using Link Grammar,statistical method;LG formalism;preposition,"The Internet provides most information in English language. However, most people are non-English speaker. Hence, it will be a great advantage for the people to have reliable machine translation. The expectation from the Machine Translation (MT) is sentences translation in a natural way based on the contexts. There are some reasons of why MT is hard to develop. One of the cause is there exists many mapping from source to target words in one-to-many, many-to-one, and many to-many. For example, an English preposition can have more than one translation in Indonesian words depend on the context. This research tries to find a technique that can provide a suitable translation of the English prepositions to the Indonesian words. The technique will use LG formalism and statistical method. The meaning of preposition in a sentence depends on the preceding word and the following word. The word before the preposition is a word explained by the preposition. Meanwhile, the word after a preposition is a word that explains the preposition. Knowing that both preceding and following words are not always precisely in the right and left positions of the preposition, we then need a method to find those connected words. We try to handle the problem by using LG formalism. LG formalism consists of a set of words and each word has a linking requirement. Using this linking requirement, the words that have a link to the preposition can be resolved. After obtaining the connected words, the translation is done using statistical method. Statistical method translates the preposition based on the probability of the relation which is obtained from LG formalism. This work expresses its relation in the bigram form. If an English preposition bigram has more than one Indonesian translation, then the output is the bigram that have the biggest probability. In this research, the combination between LG formalism and statistical method give a better English preposition translation than the existing methods.",2011,L. HUANG; W. CHEN,1,6,6,1,10.1109/ICEEI.2011.6021644,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021644,IEEE Conferences,IEEE
Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages,metamorphic relation;data validation;data quality assessment;natural language processing;machine translation;sentiment analysis;oracle problem;metamorphic testing;social media;Douban,"In conventional metamorphic testing, metamorphic relations (MRs) are identified as necessary properties of a computer program's intended functionality, whereby violations of MRs reveal faults in the program-under the assumption that the source and follow-up inputs (test cases used in metamorphic testing) are valid. In the present study, the authors argue that MRs can also be used to validate and assess the quality of the program's input data-under the assumption that the source or follow-up inputs can be inappropriately generated. Using this new perspective, a case study in the natural language processing domain is used to explore the different types of text messages that are difficult to interpret by (Chinese-English) machine translation. A total of 46,180 short user comments on Personal Tailor (a 2013 Chinese film), collected from Douban (a popular Chinese social media platform), has been used as the primary dataset of this study, and the analysis of results demonstrates that the proposed MR-based data validation method is useful for the automatic identification of poorly translated text messages.",2019,L. J. McGibbney; K. D. Whitehall; C. A. Mattmann; P. M. Carter,70,75,6,,10.1109/MET.2019.00018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785644,IEEE Conferences,IEEE
Active Learning for Neural Machine Translation,Active Learning;NMT;Low-resource;Data Selection,"Neural machine translation (NMT) normally requires a large bilingual corpus to train a high-translation-quality model. However, building such parallel corpora for many low-resource language pairs is rather expensive. In this paper, we propose to select informative source sentences to build a parallel corpus under the active learning framework so as to reduce the cost of manual translation as much as possible. Particularly, we propose two novel and effective sentence selection methods for active learning: selection based on semantic similarity and decoder probability. Experiments on Indonesian-English and Chinese-English show that our selection approaches are superior to random selection and two conventional selection methods.",2018,L. Kof,153,158,6,,10.1109/IALP.2018.8629116,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629116,IEEE Conferences,IEEE
An unsupervised & statistical word sense tagging using bilingual sources,Word Sense Tagging;Machine Translation,"This paper presents an approach for choosing the correct translation of an ambiguous word in a given sentence. An unsupervised learning is applied and a non-aligned bilingual Portuguese to Chinese bilingual corpus is used in disambiguating word senses. The identification of the relationships between words is done by considering its surrounding words and their relative distance to tackle syntactical relationships. All the related words are then translated to the target language in finding out the correct senses of ambiguous words. The selection is based on a statistical and a mathematical model by assigning a score to each of the sense identified previously. After all the senses discovered, its semantic and syntactical information are converted into a set of rules and stored in the database for later use in the disambiguation process. Preliminary experiment results of the proposed method shows an improvement of 6% in assigning correctly the corresponding translation over the baseline method.",2005,L. M. Hai; P. T. Tuoi,3749,3754,6,1,10.1109/ICMLC.2005.1527592,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1527592,IEEE Conferences,IEEE
Word alignment system based on hybrid approach for Myanmar-English machine translation,Word Alignment;IBM Models;Word-aligned Parallel Corpus,"Word alignment is a basic and critical process in the Statistical Machine Translation (SMT). Word alignment is to identify word correspondence that are translations of each other based on information found on parallel text. Essential for building parallel corpora is the alignment of translated segments with source segments. A parallel corpus is a collection of texts in two languages, one of which is the translation equivalent of the other. Nowadays, Myanmar-English word-aligned parallel corpora are not available. This paper describes the construction of an aligned Myanmar - English parallel corpus to be able to use as a resource in Myanmar-English machine translation. The proposed system uses the combination of corpus-based approach and the dictionary lookup approach. The corpus-based approach is based on the first three IBM models and Expectation Maximization (EM) algorithm. For the dictionary lookup approach, the proposed system uses the bilingual Myanmar-English Dictionary. The system also uses a list of cognates and morphological analysis to get better alignment accuracy. Accuracy of modern statistical machine translation depends on good word alignment.",2011,L. Montgomery; D. Damian,2841,2846,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060466,IEEE Conferences,IEEE
Linguistic Divergence of Sinhala and Tamil Languages in Machine Translation,Language Divergence;Sinhala;Tamil;Dorr's classification;NLP;translation challenges,"This paper presents a study of the lexical-semantic divergence between Sinhala and Tamil languages. Study of divergence is critical as differences in linguistic and extra-linguistic features in languages play pivotal roles in translation. This research the first study of the divergence between Sinhala and Tamil languages and is based on Dorr's classification. We propose a computer-assisted divergence study procedure using statistical machine translation, which is easy and gives good performance compared to traditional approaches. Accordingly, this research has the twin aims of revisiting classification of divergence types as outlined by Dorr and outlining some of the new divergence patterns specific to Sinhala and Tamil languages. This study proposes a rule-based algorithm to classify a divergence.",2018,L. Nian-feng; W. Li-rong,13,18,6,2,10.1109/IALP.2018.8629113,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629113,IEEE Conferences,IEEE
Extraction of phrases useful for machine translation,translation;lexicon;salient expression,"To improve the quality of a machine translation system, it is useful to extract and store words and phrases which are salient in a domain and should be translated in a specific way. We tried several existing technologies for salient word extraction and compared their mechanisms and quality. Based on the comparison, we propose a new method which includes pre-processing of sentences in corpora and utilization of syntactic information. We evaluated the usefulness of our new method.",2016,L. Quach; C. Nguyen,1,6,6,,10.1109/ICAICTA.2016.7803129,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803129,IEEE Conferences,IEEE
ATM - Awesome Translation Machine,Image capture;Image processing;Character recognition;Pattern recognition methods,"In this paper, we present the ATM (Awesome Translation Machine), which translates handwriting texts in English into Chinese, and then provides its pronunciations in both the two languages. Specifically, two types of the databases that contain characters and sentences for training the ATM are constructed. Various signal processing techniques are employed sequentially for processing and analyzing the image raw data. After all the preparation stages, we apply multiple pattern recognition techniques, i.e., Principle component analysis, linear discriminant analysis, and support vector machines, for the purpose of character recognition. The identified characters are thereby automatically linked to their actual meanings stored. Extensive experiments are conducted to gauge the performance for different techniques.",2014,L. S. Brea; N. B. RodrÃ­guez; A. M. GonzÃ¡lez; K. Evans,226,231,6,,10.1109/ICDH.2014.50,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996765,IEEE Conferences,IEEE
Transliteration Engine for Union Catalogue of Malay Manuscripts in Malaysia: E-Jawi Version 3,Malay Manuscripts;transliteration machine;Information System;E-Jawi;Jawi;text mining tool,"There are several online transliteration tools in web version available for modern Jawi to Rumi and vice versa, however is not available for old Jawi, which was widely used in old Malay manuscripts. E-jawi is one of the well-known Malay-Jawi and Jawi-Malay transliteration tools available online, besides Dewan Bahasa dan Pustaka (DBP) Daftar Rumi-Jawi Beta which transliterate modern jawi terms into rumi and vice versa. This paper aims to review the background of E-Jawi as one of the popular tools available online and the method used by E-Jawi version 3 which is the combination of two methods: E-Jawi Transliteration Database and E-Jawi Algorithm Technique; to compare the results of transliterating old manuscript terms both in old jawi and its modern jawi form (obtained from Daftar Kata Bahasa Melayu: Rumi-Sebutan-Jawi) using E-Jawi; and to propose an initial architecture of text mining tool for transliteration part, which will integrate with E-Jawi as part of its transliteration engine. The pilot data used is extracted from BidaÌ…yat al-mubtadiÌ… bi-FadlillaÌ…h al-MuhdiÌ… manuscript. The research found that E-Jawi has low error percentage for modern jawi and there are some enhancements that can be done in supporting transliteration for old jawi as well as to improve the transliteration for modern jawi. All the findings shall contribute to the development of Union Catalogue of Malay Manuscript (UCMM) catalogue system, which targets to provide an informative platform consisted of old manuscript corpus for Malay Manuscript researchers as well as text mining tool for mining of Manuscripts data.",2018,L. Wang; W. Qu; H. Wang; S. Yu,58,63,6,1,10.1109/ICT4M.2018.00020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567096,IEEE Conferences,IEEE
Neural Machine Based Mobile Applications Code Translation,Cross-Platform Development;Mobile Applications;Data synthesis;Code Conversion;Transformer Model;Android;iOS;Tokenization;Encoding;Tokens accuracy;BLEU,"Although many cross platform mobile development software used a trans-compiler-based approach, it was very difficult to generalize it to work in both directions. For example, to convert between Java for Android Development and Swift for iOS development and vice versa. This is due to the need of writing a specific parser for each source language, and a specific code generator for each destination language. Neural network-based models are used successfully to translate between natural languages, including English, French, German any many others by providing enough datasets and without the need of adding language specific code for understanding and generation. In this paper, a source code converter based on the Neural Machine Translation Transformer Model that can translate from Java to Swift and vice versa is introduced. A synthesized dataset is used to train the model, the pipeline used for the translation as well as the code synthesis procedure throughout the work are illustrated. Initial results are promising and give motivation to further enhance the proposed tool.",2020,L. Wijerathna; W. L. S. L. Somaweera; S. L. Kaduruwana; Y. V. Wijesinghe; D. I. De Silva; K. Pulasinghe; S. Thellijjagoda,302,307,6,,10.1109/NILES50944.2020.9257935,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257935,IEEE Conferences,IEEE
Building a Machine Translation System in a Restrict Context from Ka-Tu Language into Vietnamese,KATU,"The paper introduces some basic characteristics of Ka Tu language, from that we built the machine translation system from Ka Tu language into Vietnamese in a restrict context for translating the weather forecast bulletins, supporting the communication of Ka Tu language of Vietnamese voice emission. The system was tested at the Quang Nam Radio and Television station. The initial Results are Positive for the test of the system. The machine translation system from Ka Tu language into Vietnamese in a restrict context contributed to solving the serious lack of information in aboriginal languages and can be expanded into other areas such as warming fire alarm, broadcasting policies and laws of the State, farming experience, animal husbandry, natural disaster prevetion... Because the corpus with open structure, the optical axis is in Vietnamese language, a multilingual corpus can be easily built by adding other ethnic languages such as Cham, Ede, Jarai, Muong,...",2012,Lin Liu; Hailong Cao; Tiejun Zhao,167,172,6,,10.1109/KSE.2012.26,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299415,IEEE Conferences,IEEE
Handling organization name unknown word in Chinese-Vietnamese machine translation,Chinese-Vietnamese SMT;unknown word;named entity;organization name,"Unknown word (UKW) is an obvious problem of machine translation and named entity (NE) is the most common UKW type. In this paper, we will present a new approach based on the meaning relationship in Chinese and Vietnamese to re-translate organization name UKW. This is the most complicated NE because it consists of other NEs and entities. Applying this approach to Chinese-Vietnamese statistical machine translation (SMT), experimental results show that our approach has significantly improved machine's performance.",2013,Liqing Wan; Longhe Sun,242,247,6,1,10.1109/RIVF.2013.6719901,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719901,IEEE Conferences,IEEE
Handling OOV Words in NMT Using Unsupervised Bilingual Embedding,Machine Translation;Neural Machine Translation;Out-of-Vocabulary Words,"Neural machine translation has recently become the premier approach in Machine Translation however, it still has some unsolved issues. In this paper we have focused on handling the out-of-vocabulary (OOV) words as an open problem in neural machine translation. The method we introduce in this paper chooses appropriate alternative words inside the vocabulary for the OOV words by considering the word embeddings trained on monolingual corpora. Both monolingual and bilingual embeddings are used in finding the proper substitute for each OOV word. Using this technique we have improved the quality of translation up to 2.3 BLEU without using any additional annotated data.",2018,M. A. H. Madhfar; A. M. Qamar,569,574,6,1,10.1109/ISTEL.2018.8661016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661016,IEEE Conferences,IEEE
Improvement of Translation Accuracy for the Outlines of Japanese Statutes by Splitting Parenthesized Expressions,legal information;statistical machine translation,"To globally share Japanese legal information, we translate the Outlines of Japanese statutes. These outlines are the official summaries of Japanese statutes and are useful to quickly understand their contents. In a previous statistical machine translation system for the outlines, we found that the training corpus consisted of both statutes and their outlines, including many long sentences that reduced the translation quality. To solve this problem, we shortened the length of sentences and focused on parenthesized expressions. In this paper, we propose a translation method that splits off parenthesized expressions from the sentences. Experimental result shows the effectiveness of our method.",2015,M. A. Hasan; F. Alam; S. A. Chowdhury; N. Khan,67,72,6,,10.1109/KSE.2015.61,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371760,IEEE Conferences,IEEE
Enhanced Beam-Search Restructuring Restraint for Phrase-Based Statistical Machine Translation,Beam Search;Bilingual evaluation understudy (BLEU);Generalized Limited Discrepancy Search (GLDS);ITG constraints;Word Error Rates (WER),"Within ""Phrase Based Statistical Machine Translation (SMT)"", the hypothesis translation generation is computationally costly. On the off chance that the legitamate subjective reorganization made, then the exploration issue becomes nondeterministic polynomial time (NP)-hard. Then again, on the off chance that the researcher confine the conceivable reordering in a proper way, to get a polynomial-time look calculation. This paper explores diverse reordering limitations for expression-based SMT, specifically the ITG requirements, presenting effective unique programming calculations for the two requirements. the researcher assess the constraints regarding interpretation quality on the Telugu- English undertakings. This paper demonstrates the reordering limitations which enhance the interpretation quality contrasted with an unrestricted exploration with the aim of licenses subjective expression reorganizations. The Inversion Transduction Grammer (ITG) requirements achieve most excellent lying on the two errands and this yield factually huge upgrades contrasted with the unconstrained inquiry.",2019,M. Abrishami; M. J. Rashti; M. Naderan,1,6,6,,10.1109/ICECCT.2019.8869367,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869367,IEEE Conferences,IEEE
Improving Thai-English word alignment for interrogative sentences in SMT by grammatical knowledge,Thai-English interrogative grammatical attribute;Thai-English interrogative sentence;linguistic knowledge;word alignment;statistical machine translation,"This paper presents a method to improve Thai-English word alignment in statistical machine translation (SMT) for interrogative sentences in a parallel corpus. We utilize the Thai and English grammatical knowledge i.e. tense, part of speech (POS), and question inversion pattern. The proposed method handles the difference of Thai and English interrogative sentences using sentence transformation, interrogative grammatical attribute extraction, and interrogative grammatical attribute annotation. This method works as a pre-processing of GIZA, a standard word co-occurrence alignment tool in SMT. We hypothesize that using grammatical knowledge as a pre-processing of GIZA can provide higher accuracy. We experiment by using 43,500 interrogative sentences to compare alignment result between interrogative sentences attached an interrogative grammatical label and interrogative sentences unattached interrogative grammatical label. The experimental results yield 95% of accuracy with significant improvement than the conventional one. With the increasing accuracy of word alignment, the translation accuracy is consequently improved.",2017,M. Bavandpour; M. R. Mahmoodi; D. B. Strukov,226,231,6,1,10.1109/KST.2017.7886115,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886115,IEEE Conferences,IEEE
A multilingual chat system with image presentation for detecting mistranslation,machine translation;image retrieval;keywords;morphological analysis,"We have designed and developed a multilingual chat system, MCHI (Multilingual Chat with Hint Images), which is based on machine translation and equipped with a presentation function of images related to the contents of the messages by utterers so that listeners are able to notice the mistranslation. MCHI accepts English, French, Chinese, Japanese, and Korean languages. It uses Google API to retrieve related images from the image posting site Flickr. As a result of evaluation experiment, we have observed that participants detected the mismatch of a translated message with its related image. According to the answers of participants for a question in a questionnaire, it turned out that the usability of the MCHI system is good enough though the related images are not satisfactory.",2011,M. Bravin; D. PfÃ¤ffli; S. Mazumder; M. Pouly,287,292,6,1,10.2498/cit.1002028,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974037,IEEE Conferences,IEEE
Automating Transliteration of Cuneiform from Parallel Lines with Sparse Data,Cuneiform;Transliteration;HMM;Machine Learning;Computer Linguistics;Online Databases;Handwriting Recognition;Language Modeling,"Cuneiform tablets appertain to the oldest textual artifacts and are in extent comparable to texts written in Latin or ancient Greek. The Cuneiform Commentaries Project (CPP) from Yale University provides tracings of cuneiform tablets with annotated transliterations and translations. As a part of our work analyzing cuneiform script computationally with 3D-acquisition and word-spotting, we present a first approach for automatized learning of transliterations of cuneiform tablets based on a corpus of parallel lines. These consist of manually drawn cuneiform characters and their transliteration into an alphanumeric code. Since the Cuneiform script is only available as raster-data, we segment lines with a projection profile, extract Histogram of oriented Gradients (HoG) features, detect outliers caused by tablet damage, and align those features with the transliteration. We apply methods from part-of-speech tagging to learn a correspondence between features and transliteration tokens. We evaluate point-wise classification with K-Nearest Neighbors (KNN) and a Support Vector Machine (SVM); sequence classification with a Hidden Markov Model (HMM) and a Structured Support Vector Machine (SVM-HMM). Analyzing our findings, we reach the conclusion that the sparsity of data, inconsistent labeling and the variety of tracing styles do currently not allow for fully automatized transliterations with the presented approach. However, the pursuit of automated learning of transliterations is of great relevance as manual annotation in larger quantities is not viable, given the few experts capable of transcribing cuneiform tablets.",2017,M. D. F. Ansari; R. S. Shaji; T. J. SivaKarthick; S. Vivek; A. Aravind,615,620,6,,10.1109/ICDAR.2017.106,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8270037,IEEE Conferences,IEEE
Extrinsic calibration of a laser range finder and a camera based on the automatic detection of line feature,Laser ranger finder;Camera;extrinsic calibration;Automatic detection,"This paper presents an extrinsic calibration method of a camera and a laser range finder based on the automatic detection of the line feature. Firstly, a special 3D calibration target which contained four planes and five edges was projected, and then the visible image and laser data of the 3D calibration target could be obtained. Secondly, the automatic detection method of the line feature was presented, which used the linear fitting to acquire the equations of the line features detected by the Hough transform. With the obtained equations, the laser data corresponding to the line features of the 3D calibration target could be acquired by computing the crossover point of two straight-lines. Finally, the rotation matrix and translation matrix between the camera and laser range finder could be acquired with computing the linear equations provided by the laser data and the corresponding crossover point. Experimental result showed the proposed method could acquire the accurate external calibrations.",2016,M. E. Benalcazar Palacios; M. Brun; V. L. Ballarin; R. M. Hidalgo,448,453,6,3,10.1109/CISP-BMEI.2016.7852753,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852753,IEEE Conferences,IEEE
Development of morpholoical analyzer for Kannada verbs,Natural language processing;Machine translation;Paradigms;Suffix-stripping;Stemmer;Morphological analyzer;Morphological features,"Morphological analyzer is a tool which identifies and analyzes the internal structure of given word and also gives the morphological and grammatical information associated with the given word. Kannada is an inflectional, derivational, agglutinative and morphologically very rich language. Developing a well-fledged morphological analyzer (MA) for Kannada is a challenging task. In this paper, a hybrid MA for Kannada verbs is proposed as a part of machine translation system from Kannada to any other language. This model is developed using suffix-stripping, rule-based and paradigm-based approaches. The performance of this model is tested against a set of verbs randomly taken from a well-known dictionary called â€œKannada Rathna Koshaâ€? [1].",2013,M. Fang; Q. Zhao,22,27,6,,10.1049/cp.2013.2219,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6842966,IET Conferences,IET
MAST: Myo Armband Sign-Language Translator for Human Hand Activity Classification,Electromyography;Myo Armband;Signlanguage Translator;Random Forest;Support Vector Machine;Convolutional Neural Network,"As Computer Science has grown into an encompassed field in various scientific areas, the need for developing a computer aided and artificially intelligent device has become more important especially in the medical field. Artificial Intelligence (AI) plays a vital role not only in accelerating and optimizing common tasks but also in performing tasks that humans are incapable of. This paper presents a Myo Armband Sign-Language Translator (MAST), which is a novel algorithm to translate a hand's gestures into medical sign language using a Myo armband sensor which collects muscles' electromyography signals and then to classify them using an enhanced version of a dynamic random forest. Our experimental results indicate that a systematic fine tuning of MAST parameters leads to an accuracy improvement of 13% over the state-of-the-art scheme such as SCIKIT's random forest. Other comparison results show an improvement of over 20% compared to a popular classification scheme such as Support Vector Machines (SVM) and a deep learning technique such as Convolutional Neural Network (CNN).",2020,M. Haque; M. Hasan,494,499,6,,10.1109/ICTC49870.2020.9289153,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289153,IEEE Conferences,IEEE
A chunk-based reordering model for phrase-based SMT systems,Statistical Machine Translation (SMT);Phrase-Based Translation Models (PBTM);Reordering Models;Chunk-Based Models,"This paper proposed a novel reordering model based on the reordering of source language chunks. This model is used as a preprocessing step of phrase-based translation models and could be well integrated with them. At the same time, as a chunk-based model, syntax information could be concerned in the process of reordering while the entire parsing of the source sentence is not required. Two experiments were carried out and the results showed that the proposed model could improve the performance of a phrase-based statistical machine translation (SMT) system greatly.",2008,M. Islam; G. Mallikharjunudu; A. S. Parmar; A. Kumar; R. H. Laskar,1,6,6,1,10.1109/NLPKE.2008.4906767,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906767,IEEE Conferences,IEEE
Translating Natural Language Sentences into Database Query,Natural Language Processing;Logical Forms;Machine Learning,"The aim of this work is to transcribe natural language statements into logical forms, specifically SQL statements. The purpose of such conversion is to efficiently interact with the database. In this work, for sequence translation, an RNN auto-encoder is used which has been the foundation for several online translation between human languages. Decoder used is hierarchical RNN's, which has the ability to extract additional structure information from the special encodings in the training data inputs. This provides the decoder more information about the structure of the output that it can then correlate back to the inputs and generalize statements with the same logical form but with different specifics, such as locations, points of interest, time spans, or people. Evaluation is done on Geo-Query dataset and experimental results achieved good results.",2018,M. J. C. Samonte; J. A. V. Lopez; J. L. C. Santiago,1,6,6,,10.1109/ICETIETR.2018.8529006,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8529006,IEEE Conferences,IEEE
Abusive Comments Detection in Bangla-English Code-mixed and Transliterated Text,code-mixing;transliterated;machine learning;svm;random forest;adaboost;profanitype;cybercrime;cyberbullying;cyber-harassment;hate speech;abusive words;curse words;comments;bangla text,"The comment section in public websites, while reflecting public opinion and enabling people to provide constructive criticism or to show appreciation, can be viewed by some people as a stage to use vulgar and offensive words without any consequences. With the rising popularity of micro-blogging websites like Facebook, Twitter etc., Bangla Language speakers' tendency to use code-mixing and transliteration is increasing as well. Manually checking and removing abusive comments from public websites can get tedious, which is undesirable in the present day of technological automation. In this paper, we propose a method to detect abusive comments using Machine Learning algorithms. This paper works not only with Bangla text but also with Bangla-English code-mixed text and transliterated Bangla text. The proposed method involves great amount of preprocessing as a result of people's disregard for correct spelling, grammar and punctuation when it comes to writing comments on the internet. For the dataset, we collected comments from public Facebook pages along with the number of likes they got. For features, we used Unigrams, Bigrams, number of likes, emojis along with their categories, sentiment scores, offensive and threatening words used in the comments, detected using our proposed algorithm, and the number of abusive words in each comment. The aforementioned algorithm can detect profanitypes too. After experimenting with three Machine Learning algorithms, namely Support Vector Machine, Random Forest, and Adaboost, the proposed method achieved a highest accuracy of 72.14%.",2019,M. M.; S. P.,1,6,6,,10.1109/ICIET48527.2019.9290630,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290630,IEEE Conferences,IEEE
Realizing Target Language Generation in Data-Oriented English-Chinese Machine Translation,Data-Oriented Parsing;target language generation;treebank;fragment bank;fragment-combination-form bank;generation-fragment-combination-form,"This paper presents a kind of target language generation mechanism in data-oriented English-Chinese machine translation. This mechanism applies the theory of data-oriented parsing used in language analysis traditionally into target language generation equally. Through linearizing the result of source language analysis - a parse tree, the final translation in target language is generated. To prove the efficiency of the proposed method, the knowledge source is constructed based on the real-world English corpus, and the other real-world English corpus is used as the test set. The experiment result shows that the quality of translation in target language is satisfactory",2006,M. Mohaghegh; A. Sarrafzadeh,2624,2629,6,,10.1109/ICMLC.2006.258915,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028506,IEEE Conferences,IEEE
Evaluation of Transformer model performance on a set of language pairs by varying standard parameters,Transformer Model;Neural Machine Translation;BLEU score;TED talk Dataset,"In this paper, we have performed machine translation using modified Transformer model on TED Talk Dataset and from this we have selected four language pairs (English-Portuguese, Russian-English, French-Portuguese, Turkish-English) for testing. We have evaluated and analyzed the machine translation model on critical criteria's such as dataset size, batch size and training time over all four language pairs and have used BLEU scoring to generalize the results. We have searched for general trends and have analyzed the impacts of these variations on the scoring of the translation upon variation of different parameters, this analysis has been performed on each language pairs as well as have been compared with the results of other language pairs. From the results we found that with increase in dataset size, batch size and training time the BLEU score increases. The English - Portuguese pair achieves highest BLEU score of 23.2 from all language pairs and we get lowest BLEU score of 19.1 from the French - Portuguese pair.",2021,M. Nassirudin; A. Purwarianti,194,199,6,,10.1109/ICIPTM52218.2021.9388359,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388359,IEEE Conferences,IEEE
Neural network-based reranking model for statistical machine translation,SMT;reranking;neural network;conjugate gradient method,"The non-local feature always plays an important role in improving performance of SMT. Nonlinear neural network model can take better advantage of non-local features to improve the performance of translation through the introduction of the hidden layer. So this paper will build reranking models based on neural network to make use of non-local features to improve the translation performance. In this paper, we will introduce two models: Reranker-WC and Reranker-D. Compared with performance of the baseline system, the performance of Reranker-WC can be promoted to about 1.4 BLEU score. Moreover, we find that different hyper-parameter Î» will also affect the quality of SMT output at the same time. We achieve the best performance while Î» is 40.",2014,M. Nauman; A. Hassan; F. Riaz; S. Rehman; R. W. Nedergard; K. Holt; H. Haavik; I. K. Niazi,460,465,6,2,10.1109/FSKD.2014.6980878,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980878,IEEE Conferences,IEEE
File model approach to optimize the performance of Tree Adjoining Grammar based Machine Translation,Performance optimization;NLP complexity;File model;Tree Adjoining Grammar;Parser;Generator;Natural Language Processing and Speedup,"The growing pace of information technology demands fast operation for communication and other related applications. After having a successful Machine Translation System [MTS], it has been felt to optimize the performance of Machine Translation for its real-time uses. The considered MTS is Tree Adjoining Grammar [TAG] based system. An approach has been experimented to use File model instead of Database model for fast streaming of grammar into memory and operation. This model provides an efficient and a systematic way of encapsulating language resource with engineering solution to develop the speedy MTS. The computational experiments demonstrate that substantial performance in terms of time and memory has been obtained by using this approach.",2015,M. Nguyen; V. TanBui; H. Vu; P. Nguven; C. Luong,1,6,6,,10.1109/IC4.2015.7375652,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375652,IEEE Conferences,IEEE
Phone-to-word decoding through statistical machine translation and complementary system combination,ASR system combination;phone-to-word transducer;word graph rescoring,"In this paper, phone-to-word transduction is first investigated by coupling a speech recognizer, generating for each speech segment a phone sequence or a phone confusion network, with the efficient decoder of confusion networks adopted by MOSES, a popular statistical machine translation toolkit. Then, system combination is investigated by combining the outputs of several conventional ASR systems with the output of a system embedding phone-to-word decoding through statistical machine translation. Experiments are carried out in the context of a large vocabulary speech recognition task consisting of transcription of speeches delivered in English during the European Parliament Plenary Sessions (EPPS). While only a marginal performance improvements is achieved in system combination experiments when the output of the phone-to-word transducer is included in the combination, partial results show a great potential for improvements.",2009,M. Nimaiti; Y. Izumi,519,524,6,1,10.1109/ASRU.2009.5373281,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5373281,IEEE Conferences,IEEE
Adopting New Rules in Rule-Based Machine Translation,MT;Grammar;SL;TL;NLP;Parser;APP;POS;VSO;RBMT,"This paper examines the agreement and word-order tackling in Arabic MT systems. The paper represents an English to Arabic approach for translating well-structured English sentences into well-structured Arabic sentences using a new rules to handle the problems of ordering and agreement. The methodology is flexible and scalable, the main advantages are: first, it is a rule-based approach, and second, it can be applied on some other languages with minor modifications. The database has been designed to be flexible where most of the rules are defined in tables in order to generalize the code. Validation rules have been applied in both the database design and the programming code in order to ensure the integrity of data. A major design goal of this system is that it will be used as a stand-alone tool and can be very well integrated with a general machine translation system for English sentence.",2010,M. Nuo; H. Liu; L. Ma; J. Wu; Z. Ding,62,67,6,2,10.1109/UKSIM.2010.20,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5481082,IEEE Conferences,IEEE
Calculating Wikipedia Article Similarity Using Machine Translation Evaluation Metrics,Cross-language Document Similarity;Bilingual Dictionary Construction;Wikipedia Mining,"Calculating the similarity of Wikipedia articles in different languages is helpful for bilingual dictionary construction and various other research areas. However, standard methods for document similarity calculation are usually very simple. Therefore, we describe an approach of translating one Wikipedia article into the language of the other article, and then calculating article similarity with standard machine translation evaluation metrics. An experiment revealed that our approach is effective for identifying Wikipedia articles in different languages that are covering the same concept.",2011,M. Orhun; A. Cuneyd Tantug; E. Adali; A. C. Sonmez,620,625,6,1,10.1109/WAINA.2011.132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763570,IEEE Conferences,IEEE
Neural Machine Translation Strategies for Generating Honorific-style Korean,honorific fusion training;data labeling;korean honorific,"Expression with honorifics is an important way of dressing up the language and showing politeness in Korean. For machine translation, generating honorifics is indispensable on the formal occasion when the target language is Korean. However, current Neural Machine Translation (NMT) models ignore generation of honorifics, which causes the limitation of the MT application on business occasion. In order to address the problem, this paper presents two strategies to improve Korean honorific generation ratio: 1) we introduce honorific fusion training (HFT) loss under the minimum risk training framework to guide the model to generate honorifics; 2) we introduce a data labeling (DL) method which tags the training corpus with distinctive labels without any modification to the model structure. Our experimental results show that the proposed two strategies can significantly improve the honorific generation ratio by 34.35% and 45.59%.",2019,M. P. Paulraj; A. H. Adom; C. R. Hema; D. Purushothaman,450,455,6,,10.1109/IALP48816.2019.9037681,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037681,IEEE Conferences,IEEE
"A Comparison of Transformer, Recurrent Neural Networks and SMT in Tamil to Sinhala MT",Neural Machine Translation (NMT);Byte Pair Encoding (BPE);Sinhala;Tamil,"Neural Machine Translation (NMT) is currently the most promising approach for machine translation. The attention mechanism is a successful technique in modern Natural Language Processing (NLP), especially in tasks like machine translation. The recently proposed network architecture of the Transformer is based entirely on attention mechanisms and achieves a new state of the art results in neural machine translation, outperforming other sequence-to-sequence models. Although it is successful in a resource-rich setting, its applicability for low-resource language pairs is still debatable. Additionally when the language pair is morphologically rich and also when the corpora is multi-domain, the lack of a large parallel corpus becomes a significant barrier. In this study, we explore different NMT algorithms - Long Short Term Memory (LSTM) and Transformer based NMT, to translate the Tamil to Sinhala language pair. Where we clearly see transformer outperforms LSTM by 2.43 BLEU score for Tamil to Sinhala direction. And this work provides a preliminary comparison of statistical machine translation (SMT) and Neural Machine Translation (NMT) for Tamil to Sinhala in the open domain context.",2020,M. S. Z. Azalan; M. P. Paulraj; S. bin Yaacob,155,160,6,,10.1109/ICTer51097.2020.9325431,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325431,IEEE Conferences,IEEE
CUDA-Based Parallel Implementation of IBM Word Alignment Algorithm for Statistical Machine Translation,Word Alignment;GPU;Parallel Computation;Expectation-Maximization Algorithm;CUDA,"Word alignment is a basic task in natural language processing and it usually serves as the starting point when building a modern statistical machine translation system. However, the state-of-art parallel algorithm for word alignment is still time-consuming. In this work, we explore a parallel implementation of word alignment algorithm on Graphics Processor Unit (GPU), which has been widely available in the field of high performance computing. We use the Compute Unified Device Architecture (CUDA) programming model to re-implement a state-of-the-art word alignment algorithm, called IBM Expectation-Maximization (EM) algorithm. A Tesla K40M card with 2880 cores is used for experiments and execution times obtained with the proposed algorithm are compared with a sequential algorithm and a multi-threads algorithm on an IBM X3850 server, which has two Intel Xeon E7 CPUs (2.0GHz * 10 cores). The best experimental results show a 16.8-fold speedup compared to the multi-threads algorithm and a 234.7-fold speedup compared to the sequential algorithm.",2016,M. Senthilarasi; S. M. M. Roomi; M. R. H. Prasanna,189,194,6,1,10.1109/PDCAT.2016.050,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7943355,IEEE Conferences,IEEE
Machine translation using deep learning: An overview,Neural Network(NN);Deep neural network(DNN);convolutional neural network(CNN);feed-forward neural network(FNN);recurrent neural network(RNN);recursive auto-encoder( RAE);Long Short-term memory(LSTM),"This Paper reveals the information about Deep Neural Network (DNN) and concept of deep learning in field of natural language processing i.e. machine translation. Now day's DNN is playing major role in machine leaning technics. Recursive recurrent neural network (R2NN) is a best technic for machine learning. It is the combination of recurrent neural network and recursive neural network (such as Recursive auto encoder). This paper presents how to train the recurrent neural network for reordering for source to target language by using Semi-supervised learning methods. Word2vec tool is required to generate word vectors of source language and Auto encoder helps us in reconstruction of the vectors for target language in tree structure. Results of word2vec play an important role in word alignment of the input vectors. RNN structure is very complicated and to train the large data file on word2vec is also a time-consuming task. Hence, a powerful hardware support (GPU) is required. GPU improves the system performance by decreasing training time period.",2017,M. Sharma,162,167,6,15,10.1109/COMPTELIX.2017.8003957,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8003957,IEEE Conferences,IEEE
Evaluating Human-Machine Translation with Attention Mechanisms for Industry 4.0 Environment SQL-Based Systems,NLP;Attention;Industry;IoT;Measurement;SQL;Deep Learning,"The use of relational databases is increasingly present in the industry. Applications in medical, IoT and industry 4.0 are examples of this. Despite the large capacity and efficiency in storing and retrieving data, this type of database requires technical knowledge in specific query languages to access this information, which distances these types of application from the lay public. In this work, we propose an application of recent models in natural language processing that use neural networks, as well as attention mechanisms for the translation of natural language in English to SQL applied in an SQL database of a system to store data from sensors, focused on the concept of Industry 4.0. Paired examples of natural language phrases were generated with their corresponding SQL query to be used for training and validation. By training the neural network, we obtained a language model with an accuracy of approximately 99 % in the validation set.",2020,M. Sharma; M. Jain; M. Garg; M. M. Tripathi,229,234,6,,10.1109/MetroInd4.0IoT48571.2020.9138181,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138181,IEEE Conferences,IEEE
Identifying Racist Social Media Comments in Sinhala Language Using Text Analytics Models with Machine Learning,racism;social media;text analytics;machine learning.,"Racism or the act of discriminating people based on their race, gender, skin colour and other such related factors has been ruling the world since ancient times. With the development of technology and the introduction of various platforms to communicate with each other such as social media, it soon turned in to a platform to spread racial thoughts within communities. This became a serious issue when certain conversations and actions lead to the outbreak and spread of violence within communities. One such incident that happened in China caused banning of Facebook and certain social media inside the country permanently, while in March 2018, another incident that happened in Sri Lanka made the government ban social media for about one week to stop the spreading of false information and racist thoughts that can make the situation worst. Later, the social media authorities released a statement specifying that the reason why they failed to moderate and stop the spread of hatred and racist comments was due to the unavailability of language translators within their organization. Therefore, the requirement for automatic identification of racist comments on social media has become of utmost importance. However, simple keyword spotting techniques cannot be used to accurately identify the exact intent of a comment. In this paper, we address this issue by building a text analytics model with machine learning that can be used to filter racist comments in Sinhala language. A Two-Class Support Vector Machine was trained with a set of carefully chosen comments from Facebook that were labelled as racist and non-racist based on intent. The trained model was then able to classify racist comments with a 70.8% accuracy in our experimental results.",2018,M. Taraghi; S. Khadivi,1,6,6,3,10.1109/ICTER.2018.8615492,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615492,IEEE Conferences,IEEE
Semantic Document Exchange through Mediation of Machine Natural Language,Semantic document exchange;Natural language processing;Machine natural language;Universal grammar,"In global e-commerce, semantic document exchange ensures unambiguity and shares same meaning for documents sender and receiver cross different natural languages (e.g., English to Chinese), as the difference makes the translation between cross-language documents complex and inaccurate. This paper proposed a novel collaborative framework of semantic document exchange through a mediation approach which provides a sentence-based machine natural language (MNL). Here, the MNL constructs a grammatical case structure to compatible with all languages. Thus, the mediation framework enables the sentence computer-readable and understandable without ambiguity, simultaneously the MNL can improve accuracy and reduce the complexity of mapping in semantic document exchange.",2018,M. Tariq; A. Iqbal; A. Zahid; Z. Iqbal; J. Akhtar,245,250,6,,10.1109/ICEBE.2018.00047,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8592658,IEEE Conferences,IEEE
Transformational generative grammar (TGG): An efficient way of parsing Bangla sentences,natural language processing;machine translation;lexical analysis;syntactic analysis;transformational generative grammar;parse tree;lexicon,"Natural language processing (NLP) refers to the ability of systems to process sentences in a natural language such as Bangla, rather than in a specialized artificial computer language. Computer processing of Bangla language is a challenging task due to its varieties of words formation and way of speaking. The same meaning can be expressed in different ways which is a great challenge to face for translation by an automatic machine translation system. With the advent of internet technology and e-commerce, the demand of automatic machine translation has been increased. Parsing is essential for any type of natural language processing. Parsing of Bangla natural language can be used as a subsystem for Bangla to another language machine aided translation. A parser usually checks the validity of a sentence using grammatical rule. In this paper, we propose a set of transformational generative grammar (TGG) in conjunction with phrase structure grammar to generate parse tree and to recognize assertive, interrogative, imperative, optative and exclamatory sentences of Bangla language. It is applicable for many sentences that cannot be parsed using only phrase structure grammars. The process involves analysis of Bangla sentence morphologically, syntactically where tokens and grammatical information are passed through parsing stage and finally output can be achieved. A dictionary of lexicon is used which contains some syntactic, semantic, and possibly some pragmatic information. We have tested our system for different kinds of Bangla sentences and experimental result reveals that the overall success rate of the proposed system is 84.4%.",2016,M. Tufano; C. Watson; G. Bavota; M. di Penta; M. White; D. Poshyvanyk,1,6,6,,10.1109/ICECTE.2016.7879583,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879583,IEEE Conferences,IEEE
Design and implementation of an efficient DeConverter for generating Bangla sentences from UNL expression,DeConverter;EnConverter;Machine Translation;UNL,"In this paper, the design and implementation of Bangla DeConverter for DeConverting Universal Networking Language (UNL) expressions into the Bangla Language is propounded. The UNL is an Artificial Language, which not only facilitates the translation stratagem between all the Natural Languages across the world, but also proffers the unification of those Natural Languages as well. DeConverter is the core software contrivance in a UNL system. The paper also focuses on the Linguistic Analysis of Bangla Language for the DeConversion process. A set of DeConversion rules have been burgeoned for converting UNL expression to Bangla. Experimental result shows that these rules successfully generate correct Bangla text from UNL expressions. These rules can currently produce basic and simple Bangla sentences; however, it is being aggrandized to superintend advanced and complex sentences.",2015,M. Vosoughpour Yazdchi; H. Faili,1,6,6,,10.1109/ICIEV.2015.7334006,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334006,IEEE Conferences,IEEE
Learning Method for Extraction of Partial Correspondence from Parallel Corpus,extraction rule;learning;machine translation;partial correspondence;parallel corpus,"For machine translations using a parallel corpus, it is effective to extract partial correspondences: pairs of phrases of the source language(SL) and target language(TL) in bilingual sentences. However, it is difficult to extract the partial correspondences correctly and efficiently in the data sparse corpus. In this paper, we propose a new learning method that extracts the partial correspondences solely from the parallel corpus without any analytical tools. In the proposed method, the extraction rules are automatically acquired from bilingual sentences using bi-gram statistics in each language sentence and the similarity based on Dice coefficient between SL words and TL words. The acquired extraction rules possess information about the first parts(e.g., ""a"", ""the"") or the last parts in phrases. Moreover, the partial correspondences are extracted from the bilingual sentences using the extraction rules correctly and efficiently. Evaluation experiments indicated that our proposed method can improve the translation quality of the learning-type machine translation by correctly and efficiently extracting the partial correspondences in bilingual sentences.",2009,M. W. Ahmad; M. E. Arafat; S. M. Shovan; M. Uddin; O. F. Osama; S. Shatabda,293,298,6,2,10.1109/IALP.2009.69,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380752,IEEE Conferences,IEEE
Numerical Methods for Retrieval and Adaptation in Nagaoâ€™s EBMT model,Example-based machine translation;Numerical methods,"We build an example-based machine translation system. It is an instance of case-based reasoning for machine translation. We introduce numerical methods instead of symbolic methods in two steps: retrieval and adaptation. For retrieval, we test three different approaches to define similarity between sentences. For adaptation, we use neural networks to solve analogies between sentences across languages. Oracle experiments allow to identify the best retrieval technique and to estimate the possibilities of such an approach. The system could place itself between a statistical and a neural machine translation systems on a task with not so large data.",2018,M. Wolfel; M. Kolss; F. Kraft; J. Niehues; M. Paulik; A. Waibel,195,200,6,,10.1109/ICACSIS.2018.8618226,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618226,IEEE Conferences,IEEE
A mobile application of American sign language translation via image processing algorithms,Computer Vision;Gesture Recognition;Image Processing;Machine Learning;Sign Language,"Due to the relative lack of pervasive sign language usage within our society, deaf and other verbally-challenged people tend to face difficulty in communicating on a daily basis. Our study thus aims to provide research into a sign language translator applied on the smartphone platform, due to its portability and ease of use. In this paper, a novel framework comprising established image processing techniques is proposed to recognise images of several sign language gestures. More specifically, we initially implement Canny edge detection and seeded region growing to segment the hand gesture from its background. Feature points are then extracted with Speeded Up Robust Features (SURF) algorithm, whose features are derived through Bag of Features (BoF). Support Vector Machine (SVM) is subsequently applied to classify our gesture image dataset; where the trained dataset is used to recognize future sign language gesture inputs. The proposed framework has been successfully implemented on smartphone platforms, and experimental results show that it is able to recognize and translate 16 different American Sign Language gestures with an overall accuracy of 97.13%.",2016,M. Z. Boito; A. BÃ©rard; A. Villavicencio; L. Besacier,104,109,6,23,10.1109/TENCONSpring.2016.7519386,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519386,IEEE Conferences,IEEE
GLAsT: Learning formal grammars to translate natural language specifications into hardware assertions,hardware design;verification;machine learning;natural language processing,"The purpose of functional verification is to ensure that a design conforms to its specification. However, large written specifications can contain hundreds of statements describing correct operation which an engineer must use to create sets of correctness properties. This laborious manual process increases both verification time and cost. In this work we present GLAsT, a new learning algorithm which accepts a small set of sentences describing correctness properties and corresponding SystemVerilog Assertions (SVAs). GLAsT creates a custom formal grammar which captures the writing style and sentence structure of a specification and facilitates the automatic translation of English specification sentences into formal SystemVerilog Assertions. We evaluate GLAsT on English sentences from two ARM AMBA bus protocols. Results show that a translation system using the formal grammar generated by GLAsT automatically generates correctly formed SVAs from the targeted AMBA specification as well as from a second, different AMBA bus specification.",2016,M. Z. Mohamed; A. Ihalapathirana; R. A. Hameed; N. Pathirennehelage; S. Ranathunga; S. Jayasena; G. Dias,966,971,6,5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459447,IEEE Conferences,IEEE
Describing images by feeding LSTM with structural words,Image description;structural words;LSTM;machine translation,"Generating semantic description draws increasing attention recently. Describing objects with adaptive adjunct words make the sentence more informative. In this paper, we focus on the generation of descriptions for images according to the structural words we have generated such as a tetrad of <;object, attribute, activity, scene>. We propose to use deep machine translation method to generate semantically meaningful descriptions. In particular, the description is composed of objects with appropriate adjunct words, corresponding activities and scene. We propose to use a multi-task method to generate structural words. Taking these words sequence as source language, we train a LSTM encoder-decoder machine translation model to output the target language. Experiments on the benchmark datasets demonstrate our method has better performance than state-of-the-art methods of image caption in terms of language generation metrics.",2016,M. Zhou; M. Huang; X. Zhu,1,6,6,7,10.1109/ICME.2016.7552883,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552883,IEEE Conferences,IEEE
Lexico-syntactic normalization model for noisy SMS text,Natural Language Processing;Machine Translation;Social Media;Text Normalization;Noisy words;SMS;Non-noisy word;Lexical Normalization;Parser,"Today, digital mediated interactions and communications being an important constituent. The expeditious growth of electronic communications such as Emails, micro blogs, SMS and chats etc has fabricated extensively noisy forms of text. It predominantly in young urbanites. The tremendous growth of noises in text are due to a variety of factors, such as the small number of characters allowed per text messages (160 characters is allowed per SMS and 140 characters allowed per tweets), inventing new abbreviations, using non standard orthographic forms, phonetic substitution etc. In this paper we introduce a lexico-syntactic normalization model for cleaning the noisy texts. The normalization is based on the channelized database and a user feedback system. The syntactic analysis of sentences is based on a bottom up parser. The model will capture the user interaction for improving the model accuracy. Precursory evaluation shows that the channel model will normalize the noisy word to their standard peer with better accuracy. The sentence validation achieved 95.7% accuracy.",2014,N. Askarian; A. Fazly; A. Hamzeh,163,168,6,2,10.1109/ICECCE.2014.7086652,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7086652,IEEE Conferences,IEEE
Towards Automated Translating Natural Language Sentences into Intensional Constructions,logical analysis of natural language;natural language processing;semantic machine,"This paper aims to introduce a new and original implementation of the semantic machine of transparent intensional logic. This logic system is characterized by its procedural semantics, thanks to which it is used in the field of logical analysis of natural language. Transparent intensional logic is a high-order logic, where partial functions of the intensional typed Î»-calculus allow to remove the semantic ambiguities of natural language. Natural language expressions are usually analyzed in three steps - type analysis, synthesis of construction, and type control, which is an optional step. The presented implementation of the semantic machine of transparent intensional logic is focused on the first two of the mentioned steps of formalizing the meaning of sentences. This semantic machine uses outputs from the Stanford CoreNLP parser. Its functionality and correctness are demonstrated at the end of the paper through the analysis of several sentences of natural language.",2019,N. C. Tamer; M. SaraÃ§lar,345,350,6,,10.1109/Informatics47936.2019.9119252,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119252,IEEE Conferences,IEEE
Improved punctuation recovery through combination of multiple speech streams,speech recognition;machine translation;punctuation;multistream;combination,"In this paper, we present a technique to use the information in multiple parallel speech streams, which are approximate translations of each other, in order to improve performance in a punctuation recovery task. We first build a phraselevel alignment of these multiple streams, using phrase tables to link the phrase pairs together. The information so collected is then used to make it more likely that sentence units are equivalent across streams. We applied this technique to a number of simultaneously interpreted speeches of the European Parliament Committees, for the recovery of the full stop, in four different languages (English, Italian, Portuguese and Spanish). We observed an average improvement in SER of 37% when compared to an existing baseline, in Portuguese and English.",2013,N. Deniz ALP; C. Turhan,132,137,6,1,10.1109/ASRU.2013.6707718,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707718,IEEE Conferences,IEEE
Extending BLEU Evaluation Method with Linguistic Weight,Machine translation evaluation;BLEU;Linear regression;linguistic weight.,"BLEU is one of the most popular metrics for automatic evaluation of machine translation quality. Focusing on its ignorance of different effects of various translation units upon translation quality, this paper extends proper weights to different words and n-grams in the framework of BLEU. The linear regression method is adopted to capture the human perception on translation quality via word types and n-gram length. Compared with other linguistic-rich metrics based on machine learning, the proposed approach is simple and largely preserves BLEUpsilas advantage of language independence. Experimental results indicate that this method brings a much better evaluation performance for both human translation and machine translation than original BLEU.",2008,N. J. Ria; S. A. Khushbu; M. A. Yousuf; A. K. M. Masum; S. Abujar; S. A. Hossain,1683,1688,6,3,10.1109/ICYCS.2008.362,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4709226,IEEE Conferences,IEEE
An Approach to Sign Language Translation using the Intel RealSense Camera,Sign Language Translation;American Sign Language;Intel RealSense;Machine Learning,"An Intel RealSense camera is used for translating static manual American Sign Language gestures into text. The system uses palm orientation and finger joint data as inputs for either a support vector machine or a neural network whose architecture has been optimized by a genetic algorithm. A data set consisting of 100 samples of 26 gestures (the letters of the alphabet) is extracted from 10 participants. When comparing the different learners in combination with different standard preprocessing techniques, the highest accuracy of 95% is achieved by a support vector machine with a scaling method, as well as principal component analysis, used for preprocessing. The highest performing neural network system reaches 92.1% but produces predictions much faster. We also present a simple software solution that uses the trained classifiers to enable user-friendly sign language translation.",2018,N. Koshizuka,219,224,6,2,10.1109/CEEC.2018.8674227,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674227,IEEE Conferences,IEEE
Human-in-the-Loop Error Precursor Detection using Language Translation Modeling of HMI States,Attention;Human Machine Interface (HMI);Human-in-the-loop error;Expert Supervisory System;Natural Language Processing;Sequence to Sequence(Seq2Seq),"Situational Awareness (SA) is paramount to ensuring operational safety in Nuclear Power Plant (NPP) and Commercial aviation industry. An increase in Human-in-the-loop (HITL) error rate may be indicative of reduced operator SA while undermining safety. In this paper, natural language processing (NLP) is applied for modelling industrial Human Machine Interface (HMI) state transitions as a means to detect operator HITL error precursors in real-time. A custom seq2seq encode-decoder deep-learning model design is implemented and evaluated using real-plant scenario dataset obtained from a NPP Operator training simulator. Results support NLP HMI state model may be employed to detect HITL error precursor within the desired N time-steps prior to an accident event.",2020,N. Kritsuthikul; A. Thammano; T. Supnithi,2237,2242,6,,10.1109/SMC42975.2020.9283392,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283392,IEEE Conferences,IEEE
System Independent Machine Fault Diagnosis Using Convolutional Neural Networks,Machine fault diagnosis;Support vector machine (SVM);Nuisance attribute projection (NAP);Deep learning (DL);Convolutional neural network (CNN),"A unified fault-modeling approach for machines with varying capacity, rating, size is of interest in automating production facilities. Building a unified fault-model is challenging due the presence of system specific attributes in the features derived. We explore how the effect of system specific attributes from the feature vectors can be minimized to improve the performance of system independent fault models(SIFM). In this work, we used three-phase synchronous generators with 3kVA and 5kVA ratings, for detecting the stator inter-turn short circuit faults. Our baseline-system uses statistical features derived from the current signal, with a support vector machine(SVM) used as a backend-classifier.In the first approach, we consider the system specific attributes as a nuisance and remove it using nuisance attribute projection (NAP) algorithm. We obtained a performance improvement of 19.63%, 8.31% and 11.80% classification accuracy for R,Y, B phases respectively, over the baseline-system.When we use a SVM backend-classifier, it is required that the features match the kernels used with the SVM. This often limits the performance of the classifier. Next, we explored convolutional neural networks(CNN) with the raw current signal as its input. Max-pooling is a technique used to minimize the size of feature map, simultaneously it construct a condensed feature map by selecting translation-invariant features. Thus, CNNs have the ability to absorb the irrelevant system specific variations, and improve the SIFM performance. It is observed that the CNN based SIFM outperforms NAP-SVM model by 12.56%, 10.37% and 20.15%, for R, Y, B phase fault models respectively.",2018,N. Nur; N. Park; K. Lee; H. Kang; S. Kwon,1,6,6,,10.1109/INDICON45594.2018.8987125,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987125,IEEE Conferences,IEEE
Experiments for various alignment models in Chinese-to-English SMT,word alignment;experiment analysis;statistical machine translation,"In this paper we analyze and compare three basic word alignment models to acquire the useful knowledge and parameters for the statistical machine translation. A series of experiments are made and a very detailed analysis based on the experiments is given. According to the different features of the three models, the merits and demerits of the models are described and analyzed respectively. Finally, the word alignment probabilities and the phrases extracted using HMM Viterbi-alignment are used to develop the Chinese-to-English statistical machine translation system. The experimental results show that the translation quality will be increased with the preprocessing of the training data, joining of the dictionary and enlarging the translation grain appropriately.",2005,N. P. Wright; R. Gan; C. McVae,443,448,6,,10.1109/NLPKE.2005.1598778,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1598778,IEEE Conferences,IEEE
Sign language localization: Learning to eliminate language dialects,Sign Language Recognition;Dialect Independence;Machine Translation;Digital Image Processing;Artificial Neural Networks,"Machine translation of sign language into spoken languages is an important yet non-trivial task. The sheer variety of dialects that exist in any sign language makes it only harder to come up with a generalized sign language classification system. Though a lot of work has been done in this area previously but most of the approaches rely on intrusive hardware in the form of wired or colored gloves or are specific language/dialect dependent for accurate sign language interpretation. We propose a cost-effective, non-intrusive webcam based solution in which a person from any part of the world can train our system to make it learn the sign language in their own specific dialect, so that our software can then correctly translate the hand signs into a commonly spoken language, such as English. Image based hand gesture recognition carries sheer importance in this task. The heart of hand gesture recognition systems is the detection and extraction of the sign (hand gesture) from the input image stream. Our work uses functions like skin color based thresholding, contour detection and convexity defect for detection of hands and identification of important points on the hand respectively. The distance of these important contour points from the centroid of the hand becomes our feature vector against which we train our neural network. The system works in two phases. In the training phase the correspondence between users hand gestures against each sign language symbol is learnt using a feed forward neural network with back propagation learning algorithm. Once the training is complete, user is free to use our system for translation or communication with other people. Experimental results based on training and testing the system with numerous users show that the proposed method can work well for dialect-free sign language translation (numerals and alphabets) and gives us average recognition accuracies of around 65% and 55% with the maximum recognition accuracies rising upto 77% and 62% respectively.",2012,N. Piazza,17,22,6,4,10.1109/INMIC.2012.6511463,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6511463,IEEE Conferences,IEEE
Research on Chinese-English Cross-Language Information Retrieval,Information retrieval;Cross-language information retrieval;Machine translation;Machine readable dictionary;Word segmentation,"With the rapid growing amount of available information, an important problem is formed, to match the user queries specified in one language against documents in another different language, i.e. cross-language information retrieval. Based on the work for cross-language information retrieval evaluation task in the 9th Text Retrieval Conference, a Chinese-English cross-language information retrieval pattern has been constructed. In this pattern, Chinese-English query translation is adopted as the dominant strategy, Chinese queries are used as translation objects, and Chinese-English machine readable dictionaries are utilized as the important knowledge source to acquire correct translations. By combining English monolingual information retrieval module constructed, the Chinese-English cross-language information retrieval process can be implemented successfully.",2008,N. T. Duc; S. Ryu; M. Choi; M. N. Iqbal Qureshi; B. Lee,2591,2596,6,1,10.1109/ICMLC.2008.4620845,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4620845,IEEE Conferences,IEEE
Similar words in Turkic languages,Similar Words;Machine Translation;Turkic Languages;Uzbek Grammar;Uyghur Sentence,"Detecting and analyzing similar words are an important component of natural language processing tasks such as information retrieval, document clustering, making dialog systems, word-sense disambiguation, text summarization and machine translation systems etc. Similar words have notable effect on machine translation. Especially, close languages such as Uyghur, Uzbek, Turkmen, Kazakh, Kyrgyz, Tatar, Azeri and Turkish that belong to the Turkic languages family. There are a huge number of similar words, and these similar words affect the quality of translations. In this article, computer-based methods were suggested to detect similar words in Turkic languages and proposed method has been tested to find similar words in Uzbek and Uyghur.",2017,N. T. T. Aung; N. L. Thein,49,54,6,,10.1109/UBMK.2017.8093556,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093556,IEEE Conferences,IEEE
Unsupervised word sense disambiguation and rules extraction using non-aligned bilingual corpus,Word Sense Disambiguation;Natural Language Processing;Machine Translation,"This paper presents a statistical word sense disambiguation with application in Portuguese-Chinese machine translation systems. Due to the limited availability of Portuguese-Chinese resources in the form of digital corpora and annotated Treebank, an unsupervised learning and a non-aligned bilingual corpus are applied. The proposed method first identifies words related to each of the ambiguous words based on their surrounding words and relative distance. A mathematical model is then applied in the identification of the most suitable sense of an ambiguous word in terms of the related words. All the senses discovered are converted into a set of rules and stored in the sense knowledge base for later use in disambiguation and translation process. Preliminary experiment results show an improvement of 6% in assigning correctly the corresponding translation over the baseline method.",2005,N. T. T. Thuy; N. X. Bach; T. M. Phuong,30,35,6,2,10.1109/NLPKE.2005.1598702,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1598702,IEEE Conferences,IEEE
Research on English-Chinese Cross-Language Information Retrieval,Information retrieval;Cross-Language information retrieval;Machine translation;Corpus;Linguistics resource,"With the rapidly growing amount of available information, an important issue arises of matching the user queries in one language against documents in another language, i.e. cross-language information retrieval (CLIR). Based on the work in CLIR evaluation task at the 9th Text Retrieval Conference (TREC-9), an English-Chinese CLIR system has been established. In this system, English-Chinese query translation is adopted as the dominant strategy; English queries are used as translation objects, and English-Chinese machine readable dictionary is utilized as the important knowledge source to acquire correct translations. By combining constructed Chinese monolingual IR system, the complete English-Chinese CLIR process is successfully implemented.",2007,N. Thongbai; N. Nakpong,3448,3453,6,1,10.1109/ICMLC.2007.4370744,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370744,IEEE Conferences,IEEE
Categorizing sentence structures for phrase level morphological analyzer for English to Hindi RBMT,Morphological Analyzer (MA);NLP processes;Knowledge Base;bilingual corpus;noise;Rule Based Machine Translation (RBMT);Recursive Transition Networks (RTN);Finite State Transducers (FST),"Algorithms for morphological analyzers have evolved majorly around words. Since writing styles are changing due to impact of languages on each other, higher version of morphological analyzers are desired for various NLP systems such as Machine Translation, Knowledge Extraction, Information Retrieval, etc. Often word level morphological analyzers adhere to language grammars and knowledge set pertaining to GNP and dictionary. Some algorithms use phrasal dictionaries also. But, impact of languages on each other leads to changes in GNP, grammatical and phrasal usage of words. General morph algorithms cannot deal with impact of such usage of words or phrases. Therefore new generation of morph analyzers are desired to handle cross lingual impact. In this paper, methodology for English language morphological analyzer is proposed for interpretation of phrases and group of words to derive knowledge in Hindi for tourism domain. The methodology, although general, is oriented towards Machine Translation. Proposed methodology is based on creation of knowledge base for morph analyzers using formulations of FST and RTN. Using this methodology, ten categories of phrasal structures in sentences have been identified which when used in MA of RBMT would improve the functional efficiency of MT in producing correct translation.",2015,N. Wang; S. Burgess; M. Lawrence; S. Bridges,1,6,6,1,10.1109/CCIP.2015.7100741,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100741,IEEE Conferences,IEEE
Neonatal seizure detection using convolutional neural networks,neonatal seizure detection;convolutional neural networks;support vector machine;EEG waveforms,"This study presents a novel end-to-end architecture that learns hierarchical representations from raw EEG data using fully convolutional deep neural networks for the task of neonatal seizure detection. The deep neural network acts as both feature extractor and classifier, allowing for end-to-end optimization of the seizure detector. The designed system is evaluated on a large dataset of continuous unedited multichannel neonatal EEG totaling 835 hours and comprising of 1389 seizures. The proposed deep architecture, with sample-level filters, achieves an accuracy that is comparable to the state-of-the-art SVM-based neonatal seizure detector, which operates on a set of carefully designed hand-crafted features. The fully convolutional architecture allows for the localization of EEG waveforms and patterns that result in high seizure probabilities for further clinical examination.",2017,N. Yanes; A. M. Mostafa; M. Ezz; S. N. Almuayqil,1,6,6,3,10.1109/MLSP.2017.8168193,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168193,IEEE Conferences,IEEE
Multiresolution Framwork with Neural Network Approach for Automatic Target Recognition (ATR),Automatic Target Recognition;Wavelet Transform,"Automatic Target Recognition (ATR) is an approach by which we identify one or a group of target-objects in a scene. It plays a pivotal role in the challenging fields of defense and civil. Most of the methods in this context are based on fix window-size technique. In this paper we propose a novel approach which gives scale, rotation and translation invariant results for automatic target recognition in high-resolution satellite images which in turn are able to recognize the multiple targets in a scene. We have developed a system which can predict the possible area of interest in a scene, where target may be present or not. Prediction of areas of interest is based on edge detection and similarity measure of wavelet co-occurrence features of segmented sub-blocks. Zernike moments, calculated for scale and translation normalized area of interest, is thereby used as the features of the concerned area. Zernike moments are rotation invariant. The extracted features are then fed to trained neural network for recognition. This approach is more suitable for the satellite images because resolution of image and idea about the target are two essential factors by which we can predict the minimum and maximum size of the target. The approach takes considerably less time compared to the fix window based approach because the predicted numbers of interest areas to be processed in a scene are very less. The proposed approach has successfully been tested on number of satellite images of different resolutions and their timing analysis has been compared with fix window based approach.",2009,Nam-Yong Han; Hoi-Rin Kim; Kyu-Woong Hwang; Young-Mok Ahn; Joon-Hyung Ryoo,168,173,6,,10.1109/ICSAP.2009.58,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5163848,IEEE Conferences,IEEE
Language style and domain adaptation for cross-language SLU porting,Spoken Language Understanding;Statistical Machine Translation;Domain Adaptation,"Automatic cross-language Spoken Language Understanding porting is plagued by two limitations. First, SLU are usually trained on limited domain corpora. Second, language pair resources (e.g. aligned corpora) are scarce or unmatched in style (e.g. news vs. conversation). We present experiments on automatic style adaptation of the input for the translation systems and their output for SLU. We approach the problem of scarce aligned data by adapting the available parallel data to the target domain using limited in-domain and larger web crawled close-to-domain corpora. SLU performance is optimized by reranking its output with Recurrent Neural Network-based joint language model. We evaluate end-to-end SLU porting on close and distant language pairs: Spanish - Italian and Turkish - Italian; and achieve significant improvements both in translation quality and SLU performance.",2013,O. Amin; H. Said; A. Samy; H. K. Mohammed,144,149,6,4,10.1109/ASRU.2013.6707720,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707720,IEEE Conferences,IEEE
Semantic Representations for Multilingual Natural Language Processing,natural language processing;semantics;syntax;vector spaces;hybrid models;machine translation;multilingual knowledge extraction;intelligent systems,"The paper focuses on the problems of research and integral modeling of semantic representations of language structures for the implementation of knowledge extraction from texts and machine translation. The method of presenting language structures and resolving their ambiguity is based on logical linguistic rules and vector spaces. An effective method of displaying the vector of natural language structures in an expanded space of features for the classification of new language objects and structures has been developed. A focal sample of parallel texts of business and scientific documents in Russian, English and French has been formed for various fields of science and technology; an expanded system of new categories has been developed to enhance the expressive power of the original version of the unification grammar. The multilingual parsing procedures have been developed, which take into account the translational transformations.",2019,O. Hrinchuk; M. Popova; B. Ginsburg,433,438,6,,10.1109/CSCI49370.2019.00085,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071289,IEEE Conferences,IEEE
Answering English Queries in Automatically Transcribed Arabic Speech,Arabic information retrieval;Cross-language;information retrieval;Machine translation.,"There are several well-known approaches to parsing Arabic text in preparation for indexing and retrieval. Techniques such as stemming and stopping have been shown to improve search results on written newswire dispatches, but few comparisons are available on other data sources. In this paper, we apply several alternative stemming and stopping approaches to Arabic text automatically extracted from the audio soundtrack of news video footage, and compare these with approaches that rely on machine translation of the underlying text. Using the TRECVID video collection and queries, we show that normalisation, stopword- removal, and light stemming increase retrieval precision, but that heavy stemming and trigrams have a negative effect. We also show that the choice of machine translation engine plays a major role in retrieval effectiveness.",2007,O. Klejch; P. Bell; S. Renals,11,16,6,,10.1109/ICIS.2007.61,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4276350,IEEE Conferences,IEEE
Combining Pathway Analysis and Supervised Machine Learning for the Functional Classification of Single-Cell Transcriptomic Data,"single-cell experiment, hematopoietic cells, pathway analysis, supervised machine learning, classification, semantic analysis","The revolution of single-cell technologies established a novel framework to investigate gene expression profiles in the level of individual cells. Scientists are able to investigate the biological variability of the same tissue, producing isolated transcriptomic data for each single cell. As a result, each transcriptomic experiment could extract a unique expression profile for each cell, posing new challenges in the translation analysis of all these profiles. Pathway analysis tools need to be adapted, not only to analyze simultaneously numerous gene expression profiles, but also to compare them, detecting functional differences and commonalities among the cells of the same issue, separating them to functional subclusters. In this study, we used the output of a single-cell experiment in the hematopoietic system, in order to determine a novel framework for the functional comparison of single cells, based on their pathway analysis with Gene Ontology annotation. Thousands of expression profiles of single cells, congregated in 15 different hematopoietic classes, were translated into networks of significant biological mechanisms, through the use of BioInfoMiner platform. We propose a novel framework to exploit these results and construct appropriate feature spaces of functional components, with a view to perform supervised learning to different hematopoietic cell types and separate their respective single cells, according to their functional profile. The constructed classification model performed interestingly high precision and sensitivity scores for some cell types, while the overall performance needs to be improved with further conceptual and technical refinements.",2019,O. Scharenborg; L. Besacier; A. Black; M. Hasegawa-Johnson; F. Metze; G. Neubig; S. StÃ¼ker; P. Godard; M. MÃ¼ller; L. Ondel; S. Palaskar; P. Arthur; F. Ciannella; M. Du; E. Larsen; D. Merkx; R. Riad; L. Wang; E. Dupoux,861,866,6,,10.1109/BIBE.2019.00160,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941911,IEEE Conferences,IEEE
Noisy SMS text normalization model,Natural Language Processing;Machine Translation;Social Media;Text Normalization;Noisy words,"Today digital media such as social networks, chat rooms, and forums have gained much importance in human life for information sharing. Users will share their knowledge and emotions in their own languages. This will create a novel syntax to communicate their messages with as much as pithiness as possible. Noisy text is characterized by unusual forms such as abbreviations, phonetic translations, short forms etc. This led to the emergence of text normalization. Cleaning the noisy text has become an important factor for adequate development and deployment of NLP (Natural Language Processing) services such as text-to-speech and automatic translation. In this paper we introduce a channel based normalization model for cleaning the noisy texts. The normalization is based on the types of distortion such as grapheme distortion, abbreviation and phoneme distortion. The model will explore the type of distortion occurred in the noisy word and replace it by using the different channel list. Precursory evaluation shows that the channel model will normalize the noisy word to their standard peer with 96.43 % accuracy.",2014,P. Bahadur; A. Jain; D. S. Chauhan,1,6,6,1,10.1109/I2CT.2014.7092164,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092164,IEEE Conferences,IEEE
Acoustic unit discovery and pronunciation generation from a grapheme-based lexicon,acoustic unit discovery;automatic speech recognition;grapheme-based speech recognition;pronunciation learning,"We present a framework for discovering acoustic units and generating an associated pronunciation lexicon from an initial grapheme-based recognition system. Our approach consists of two distinct contributions. First, context-dependent grapheme models are clustered using a spectral clustering approach to create a set of phone-like acoustic units. Next, we transform the pronunciation lexicon using a statistical machine translation-based approach. Pronunciation hypotheses generated from a decoding of the training set are used to create a phrase-based translation table. We propose a novel method for scoring the phrase-based rules that significantly improves the output of the transformation process. Results on an English language dataset demonstrate the combined methods provide a 13% relative reduction in word error rate compared to a baseline grapheme-based system. Our approach could potentially be applied to low-resource languages without existing lexicons, such as in the Babel project.",2013,P. Basmatkar; H. Holani; S. Kaushal,380,385,6,5,10.1109/ASRU.2013.6707760,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707760,IEEE Conferences,IEEE
Social media and NLP tasks: Challenges in crowdsourcing linguistic information,NLP;MOOC;Crowdsourcing;CrowdFlower;Machine Translation,"In the framework of the TraMOOC1(Translation for Massive Open Online Courses) research and innovation project, data collection tasks for parallel translation are implemented using a crowdsourcing platform. The educational genre (videolectures subtitles, forums discussions, course assignments), the type of text (segmentation, misspellings, syntax errors, specialized terminology, scientific formulas, limited knowledge on context) of the source data, and the multilingual approach of the involved activities (the focus is on a total of 12 European and BRIC languages) provides a challenging setting for the success of the project. Experimental trials reveal significant findings for the purposes of Language Technology research as well as limitations in crowdsourcing linguistic data collections for multilingual tasks.",2016,P. Chitwirat; N. Facundes; B. Sirinaovakul,53,58,6,,10.1109/SMAP.2016.7753384,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753384,IEEE Conferences,IEEE
Universal networking language: A framework for emerging NLP applications,UNL;NLP;information retrieval;machine translation;summarization,"Presently there has been a surge for representing information in a common language for use cases like question-answering system, machine translation, text summarization etc. UNL has been a centre of attraction for researchers in the past two decades and many have tried to harness its power. This paper throws a glimpse into the strides made by such researchers. As UNL provides a language independent platform it eases out the decision making by accessing the valuable and meaningful information, which is otherwise a challenging errand. Thus it captures information and finds its major application in Natural Language Processing (NLP) domain. The paper is written with the intent to introduce its readers to the UNL framework and explain how it is being used to solve some real world problems.",2016,P. Dubey; Devanand,1,6,6,,10.1109/IICIP.2016.7975375,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975375,IEEE Conferences,IEEE
A model of the MT lexicon for verbs as an interface between syntactic parsing and semantic representations,Machine translation;Lexicon for a parser;Lexicon of verbs;Metaphoric usages of verbs,"Machine translation (MT) deals with a large amount of data which represents sentence meanings constructed on the basis of the grammatical rules and the lexical knowledge of the source and target languages. As it is hardly possible to make an automated semantic analysis of the source language data, predominant methods in use have been transfer models such as those of phrase-based statistical MT and pattern-based MT, the main task of which is to replace the source language text with the target language text without understanding them. As it is reported that nearly half the text data consist of unanalyzable multiword like collocations, idioms, and phrasal verbs, it would be inevitable to resort to such a method. At the same time, however, it has been observed that MT output quality suffers to a significant extent when the sentences are not divided into proper segments. This paper proposes a model of the lexicon of verbs whose rich relational information contributes to parsing and understanding sentences. While other existing models of lexicons have no or little consideration for their roles of interaction with processes of syntactic parsing and semantic representation, the proposed model is designed for playing a role as an interface between the two processes in handling sentences with regular usages of verbs as well as idiomatic and metaphoric usages.",2014,P. Dziurzanski; S. Gerasimou; D. Kolovos; N. Matragkas,382,387,6,,10.1109/ICInfA.2014.6932686,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6932686,IEEE Conferences,IEEE
A Sequence-to-Sequence Model Approach for ImageCLEF 2018 Medical Domain Visual Question Answering,Visual question answering;ImageCLEF VQA-med;Image captioning;Machine translation;Computer vision;Natural Language Processing,"Numerous attempts have been made in the recent past for the task of free-form and open-ended Visual Question Answering (VQA). Solving VQA problem typically requires techniques from both computer vision for a deeper understanding of the images and Natural language processing for understanding the semantics of the question and generating appropriate answers. It has caught the attention of a lot of researchers because of its enormous applications in the real-world scenarios. But none of the existing approaches are designed for the medical image-question pairs which require a sequence of words as an answer. We propose a novel approach by combining the tasks of Image captioning and Machine translation and provided a comprehensive model that takes a medical image-question pair as an input and generates a sequence of words as an answer. We evaluate our model on the dataset provided by ImageCLEF as a part of the ImageCLEF 2018 VQA-med challenge. We outperformed all the contestants of the challenge by achieving the best BLEU and WBSS scores. Furthermore, we provide additional insights that can be adopted to develop our baseline model and the challenges that lie ahead of us while building Machine learning models for medical datasets.",2018,P. Gupta; R. Ahmad; M. Shrivastava; P. Kumar; M. K. Sinha,1,6,6,,10.1109/INDICON45594.2018.8987108,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987108,IEEE Conferences,IEEE
Pseudogen: A Tool to Automatically Generate Pseudo-Code from Source Code,machine translation;programming language;natural language,"Understanding the behavior of source code written in an unfamiliar programming language is difficult. One way to aid understanding of difficult code is to add corresponding pseudo-code, which describes in detail the workings of the code in a natural language such as English. In spite of its usefulness, most source code does not have corresponding pseudo-code because it is tedious to create. This paper demonstrates a tool Pseudogen that makes it possible to automatically generate pseudo-code from source code using statistical machine translation (SMT). Pseudogen currently supports generation of English or Japanese pseudo-code from Python source code, and the SMT framework makes it easy for users to create new generators for their preferred source code/pseudo-code pairs.",2015,P. Hays; R. Ptucha; R. Melton,824,829,6,2,10.1109/ASE.2015.107,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372074,IEEE Conferences,IEEE
Parallel Corpus Approach for Name Matching in Record Linkage,Record Linkage;Crowd Sourcing;Machine Translation,"Record linkage, or entity resolution, is an important area of data mining. Name matching is a key component of systems for record linkage. Alternative spellings of the same name are a common occurrence in many applications. We use the largest collection of genealogy person records in the world together with user search query logs to build name-matching models. The procedure for building a crowd-sourced training set is outlined together with the presentation of our method. We cast the problem of learning alternative spellings as a machine translation problem at the character level. We use information retrieval evaluation methodology to show that this method substantially outperforms on our data a number of standard well known phonetic and string similarity methods in terms of precision and recall. Our result can lead to a significant practical impact in entity resolution applications.",2014,P. Karageorgakis; A. Potamianos; I. Klasinas,995,1000,6,2,10.1109/ICDM.2014.76,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7023436,IEEE Conferences,IEEE
Feedback Learning: Automating the Process of Correcting and Completing the Extracted Information,"Document Understanding, Post IE Error Correction and Completeness, Sequence to Sequence Neural Machine Translation","In recent years, with the increasing usage of digital media and advancements in deep learning architectures, most of the paper-based documents have been revolutionized into digital versions. These advancements have helped state-of-the-art information extraction and digital mailroom technologies become progressively efficient. Even though many efficient post-Information Extraction (IE) error rectification methods have been introduced in the recent past to improve the quality of digitized documents. They are still imperfect and they demand improvements in the area of context-based error correction, specifically when we are dealing with the documents involving sensitive information such as invoices. This paper describes the self-correction approach based on the sequence to sequence Neural Machine Translation (NMT) as applied to rectify the incorrectness in the results of any information extraction approach such as Optical Character Recognition (OCR). We accomplished this approach by exploiting the concepts of sequence learning with the help of feedback provided during each cycle of training. Finally, we have compared state-of-the-art post-OCR error correction methods with our feedback learning approach. Our empirical results have outperformed state-of-the-art post-OCR error correction methods.",2019,P. Kucher; S. Chakrabartty,116,121,6,,10.1109/ICDARW.2019.40091,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8893050,IEEE Conferences,IEEE
Design and development of a frame based MT system for English-to-ISL,machine translation;Indian sign language;language processing;motioncapture;3D virtual human,"This paper presents the design and development of a frame based approach for speech to sign language machine translation system in the domain of railways and banking. This work aims to utilize the capability of Artificial intelligence for the improvement of physically challenged, deaf-mute people. Our work concentrates on the sign language used by the deaf community of Indian subcontinent which is called Indian Sign Language (ISL). Input to the system is the clerk's speech and the output of this system is a 3D virtual human character playing the signs for the uttered phrases. The system builds up 3D animation from pre-recorded motion capture data. Our work proposes to build a Malayalam to ISL.",2009,P. Kumar; R. Ahmad; B. D. Chaudhary; R. Sangal,1382,1387,6,9,10.1109/NABIC.2009.5393721,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393721,IEEE Conferences,IEEE
Improving text simplification by corpus expansion with unsupervised learning,unsupervised machine translation;Japanese simplification;corpus expansion,"Automatic sentence simplification aims to reduce the complexity of vocabulary and expressions in a sentence while retaining its original meaning. We constructed a simplification model that does not require a parallel corpus using an unsupervised translation model. In order to learn simplification by unsupervised manner, we show that pseudo-corpus is constructed from the web corpus and that the corpus expansion contributes to output more simplified sentences. In addition, we confirm that it is possible to learn the operation of simplification by preparing large-scale pseudo data even if there is non-parallel corpus for simplification.",2019,P. Kurariya; P. Chaudhary; P. Jain; A. Lele; A. Kumar; H. Darbari,216,221,6,,10.1109/IALP48816.2019.9037567,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037567,IEEE Conferences,IEEE
OCR Error Correction: State-of-the-Art vs an NMT-based Approach,OCR Error Correction;OCR Post-Processing;Neural Machine Translation (NMT),"Although the performance of the state-of-the-art OCR systems is very high, they can still introduce errors due to various reasons, and when it comes to historical documents with old manuscripts the performance of such systems gets even worse. That is why Post-OCR error correction has been an open problem for many years. Many state-of-the-art approaches have been introduced through the recent years. This paper contributes to the field of Post-OCR Error Correction by introducing two novel deep learning approaches to improve the accuracy of OCR systems, and a post processing technique that can further enhance the quality of the output results. These approaches are based on Neural Machine Translation (NMT) and were motivated by the great success that deep learning introduced to the field of Natural Language Processing. Finally, we will compare the state-of-the-art approaches in Post-OCR Error Correction with the newly introduced systems and discuss the results.",2018,P. Lambert; S. R. Schwer; N. Boffo,429,434,6,3,10.1109/DAS.2018.63,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395234,IEEE Conferences,IEEE
Multilingual cloudlet-based dictionary,Cloud Computing;Virtualization;Cloudlet;Dictionary;Virtual Machines,"Cloud Computing is a technology that moves the World forward. It helps the mobile users to run compute demanding applications on a remote cloud and access the results on their mobile devices. Usual processing of the cloud based applications is realized via a WAN connection. However, this approach is inefficient for real-time applications due to relatively huge WAN latency. Cloudlets solve this problem by exploiting the benefits of Cloud Computing without being WAN-limited. The cloudlet is a small cloud located near the mobile user. Cloudlets can perform the same processing tasks as a remote cloud by using Virtual Machines (VMs). In this paper we introduce the cloudlet approach to design a Multilingual Dictionary, which is a Cloudlet based application specifically developed to be processed on a near cloudlet as well as on a distant cloud. It will be used for translating words entered through a mobile device by using a VM deployment on the cloud/cloudlet and displaying the results on the mobile device. The initial version will support translation between two languages. Afterwards, it will be expanded to support multilingual translation.",2014,P. Papadakis; F. Pirri,380,385,6,4,10.1109/MIPRO.2014.6859595,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6859595,IEEE Conferences,IEEE
Phishing website detection using Latent Dirichlet Allocation and AdaBoost,boosting;detection;identity theft;semantic analysis;machine learning;natural language processing;phishing website,"One of the ways criminals steal identity in the cyberspace is using phishing. Attackers host phishing websites that resemble a legitimate website and entice users to click on hyperlinks which directs them to these fake websites. Attackers use these fake sites to capture personal information such as login, passwords and social security numbers from innocent victims, which they later use to commit crimes. We propose here a robust methodology to detect phishing websites that employs for semantic analysis a topic modeling technique, Latent Dirichlet Allocation, and for classification, AdaBoost. The methodology developed is a content driven approach that is device independent and language neutral. The website content of mobile and desktop clients are collected by employing an intelligent web crawler. The website contents that are not in English are translated to English using Google's language translator. Topic model is built using the translated contents of desktop and mobile clients. The phishing website classifier is built using (i) distribution probabilities for the topics found as features using Latent Dirichlet Allocation and (ii) AdaBoost voting technique. Experiments were conducted using one of the large public corpus of website data containing 47500 phishing websites and 52500 good websites. Results show that our method achieves a F-measure of 99%.",2012,P. Pawar; P. Ardhapurkar; P. Jain; A. Lele; A. Kumar; H. Darbari,102,107,6,16,10.1109/ISI.2012.6284100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6284100,IEEE Conferences,IEEE
Multilingual Case Method System for Cross-Cultural Analysis,intercultural collaboration;machine translation;language grid;web service;case method,"The case method is an effective teaching technique for business management education. The main objective with this method is to spark discussion and share ideas. However, discussions are generally conducted in a single-language environment, which is difficult for non-native speakers. We therefore developed a multilingual case method system for global classroom environments to benefit students of different cultures and who speak various languages. The system provides a learning environment in which students can communicate in their native language through the Language-Grid service. We evaluated our system by conducting experiments using a short case of an unresolved cultural conflict. Japanese and Korean students participated in the experiments. The system enabled sufficiently effective communication in their native languages. We were also able to address cultural differences, for example, Japanese students tend to think of cultural conflicts more negatively than Korean students.",2013,P. Satam; H. Alipour; Y. Al-Nashif; S. Hariri,117,122,6,2,10.1109/CultureComputing.2013.28,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680341,IEEE Conferences,IEEE
Analysis of self-tagging during conversational chat in multilingual gaming simulation,gamification;intercultural collaboration;machine translation;language grid,"A multilingual gaming simulation is suggested as the basis of an experiment by which we discuss complex problems such as global civics or environmental problems. Assigning tags is a very important way to analyze this experiment. However, assigning tags has a cost that is too large for analysts. In this study, we suggest and introduce a method for participants to voluntarily self-tag, focusing on gamification and crowdsourcing. As a result, we verified that it is possible for analysts to reduce the tagging cost when analyzing and to analyze results more accurately.",2013,P. Shah; V. Bakrola; S. Pati,81,86,6,1,10.1109/FGCT.2013.6767188,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6767188,IEEE Conferences,IEEE
Measuring the impact of cognates in parallel text alignment,Parallel text alignment;Machine translation;evaluation;cognates,"This paper evaluates the impact of considering cognates for aligning parallel texts using our aligner. By considering that two words may be cognates if their similarity is higher than a certain threshold and if they are automatically selected as aligners, we tested different degrees of cognativeness, by varying threshold values. A new methodology to measure the quality of resulting alignments is presented. Two language pairs are addressed: Portuguese-Spanish, and Portuguese-English",2005,P. Shen; X. Lu; H. Kawai,338,343,6,1,10.1109/EPIA.2005.341306,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145984,IEEE Conferences,IEEE
"Recovery of acronyms, out-of-lattice words and pronunciations from parallel multilingual speech",speech recognition;machine translation;pronunciation;out-of-lattice;acronyms,"In this work we present a set of techniques which explore information from multiple, different language versions of the same speech, to improve Automatic Speech Recognition (ASR) performance. Using this redundant information we are able to recover acronyms, words that cannot be found in the multiple hypotheses produced by the ASR systems, and pronunciations absent from their pronunciation dictionaries. When used together, the three techniques yield a relative improvement of 5.0% over the WER of our baseline system, and 24.8% relative when compared with standard speech recognition, in an Europarl Committee dataset with three different languages (Portuguese, Spanish and English). One full iteration of the system has a parallel Real Time Factor (RTF) of 3.08 and a sequential RTF of 6.44.",2012,P. T. Le Thuyen; V. T. Hung,348,353,6,2,10.1109/SLT.2012.6424248,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424248,IEEE Conferences,IEEE
Equivalence checking between SLM and RTL using machine learning techniques,Equivalence Checking;FSMD;Machine Learning;System Level Modeling;Formal Verification,"The growing complexity of modern digital design makes designers shift toward starting design exploration using high-level languages, and generating register transfer level (RTL) design from system level modeling (SLM) using high-level synthesis or manual transformation. Unfortunately, this translation process is very complex and may introduce bugs into the generated design. In this paper, we propose a novel SLM and RTL sequential equivalence checking method. The proposed method bases on Finite state machines with datapath (FSMD) equivalence checking method. The proposed method recognizes the corresponding path-pairs of FSMDs using machine learning (ML) technique from all the paths. And then it compares the corresponding path-pairs by symbolic simulation. The advantage of our method is that it separates the corresponding path-pairs from all the paths and avoids blind comparisons of path-pairs. Our method can deal with greatly different SLM and RTL designs and dramatically reduce the complexity of the path-based FSMD equivalence checking problem. The promising experimental results show the efficiency and effectiveness of the proposed method.",2016,P. Unlee; P. Seresangtakul,129,134,6,,10.1109/ISQED.2016.7479188,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479188,IEEE Conferences,IEEE
A novel multimodal image fusion method using Shift invariant Discrete Wavelet Transform and Support Vector Machines,Image fusion;Shift Invariant Discrete Wavelet Transform;Support Vector Machines,"In this paper, a multimodal image fusion technique using Shift invariant Discrete Wavelet Transform (SIDWT) and Support Vector Machines (SVM) suitable for surveillance applications is proposed. This technique uses SIDWT for multiresolution decomposition as it is translation invariant. A Support Vector Machine is trained to select the coefficient blocks with significant features, extracted from the SIDWT coefficients. The corresponding selected coefficients are used in forming the composite fused coefficient representation. The proposed method is tested for a number of multimodal images and found to outperform other traditional image fusion algorithms in terms of the various fusion metrics. Experimental results show that the quality of the fused image is significantly improved for multimodal images.",2011,Peng Jin; Fuxin Li; Danqing Zhu; Yunfang Wu; Shiwen Yu,932,937,6,4,10.1109/ICRTIT.2011.5972405,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5972405,IEEE Conferences,IEEE
Fusion of Visible and Thermal Images Using Support Vector Machines,Image Fusion;Thermal & Visible images;Support Vector Machines (SVM) and Kernel Principal Component Analysis (K-PCA),"Both in military and civilian applications, an increasing interest is being shown in fusing infra-red and visible images. In this paper, we propose a novel pixel-based infra-red and visible image fusion algorithm exploiting discrete wavelet frame transform (DWFT), kernel principle component analysis (K-PCA) and support vector machine (SVM). Strong characteristics of DWFT such as translation invariant signal representation and directional selectivity add additional support to fusion process. K-PCA exploits the low frequency features mainly attributed from infra-red image, while SVM, on the other hand, exploits detail regions. Evaluations of the proposed technique through an image database show that the proposed method gives promising results both objectively and visually.",2006,Q. Chen; T. Yao,146,151,6,4,10.1109/INMIC.2006.358152,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4196395,IEEE Conferences,IEEE
An Automatic and Robust System for Identification of Problematic Call Centre Conversations,SVM;MFCC;Machine Learning;Problematic Calls,"In this Globalized world, the Call Centers and BPOsare increasing at an exponential rate. There is stiff competitionamong various companies and every company wants to have itsclients happy and satisfied with the resolution of the problems. For this purpose, Agent Quality Monitoring is an importantrequirement. Since in a typical Call Centre, thousands of calls aremade by agents in a single day, it is not possible to manuallyidentify problematic calls by monitoring each and every agentclientconversation. Moreover, sometimes, individual monitoringis biased. What is non problematic for one can be problematic foranother individual. Moreover, it is almost impossible to manuallyidentify problematic calls in a language one doesn't know. Without a suitable technical approach, it is difficult to identifyproblematic calls without translating the call contents into ourlanguage, which often leads to security and privacy concerns fora private company. In this paper a sample of calls was taken anda proper technical approach is used to analyze the calls. Thedesign of the proposed system is language independent. In thisproject, we make use of Support Vector Machine (SVM) classifier based on 4 robust audio features, namely MelFrequency Cepstral Coefficients (MFCCs), Energy, Volume andZero Crossing Rate (ZCR). The support vectors are obtained bytraining the sample data set. The SVM Classifier is based on asimple algorithm which solves the two class problem andclassifies the calls as problematic or non-problematic. Duringexperiments 87.5% of the calls are identified correctly.",2016,Q. H. Ngo; W. Winiwarter,325,330,6,,10.1109/ICMETE.2016.48,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7938935,IEEE Conferences,IEEE
Towards a Ubiquitous Language Resource Management System,"machine language processing;language resources;client server systems;crowd sourcing;translation, automatic speech recognition;data warehousing;mobile applications development","Natural Language Processing has a strong need for large scale quality speech, sign and text resources. The problem in developing countries in African and globally, is the lack of such resources. Significant progress has been made by research groups in South Africa under the coordination Language Resource Management Agency, to collect language resources for the 11 official languages of South Africa. Existing limitations are that resources have been collected manually, in a unidirectional manner that only benefits research institutions and not the wider community that needs them the most and the data is statically pre-packaged and not dynamic. In this paper we detail the design and initial implementations of a ubiquitous language resource management system. The system is aimed at supporting manual collection, crowdsourcing and distribution of language resources and to provide a dynamic resource management system that allows submission, acquisition and quality auditing of languages resources based on user specifications as opposed to pre-packaged data formats. We present initial implementations of the server side and mobile application clients and outline future developments and system integration.",2019,Q. Li; D. F. Wong; L. S. Chao; M. Zhu; T. Xiao; J. Zhu; M. Zhang,1,6,6,,10.1109/AFRICON46755.2019.9134045,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134045,IEEE Conferences,IEEE
Efficient Labeling of EEG Signal Artifacts Using Active Learning,EEG;Artifacts;Active Learning;Support Vector Machine;Autoregressive Model,"Electroencephalography (EEG) has been widely used in a variety of contexts, including medical monitoring of subjects as well as performance monitoring in healthy individuals. Recent technological advances have now enabled researchers to quickly record and collect EEG on a wide scale. Although EEG is fairly easy to record, it is highly susceptible to noise sources called artifacts which can occur at amplitudes several times greater than the EEG signal of interest. Because of this, users must manually annotate the EEG signal to identify artifact regions in the data prior to any downstream processing. This can be time-consuming and impractical for large data collections. In this paper we present a method which uses Active Learning (AL) to improve the reliability of existing EEG artifact classifiers with minimal amounts of user interaction. Our results show that classification accuracy equivalent to classifiers trained on full data annotation can be obtained while labeling less than 25% of the data. This suggests significant time savings can be obtained when manually annotating artifacts in large EEG data collections.",2015,Q. Nguyen; A. Vo; J. Shin; C. Ock,3217,3222,6,8,10.1109/SMC.2015.558,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379690,IEEE Conferences,IEEE
Hierarchical internal representation of spectral features in deep convolutional networks trained for EEG decoding,Electroencephalography;EEG analysis;machine learning;convolutional networks;visualization;model inter-pretability;spectral features,"Recently, there is increasing interest and research on the interpretability of machine learning models, for example how they transform and internally represent EEG signals in Brain-Computer Interface (BCI) applications. This can help to understand the limits of the model and how it may be improved, in addition to possibly provide insight about the data itself. Schirrmeister et al. (2017) have recently reported promising results for EEG decoding with deep convolutional neural networks (ConvNets) trained in an end-to-end manner and, with a causal visualization approach, showed that they learn to use spectral amplitude changes in the input. In this study, we investigate how ConvNets represent spectral features through the sequence of intermediate stages of the network. We show higher sensitivity to EEG phase features at earlier stages and higher sensitivity to EEG amplitude features at later stages. Intriguingly, we observed a specialization of individual stages of the network to the classical EEG frequency bands alpha, beta, and high gamma. Furthermore, we find first evidence that particularly in the last convolutional layer, the network learns to detect more complex oscillatory patterns beyond spectral phase and amplitude, reminiscent of the representation of complex visual features in later layers of ConvNets in computer vision tasks. Our findings thus provide insights into how ConvNets hierarchically represent spectral EEG features in their intermediate layers and suggest that ConvNets can exploit and might help to better understand the compositional structure of EEG time series.",2018,Q. Nguyen; A. Vo; J. Shin; P. Tran; C. Ock,1,6,6,7,10.1109/IWW-BCI.2018.8311493,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8311493,IEEE Conferences,IEEE
Automatic creation of a word aligned Sinhala-Tamil parallel corpus,word alignment;parallel corpus;sinhala;tamil,"A parallel corpus aligned at both sentence and word level is an important prerequisite in statistical machine translation. However, manual creation of such a parallel corpus is time consuming, and requires experts fluent in both languages. This paper presents the first ever empirical evaluation carried out to identify the best unsupervised word alignment technique for Sinhala and Tamil. It also presents a novel approach that combines the output of individual aligners, which outperforms the solitary use of these aligners. Sentence aligned parallel text from annual reports and letters of Sri Lankan Government institutions, and order papers from the Parliament of Sri Lanka were used in the evaluation.",2017,R. Ahmad; P. Gupta; N. Vuppala; S. K. Pathak; A. Kumar; G. Soni; S. Kumar; M. Shrivastava; A. K. Singh; A. K. Gangwar; P. Kumar; M. K. Sinha,425,430,6,1,10.1109/MERCon.2017.7980522,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7980522,IEEE Conferences,IEEE
Sign language recognition using the Extreme Learning Machine,Extreme Learning machine (ELM);Artificial Neural Networks (ANN);Instrumented glove;Hidden Markov Models (HMMs),"The Extreme Learning Machine (ELM) is a simplified neural network. It non-linearly embeds input data in a higher dimensional space using randomly generated sigmoidal basis functions. The training target vector is then approximated by a linear weighted sum of these basis functions. In this paper the ELM algorithm has been applied to classify static hand gestures that represent different letters of the Auslan(Australian Sign Language) dictionary. ELM offers very fast learning with very consistent performance. It has only one tuning parameter. It can be adapted to multiclass classification and multi output regression without any increase in training time. Its low computational intensity and short training time makes it superior to traditional algorithms such as Hidden Markov Models (HMMs), Single and Recurrent Feed Forward Neural Networks for real time translations. Preliminary experimental results have shown that ELM can produce good generalization performance as a classifier. Increasing the dimensionality of the data results in better separation. Consequently the gestures become more distinguishable improving the probability of correct classification. An investigation into its classification performance for the entire alphabet is currently under way.",2011,R. Ali; M. A. Khan; R. Ahmad; I. Rabbi,1,6,6,12,10.1109/AFRCON.2011.6072114,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6072114,IEEE Conferences,IEEE
A Research for Internal Fault Simulation of Single Phase Transformer Based on the Magnetic Transient and Support Vector Machine,transformer;short-cut fault;magnetic transient;support vector machine,"In order to improve the ability of transformer differential protection in the inrush identification, this paper proposes an algorithm based on the magnetic transient for internal fault simulation of single-phase transformer. A new fitting method for the hysteresis loop of transformer based on support vector machine is set forth, which is original optimization of the hysteresis loop test data regression translates into the allelomorph optimization. According to the fractal characteristic of local hysteresis loop, a search for internal fault simulation of single phase transformer is put forward .The application of the proposed algorithm to a test system shows its validity",2006,R. Arar,7484,7489,6,,10.1109/WCICA.2006.1713420,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1713420,IEEE Conferences,IEEE
Prediction of post-operative implanted knee function using machine learning in clinical big data,Predictive medicine;Total knee arthroplasty;Clinical big data;Machine learning;Principal component analysis,"Total knee arthroplasty (TKA) is one of the common knee surgeries. Because there are some types of TKA implant, it is hard to select appropriate type of TKA implant for individual patient. For the sake of pre-operative planning, this study presents a novel approach, which predicts post-operative implanted knee function of individuals. It is based on a clinical big data analysis. The big data is composed by a set of pre-operative knee mobility function and post-operative knee function. The method constructs a post-operative knee function prediction model by means of a machine learning approach. It extracts features using principal component analysis, and constructs a mapping function from pre-operative feature space to post-operative feature space. The method was validated by applying to prediction of post-operative anterior-posterior translation in 52 TKA operated knees. Leave-one-out cross validation test revealed the prediction performances with a mean correlation coefficients of 0.79 and a mean root-mean-squared-error of 3.44 mm.",2016,R. C.; D. K.; R. Ravindran; K. P. Soman,195,200,6,2,10.1109/ICMLC.2016.7860900,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7860900,IEEE Conferences,IEEE
Development of a bilingual corpus of Arabic and Arabic Sign Language based on a signed content,Arabic Sign Language;Bilingual Corpus;Statistical Machine Translation;Example-Based Machine Translation,"This paper deals with the creation process of a bilingual corpus of Arabic and Arabic Sign Language. This work will be concerned with a challenging research approach that aims to develop a solution that meets communication need of the Arab deaf community. Many sign language corpora have been proposed, but unfortunately, none of them is adapted to Arabic Sign Language (ArSL). To tackle this problem we designed a methodology for developing a bilingual Arabic and Arabic Sign Language corpus. To achieve this, the study will rely on sign content exported from Aljazeera Mubachir Egypt [1] TV news for deaf and hearing-impaired people.",2016,R. G. Negri; S. J. S. Sant'Anna; L. V. Dutra,349,354,6,,10.1109/CIST.2016.7805070,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805070,IEEE Conferences,IEEE
Real-time translation of discrete Sinhala speech to Unicode text,Automatic Speech recognition;Hidden Markov Models;Sinhala speech,"This paper presents a methodology to translate discrete Sinhala speech to Sinhala Unicode text in real time. Initially, the Hidden Markov Model and the associated Hidden Markov Toolkit (HTK) is used as the speech recognizer. While real time decoding is obtained by the Julius decoder a three-states Bakis HMM topology is used to build the acoustic model. The normalized Mel frequency cepstral coefficients with zeroth coefficient as the feature vector is used to recognize speech. Although a single person is used during the training session, an average accuracy of 85% is obtained for both speaker dependent and speaker independent speech recognition. Performance evaluation shows the capabilities of the proposed system to convert discrete Sinhala speech to Sinhala Unicode in both quiet and noisy environments.",2015,R. G. Rodrigues; F. Carvalho; G. Nascimento; G. P. Guedes,140,145,6,1,10.1109/ICTER.2015.7377680,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377680,IEEE Conferences,IEEE
Query expansion for Cross Language Information Retrieval Improvement,component;Cross-Language Information Retrieval;Machine Translation;Query Expansion;Natural Language Processing,"This paper is devoted to a new method that uses query expansion to improve multilingual information retrieval. The backbone is an Information Retrieval (IR) system based on a search engine and a multilingual module based on statistical machine translation of documents. To this system is added a Query Expansion (QE) module which mainly uses linguistic resources to perform the expansion. The aim is to use QE to overcome the limitations of machine translation, and to retrieve more relevant results. The authors demonstrate, with examples, the usefulness of such a system. They also validate it with several measures, which show a clear reduction of the silence for results.",2010,R. GuimarÃ£es Rodrigues; K. Tavares Rodrigues; R. Reis Gomes; L. Ferrari; E. Ogasawara; G. Paiva Guedes,337,342,6,5,10.1109/RCIS.2010.5507393,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5507393,IEEE Conferences,IEEE
Towards automatic building extraction: Variational level set model using prior shape knowledge,level sets;prior shape knowledge;label;function;building detection;segmentation;variational;method,"A novel variational level set model for multiple-building extraction from a single remote image is proposed in this paper. Multi-competing shapes are considered together with the level set model, the curve evolution is constrained by the prior shape knowledge and the label function that dynamically indicates the region with which the prior shape should be compared. The building extraction is addressed through a level set image segmentation approach that involves the use of the label function, as well as the prior shape knowledge. In addition, the proposed model permits translation, scaling, and rotation of the prior shape. Experimental results and the qualitative and quantitative evaluations demonstrate the potential of the approach.",2012,R. Kulesza; Y. Kumar; R. Ruiz; A. Torres; E. Weinman; J. J. Li; P. Morreale,1,6,6,3,10.1109/IASP.2012.6424990,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424990,IEEE Conferences,IEEE
Approach for multiword expression recognition & annotation in urdu corpora,Multiword expression (MWE);Machine Translation (MT);Natural Language Processing (NLP);Urdu;Annotation,"Multiword Expression (MWE) is an open challenging task in NLP because of its compositional behavior. In this paper, we have presented the classification of multiword expressions and also designed some MWE tags for annotation of Urdu corpora. If MWE annotation is proper then it can be accurately processed through parsing phase and can improve the accuracy of machine translator. For annotation of MWEs, initially extracted the compound type MWE on the basis of automatic approach and also extracted different type of MWEs using semiautomatic and manual approach. These extracted MWEs are pre-processed and after that got the correct multiword expressions. Using these MWEs, we have annotated the Urdu corpora of 50,000 sentences.",2017,R. M. K. Sinha; K. Sivaraman; A. Agrawal; R. Jain; R. Srivastava; A. Jain,1,6,6,,10.1109/ICIIP.2017.8313706,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8313706,IEEE Conferences,IEEE
Grammar-Based Automatic Extraction of Definitions,Grammar;E-learning;Wikipedia;Question Answering;Google Search API;Google Translation Service,"The paper describes the development and usage of a grammar developed to extract definitions from documents. One of the most important practical usages of the developed grammar is the automatic extraction of definitions from web documents. Three evaluation scenarios were run, the results of these experiments being the main focus of the paper. One scenario uses an e-learning context and previously annotated e-learning documents; the second one involves a large collection of unannotated documents (from Wikipedia) and tries to find answers for definition type questions. The third scenario performs a similar question-answering task, but this time on the entire web using Google web search and the Google Translation Service. The results are convincing, further development as well as further integration of the definition extraction system in various related applications are already under way.",2008,R. P. Haroon; T. A. Shaharban,110,115,6,2,10.1109/SYNASC.2008.12,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5204797,IEEE Conferences,IEEE
Improvement of an abstractive summarization evaluation tool using lexical-semantic relations and weighted syntax tags in Farsi language,Farsi Natural Language Processing (NLP);Semantics;Evaluation;Automatic Abstractive Summarizer;Sentences groups;Parse tree;parser,"In recent years, high increase in the amount of published web elements and the need to store, classify, restore, and process them have intensified the importance of natural language processing and its related tools such as automatic summarizers and machine translators. In this paper, a novel approach for evaluating automatic abstractive summarization system is proposed which can also be used in the other Natural Language Processing and Information Retrieval Applications. By comparing auto-abstracts (abstracts created by machine) with human abstracts (ideal abstracts created by human), the metrics introduced in the proposed tool can automatically measure the quality of auto-abstracts. Evidently, we can't semantically compare texts of abstractive summaries by comparison of just their words' appearance. So it is necessary to use a lexical database such as WordNet. We use FerdowsNet with a proper idea for Farsi language and it notably improves the evaluation results. This tool has been assessed by linguistic experts. This tool contains metric for determining the quality of summaries automatically by comparing them with summaries generated by humans (Ideal summaries). Evidently, we can't semantically compare texts of abstractive summaries by comparison of just their words' appearance and it is necessary to use a lexical database. We use this database with a proper idea together with Farsi parser in order to identify groups forming sentences and the results of evaluation improve significantly.",2014,R. Upadhyay; P. K. Kankar; P. K. Padhy; V. K. Gupta,1,6,6,5,10.1109/IranianCIS.2014.6802594,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802594,IEEE Conferences,IEEE
Lung Diseases Classification based on Machine Learning Algorithms and Performance Evaluation,Machine learning (ML);Artificial Intelligence (AI);Gray-Level Co-occurrence Matrix (GLCM);Multilayer perceptron (MLP);K-nearest neighbors (KNN);Support vector machine(SVM),"Machine learning (ML) is a significant subset of Artificial Intelligence (AI) that plays a key role in medical diagnosis. The advantage of AI is they can automatically learn, extract and translate the features from data sets such as images, text or video, without introducing traditional hand-coded code or rules. This paper focuses on recognizing and classifying lung diseases by ML algorithms. It includes 400 lung disease images (i.e. CT scan images) including bronchitis, emphysema, pleural effusion, cancer, and normal. The input image is analyzed, categorized and classified using ML algorithms such as the MLP, KNN and SVM classifier. After feature extraction, the output is segmented and compares the classifier's accuracy. When a CT scan image was given to a classifier as an input, it contains irrelevant information. For the selection of the most relevant features (i.e. for extracting characteristics) here Gray Level Co-occurrence Matrix (GLCM) is used. For MLP, this classifier acquires 98% accuracy, for SVM accuracy is 70.45% and for KNN accuracy is 99.2%. These classifiers will help the doctors to prescribe the most effective treatment for a patient.",2020,Rongbo Wang; Zheru Chi,315,320,6,,10.1109/ICCSP48568.2020.9182324,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182324,IEEE Conferences,IEEE
Chatbot using TensorFlow for small Businesses,Chatbots;Neural Networks;Machine learning;Conversational models;Machine translation;Artificial intelligence;Statistics;Computational linguistics;Natural language processing;Text mining;TensorFlow;Tflearn,"Chatbots are software used in entertainment industry, businesses and user support. Chatbots are modeled on various techniques such as knowledge base, machine learning based. Machine learning based chatbots yields more practical results. Chatbot which gives responses based on the context of conversation tends to be more user friendly. The chatbot we are proposing demonstrates a method of developing chatbot which can follow the context of the conversation. This method uses TensorFlow for developing the neural network model of the chatbot and uses the nlp techniques to maintain the context of the conversation. This chatbots can be used in small industries or business for automating customer care as user queries will be handled by chatbots thus reducing need of human labour and expenditure.",2018,S. Ananthakrishnan; S. S. Narayanan,1614,1619,6,5,10.1109/ICICCT.2018.8472998,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472998,IEEE Conferences,IEEE
Combined Approach to Problem of Part-of-Speech Homonymy Resolution in Russian Texts,text processing;part-of-speech homonymy;combined approach;machine learning;homonymy resolution,"The Russian language has an inflective structure and does not have a strict word order. This causes processing difficulties, such as part-of-speech homonymy. This article is devoted to the mentioned issue. The existing approaches to resolving the morphological homonymy problem can be divided into the following groups: rule-based approaches, statistical approaches, machine learning approaches, and combined methods. In the paper, we showed that each approach has its advantages and disadvantages; however, combining several approaches can significantly increase the precision of the algorithm. Moreover, the article provides the analysis of the influence of certain features on the morphological homonymy resolution. The precision of the proposed algorithm is sufficient for its use in the tasks of intellectual text processing texts, for example, in machine translation and summarization systems. The proposed method is successfully used in the geographic location system. The main problem is the distinction between function words (conjunctions, particles, prepositions, interjections). Solving this problem is one of the priorities for the further work. We also plan to implement a system without a dictionary, in order to determine better morphological features for unknown words.",2018,S. B. Kulkarni; P. D. Deshmukh; K. V. Kale,1,6,6,,10.1109/RUSAUTOCON.2018.8501718,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501718,IEEE Conferences,IEEE
Parameters optimization of deep learning models using Particle swarm optimization,smart building services;deep machine learning;parameter optimization;particle swarm optimization,"Deep learning has been successfully applied in several fields such as machine translation, manufacturing, and pattern recognition. However, successful application of deep learning depends upon appropriately setting its parameters to achieve high-quality results. The number of hidden layers and the number of neurons in each layer of a deep machine learning network are two key parameters, which have main influence on the performance of the algorithm. Manual parameter setting and grid search approaches somewhat ease the users' tasks in setting these important parameters. Nonetheless, these two techniques can be very time-consuming. In this paper, we show that the Particle swarm optimization (PSO) technique holds great potential to optimize parameter settings and thus saves valuable computational resources during the tuning process of deep learning models. Specifically, we use a dataset collected from a Wi-Fi campus network to train deep learning models to predict the number of occupants and their locations. Our preliminary experiments indicate that PSO provides an efficient approach for tuning the optimal number of hidden layers and the number of neurons in each layer of the deep learning algorithm when compared to the grid search method. Our experiments illustrate that the exploration process of the landscape of configurations to find the optimal parameters is decreased by 77 % - 85%. In fact, the PSO yields even better accuracy results.",2017,S. Bakhshaei; S. Khadivi,1285,1290,6,19,10.1109/IWCMC.2017.7986470,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7986470,IEEE Conferences,IEEE
Problem Domain Ontology Mining Based on Distributional Semantics,natural language processing;distributional semantics;ontology;syntax;vector spaces;hybrid models;translation;machine translation;intelligent systems;multilingual knowledge extraction,"The paper presents the method of creating an extended ontology as an associative portrait of a subject area and the construction of a semantic space for intelligent knowledge extracting systems development. The ideology of semantic contextual spaces is based on the Distributional hypothesis: linguistic items with similar distributions have similar meanings. The model employed uses an extended hypothesis which includes the study of similarities and differences in contexts not only for a separate lexeme, but also for arbitrary multi-word text fragments which are considered as meaningful phrases.",2019,S. Caballero-Morales; F. Trujillo-Romero,439,444,6,,10.1109/CSCI49370.2019.00086,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071301,IEEE Conferences,IEEE
Machine Learning for Author Affiliation within Web Forums -- Using Statistical Techniques on NLP Features for Online Group Identification,Text Classification;Stylometrics;Natural language processing;feature extraction;feature combination;Support vector machines;k-nearest neighbor;arccosine kernels,"Although there have been previous studies performing authorship attribution to a specific individual, we find a shortage of efforts to group authors based on their affiliations. This paper presents our work on classification of website forum posts by the author's group affiliation. Specifically, we seek to classify translated website forum posts by the (inferred) political affiliation of the author. The two datasets that we attempt to classify consist of real-world data discussing current issues -- Israeli/Palestinian dialogue (Bitter Lemons corpus) and translated Extremist/Moderate forum entries (from internet websites). To achieve our goal of reliable authorship affiliation, we extract term frequency-based features (that are conventional in document classification) along with less commonly used linguistic style-based features. The resulting set of stylometric features are then utilized in two widely used supervised classification algorithms, namely k-Nearest Neighbor algorithm and Support Vector Machines. Specifically, we used k-NN with cosine distance and Support Vector Machines with two different kernel functions. In addition to the popular RBF kernels, we also evaluate the applicability and performance of the recently introduced arc-cosine kernels for group affiliation. The results of our experiments show strong performance across a range of pertinent metrics.",2011,S. Cardey; P. Greenfield; R. Anantalapochai; M. Beddar; D. DeVitre; G. Jin,100,105,6,3,10.1109/ICMLA.2011.90,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6146951,IEEE Conferences,IEEE
MASKER: Adaptive Mobile Security Enhancement against Automatic Speech Recognition in Eavesdropping,Automatic Speech Recognition;Adversarial Example,"Benefited from recent artificial intelligence evolution, Automatic Speech Recognition (ASR) technology has achieved enormous performance improvement and wider application. Unfortunately, ASR is also heavily leveraged by speech eavesdropping, where ASR is used to translate large volume of intercepted vocal speech into text content, causing considerable information leakage. In this work, we propose MASKER - a mobile security enhancement solution to protect the mobile speech data from ASR in eavesdropping. By identifying ASR models' ubiquitous vulnerability, MASKER is designed to generate human imperceptible adversarial noises into the real-time speech on the mobile device (e.g. phone call and voice message). Even the speech data is exposed to eavesdropping during data transmission, the adversarial noises can effectively perturb the ASR process with significant Word Error Rate (WER). Meanwhile, MASKER is further optimized for mobile user perception quality and enhanced for environmental noises adaptation. Moreover, MASKER has outstanding computation efficiency for mobile system integration. Experiments show that, MASKER can achieve security enhancement with an average WER of 84.55% for ASR perturbation, 32% noise reduction for user perception quality and 16Ã— faster processing speed compared to the state-of-the-art method.",2019,S. D. Samantaray,1,6,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807068,IEEE Conferences,IEEE
A Novel Method of Language Modeling for Automatic Captioning in TC Video Teleconferencing,Automatic speech recognition;mixture language model (LM);telemedicine;teleconsultation (TC);video teleconferencing,"We are developing an automatic captioning system for teleconsultation video teleconferencing (TC-VTC) in telemedicine, based on large vocabulary conversational speech recognition. In TC-VTC, doctors' speech contains a large number of infrequently used medical terms in spontaneous styles. Due to insufficiency of data, we adopted mixture language modeling, with models trained from several datasets of medical and nonmedical domains. This paper proposes novel modeling and estimation methods for the mixture language model (LM). Component LMs are trained from individual datasets, with class n-gram LMs trained from in-domain datasets and word n-gram LMs trained from out-of-domain datasets, and they are interpolated into a mixture LM. For class LMs, semantic categories are used for class definition on medical terms, names, and digits. The interpolation weights of a mixture LM are estimated by a greedy algorithm of forward weight adjustment (FWA). The proposed mixing of in-domain class LMs and out-of-domain word LMs, the semantic definitions of word classes, as well as the weight-estimation algorithm of FWA are effective on the TC-VTC task. As compared with using mixtures of word LMs with weights estimated by the conventional expectation-maximization algorithm, the proposed methods led to a 21% reduction of perplexity on test sets of five doctors, which translated into improvements of captioning accuracy",2007,S. Deena; R. W. M. Ng; P. Madhyastha; L. Specia; T. Hain,332,337,6,5,10.1109/TITB.2006.885549,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4167905,IEEE Journals,IEEE
Evaluating Open-source Toolkits for Automatic Speech Recognition of South African Languages,automatic speech recognition;under-resourced;evaluation;languages;isiXhosa;English,"Automatic speech recognition is a critical component of human language technologies. It concerns the translation of speech into textual data which can be processed by computers. Thus, it offers the creation of an intimate link allowing humans to interact with machines on a completely natural level. A variety of open-source toolkits exist for the development of these systems. These toolkits have been successfully implemented and tested for use on well-resourced languages. However, the same level of testing has not been performed for South African languages. This investigation sets out to evaluate popular open-source tools for South African languages and identify optimal toolkit configurations for each language and toolkit. The NCHLT corpora were used to set up automatic speech recognition systems for English and isiXhosa using Kaldi, CMU Sphinx, and HTK. The word error rates achieved during this investigation showed that the best configurations from this investigation achieved better performance than those which were reported by the developers of the NCHLT corpus.",2019,S. Dey; K. Tahiliani; J. R. Harish Kumar; A. K. Pediredla; C. S. Seelamantula,160,165,6,,10.1109/RoboMech.2019.8704774,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704774,IEEE Conferences,IEEE
Automatic Spelling Correction for ASR Corpus in Traditional Chinese Language using Seq2Seq Models,"automatic speech recognition, spelling check, sequence to sequence model, pointer network","The goal of Automatic Speech Recognition (ASR) service is to translate spoken language into text. There exist many factors that will degrade the performance of the ASR system, such as environmental noise, human pronunciation, etc. This research focuses on automatic spelling correction for traditional Chinese corpus generated by ASR systems. We show that a Sequence to Sequence (Seq2Seq) neural network model with attention mechanism could be improved by adding pointer network with auxiliary phoneme features of the input word sequence.",2020,S. Duan; H. Zhao; J. Zhou; R. Wang,553,558,6,,10.1109/ICS51289.2020.00113,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359053,IEEE Conferences,IEEE
MaRePhoR â€” An open access machine-readable phonetic dictionary for Romanian,phonetic dictionary;phoneme;grapheme;phonetic transcription;open access,"This paper introduces a novel open access resource, the machine-readable phonetic dictionary for Romanian - MaRePhoR. It contains over 70,000 word entries, and their manually performed phonetic transcription. The paper describes the dictionary format and statistics, as well as an initial use of the phonetic transcription entries by building a grapheme to phoneme converter based on decision trees. Various training strategies were tested enabling the correct selection of a final setup for our predictor. The best results showed that using the dictionary as training data, an accuracy of over 99% can be achieved.",2017,S. Ferilli,1,6,6,2,10.1109/SPED.2017.7990435,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990435,IEEE Conferences,IEEE
Mechatronic Implementation and Trajectory Tracking Validation of a BCI-based Human-wheelchair Interface,Brain-machine interfaces;Human-machine interfaces;Algorithms and machine learning,"This paper presents a mechatronic P300-based brain computer interface (BCI) for wheelchair control applications. A translucent visual stimulus panel (TVSP) is set up in front of the wheelchair to provide an intuitive P300 visual stimulus operation as well as to realize the see-through scene during operating wheelchairs. In this research, a micro projector is utilized to produce flickering visual stimuli on the display board which is 35cm away from the user. To improve the information transfer rate (ITR), a spatial filter based on Canonical Correlation Analysis (CCA) and Support Vector Machine (SVM) were also applied to this work to improve the performance of BCI classification. The result of experiments showed that the proposed BCI is with 88.2% in accuracy and 22.97 bits/min information transfer rate in average received from ten subjects. In ground truth experiments of practical trajectory tracking, the root mean squared error (RMSE) of P300 BCI are 12.11cm in â€œUâ€? trajectory test.",2020,S. G. Abbott; A. Ade-Ibijola,304,309,6,,10.1109/BioRob49111.2020.9224373,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224373,IEEE Conferences,IEEE
Rule-Based Pronunciation Models to Handle OOV Words for Indonesian Automatic Speech Recognition System,pronunciation dictionary;rule-based;Indonesian;OOV;ASR,"A representative pronunciation dictionary becomes a necessity to cover large vocabulary in many domains. While creating a hand designed pronunciation dictionary in an extensive corpus is expensive and time-consuming, a rule-based pronunciation generation method is considerably effective to be applied in Indonesian language due to simpler graphemetophoneme mapping. In this paper, we propose a rule based G2P translation including an efficient way to handle abbreviation and word splitting. The accuracy of the proposed G2P translation achieved 93.65% for Indonesian word entries, and 87.29% for the overall entries that contain abbreviation and words from other language. The addition of rule based G2P translated OOV words to the dictionary has comparable speech recognition system performance with the hand designed dictionary. With the same amount of OOV addition, the speech recognition system performance is reduced by only 0.27 percent when using the rule-based G2P translated dictionary compared to the hand designed dictionary. From the experiment results, generating a dictionary for the OOV words with the proposed G2P mapping is considerably efficient without a big gap in the speech recognition performance score while reducing great amount of time and resources.",2019,S. Gupta,246,251,6,,10.1109/ICSITech46713.2019.8987472,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987472,IEEE Conferences,IEEE
Lexical normalization model for noisy SMS text,Natural Language Processing;Machine Translation;Social Media;Text Normalization;Noisy words;SMS;Non-noisy word;Lexical Normalization,"In day to day life, digital mediated interactions and communications being an important constituent. The expeditious growth of electronic communications such as E-mails, micro blogs, SMS and chats etc has fabricated extensively noisy forms of text. It predominantly in young urbanitÃ©s. The tremendous growth of noises in text are due to a variety of factors, such as the small number of characters allowed per text messages (160 characters is allowed per SMS and 140 characters allowed per tweets), inventing new abbreviations, using non standard orthographic forms, phonetic substitution etc. In this paper we introduce a lexical normalization model for cleaning the noisy texts. The normalization is based on the channelized database. The model will capture the user interaction for improving the model accuracy. Precursory evaluation shows that the channel model will normalize the noisy word to their standard peer with 97.5 % accuracy.",2014,S. H. Rubin; S. Chen; J. B. Law,57,62,6,1,10.1109/COMPSC.2014.7032621,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7032621,IEEE Conferences,IEEE
Manipuri morphological generator,Morphological Generator;morpho-syntax;morphonemics;Machine Translation;Information Retrieval,"The present paper deals with the design and development of a morphological generator for Manipuri language, a Tibeto-Burman language. It is highly agglutinating language. The input of the morphological generator would be the root word which then inflects the word to the morphology of the language and gives the target forms of the word. The Morphological structure of Manipuri Noun is quite complex since it caters to gender, diminutive, numbers, case and number markings etc. Manipuri nouns are broadly classified into 27 categories according to ending characters and phonological factors. Also Manipuri verbs are classified into 15 main categories. The coverage of the system is directly related to the size of the root list.",2015,S. Hussain; J. J. Kuli; G. C. Hazarika,103,108,6,,10.1109/ISACC.2015.7377324,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377324,IEEE Conferences,IEEE
Sentiment Analysis Model for Opinionated Awngi Text,Sentiment Analysis;Feature-Level;Unigram;NaÃ¯ve Bayes;Support Machine Vectors;Machine learning,"Sentiments are very imperative to decide for both individuals and organizations. Due to the rapid growth of Awngi text on the web, there is no sufficiently available sentiment corpus to be used for research. We developed our corpus by collecting around one thousand five hundred posts from online sources. Even infrequent texts available on the web mostly transliterated in Latin due to lack of accessibility and convenience to typing. This paper proposed a feature-level sentiment analysis method based on machine learning for opinionated Awngi music sentiments. Thus, pre-processing techniques have been employed to clean the data, to convert transliterations to the native Ethiopic script, and to change the words to their base form by removing the inflectional morphemes. To improve the calculation method of feature selection and weighting and proposed a more suitable sentiment analysis algorithm for feature extraction named CHI and weight calculation called TF IDF, increasing the proportion and weight of sentiment words in the feature words. The experiment results show that, among the two learning setups, the accuracy of the SVM is found to be promising.",2019,S. Kumar; M. Kashyap; Y. Choudhary; S. S. Pal; M. Bhattacharya,1,6,6,,10.1109/AFRICON46755.2019.9134016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134016,IEEE Conferences,IEEE
A new approach for detection Alzheimer's Disease with machine learning using Whole Genomic and Single Nucleotide Polymorphism-Chip data,AD (Alzheimer's disease);Dataset;DNA (De-oxyribonucleic acid);Genome;SNP (Single-nucleotide polymorphism);WGS (Whole Genome Sequencing),"One advantage of exploring the human DNA (De-oxyribonucleic acid) is the revelation of its contribution to many human diseases. In result of exploring the DNA, there were specific genes in specific chromosomes in the DNA that reveal Alzheimer's Disease (AD). Prognosis of AD helps in slowing down the progression of the disease considerably which is our main goal. AD is an irreversible progressive disease in the brain that slowly causes decline in the memory affecting the patient's life. AD can be detected by screening the WGS (Whole Genome Sequence) to search in specific genes that are responsible for detecting AD or by finding the mutations that happens in the SNPs (Single-Nucleotide Polymorphism) in these specific genes. This research applies two different approaches to study and analyze the DNA and compares them to each other to determine the most suitable approach regarding detecting AD. A dataset was imported and accommodated from The Alzheimer's Disease Neuroimaging Initiative (ADNI) used to implement our research. Our research obtained that using SNPs in studying and analyzing AD is faster and more reliable than using WGS.",2021,S. Li; J. Zhang; Y. Zhao; F. Dao; H. Ding; W. Chen; H. Tang,1535,1540,6,,10.1109/CCWC51732.2021.9376121,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376121,IEEE Conferences,IEEE
Automatic Detection and Recognition of Shop Name in Outdoor Signboard Images,Text detection;Text segmentation;Recognition;signboard image,"In this paper, a system for automatic detection and recognition of Korean texts or shop names in outdoor signboard images is described. The system includes detection, binarization and extraction of text in a signboard image captured by a camera of a mobile phone for the recognition of the shop name. It can deal with different font styles and sizes as well as illumination changes. Individual characters detected by connected component analysis are recognized by using nonlinear mesh, in which feature vectors of vertical and horizontal components are extracted from the binarized image. Proposed methods have been applied to a Korean text translation system, which can automatically detect and recognize Korean texts and generate the translation result.",2008,S. M. B. Rafi B.; K. S. R. Murty,111,116,6,4,10.1109/ISSPIT.2008.4775652,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4775652,IEEE Conferences,IEEE
Analyze Informant-Based Questionnaire for The Early Diagnosis of Senile Dementia Using Deep Learning,Dementia;information gain;deep neural network;machine learning,"Objective: This paper proposes a multiclass deep learning method for the classification of dementia using an informant-based questionnaire. Methods: A deep neural network classification model based on Keras framework is proposed in this paper. To evaluate the advantages of our proposed method, we compared the performance of our model with industry-standard machine learning approaches. We enrolled 6,701 individuals, which were randomly divided into training data sets (6030 participants) and test data sets (671 participants). We evaluated each diagnostic model in the test set using accuracy, precision, recall, and F1-Score. Results: Compared with the seven conventional machine learning algorithms, the DNN showed higher stability and achieved the best accuracy with 0.88, which also showed good results for identifying normal (F1-score = 0.88), mild cognitive impairment (MCI) (F1-score = 0.87), very mild dementia (VMD) (F1-score = 0.77) and Severe dementia (F1-score = 0.94). Conclusion: The deep neural network (DNN) classification model can effectively help doctors accurately screen patients who have normal cognitive function, mild cognitive impairment (MCI), very mild dementia (VMD), mild dementia (Mild), moderate dementia (Moderate), and severe dementia (Severe).",2020,S. Manna; S. Biswas; R. Kundu; S. Rakshit; P. Gupta; S. Barman,1,6,6,1,10.1109/JTEHM.2019.2959331,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933438,IEEE Journals,IEEE
Recognition of Shaft Orbit Based on Walsh Spectrum and Support Vector Machine,Shaft orbit;Pattern recognition;Walsh transform;Support vector machine,"In order to recognize shaft orbits exactly and quickly, a novel recognition method based on Walsh spectrum and support vector machine is proposed in this paper. Firstly, distance vector between the point on the shaft orbit and its center is calculated and obtained. Secondly, the distance vector is transformed by Walsh orthogonal matrix, and obtained Walsh spectrum has property of invariance to rotation, scaling and translation. Thirdly, Walsh spectrum, as feature of shaft orbit, is trained by support vector machine, and classifying functions are obtained. Finally, the remaining samples are tested by the classifying functions, and experimental results are encouraging which demonstrates the effectiveness and robustness of the proposed approach.",2007,S. Mehrang; O. Lahdenoja; M. Kaisti; M. J. Tadi; T. Hurnanen; A. Airola; T. Knuutila; J. Jaakkola; S. Jaakkola; T. Vasankari; T. Kiviniemi; J. Airaksinen; T. Koivisto; M. PÃ¤nkÃ¤Ã¤lÃ¤,3750,3755,6,,10.1109/ICMA.2007.4304171,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4304171,IEEE Conferences,IEEE
Role of Ontology and Machine Learning in Recommender Systems,recommender system;ontology;machine learning;user profile;systematic review,"Currently, information overload can make selecting the information appropriately as time consuming needs. Therefore created a recommender system that helps the selection of information appropriately and personalized as needed. A system recommender has various types and support techniques to determine recommendations, including ontology and machine learning. Ontology is a conceptualization of the representation of knowledge that can be translated into machine language as well as machine learning which is the formalization of human learning applied to the computer in order to gain knowledge from the real world is considered as techniques that can help find the right recommendations. This study conducted of 750 previous studies that have been carefully analyzed using the Kitchenham method to find the most commonly used recommender system and the roles of both techniques in the system recommendations.",2018,S. P. SaviÄ‡; B. RistiÄ‡; N. ProdanoviÄ‡; G. DevedÅ¾iÄ‡,371,376,6,,10.1109/EECCIS.2018.8692809,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692809,IEEE Conferences,IEEE
Machine Learning-based Prediction for Phase-Based Dynamic Architectural Specialization,"machine learning, artificial neural network, feature reduction, configurable cache, embedded systems, phases","Embedded computing systems are becoming increasingly complex, now performing tasks that were generally limited to desktop computing systems. However, embedded system designers are still required to adhere to stringent embedded design constraints (e.g., energy and area requirements) when designing such increasingly complex systems. To meet these constraints, configurable hardware components introduce configurable parameters (e.g., CPU voltage and frequency, cache size, cache associativity, cache line size, pipeline depth/width, etc.) that can be tuned to specific values to meet different design constraints (e.g., area, energy, performance, etc.) and user demands (e.g., increased battery life, increased performance, or a desired trade off), which translates to a better quality of the user experience. However, determining these specific parameter values is increasingly difficult and time-consuming as the configurable parameter design space increases. This issue is further complicated when considering that each application has a different set of optimal/best parameter values based on these demands and requirements. Furthermore, repetitious application behavior, known as phases, which occur throughout an application's runtime, can be exploited by tracking each phase's unique optimal parameter values; resulting in a multiplicative increase or an exponential increase in the size of the size of the configuration space. In this paper, we propose a machine learning-based methodology to significantly reduce the time required to find the optimal configurable parameter values for the instruction and data caches for each application phase. In our method, we use artificial neural networks (ANNs) to predict the optimal configuration for application phases. We collect execution statistics for use as features for an application phase and use feature reduction to significantly reduce the features size. We show that ANNs exhibit high, stable accuracy over multiple training and testing iterations. We also show that applications exhibit low energy degradations (less than 1%) for both the instruction and data caches using our methodology.",2019,S. P. Singh; A. Kumar; H. Darbari; A. Gupta,529,534,6,,10.1109/ISVLSI.2019.00101,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839472,IEEE Conferences,IEEE
Towards the Automation of a Chemical Sulphonation Process with Machine Learning,sulphonation;surfactants;machine learning;soft sensors;chemical process,"Nowadays, the continuous improvement and automation of industrial processes has become a key factor in many fields, and in the chemical industry, it is no exception. This translates into a more efficient use of resources, reduced production time, output of higher quality and reduced waste. Given the complexity of today's industrial processes, it becomes infeasible to monitor and optimize them without the use of information technologies and analytics. In recent years, machine learning methods have been used to automate processes and provide decision support. All of this, based on analyzing large amounts of data generated in a continuous manner. In this paper, we present the results of applying machine learning methods during a chemical sulphonation process with the objective of automating the product quality analysis which currently is performed manually. We used data from process parameters to train different models including Random Forest, Neural Network and linear regression in order to predict product quality values. Our experiments showed that it is possible to predict those product quality values with good accuracy, thus, having the potential to reduce time. Specifically, the best results were obtained with Random Forest with a mean absolute error of 0.089 and a correlation of 0.978.",2019,S. P. Singh; A. Kumar; H. Darbari; A. Rastogi; S. Jain,352,357,6,,10.1109/ICCMA46720.2019.8988752,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8988752,IEEE Conferences,IEEE
Machine Learning Model for the Detection of Electric Energy Fraud using an Edge-Fog Computing Architecture,edge computing;energy fraud;fog computing;machine learning;smart meter,"One of the most relevant applications today in the smart grid is the use of artificial intelligence and analysis techniques over the data generated, allowing both end-users and utility companies new applications. Energy fraud is considered one of the main non-technical losses for utilities that translate into economic losses, so being able to detect and minimize fraud becomes a vital necessity for utilities. This paper presents a machine learning model that allows the detection of abnormal behaviors in readings of consumption and/or production of electrical energy that can be classified as energy fraud. The proposed model is based on regression and classification techniques over an edge-fog computing architecture, and the results obtained show that its implementation in smart metering systems is adequate.",2020,S. P. Singh; A. Kumar; H. Darbari; L. Singh; A. Rastogi; S. Jain,1,6,6,,10.1109/ICEV50249.2020.9289669,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289669,IEEE Conferences,IEEE
Indonesian-Japanese term extraction from bilingual corpora using machine learning,term extraction;parallel;comparable;linguistic;statistic;machine learning;SVM,"As bilateral relation between Indonesia and Japan strengthens, the need of consistent term usage for both languages becomes important. In this paper, a new method for Indonesian-Japanese term extraction is presented. In general, this is done in 3 steps: (1) n-gram extraction for each language, (2) n-gram cross-pairing between both languages, and (3) classification. This method is aimed to be able to handle term extraction from both parallel corpora and comparable corpora. In order to use this method, we have to build a classification model first using machine learning. There are 4 types of feature we take into consideration. They are dictionary based features, cognate based features, combined features, and statistic features. The first three features are linguistic features. Dictionary based features consider word-pair existence in a predefined dictionary, cognate based features consider morpheme level similarity, combined features consider both dictionary and cognate based features altogether, and statistic features is used in case the first 3 features fail. The only statistic feature we use is context heterogeneity similarity, which consider the variety of words that can precede or follow a term. For learning algorithm, we use SVM (Support Vector Machine). In the experiment, we compared several scenarios: only linguistic features, only statistic features, or both features combined. The classification model was built from parallel corpora since plenty of term pairs can be extracted from parallel corpora. The size of training data was 5,000 term pairs. The best result was achieved by using only linguistic features and without the preprocessing step. The accuracy was up to 90.98% and recall 92.14%. A testing from comparable corpora was also done with size of 37,392 term pairs where 94 were equivalent translation and 37,298 were not. Evaluation using test set gave accuracy of 98.63% precision, but with low recall score of 24.47%.",2015,S. Parrini; L. Zhang; S. Condino; V. Ferrari; D. Caramella; M. Ferrari,111,116,6,2,10.1109/ICACSIS.2015.7415180,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415180,IEEE Conferences,IEEE
Hand Gesture Detection Based Real-Time American Sign Language Letters Recognition using Support Vector Machine,"Sign Language Recognition, skin color algorithm, Principal Component Analysis, Support Vector Machine","Sign language is an indispensable communication means for deaf-mute people because of their hearing impairment. At present, sign language is not a popular communication method among hearing people, so that the majority of the hearing is not willing to have a talk with the deaf-mute, or they have to spend much time and energy trying to figure out what the correct meaning is. Sign Language Recognition (SLR), which aims to translate sign language to people who know few about it in the form of text or speech, can be said to be a great help to deaf-mute and hearing people communicate. In this study, a real-time vision-based static hand gesture recognition system for sign language was developed. All data is collected from a USB camera connected to a computer, and no auxiliary items (such as gloves) were required. The proposed system is based on a skin color algorithm in HSV color space to find the Region of Interest (ROI), where hand gesture is. After completing all pre-processing work, 8 features were extracted from each sample using Principal Component Analysis (PCA). The recognition machine learning approach used was based on Support Vector Machine (SVM). The experimental results show that this system can distinguish B, D, F, L and U, these five American sign language hand gestures, with the success rate of about 99.4%.",2019,S. Paulson; T. S. Jyothis,380,385,6,2,10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00078,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890379,IEEE Conferences,IEEE
Support vector machine based approach for quranic words detection in online textual content,Quranic words;Arabic words;detection;classification;learning model;Support Vector Machine,"Quran is the holy book for Muslims around the world. Since it was revealed to the Prophet Muhammad (PBUH) before about 14 hundreds years, Quran is preserved in all imaginable ways from distortion. The rapid and huge growth of digital media and internet usage, cause a wide spread of the Quranic knowledge as well as Quranic Verses, scripts, Translations, and many other Quranic sciences in its digital formats. Some of the online sources, websites, services and social network users are introducing a less authentic Quranic content, services and applications. The ordinary user of such online resources could not detect and authenticate the provided Quranic verses. In this paper, we propose a machine learning approach to detect Quranic words in a text extracted from online sources. The proposed approach of detection utilizes Support Vector Machine to generate a learning model of Quranic words by training the learner on the Quranic words dataset. The generated classification model is used later to classify the words from online content. Experiments based on different features categories such as the Diacritics, and Statistical features are performed and a prototype is developed, Results show that the accuracy and other evaluation measurements achieved by the proposed approach are higher than the previous measurement in the domain. The Future works will focus on incorporating more machine learning and optimization techniques for achieving higher evaluation measurements.",2014,S. R. Fahim; D. Datta; M. R. I. Sheikh; S. Dey; Y. Sarker; S. K. Sarker; F. R. Badal; S. K. Das,325,330,6,4,10.1109/MySec.2014.6986038,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986038,IEEE Conferences,IEEE
An Application Awareness Framework Based on SDN and Machine Learning: Defining the Roadmap and Challenges,Application awareness; SDN; application metric;qoE; KPI; machine learning,"Software Defined Networking (SDN) has presented a unique networking paradigm to develop network innovations and address the issues discovered by distributed network architectures. This paper aims to address challenges involved in introducing application aware network framework using an arbitrary performance metric and preparing network information for machine learning (ML) analysis. The main goal of this is to automate application specific resource allocation and orchestration.A key facet of the framework is utilizing an application feedback interface to the SDN's Northbound Interface which can receive, during runtime, an arbitrary performance metric from an application and characterizes this in accordance with the network path features, thus making it unique among the literature. The metric describes how well the application is performing in its performance goals. The framework analyses and translates this metric into network features allowing a network manager to calculate the effect of network decisions on application goals.To achieve this the framework utilizes centralized SDN architecture, collects and prepares network information that is better predisposed for ML analysis.",2018,S. R. Laskar; A. Dutta; P. Pakray; S. Bandyopadhyay,411,416,6,7,10.1109/ICCSN.2018.8488328,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488328,IEEE Conferences,IEEE
Utalk: Sri Lankan Sign Language Converter Mobile App using Image Processing and Machine Learning,Sinhala Sign Language;Computer Vision;Machine Learning,"Deaf and mute people face various difficulties in daily activities due to the communication barrier caused by the lack of Sign Language knowledge in the society. Many researches have attempted to mitigate this barrier using Computer Vision based techniques to interpret signs and express them in natural language, empowering deaf and mute people to communicate with hearing people easily. However, most of such researches focus only on interpreting static signs and understanding dynamic signs is not well explored. Understanding dynamic visual content (videos) and translating them into natural language is a challenging problem. Further, because of the differences in sign languages, a system developed for one sign language cannot be directly used to understand another sign language, e.g., a system developed for American Sign Language cannot be used to interpret Sri Lankan Sign Language. In this study, we develop a system called Utalk to interpret static as well as dynamic signs expressed in Sri Lankan Sign Language. The proposed system utilizes Computer Vision and Machine Learning techniques to interpret sings performed by deaf and mute people. Utalk is a mobile application, hence it is non-intrusive and cost-effective. We demonstrate the effectiveness of the our system using a newly collected dataset.",2020,S. Ramakrishnan; P. Isawasan; V. Mohanan,31,36,6,,10.1109/ICAC51239.2020.9357300,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357300,IEEE Conferences,IEEE
Computing Radial Basis Function Support Vector Machine using DNA via Fractional Coding,Molecular Computing;Fractional Coding;Stochastic Logic;Support Vector Machine;Radial Basis Function;DNA computing,"This paper describes a novel approach to synthesize molecular reactions to compute a radial basis function (RBF) support vector machine (SVM) kernel. The approach is based on fractional coding where a variable is represented by two molecules. The synergy between fractional coding in molecular computing and stochastic logic implementations in electronic computing is key to translating known stochastic logic circuits to molecular computing. Although inspired by prior stochastic logic implementation of the RBF-SVM kernel, the proposed molecular reactions require non-obvious modifications. This paper introduces a new explicit bipolar-to-unipolar molecular converter for intermediate format conversion. Two designs are presented; one is based on the explicit and the other is based on implicit conversion from prior stochastic logic. When 5 support vectors are used, it is shown that the DNA RBF-SVM realized using the explicit format conversion has orders of magnitude less regression error than that based on implicit conversion.",2019,S. Ramanathan; M. Sangeetha; S. Talwai; S. Natarajan,1,6,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806881,IEEE Conferences,IEEE
Development of thai text-mining model for classifying ICD-10 TM,ICD-10 TM;Text mining;IR;machine learning;Thai diagnosis,"This paper presents a model for classifying ICD-10 TM using machine learning and information retrieval. The scope of this research take systematic approach for translating diagnosis from medical records to ICD-10 TM is proposed. First, an information retrieval is used to find similarity word in Thai and English diagnose. Then, machine learning approach is applied to classify ICD-10 TM by training models using NaÃ¯ve Bayes algorithm. The result shows that our proposed approach can accurately classify ICD-10 TM in Thai-English diagnose at 81.41%.",2016,S. Ranathunga; F. Farhath; U. Thayasivam; S. Jayasena; G. Dias,1,6,6,2,10.1109/ECAI.2016.7861163,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7861163,IEEE Conferences,IEEE
Deep Learning based Automatic Image Caption Generation,automated captions;deep neural network;CNN;RNN;feature extraction;attention,"The paper aims at generating automated captions by learning the contents of the image. At present images are annotated with human intervention and it becomes nearly impossible task for huge commercial databases. The image database is given as input to a deep neural network (Convolutional Neural Network (CNN)) encoder for generating ""thought vector"" which extracts the features and nuances out of our image and RNN (Recurrent Neural Network) decoder is used to translate the features and objects given by our image to obtain sequential, meaningful description of the image. In this paper, we systematically analyze different deep neural network-based image caption generation approaches and pretrained models to conclude on the most efficient model with fine-tuning. The analyzed models contain both with and without `attention' concept to optimize the caption generating ability of the model. All the models are trained on the same dataset for concrete comparison.",2019,S. Suganthi; P. Bamarukmani; K. G. Srinivasagan; M. Saravanan,1,6,6,2,10.1109/GCAT47503.2019.8978293,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978293,IEEE Conferences,IEEE
Sign Language Interpreter System: An alternative system for machine learning,American Sign Language (ASL);Arabic Sign Language (ArSL);Sign Language Recognition (SLR);sensor glove,"Losing the ability to speak exerts psychological and social impacts on the affected people due to the lack of proper communication. Thus, Sign Language (SL) is considered a boon to people with hearing and speech impairment. SL has developed as a handy mean of communication that form the core of local deaf cultures. It is a visual-spatial language based on positional and visual components, such as the shape of fingers and hands, their location and orientation as well as arm and body movements. The problem is that SL is not understood by everyone, forming a communication gap between the mute and the able people. Multiple and systematic scholarly interventions that vary according to context have been implemented to overcome disability-related difficulties. Sign language recognition (SLR) systems based on sensory gloves are significant innovations that aim to procure data on the shape or movement of the human hand to bridge this communication gap, as the proposed system. The proposed model is a glove equipped with five flex sensors, interfacing with a control unit fixed on the arm, translating American Sign Language (ASL) and Arabic Sign Language (ArSL) to both text and speech, displayed on a simple Graphical User Interface (GUI). The proposed system aims to provide an affordable and user friendly SL translator system, working on the basis of Machine Learning (ML). However, it adapts to each person's hand instead of using a generic data set. The system achieved 95% recognition rate with static gestures and up to 88% with dynamic gestures.",2020,S. Suresh; B. S. Duerstock,332,337,6,,10.1109/NILES50944.2020.9257958,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257958,IEEE Conferences,IEEE
A Survey on Convolution Neural Networks,Artificial Intelligence;Artificial Neural Network;Convolution Neural Network;Computer Vision;Machine Intelligence;Machine Learning;Neural Network AI;Pattern Recognition;Symbolic AI,"Major tools to implement any Artificial Intelligence and Machine Learning systems are Symbolic AI and Artificial Neural Network (ANN) AI. ANN has made a dramatic improvement in the versatile area of Machine Learning (ML). ANN is a gathering of vast number of weighted interconnected artificial neurons, initially invented with the inspiration of biological neurons. These models are much better than previous models implemented with Symbolic AI so far as their performance is concerned. One revolutionary change in ANN is Convolution Neural Network (CNN). These structures are mainly suitable for complex pattern recognition tasks within images. Here we would discuss basics of ANN as a tool for complex pattern recognition and image processing task. Also some applications of the CNN tool we will present OCR based text translation and biometric based uni modal and multimodal person identification systems.",2020,S. T. Cheong; J. Xu; Y. Liu,923,928,6,,10.1109/TENCON50793.2020.9293902,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293902,IEEE Conferences,IEEE
A framework for recognizing and segmenting sign language gestures from continuous video sequence using boosted learning algorithm,Sign language recognition;machine learning;boosted subunits;support vector machine,"The problem of vision-based sign language recognition, which is used to translate signs to English sentence, is addressed in this paper. A fully automatic system to recognize signs that starts with breaking up signs into manageable subunits is proposed. A framework for segmenting and tracking skin objects from signing videos is described. A boosting algorithm to learn a subset of weak classifiers for extracted features to combine them into a strong classifier for each sign is then applied. A joint learning strategy to share subunits across sign classes is adopted, which leads to a more efficient classification of sign gestures. Experimental results shown by the system demonstrate that the proposed approach is promising to build an effective and scalable system on real-world hand gesture recognition from continuous video sequences.",2014,S. T. Gollapudi; S. Sasi,498,503,6,2,10.1109/ICICICT.2014.6781333,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781333,IEEE Conferences,IEEE
Semi-Automatic Tool for Dynamic Contour Tracking in Image-Guided Ultrasound Procedures,Ultrasound imaging;Image-guided procedures;Visual servoing;Active contours;Image moments,"Tracking tools for target structures in ultrasound imaging are a crucial point in the development of semiautonomous image guided procedures. This paper presents an algorithm for semi-autonomous target-structure tracking, which uses a parametric active contour model with a Fourier descriptor formulation. The algorithm is tested in a soft real-time scenario, and its robustness is analysed w.r.t. probe translation and rotation, including also target structure deformations. In terms of temporal performance, the algorithm implemented in MATLAB has shown the ability to operate easily at 25 fps when coupled with an ultrasound probe, showing however capability to reach 40 fps when tested as a standalone algorithm.",2020,S. Yang; S. Wu; L. Chen; W. Hsieh; S. T. Chou,686,691,6,,10.1109/ICIT45562.2020.9067109,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9067109,IEEE Conferences,IEEE
Moment invariant features for automatic identification of critical malaria parasites,Malaria Identification;Plasmodium falciparum;Hu Moments;Microscope Imaging;Parasite Identification,"Malaria is a globally widespread mosquito-borne disease which is caused by Plasmodium parasite. Plasmodium falciparum is the most ubiquitous among few species of Plasmodium and its Gametocyte stage is the most virulent among all stages and species. Although blood films are stained for better visualisation through the microscope, the color difference between red blood cells and parasites is barely identifiable for a computer as images are represented in the RGB color space. Moreover, there are several parasites spread throughout the blood film in various orientations and sizes. The automatic classification becomes further challenging due to the presence of many artefacts in the blood film. A photomicrograph analysis method to determine the presence of the most critical parasite -Gametocyte stage of Plasmodium falciparum - in Giemsa-stained blood films is presented. Having extracted the parasite from the background of the image after a series of pre-processing operations, it is classified using both K-nearest neighbors (K-NN) and Gaussian naÃ¯ve Bayes classifiers. As the key element of the research, moment invariant features are utilised to make the input features invariant to translation, rotation and scale (TRS). Based on leave-one-out cross-validation, true positive rates of 77.78% and 88.89% and, true negative rates of 95.24% and 80.95% were achieved for K-NN and Gaussian naÃ¯ve Bayes classifiers respectively. Since a higher true positive rate is desirable in this application, Gaussian naÃ¯ve Bayes qualifies as the classifier while moment invariant features provide robust covariates for classifying Plasmodium falciparum from other Plasmodium species.",2015,S. Zhang; Z. Shuang; Y. Qin,474,479,6,2,10.1109/ICIINFS.2015.7399058,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399058,IEEE Conferences,IEEE
Toward automatic construction of lexical semantic networks,Clustering;Feature Extraction;Semantic Feature;Lexical Semantic Network,"Nowadays, language resources, such as machine readable dictionaries, WordNets, thesaurus, ontology, and semantic networks, are becoming crucial bases for many intelligent systems like Machine Translation, Information Retrieval, and Natural Language Understanding, etc. The purpose of this work is to extract features and to analyze the manually built Korean wordnet, namely U-WIN, for the automatic construction of a feature based U-WIN. We used ICA and CBC clustering methods and methodologies in the experiments and compared their results. Further we have identified various issues affecting the quality of clustering score.",2010,Shahnawaz,1,6,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484840,IEEE Conferences,IEEE
Automatic Temporally Coherent Video Colorization,Computer Vision;Generative Adversarial Networks,"Greyscale image colorization for applications in image restoration has seen significant improvements in recent years. Many of these techniques that use learning-based methods struggle to effectively colorize sparse inputs. With the consistent growth of the anime industry, the ability to colorize sparse input such as line art can reduce significant cost and redundant work for production studios by eliminating the in-between frame colorization process. Simply using existing methods yields inconsistent colors between related frames resulting in a flicker effect in the final video. In order to successfully automate key areas of large-scale anime production, the colorization of line arts must be temporally consistent between frames. This paper proposes a method to colorize line art frames in an adversarial setting, to create temporally coherent video of large anime by improving existing image to image translation methods. We show that by adding an extra condition to the generator and discriminator, we can effectively create temporally consistent video sequences from anime line arts.",2019,Shuo Zang; H. Zhao; Chunyang Wu; R. Wang,189,194,6,3,10.1109/CRV.2019.00033,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8781608,IEEE Conferences,IEEE
Machine Learning with Generative Adverserial Network,Generative Adversarial Networks (GAN);digitization of images;generator;discriminator;generative modelling;incremental model,"Generative Adversarial Networks have been presented to train generative models as they have pose a certain level of exertion and difficulty in the past years. Comparatively, GAN has received less attention. This model shows that it can generate MNIST (Modified National Institute of Standards and Technology database) digits conditioned on class labels. Translating an image from a certain source image or the original image to a clearer and higher resolution target domain is the approach introduced in this paper. This work presents a non-conventional way to resolve the problem presented in digitizing handwritten digits. This approach is supposed to be easier to implement and understand while having a high efficiency and accuracy as compared to the existing models. It is shown that MNIST digits conditioned on class labels can be generated by this model. Both the generator and discriminator are to be conditioned. The idea is to nurture both the generator and discriminator together and gradually. Beginning from a low-resolution image, more layers are added so that the model can increase the definite finer details and progress towards a clearer image as the training progresses.",2020,T. Hailat; M. N. Al-Kabi; I. M. Alsmadi; E. Al-Shawakfa,543,548,6,,10.1109/ICIRCA48905.2020.9183123,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183123,IEEE Conferences,IEEE
Classification of hand movement imagery tasks for brain machine interface using feed-forward network,Brain Computer;Interface;Motor Imagery;EEG Band Power;Feed-Forward Neural Network,"In this paper, a simple Brain Machine Interface (BMI) system that translates a change of rhythm from brain signal while performing a simulation of hand movement mentally into a real activity movement command is proposed. Four different imaginary tasks are used in the analysis process. A non-stimulus-based BCI approach is used to acquire the brain signal from ten different subjects using 19 channel EEG electrodes. Five spectral band features from each channel are extracted and associated to the respective mental tasks. The features are then classified using Feed-Forward Neural Network. The training is conducted using different ratio of training/testing data set. The developed network models are then tested for its validity. The performance of the developed network models are evaluated through simulation. The result shows that the proposed of both protocol approach and frequency sub band range selection can be an alternative general procedure to classify motor imagery task for a simple BMI system.",2014,T. Ishino; I. Nishikawa; Y. Tohsato; S. Fukuchi; K. Nishikawa,431,436,6,4,10.1109/ICED.2014.7015844,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7015844,IEEE Conferences,IEEE
Adaptive binocular robotic visual tracking algorithm based on mixture kernel Support Vector Machine,Mixture kernel SVM;Binocular visual tracking;Self-calibration;Computer vision,"A novel control scheme for binocular robotic visual tracking problem is proposed. First we obtain the parallel configuration using rotation matrix and translational vector which can be both derived by corresponding points. Second, the binocular vision system provide the position in space and the references are used to estimate the transformation matrix to predict the image motion of the virtually stationary target. A nonlinear visual mapping model for the pseudo Jacobian Matrix is first proposed based on a mixture kernel Support Vector Machine implementation. We abandon the complex iteration calculating procure in Asada. M's approach, and the drawback of ill-condition of pesuodo-Jacobian matrix is overcomed due to its unsuitable initial value. Besides, it is not necessary to know exactly the camera intrinsic parameters; instead, 3 references are enough for the algorithm. The primary advantage of our approach is that only a few number of learning data are need for offline training, and it turn out that this new method not only makes the system get a satisfied fitting output, but also effectively restrains the fluctuation of the prediction output caused by local kernels. Extensive simulations and experiments demonstrate that effectiveness of the proposed control scheme.",2010,T. J. Wroge; Y. Ã–zkanca; C. Demiroglu; D. Si; D. C. Atkins; R. H. Ghomi,6512,6517,6,,10.1109/WCICA.2010.5554201,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5554201,IEEE Conferences,IEEE
A Framework of Computer-Based Learning System Based on Self-Regulated Model in English Writing,computer-based learning system;self-regulated;machine translation;English writing,"This paper presents a design phase of a computer based learning system for English writing in Thai EFL learners. This system is designed to incorporate the self-regulated model and set the components of linguistics and machine translation as a learning environment. The system is designed based on three main phases of self-regulated model: forethought phase, performance phase, and self-reflection phase. The learning environment used to guide completely target sentence writing. Moreover, the display of user interface is designed for using as assisting tool for supporting a student's self-regulated learning in English writing. There are three main modules of the system that consist of learning profile acquisition, learning behavior collection, and learning analytics. The system design is an important phase to encourages action between learners and computer-based learning system for learning in English writing. Then, learners' behavior are collected into data logs store for learning analysis. This system aims to collect Thai EFL learners' behavior and find the behavioral pattern that could helpful reference for improve system and teaching materials in the future.",2019,T. Lewis,1,6,6,,10.1109/iSAI-NLP48611.2019.9045562,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045562,IEEE Conferences,IEEE
Parallel Text Identification Using Lexical and Corpus Features for the English-Maori Language Pair,natural language processing;machine translation;bilingual corpora;Zipfian frequency distribution,"Comparable corpora contain significant quantities of useful data for Natural Language Processing tasks, especially in the area of Machine Translation. They are mainly the source of parallel text fragments. This paper investigates how to effectively extract bilingual texts from comparable corpora relying on a small-size parallel training corpus. We propose a new technique to filter non parallel articles in Wikipedia based on Zipfian frequency distribution. We also use the SVM approach to find parallel chunks of text in a candidate comparable document. In our approach we use a parallel corpus to generate the required features for the training step. The evaluations of generated bilingual texts are promising.",2016,T. M. Oo; Y. K. Thu; K. M. Soe; T. Supnithi,910,915,6,2,10.1109/ICMLA.2016.0163,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838267,IEEE Conferences,IEEE
Evaluation of time-domain features for motor imagery movements using FCM and SVM,Electroencephalogram;Feature extraction;Motor imagery;Brain-Machine Interface;Support Vector Machine;Fuzzy C-Means,"Brain-Machine Interface is a direct communication pathway between brain and an external electronic device. BMIs aim to translate brain activities into control commands. To design a system that translates brain waves and its activities to desired commands, motor imagery tasks classification is the core part. Classification accuracy not only depends on how capable the classifier is but also it is about the input data. Feature extraction is to highlight the properties of signal that make it distinct from the signal of the other mental tasks. Performance of BMIs directly depends on the effectiveness of the feature extraction and classification algorithms. If a feature provides large interclass difference for different classes, the applied classifier exhibits a better performance. In order to attain less computational complexity, five time-domain procedure, namely: Mean Absolute Value, Maximum peak value, Simple Square Integral, Willison Amplitude, and Waveform Length are used for feature extraction of EEG signals. Two classifiers are applied to assess the performance of each feature-subject. SVM with polynomial kernel is one of the applied nonlinear classifier and supervised FCM is the other one. The performance of each feature for input data are evaluated with both classifiers and classification accuracy is the considered common comparison parameter.",2012,T. Nguyen Ba Son; P. Seresangtakul,17,22,6,6,10.1109/JCSSE.2012.6261918,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6261918,IEEE Conferences,IEEE
A suite of tools for Arabic natural language processing: A UNL approach,automatic semantic analysis;universal networking language;language resources;Arabic analysis grammar;Arabic generation grammar;UNL;Arabic natural language processing,"This paper introduces the UNL framework as a collaborative framework that encourages and promotes the participation of linguists and non-linguists in the development of an integral natural language processing workbench. The UNL workbench includes a multitude of user-friendly back-end and front-end applications that facilitate the process of learning the UNL basics, participating in the development of resources within the UNL framework, as well as applications that perform several NLP tasks such as machine translation and editing. This workbench claims the ability to analyze automatically natural languages into their abstract semantic meanings, with the aim of finding the common denominator between all languages.",2013,T. Nose; R. Hishiyama,1,6,6,4,10.1109/ICCSPA.2013.6487236,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6487236,IEEE Conferences,IEEE
A New Approach to Automatic Clothing Matting from Mannequins,Clothing image matting;Virtual clothing try-on,"It is crucial to extract retail clothes from images of mannequins when building a database of clothing images for virtual try-on systems. However, clothes often have complex texture and translucent material, such as holes and laces. It is thus difficult to extract clothes as foreground by existing generic natural image matting methods. Hence in this paper, we present a novel approach to automatic clothing matting from mannequins, with auxiliary information from a rough background image of the mannequin only. Experiments show that we can achieve remarkable improvement on the alpha matte near challenging regions of complex texture and translucent material of clothes. Moreover, our approach can automatically generate trimaps to facilitate the development and evaluation of other image matting algorithms.",2019,T. P. Thi; H. L. Manh,880,885,6,,10.1109/ICME.2019.00156,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784984,IEEE Conferences,IEEE
Disambiguation and Error Resolution in Call Transcripts,homophone disambiguation;automatic speech recognition;text processing,"Ambiguity is inherent to human language and poses a unique challenge both to human listeners as well as natural language processing (NLP) systems. Ambiguity is understood as a type of uncertainty which allows for more than one plausible interpretation of utterances. Ambiguity can introduce problems for NLP systems designed to, for example, execute machine translation, determine sentiment, and perform automatic speech recognition (ASR). We seek to identify and resolve mis-transcriptions that arise from phonetic ambiguity and degraded acoustic signals in 87,000 call transcripts. We first present an alignment algorithm which identifies mis-transcriptions generated by ASR systems when compared against verified human transcriptions. This method not only allows for a general evaluation of ASR performance but also highlights specific areas of difficulty for such systems (e.g. â€œconsiderateâ€? vs. â€œconsider itâ€?). We further present an error resolution algorithm which, given a mis-transcribed word, uses contextual cues to suggest a more likely, phonetically similar word. This work has the potential to not only evaluate existing ASR systems, but also to immediately improve their performance.",2019,T. Sakai; A. Kumano; T. Manabe,4602,4607,6,,10.1109/BigData47090.2019.9005993,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005993,IEEE Conferences,IEEE
High performance natural language processing services on the GARUDA grid,natural language processing;parallel processing;computational complexity;linguistic complexity;NLP Framework;machine translation;MPJ Express;computational grid;high performance computing;GARUDA,"The main objective of this paper is to introduce a high performance natural language processing (NLP) service to fulfill the needs of researchers and users in the area of natural language computing. We consider various NLP components developed at Applied Artificial Group of C-DAC Pune, and carry out parallelization on the GARUDA grid. We demonstrate that almost linear speedup is achieved with good efficiencies. With 32 processors, we have achieved a speedup of more than 19. This allows us to offer high performance scalable NLP Web services. Further, the GARUDA grid offers high availability.",2013,T. W. Ubbens; D. C. Schuurman,1,6,6,5,10.1109/ParCompTech.2013.6621407,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6621407,IEEE Conferences,IEEE
Comparative study of existing approaches on the Task of Natural Language to Database Language,Natural language;Database languages;machine translation;deep learning,"The use of databases is growing rapidly in many domains and the interaction to these systems requires an advanced knowledge of structural languages like SQL, XQuery, XPath, etc..., in order to correctly use the contents of database systems. In this paper, we introduce the pros & cons of the existing solutions on the task of Natural Language to Database Language including Xml and Relational ones. We focus on the ones that are making use of syntax parsing and the others that utilize deep learning techniques to get the right queries.",2019,T. Wang,1,6,6,,10.1109/ICCSRE.2019.8807785,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807785,IEEE Conferences,IEEE
Human Language Question To SQL Query Using Deep Learning,Natural language;Database languages;machine translation;deep learning,"Inferring structured queries from human language is a complex task that should take into account the lack of knowledge of structural languages like SQL, XQuery, XPath, etc..., in order to effectively use the content of database systems. In this paper, we describe the pros & cons of the existing approaches in the task of text to SQL. We put the light on the ones making use of syntax parsing and the others that utilize deep learning methods to predict the appropriate queries.",2019,T. Wang,1,6,6,,10.1109/ICDS47004.2019.8942342,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942342,IEEE Conferences,IEEE
Ascertaining the morphological components of Tamil language using unsupervised approach,Morphological segmentation;unsupervised;machine translation;agglutinative;morphemes;suffix,The learning of morphological components in a natural language by means of segmentation of words to identify the prime chores of stems and affixes lead to effective morphological analysis. Morphological segmentation is an important step in the analysis of natural languages to identify its intricate properties. Remarkable approaches been used in order to construct an effective morphological segmentation framework to study the highly agglutinative Tamil language. This paper focus on unsupervised means of segmenting Tamil lexicons by using a novel algorithm across various parameters. The proposed work shows a promising result in favour to the identification of morphemes with their suffixes.,2016,T. Wu; Z. He; E. Chen; H. Wang,1,6,6,,10.1109/GET.2016.7916723,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7916723,IEEE Conferences,IEEE
Mining Textual Data to Boost Information Access in OSINT,Text Mining;OSINT;morpho-syntactic analysis;semantic analysis;functional analysis;supervised clustering;unsupervised clustering;machine translation,"The revolution in information technology is making open sources more accessible, ubiquitous, and valuable. The International Intelligence Communities have seen open sources grow increasingly easier and cheaper to acquire in recent years. Up to 80% of electronic data is textual and most valuable information is often encoded in pages which are neither structured, nor classified. The process of accessing all these raw data, heterogeneous for language used, and transforming them into information is therefore inextricably linked to the concepts of textual analysis and synthesis, hinging greatly on the ability to master the problems of multilinguality. This paper describes SYNTHEMA SPYWatch, a content enabling system for OSINT,which has been adopted by some Intelligence operative structures in Italy to support the collection,processing, exploitation, production, dissemination and evaluation cycle. By this system, operative officers can get an overview of great volumes of textual data,which helps them discover meaningful similarities among documents and find all related information.",2009,T. Xu; D. Liu; E. Chen; H. Cao; J. Tian,427,432,6,8,10.1109/IV.2009.99,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190856,IEEE Conferences,IEEE
RBF models with shallow and deep feature for skeleton-based human gesture recognition,Kinect;Gesture Recognition;Convolutional Neural Network;Support Vector Machines;Relevance Vector Machines,"Recognition of human actions is an intelligent way for human-machine communication and Radial basis function (RBF) models are among the most powerful machines on this task. One prerequisite of using this traditional model is that the movement data must be translated into a vector space via the feature extraction process. Recent development of the convolutional neural networks (CNNs) has been shown that this deep architecture could achieve state-of-the-art performance in different recognition tasks. However, it is not possible to apply the CNN directly to many applications like 3D coordinates of human skeletal joints. In this paper, we present an effective way of reorganizing the 3D skeletal joints into feature maps, which enables applying the modern CNNs to recognize human gestures. Experimental results on the Microsoft's Kinect dataset MSRC-12 show that the proposed data re-organization scheme combined with the deep feature learning of CNN could achieve very competitive predictive accuracy.",2017,U. Weiss; P. Biber; S. Laible; K. Bohlmann; A. Zell,72,77,6,,10.1109/NAFOSTED.2017.8108041,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8108041,IEEE Conferences,IEEE
Utilizing Computer Vision Algorithms to Detect and Describe Local Features in Images for Emotion Recognition from Speech,machine learning;emotion recognition;spectrogram;support-vector machines;feature selection,"One of the core problems of machine learning applications, and in turn when recognizing Emotions from speech, is the difficulty to decide which measurable features are the ones containing the relevant information concerning the emotion classification task. As there is a wide variety of feature sets extractable from audio signals, which all have different origins as well as advantages and disadvantages, one should choose a method that provides an easy search for relevant features and helps with the selection process. The novelty in our contribution is using methods concentrating on the visual distinction of spectrograms generated from emotionally loaded utterances. The aim was the improvement of the search for strongly emotion-dependent areas in spectrograms, which can be used for easy and efficient emotion classification tasks. For this we employed methods proven to work for similar problems with spectrograms. In this research, the Oriented FAST Rotated BRIEF (ORB) was selected as feature extraction algorithm, a method which is based on the Binary Robust Independent Elementary Features (BRIEF) extraction. The local features were computed from the Smartkom database, which were translated from audio recordings into visual spectrogram representations. Afterwards a Support Vector Machine (SVM) classifier was trained to recognize the emotions for a seven-case (Emotion Classes) and two-case (Valence/Arousal Distinction) problem. This proposed method attained high recall scores on this specific database comparable or in excess of similar methods in the literature. Different parameter settings, like window length, step size in spectrogram creation, denoising of spectrograms and the number of keypoints per spectrogram were analyzed to validate the impact on the classification performance.",2020,V. Dushepa,1,6,6,,10.1109/ICHMS49158.2020.9209538,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209538,IEEE Conferences,IEEE
Passive NAT detection using HTTP access logs,Network security;NAT detection;HTTP access logs;Support Vector Machine (SVM),"Network devices performing Network Address Translation (NAT) overcome the problem of the deficit of IPv4 addresses as well as introduce a vulnerability to the network with possibly insecure configurations. Therefore detection of unauthorized NAT devices is an important task in the network security domain. In this paper, a novel passive NAT detection algorithm is proposed that identifies NAT devices in the network using statistical behavior analysis. We model behavior of network hosts using eight features extracted from HTTP access logs. These features are collected within consecutive non-overlapping time windows covering last 24 hours. To classify whether a host is a NAT device or an end host (non-NAT device) a pre-trained linear classifier is used. Since labeled data for training purposes is hard to obtain, we also propose a way how to generate the training data from unlabeled traffic logs. On the basis of our experimental evaluation, the detection algorithm outperforms the state-of-the-art solution represented by [3].",2016,V. Ferdiansyah; S. Nakagawa,1,6,6,3,10.1109/WIFS.2016.7823896,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823896,IEEE Conferences,IEEE
Effects of various preprocessing techniques to Turkish text categorization using n-gram features,Turkish text classification;n-gram features;supervised machine learning,"Natural Language Processing (NLP) is a prominent subject which includes various subcategories such as text classification, error correction, machine translation, etc. Unlike other languages, there are limited number of Turkish NLP studies in literature. In this study, we apply text classification on Turkish documents by using n-gram features. Our algorithm applies different preprocessing techniques, namely, n-gram choice (character level or word level, bigram or trigram models), stemming, and use of punctuation, and then determines the Turkish document's author and genre, and the gender of the author. For this purpose, Naive Bayes, Support Vector Machines and Random Forest are used as classification techniques. Finally, we discuss the effects of above mentioned preprocessing techniques to the performance of Turkish text classification.",2017,V. Goyal; G. S. Lehal,655,660,6,4,10.1109/UBMK.2017.8093491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093491,IEEE Conferences,IEEE
Comparing deep learning performance on BigData by using CPUs and GPUs,deep learning;big data;parallel programming;machine learning,"During the last few years, we have witnessed a fast growth of the cyber world in which great attention is focused on the use of Big Data that cannot be managed or analyzed with the use of traditional tools. In the past, to convert raw data into valuable information, machine learning techniques were extensively preferred. However, conventional techniques such as Naive Bayes and support vector machines are not efficient for these huge data. Therefore, deep learning methods which are especially preferred in image/speech recognition, information retrieval, language translation, etc., arise as sophisticated and acceptable choices to process data with high accuracy in a hierarchical representation model. Depending on the size of data, even deep learning techniques can be inadequate. To increase the performance, some parallel processing techniques are needed which can be executed on a multi-core structure of the processor. With the technological improvements, the Graphical Processing Units(GPUs), which can contain a few thousands of cores, can also be used in this parallel execution platform. In this paper, we aimed to use a deep learning approach for processing big data to solve a specific problem in a multi-core platform. The experimental results are compared with a CPU execution, and it is depicted that use of GPU Technologies increases the performance of system up to 10 times depending on the type of the GPUs.",2018,V. Lawhern; D. Slayback; D. Wu; B. J. Lance,1,6,6,4,10.1109/EBBT.2018.8391429,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8391429,IEEE Conferences,IEEE
Mexican Sign Language Alphanumerical Gestures Recognition using 3D Haar-like Features,3D Haar-like features;Boosting;Gesture recognition;Machine learning;Sign language,"The Mexican Sign Language (LSM) is a language of the deaf Mexican community, which consists of a series of gestural signs articulated by hands and accompanied with facial expressions. The lack of automated systems to translate signs from LSM makes integration of hearing-impaired people to society more difficult. This work presents a new method for LSM alphanumerical signs recognition based on 3D Haar-like features extracted from depth images captured by the Microsoft Kinect sensor. Features are processed with a boosting algorithm. To evaluate performance of our method, we recognized a set of signs from letters and numbers, and compared the results with the use of traditional 2D Haar-like features. Our system is able to recognize static LSM signs with a higher accuracy rate than the one obtained with widely used 2D features.",2017,V. Ramanathan; H. Wechsler,2000,2005,6,1,10.1109/TLA.2017.8071247,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8071247,IEEE Journals,IEEE
An Undergraduate Curriculum for Deep Learning,Deep Learning;curriculum design;Machine Learning;Deep Neural Networks;Engineering Education,"Deep Learning (DL) is an interesting and rapidly developing field of research which has been currently utilized as a part of industry and in many disciplines to address a wide range of problems, from image classification, computer vision, video games, bioinformatics, and handwriting recognition to machine translation. The starting point of this study is the recognition of a big gap between the sector need of specialists in DL technology and the lack of sufficient education provided by the universities. Higher education institutions are the best environment to provide this expertise to the students. However, currently most universities do not provide specifically designed DL courses to their students. Thus, the main objective of this study is to design a novel curriculum including two courses to facilitate teaching and learning of DL topic. The proposed curriculum will enable students to solve real-world problems by applying DL approaches and gain necessary background to adapt their knowledge to more advanced, industry-specific fields.",2018,V. Rangarajan; S. Narayanan; S. Bangalore,604,609,6,,10.1109/UBMK.2018.8566575,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8566575,IEEE Conferences,IEEE
Statistical ISAR Imagery for Low-Altitude and Small-Size UAV Based on Sparse Bayesian Learning,unmanned aerial vehicle;inverse synthetic aperture radar;Bayesian Learning;machine learning;compressed sensing,"This paper aims at the problems of small Radar Cross-Section (RCS) and short coherent accumulation time in radar detection of low altitude small UAVs. An Inverse Synthetic Aperture Radar (ISAR) super-resolution imaging method based on Bayesian Statistical Machine Learning is proposed. The sparse prior characteristics of UAV with respect to the air-background is utilized by introducing a heavy-tailed Laplacian prior probability distribution, and a Bayesian posterior inference model is derived based on the Gaussian distribution assumption of observation system noise. In view of the non-conjugation of prior distribution, a hierarchical Bayesian model is introduced. Finally, the variational Bayesian expectation maximization algorithm is applied, and the posterior probability density function of the target is solved analytically. Meanwhile, the imaging defocus caused by the non-systematic translational error of the target is corrected, cooperatively. Compared with traditional methods, this method can effectively solve the problem of low imaging signal-to-noise ratio caused by the small RCS of UAV target and low imaging resolution caused by the short coherent accumulation time. The experimental results of simulation and radar data prove the effectiveness and superiority of the proposed method.",2019,V. Rohini; M. Thomas; C. A. Latha,1,6,6,,10.1109/APSAR46974.2019.9048379,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9048379,IEEE Conferences,IEEE
Convolutional Neural Network Pruning: A Survey,convolutional neural networks;machine intelligence;pruning method;training strategy;estimation criterion,"Deep convolutional neural networks have enabled remarkable progress over the last years on a variety of visual tasks, such as image recognition, speech recognition, and machine translation. These tasks contribute many to machine intelligence. However, developments of deep convolutional neural networks to a machine terminal remains challenging due to massive number of parameters and float operations that a typical model contains. Therefore, there is growing interest in convolutional neural network pruning. Existing work in this field of research can be categorized according to three dimensions: pruning method, training strategy, estimation criterion.",2020,V. V. Bakhtin; E. V. Isaeva; A. V. Tararkov,7458,7463,6,1,10.23919/CCC50068.2020.9189610,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189610,IEEE Conferences,IEEE
A Novel Automatic Hierachical Approach to Music Genre Classification,Hierarchical music genre classification;music dataset,"Automatic music genre classification is an important component in Music Information Retrieval (MIR). It has gained lot of attention lately due to the rapid growth in the use of digital music. Past work in this area has already produced a number of audio features and classification techniques, however, genre classification still remains an unsolved problem. In this paper we explore a hybrid unsupervised/supervised top-down hierarchical classification approach. Most existing work on hierarchical music genre classification relies on human built trees and taxonomies, however these hierarchies may not always translate well into machine classification problems. Therefore, we explore an automatic approach to construct a classification tree through subspace cluster analysis. Experimental results validate the tree building algorithm and provide a new research direction for automatic genre classification. We also addressed the issue of scarcity in publicly available music datasets, by introducing a new dataset containing genre, artist and album labels.",2012,W. Chao; Z. Li,564,569,6,11,10.1109/ICMEW.2012.104,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6266445,IEEE Conferences,IEEE
Road Navigation System Using Automatic Speech Recognition (ASR) And Natural Language Processing (NLP),Speech Recognition;Natural Language Processing;Road Navigation;Route Mapping;Navigational Information Extraction,"In a highly evolving technical era, Voice-based Navigation Systems play a major role to bridge the gap between human and machine. To overcome the difficulty in taking and understanding user's voice commands, simulating the natural language, process the route with user's turn by turn directions while mentioning key entities like street names, landmarks, point of interests, junctions and map the route in an interactive interface, we propose a user-centric roadmap navigation mobile application called â€œDirect Meâ€?. The approach of generating the user preferred route, system will first convert the audio streams into text through Automatic Speech Recognizer (ASR) using Pocket Sphinx Library, followed by Natural Language Processing (NLP) by utilizing Stanford CoreNLP Framework to retrieve the navigation-associated information and process the route in the Map using Google Map API upon the user request. This system is used to provide an efficient approach to translate natural language directions to a machine-understandable format and will benefit the development of voice-based navigation-oriented humanmachine interface.",2018,W. Chen,1,6,6,3,10.1109/R10-HTC.2018.8629859,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629859,IEEE Conferences,IEEE
A Semi-Automatic Soccer Video Annotation System based on Ontology Paradigm,Soccer Ontology;Annotation;soccer events;Semantic-Gap;SWRL Rules.,"Currently, the video annotation process becomes a very necessary task to overcome the problem of finding the adequate information on a huge database. To achieve this, it will be necessary to translate low level analysis results to a semantic meaning related to the video sequence, generally known as problem of semantic gap. Many researchers have worked on this issue in the aim to find new solutions, where the ontology paradigm is represented as one of them. In this paper, we consider this problem by developing a soccer ontology, that is used in our OSAS annotation system (Ontology Soccer Annotation System). This one is based on a set of Semantic Web Rule Language (SWRL) rules that bridges the semantic gap problem. Our idea show new directions and perspectives for future developments.",2019,W. Hartmann; L. Lamel; J. Gauvain,88,93,6,,10.1109/IACS.2019.8809161,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809161,IEEE Conferences,IEEE
Automatic landmark detection in cephalometry using a modified Active Shape Model with sub image matching,cephalometry;Active Shape Model;non linear diffusion;Principal Component Analysis;sub image matching,"This paper introduces a modification on using active shape models (ASM) for automatic landmark detection in cephalometry and combines many new ideas to improve its performance. In first step, some feature points are extracted to model the size, rotation, and translation of skull. A learning vector quantization (LVQ) neural network is used to classify images according to their geometrical specifications. Using LVQ for every new image, the possible coordinates of landmarks are estimated, knowing the class of new image. Then a modified ASM with a multi resolution approach is applied and a principal component analysis (PCA) is incorporated to analyze each template and the mean shape is calculated. The local search to find the best match to the intensity profile is then used and every point is moved to get the best location. Finally a sub image matching procedure, based on cross correlation, is applied to pinpoint the exact location of each landmark after the template has converged. On average It percent of the landmarks are within 1 mm of correct coordinates,percent within 1 mm, and percent within 1 mm, which shows a distinct improvement on other proposed methods.",2007,W. Qu,73,78,6,1,10.1109/ICMV.2007.4469276,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4469276,IEEE Conferences,IEEE
"Automatic Spotting of Vowels, Nasals and Approximants from Speech Signals",Broad Phoneme Classifier;Spectral Spread;Spectral Centroid;Envelope Variance;Energy Ratio;Spectral Peak Frequency;Sonorant,"Automatic speech recognition involves methodologies for translation of spoken language into text. An important problem that needs to be solved for the success of speech recognition is the accurate detection of phonemes. In this paper, a two stage system for spotting the boundaries of vowels, nasals and approximants in Malayalam speech signal is proposed. In the first stage, speech signal is classified into six broad phoneme classes using an Artificial Neural Network based broad phoneme classifier. Classifier with nine features has limited accuracy for detecting vowel, nasal and approximant boundaries. So features like difference of spectral spread, spectral centroid, envelope variance, energy ratio, difference in formant frequencies are added to the classifier. With these additional features, a major improvement in classifier accuracy is achieved. In the second stage, a frequency domain parameter named spectral peak frequency is suggested for accurate verification of nasals. Sonorant and nonsyllabic features are used for verifying approximants and syllabic feature is used for locating vowels.",2018,W. Winiwarter,272,277,6,,10.1109/CETIC4.2018.8531026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531026,IEEE Conferences,IEEE
A Deep Dive into Automatic Code Generation Using Character Based Recurrent Neural Networks,Deep Learning (DL);Natural Language Processing (NLP);Recurrent Neural Network (RNN);Training Dataset;Epoch,"Deep Learning is an emerging field in Artificial Intelligence that uses biologically inspired neural networks to recognize patterns in the natural world. These neural networks have an amazing ability to process large amounts of data and learn from them. Recurrent Neural Networks (RNN) are used in applications involving natural language processing like text translations and text generation. This research evaluates the effectiveness of a RNN to be able to automatically generate programming code. Programming languages are different from natural languages in that they have unique structure and syntax. The goal for this research is to conduct experiments on a character RNN model with for three programming languages; Java, Python and C#, and evaluate the results by testing and analyzing the ability for the RNN to automatically produce code that is able to compile.",2017,Weian Wang; Yi Liu; Jiao lu; Bo zheng,369,374,6,,10.1109/CSCI.2017.61,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8560817,IEEE Conferences,IEEE
Part-of-speech tagging based on dictionary and statistical machine learning,part-of-speech tagging;ambiguity word;word segmentation dictionary;maximum entropy;big data,"Part-of-speech tagging is the basis of Natural Language Processing, and is widely used in information retrieval, text processing and machine translation fields. The traditional statistical machine learning methods of POS tagging rely on the high quality training data, but obtaining the training data is very time-consuming. The methods of POS tagging based on dictionaries ignore the context information, which lead to lower performance. This paper proposed a POS tagging approach which combines methods based on dictionaries and traditional statistical machine learning. The experimental results show that the approach not only can solve the problem that the training data are insufficient in statistical methods, but also can improve the performance of the methods based on dictionaries. The People's Daily corpus in January 1998 is used as testing data, and the accurate rate of POS tagging achieves 95.80%. For the ambiguity word POS tagging, the accuracy achieves 88%.",2016,X. Cheng; X. Cheng; Q. Li; L. Ma,6993,6998,6,2,10.1109/ChiCC.2016.7554459,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554459,IEEE Conferences,IEEE
Implicit language identification system based on random forest and support vector machine for speech,MFCCs;SVM;LPC;Random Forest(RF),"Speech uttered by the human beings contains the information about speakers, languages and contents. Language of uttered speech can easily be identified by extracting the language specific information from it. Identification of language of speech is known as Language Identification (LID). Identification of language from speech is helpful in its translation, speech recognition and speech activated automatic systems. LID system may also play an important role in speaker recognition as identification of language can be used to reduce search space. In this paper an approach based on Linear Predictive Coding (LPC) and Mel Frequency Cepstral Coefficients (MFCCs) features for language identification is proposed using SVM and Random Forest (RF) classification techniques. Both LPC and MFCC features are vocal tract features. LPC and MFCC features extracted from uttered speech contain language as well as speaker related informations. Identification of language highly depends upon extraction of language specific features. Both these vocal tract parameters of speech contain lot of information about languages spoken compared to other parameters like excitation source parameters and prosodic parameters. Hence combination of these features performs better than individual. Experiments have been performed on the database obtained from IIIT-Hyderabad consisting of 5000 multilingual clean speech signals (Hindi, Bengali, Telugu, Tamil, Marathi and Malayalam). For training the proposed model, 600 speech signals are taken arbitrarily from the above database. Language model are created for each language. Evaluation of the proposed models has been made using other 300 speech signals from same database. Language models are evaluated using individual features as well as combined features. Experiments performed by taking both features at a time give better result as compared to taking individual features one at a time. Using these features, the accuracy of language identification is not more than 80% so far as claimed by other researchers. In the proposed approach, the accuracy of language identification is improved to 92.6% using combination of same features and random forest model.",2017,X. Deng; T. Liu; Y. Luo; B. Yang,1,6,6,1,10.1109/ICPCES.2017.8117624,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8117624,IEEE Conferences,IEEE
A multimodal-signals-based gesture recognition method for human machine interaction,Gestsure Recognition;EMG;EEG;Inertial Measurement Unit;Muscle-Computer-Interfaces,"As the capacity for machines to extend human capabilities continues to grow, the communication channels used also need to expand. Allowing machines to translate gestural command into robot movements can make the communication between humans and machines more similar to interpersonal communication. Yet for operating requirements, instantaneity and precision of the interaction must reach the application level in realistic scenarios, and the accuracy of results cannot be guaranteed by thejudgement of a single motion sensor. Therefore, exploring a gesture detection technology that integrates multisensor information is very necessary. The presented work takes a step towards real-time gesture detection by fusing multiple physiological signals with wearable motion sensors. An algorithm is presented for processing and extracting motion signal acquired via inertial measurement unit (IMU) and electromyography (EMG) with a high error-tolerant way of wearing, and it is applied to the gesture recognition model established in reasonable threshold and logical judgment. This enables real-time gesture detection of 24 various assembled movements such as rotating palms while bending arms, clenching fist when unwinding upper limb. The result of involving intentional behavior by analyzing electroencephalogram (EEG) is also added to the gesture recognition process for eliminating unconscious actions. Together, these pipelines offer efficient gesture vocabulary suitable for remotely controlling robots. Experiments evaluate classifier performance and interface efficacy. The system successfully detected 95.6% of 360 commands, and the average processing time was 25.4ms among all the 15 trials of the experiment.",2020,X. Sun; D. Huang,494,499,6,,10.1109/ICUS50048.2020.9274853,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274853,IEEE Conferences,IEEE
New algorithms for diagnosing defects of an air-operated valve for self diagnostic monitoring system,Self-Diagnostic Monitoring;Logistic Regression;Neural Network;SVM (Support Vector Machine),"We have developed a self-diagnostic monitoring system for an air operated valve system which produces arrow patterns according to the states of the system and makes a diagnosis whenever the system shows the corresponding symptom [1, 2]. In our first model, we have used a neural network and a simple comparison method for decision processor. In this paper, we modify and improve the decision processor module. We developed a logistic regression algorithm for the simple decision algorithm and modified the neural network algorithm. By changing the rule for translating arrow symbols into 2-D tuples, we could make unambiguous and rich training data set. With this, we performed some simulations and present a result.",2014,X. Zhang; Z. Ge,1,6,6,3,10.1109/ICPHM.2014.7036398,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7036398,IEEE Conferences,IEEE
Leveraging Foreign Language Labeled Data for Aspect-Based Opinion Mining,Aspect-Based Opinion Mining;Aspect Extraction;Sentiment Classification;Support Vector Machines,"Aspect-based opinion mining is the task of identifying sentiment at the aspect level in opinionated text, which consists of two subtasks: aspect category extraction and sentiment polarity classification. While aspect category extraction aims to detect and categorize opinion targets such as product features, sentiment polarity classification assigns a sentiment label, i.e. positive, negative, or neutral, to each identified aspect. Supervised learning methods have been shown to deliver better accuracy for this task but they require labeled data, which is costly to obtain, especially for resource-poor languages like Vietnamese. To address this problem, we present a supervised aspect-based opinion mining method that utilizes labeled data from a foreign language (English in this case), which is translated to Vietnamese by an automated translation tool (Google Translate). Because aspects and opinions in different languages may be expressed by different words, we propose using word embeddings, in addition to other features, to reduce the vocabulary difference between the original and translated texts, thus improving the effectiveness of aspect category extraction and sentiment polarity classification processes. We also introduce an annotated corpus of aspect categories and sentiment polarities extracted from restaurant reviews in Vietnamese, and conduct a series of experiments on the corpus. Experimental results demonstrate the effectiveness of the proposed approach.",2020,Y. Kawara; C. Chu; Y. Arase,1,6,6,,10.1109/RIVF48685.2020.9140735,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140735,IEEE Conferences,IEEE
An Analytical Review of Quantum Neural Network Models and Relevant Research,Quantum Neural Network;Quantum Computation;Quantum Machine Learning,"Quantum Machine Learning is gaining prominence with the advent of real quantum processors. The quantum analogue of one of the most important and popular model of machine learning, namely Artificial Neural Network is studied and reviewed here in this paper. Various approaches to design and implement a quantum neural network has been studied. Most of the works done in this field involved a translation of classical neural network components into the language of quantum physics. But direct translation cannot be a solution as not every classical component has a quantum analogue. Non-linear activation functions are good examples of it. Quantum operators need to be linear and therefore finding alternate solutions to activation functions is an active area of research. Nevertheless, its advantages over the classical models are profound. Quantum superposition gives exponential storage capacity to a quantum network. Quantum parallelism can be put to use and to train the network with multiple inputs in one go. Despite being a new field, many real world applications of a quantum neural network has also been theorised. These models, their advantages, applications and limitations has been discussed in this paper.",2020,Y. Lin; L. Deng; Z. Chen; X. Wu; J. Zhang; B. Yang,1395,1400,6,,10.1109/ICCES48766.2020.9137960,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9137960,IEEE Conferences,IEEE
Transformation of L2 writers to correct English: The need for A computer-assisted writing tool,computer-assisted writing tool;automatic text detection and correction;business letter;genre analysis;non-native writers,"Most of current existing writing tools are developed by native speakers of English (L1). Some of these writing tools may not be suitable for non-native writers (L2) who used English as a second language (L2). The writing styles of L2 writers are different from the writing styles of L1 writers. One of the main problems faced by L2 writers were generating ideas while writing. They tended to generate ideas in L1 and later translated into English as L2. They also lack in vocabulary which make the problem further. People with limited vocabularies are often forced to use the relatively few words they know without knowing their precise meaning. The objective of this paper is to discuss an approach to develop a computer-assisted writing tool for L2 writers. The vocabulary used in business letters will be investigated based on the part of letter, genre analysis and effective sentences and words for business letters. The collection of sentences and words based on these three aspects will be used to develop an electronic dictionary and develop rules to check the sentences and provide suggestive example sentences. Some techniques will be used in order to automatically detect and correct sentences.",2010,Y. Luo; C. Chiu; N. Jaitly; I. Sutskever,1508,1513,6,1,10.1109/ITSIM.2010.5561628,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561628,IEEE Conferences,IEEE
Transfer Learning of a Temporal Bone Performance Model via Anatomical Feature Registration,transfer learning;anatomy registration;automatic evaluation,"Evaluation of the outcome (end-product) of surgical procedures carried out in virtual reality environments is an essential part of simulation-based surgical training. Automated end-product assessment can be carried out by performance classifiers built from a set of expert performances. When applied to temporal bone surgery simulation, these classifiers can evaluate performance on the bone specimen they were trained on, but they cannot be extended to new specimens. Thus, new expert performances need to be recorded for each new specimen, requiring considerable time commitment from time-poor expert surgeons. To eliminate this need, we propose a transfer learning framework to adapt a classifier built on a single temporal bone specimen to multiple specimens. Once a classifier is trained, we translate each new specimens' features to the original feature space, which allows us to carry out performance evaluation on different specimens using the same classifier. In our experiment, we built a surgical end-product performance classifier from 16 expert trials on a simulated temporal bone specimen. We applied the transfer learning approach to 8 new specimens to obtain machine generated end-products. We also collected end-products for these 8 specimens drilled by a single expert. We then compared the machine generated end-products to those drilled by the expert. The drilled regions generated by transfer learning were similar to those drilled by the expert.",2014,Y. Motai,1916,1921,6,1,10.1109/ICPR.2014.335,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977047,IEEE Conferences,IEEE
Towards Annotating Media Contents through Social Diffusion Analysis,Automatic annotation;common interests;diffusion maximization;social diffusion;social media,"Recently, the boom of media contents on the Internet raises challenges in managing them effectively and thus requires automatic media annotation techniques. Motivated by the observation that media contents are usually shared frequently in online communities and thus have a lot of social diffusion records, we propose a novel media annotating approach depending on these social diffusion records instead of metadata. The basic assumption is that the social diffusion records reflect the common interests (CI) between users, which can be analyzed for generating annotations. With this assumption, we present a novel CI-based social diffusion model and translate the automatic annotating task into the CI-based diffusion maximization (CIDM) problem. Moreover, we propose to solve the CIDM problem through two optimization tasks, corresponding to the training and test stages in supervised learning. Extensive experiments on real-world data sets show that our approach can effectively generate high quality annotations, and thus demonstrate the capability of social diffusion analysis in annotating media.",2012,Y. Qiao; K. Hashimoto; A. Eriguchi; H. Wang; D. Wang; Y. Tsuruoka; K. Taura,1158,1163,6,12,10.1109/ICDM.2012.23,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6413736,IEEE Conferences,IEEE
Identification of miRNA signature using Next-Generation Sequencing data of prostate cancer,MicroRNA;Prostate Cancer;Principal Component Analysis;Simulated Annealing;Support Vector Machine;The Cancer Research Atlas,"MicroRNAs (miRNAs) are a class of ~22-nucleotide endogenous noncoding RNAs which have critical functions across various biological processes. It is quite well-known that the miRNAs are playing a crucial role for regulating the expression of target gene via repressing translation or promoting messenger RNAs degradation. Therefore, identification of discriminative and differentially expressed miRNA as a signature is an important task for cancer therapy. In this regard, Next-Generation Sequencing (NGS) data of miRNAs, available at The Cancer Research Atlas (TCGA) repository, is analyzed here for prostate cancer. This cancer type is a serious threat to the health of men as found in the literature. Hence, finding miRNA signature using NGS based miRNA expression data for prostate cancer is an important research direction. Generally by motivating this fact, a new miRNA signature identification method for prostate cancer is proposed. The proposed method uses a global optimization technique, called Simulated Annealing (SA), Principal Component Analysis (PCA) and Support Vector Machine (SVM) classifier. Here SA encodes L number of features, in this case miRNAs. Similar number of top L key principal components of the original dataset is extracted using PCA. Thereafter, such components are multiplied with the reduced subset of data so that the classification task can be done on diverse dataset using SVM. Here the classification accuracy of SVM is considered as an underlying objective to optimize using SA. The proposed method can be seen as feature section technique in order to find potential miRNA signature. Finally, the experimental results provide a set of miRNAs with optimal classification accuracy. However, due to the stochastic nature of this algorithm a list of miRNAs is prepared. From the top 15 miRNAs of that list, four miRNAs, hsa-mir-152, hsa-mir-23a, hsa-mir-302f and hsa-mir-101-1, are associated with prostate cancer. Moreover, the performance of the proposed method has also been compared with other widely used state-of-the-art techniques. Furthermore, the obtained results have been justified by means of statistical test along with biological significance tests for the selected miRNAs.",2016,Y. Qin; Q. Wen; J. Wang,528,533,6,1,10.1109/RAIT.2016.7507956,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507956,IEEE Conferences,IEEE
Problem solving chatbot for data structures,Chatbot;Alexa;(RNN)Recurrent Neural Network;(NSM)Neural Stack Machine,"Intelligent chatbot, is a system which can interact with humans and answers questions on a certain domain. Today, the challenge is to build a system which will resemble human brain. Generally, the brain stores the memory in a decentralized manner across the brain with the help of neuron as opposed to a centralized manner in computer file system. There are short term and long-term memory storage with different priority based on variety of situation. The system can take inputs in written or voice format and respond the question from a knowledge base. In most cases a chat bot does not have problem solving capabilities. Our system can solve data structure problems using deep neural network (DNN). With a given dataset the system can provide services to access data in format such as arrays, stacks, queues and trees. Based on these data structures we can solve problems like traversing lists, reversing numbers and translating language of syntactic divergences. The learning service is not an algorithmic program rather a trained model using DNN. With the implementation of problem solving chatbot, it will understand how to organize and retrieve data based on user's data structure choice. We used Neural Stack Machine (NSM) with Recurrent Neural Network (RNN) as the controller.",2018,Y. RebouÃ§as Serpa; M. A. Formico Rodrigues,184,189,6,2,10.1109/CCWC.2018.8301734,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301734,IEEE Conferences,IEEE
Radar target recognition using time-frequency analysis and polar transformation,Target recognition;Inverse Synthetic Aperture Radar;Machine learning;Time-Frequency Analysis;Empirical Mode Decomposition,"A new method for Automatic Radar Targets Recognition is presented based on Inverse Synthetic Aperture Radar (ISAR). In this work, the first step is to construct ISAR images via a Non uniformly Sampled Bivariate Empirical Mode Decomposition Time-Frequency Distribution (NSBEMD-TFD) method. Indeed, this Time-Frequency representation is well suited for non-stationary signals analysis and provides high resolution with good accuracy. The obtained ISAR images is used to provide the evolution of two-dimensional spatial distribution of a moving target and, therefore, its are suitable to be used for radar target recognition tasks. In second step, a feature vectors are extracted from each ISAR images in order to describe the discriminative informations about a target. In the features extraction step, we computed several rings of polar space applied on ISAR image. Then, these rings is projected on 1-D vector. To ensure translation invariance of the obtained projected 1-D vector, a Fourier Descriptors are computed. In third step of this work, the recognition task is achieved using k-Nearest Neighbors (K-NN), Fuzzy k-NN, Neural network and Bayesian classifiers. To validate our approach, simulation results are presented on a set of several targets constituted by ideal point scatterers models.",2018,Y. Su; K. Fan; N. Bach; C. -. J. Kuo; F. Huang,1,6,6,1,10.1109/ATSIP.2018.8364500,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8364500,IEEE Conferences,IEEE
Target Classification in Synthetic Aperture Radar and Optical Imagery Using Loihi Neuromorphic Hardware,High Performance Computing;Neuromorphic Computing;Machine Learning;Embedded Computing;Synthetic Aperture Radar;Optical Image Exploitation;Spiking Neural Networks;Intelligence;Surveillance and Reconnaissance,"Intel's novel Loihi processing chip has been used to explore new information exploitation techniques. Specifically, we analyzed two types of data (optical and radar). These data modalities and associated machine learning algorithms were used to showcase the ability of the system to address real world problems, such as object detection and classification. Intel's fully digital Loihi design is inspired by biological processes and brain functions. Neuromorphic architectures, such as Loihi, promise to improve computational efficiency for various machine learning tasks with a realizable path toward implementation into many systems, e.g., airborne computing for intelligence, surveillance and reconnaissance systems, and/or future autonomous vehicles and household appliances. With the current software development kit, it is possible to train an artificial neural network model in a common deep learning framework such as Keras and quantize the model weights for a simplistic, direct translation onto the Loihi hardware. The radar imagery analyzed included a seven-vehicle class target set, which was processed at a rate of 9.5 images per second and with an overall accuracy of 90.1%. The optical data included a binary (two classes), and another nine-class data set. The binary classifier processed the optical data at a rate of 12.8 images per second with 94.0% accuracy. The nine classes optical data was processed at a rate 12.9 images per second and 79.7% accuracy. Lastly, the system used ~6 Watts of total power with ~0.6 Watts being utilized by the neuromorphic cores. The inferencing energy used to classify each image varied between 14.9 and 63.2 millijoules/image.",2020,Y. Tam; Y. Lei,1,6,6,,10.1109/HPEC43674.2020.9286246,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286246,IEEE Conferences,IEEE
Remote control with accelerometer-based hand gesture recognition for interaction in digital TV,accelerometer;artificial neural networks (ANN);digital TV;embedded systems;hand gesture recognition;multilayer perceptron (MLP);remote control;support vector machine (SVM),"At the present, the digital TV allows the access to a greater amount of content and to execute interactive applications. The remote control used to control the digital TV systems is, in most cases, still solved by the traditional infrared remote control, which has become a limiting factor on the user interaction with the TV. This paper introduces the design and development of an interaction device for use in the context of digital TV in Argentina. The proposed device can be considered an evolution of the classic remote control, in which the functionality of hand gesture recognition is implemented as a natural and friendly interface for controlling digital TV systems of the home. A gestural dictionary of 20 types of gestures was adopted. The recognized gestures are translated into control commands for digital TV systems. As the hand gesture recognition is a pattern classification problem, two techniques based on artificial neural networks were explored, in order to compare results and to select the tool that best fits the problem in question. The pattern classifier design was described in detail, in order to properly select the hardware platform, fulfilling requirements of low-cost and fast execution of pattern classification algorithms. An interaction device of low-cost and excellent recognition precision was developed, for enhancing and enriching the user experience.",2014,Y. Tan; X. Wang; Y. Chen,29,34,6,2,10.1109/EAMTA.2014.6906075,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906075,IEEE Conferences,IEEE
Representation and Evolution of Knowledge Structures to Detect Anomalies in Financial Statements,Cognition;Computing Models;Deep Learning;Knowledge Structures;Structural Machines;Deep Reasoning;Deep Memory,"Deep learning, has delivered a variety of practical uses in the past decade. It has revolutionized customer experience and machine translation. It has made language recognition, autonomous vehicles and computer vision a reality. A multitude of other AI applications are common now. With Deep Learning we gain insights about hidden correlations. We extract features and distinguish categories. But we lack transparency of reasoning behind these conclusions. Most importantly, there is the absence of common sense. Deep learning models might be the best at perceiving patterns. Yet they cannot comprehend what the patterns mean. And they lack the ability to model their behaviors and reason about them.We present a new approach to augment Deep Learning using model based Deep Reasoning and its application to address fraud detection using financial statements. Recent theoretical models of computing structures with cognizing agents go beyond neural networks to provide models of observations, abstractions and generalizations from experience and create time dependent evolution and history to provide reasoning and predictive. We use Knowledge Structures defined therein to represent relevant domain knowledge. In this case, in a company's financial statements. We analyze their history to detect potential fraud based on specific rules and observations. We use information from governance and compliance rules and experience of past violations. We analyze SEC 10-K statements using Deep Learning and model based Deep Reasoning. We use the Knowledge Structures to identify red flags and anomalies.",2020,Y. Tanaka,58,63,6,,10.1109/WETICE49692.2020.00020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338576,IEEE Conferences,IEEE
Experimental evaluation of a single access point Bluetooth localisation system,Location Tracking;Support Vector Machines;Linear Discriminant Analysis,"Location tracking is a wide field of research with many different solutions. One common trait of many of these solutions is the necessity for a large amount of hardware infrastructure. This work attempts to address this deficiency of typical solutions by developing a localisation system which requires only one piece of infrastructure to be installed, the basestation computer. The proposed localisation system uses classifiers to translate the radio signals coming from a Bluetooth enabled mobile phone to predictions of the currently inhabited room. This paper investigates the applicability of Linear Discriminant Analysis and Support Vector Machines to such a system. Furthermore, experimental results for an in-home environment are used to evaluate the accuracy and repeatability of the proposed localisation system.",2008,Y. Tedla; K. Yamamoto,254,259,6,,10.1049/cp:20080672,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4780963,IET Conferences,IET
Hybrid rebalancing approach to handle imbalanced dataset for fault diagnosis in manufacturing systems,Class-Imbalanced dataset Learning;Fault diagnosis;Support Vector Machine;Condition-based Maintenance;Data-Mining;Mega Trend Diffusion,"In a mature manufacturing system, the occurrence of operating fault conditions is few and far between. Majority of the data collected from such systems typically exhibits normal operating behaviours. This phenomenon inadvertently creates an imbalance between the class distributions of the data. The imbalance ratio may fall in the range of 1:100 to 1:1000 for every fault condition data available. The nature of such datasets thus makes it harder to build reliable models for accurate fault diagnosis in Condition-Based Maintenance (CBM) due to the lack of learning exemplars of the fault class. Conventional machine learning algorithms do not handle imbalanced datasets well and generally would produce poor classification results. To improve the fault diagnosis reliability on class-imbalanced datasets, this paper proposes a hybrid rebalancing approach called Hybrid Support Vector Machine (SVM) under sampling with Mega Trend Diffusion (MTD) oversampling. Our proposed approach rebalances the dataset by (1) Reducing the amount of normal condition data whilst retaining the most informative ones and (2) Boosting the number of fault condition data to match the size of the normal data. This approach is highly applicable to the manufacturing setting as there is a level of predictability to the nature of data, i.e. data of different fault conditions tend to cluster together in the feature space. Thus, manipulating the data at this level is a logical step. As such, learning effectively with the limited available fault data can translate to significantly cost-saving. Our approach is demonstrated and validated with a case study on bearing fault detection. To end, some conclusions and future works are discussed.",2012,Y. Wang,1224,1229,6,3,10.1109/ICIEA.2012.6360910,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360910,IEEE Conferences,IEEE
Modeling Global and local Codon Bias with Deep Language Models,codon bias;deep learning;language modeling;machine learning,"Codon bias, the usage patterns of synonymous codons for encoding a protein sequence as nucleotides, is a biological phenomenon that is not fully understood. Several methods exist to represent the codon bias of an organism: codon adaptation index (CAI) [1], individual codon usage (ICU), hidden stop codons (HSC) [2] and codon context (CC) [3]. These methods are often employed in the optimization of heterologous gene expression to increase the accuracy and rate of translation. They, however, have many shortcomings as they dont take into account the local and global context of a gene. We present a method for modeling global and local codon bias through deep language models that is more robust than current methods by providing more contextual information and long-range dependencies.",2017,Y. Wang; T. Chen; H. Xu; S. Ding; H. Lv; Y. Shao; N. Peng; L. Xie; S. Watanabe; S. Khudanpur,151,156,6,,10.1109/BIBE.2017.00-63,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8251281,IEEE Conferences,IEEE
Part of Speech Tagging for Setswana African Language,NLP;POS tagging;African languages;Annotated corpus;Machine learning,"Part of speech (POS) tagging is the technique that assigns appropriate lexical categories to words in a sentence. It is a crucial step in Natural Language Processing (NLP) applications such as Machine Translation, Spell and Grammar checking, Word Predictions, Information Retrieval, etc.. A lot of work has been done on POS tagging mainly for European and Asiatic languages, while in Africa, more work is needed mostly due to the lack of the annotated corpus. Some significant works have been done on African languages, such as Arabic, Igbo, Swahili and Yoruba, South African official languages. However, African languages are generally under-resourced, in particular, in terms of lexical semantics annotated corpora, necessary for effective NLP tools and applications. Hence, advances in this direction have been limited. The main aim of the work reported in this paper is the development of a POS tagger model for an under-resourced Setswana African language. A review of some POS taggers for different African languages is conducted, challenges and techniques used in creating the POS taggers are elicited, and a POS tagger model for Setswana language using SVMTool is presented.",2019,Y. Wu; F. Li; R. Tanaka; T. Ishida,1,6,6,,10.1109/IMITEC45504.2019.9015871,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9015871,IEEE Conferences,IEEE
Individual difference for HCI systems: Examining the probability of thinking style signature in online interaction,Sternberg thinking style;digital behavioral signature;supervised machine learning approach;Individual difference;Cognitive digital signature,"Researches on human thinking styles have received wide attention, especially in online education; an aspect of human computer interaction. However, the deciphering of specific thinking styles of an online user has suffered setbacks due to the limited exposition on the probability of online thinking style signature of users. This study explored this limitation with the assumption that human daily behavioral pattern can be translated into the electronic media of communication frequently used. To ascertain this assumption, server-side web data of 43-respondents were collected for 10-months as well as a self-report thinking style measurement instrument for each respondent. Cluster dichotomies from two thinking styles were extracted. Various supervised machine learning techniques were then applied to distinguish individuals on each dichotomy. The result showed that thinking styles of individuals on different dichotomies can be reliably distinguished on the internet using Logistic model tree with Bagging technique. The result demonstrates a high probability of the existence of digital thinking style. The findings from this study find relevance and application in human-centered graphical user interface design for recommender system as well as in e-commerce services. It also finds application in online profiling processes especially in e-learning systems.",2016,Y. Yamagishi; T. Akiba; H. Tsukada,51,56,6,2,10.1109/IUSER.2016.7857933,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7857933,IEEE Conferences,IEEE
Classification of motor imagery tasks with LS-SVM in EEG-based self-paced BCI,self-paced;BCI competition IV dataset 1;support vector machine;motor imagery;EEG classification,"Motivated by the need to deal with critical disorders that involve death of neurons, such as Amyotrophic Lateral Sclerosis (ALS) and brainstem stroke, interpretation of the brain's Motor Imagery (MI) activities is highly needed. Brain signals can be translated into control commands. Electroencephalography (EEG) is considered in this work, EEG is a low-cost non-invasive technique. A big challenge is faced due to the poor signal-to-noise ratio of EEG signals. The dataset used in this work is based on asynchronous or self-paced motor imagery problem. The used self-paced Brain Computer Interface (BCI) problem poses a considerable challenge by introducing an additional class, a relax class, or non-intentional control periods that are not included in the training set and should be classified. In this work, a number of subject dependent parameters and their values are determined. These parameters are: the best frequency range, the best Common Spatial Pattern (CSP) channels, and the number of these CSP channels. System parameters are determined dynamically in the offline training phase. Energy based features are extracted afterwards from the best selected signals. The Least-Squares Support Vector Machine (LS-SVM) classifier is used as a classification back end. Results of the proposed system show superiority over the previously introduced systems in terms of the Mean Square Error (MSE) when tested on the Berlin BCI (BBCI) competition IV dataset 1.",2015,Y. Yu; Y. Huang; W. Chao; P. Zhang,244,249,6,6,10.1109/ICDIPC.2015.7323036,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7323036,IEEE Conferences,IEEE
Visual category recognition for the improved storage and retrieval performance of the CCTV camera system,Category Recognition;Feature Extraction;Scale Invariant Feature Transform;Linear Discriminant Analysis;Support Vector Machine;K-Nearest Neighbors;Cartesian Genetic programming,"In this paper, we propose a category level object recognition system for the efficient use of CCTV cameras in terms of storage and retrieval. We investigate the performance of the proposed approach by using four different classifiers. More specifically, we considered image sequences with cars, bikes and pedestrian as our three targeted object categories for classification and ultimately efficient storage and retrieval with reference to our CCTV cameras system. We utilized Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), K-Nearest Neighbors (KNN) and Cartesian Genetic Programming (CGP) algorithms for the considered object categories classification. The Linear Discriminant Analysis (LDA), KNN and Support Vector Machine (SVM) are Statistical algorithms while Cartesian Genetic Programming (CGP) is Evolutionary Algorithm. More specifically, we utilized the standard â€œCaltech 101â€? dataset for investigating the performance of our proposed classifiers. Scale Invariant Feature Transform (SIFT) has been used to extract the scale, orientation and translational invariant features from the considered images which are input to the classifiers. Our empirical results show that in most of the cases, the results of LDA and SVM are relatively the same. To be specific, LDA gives an average accuracy of 85.3% and SVM 83.6%. Similarly, KNN gives an average accuracy of 74.6% while CGP outperforming the three gives accuracy rate of 89%.",2012,Y. Zhang; Q. Ma; H. Isahara,241,246,6,,10.1109/HIS.2012.6421341,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6421341,IEEE Conferences,IEEE
Rare Geometries: Revealing Rare Categories via Dimension-Driven Statistics,machine learning;rare-category detection;geometric data analysis;secant-based dimensionality reduction,"In many situations, classes of data points of primary interest also happen to be those that are least numerous. A well-known example is detection of fraudulent transactions among the collection of all financial transactions, the vast majority of which are legitimate. These types of problems fall under the label of 'rare-category detection.' There are two challenging aspects of these problems. The first is a general lack of labeled examples of the rare class and the second is the potential non-separability of the rare class from the majority (in terms of available features). Statistics related to the geometry of the rare class (such as its intrinsic dimension) can be significantly different from those for the majority class, reflecting the different dynamics driving variation in the different classes. In this paper we present a new supervised learning algorithm that uses a dimension-driven statistic, called the kappa-profile, to determine whether unlabeled points belong to a rare class. Our algorithm requires very few labeled examples and is invariant with respect to translation so that it performs equivalently on both separable and non-separable classes.",2019,Yang He; Zong-Ying Ou; Hao Guo,276,281,6,,10.1109/ICMLA.2019.00052,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999245,IEEE Conferences,IEEE
A Synergistic Framework for Geographic Question Answering,nlp;gis;question answering;ontology;voting algorithm;machine learning;dynamic programming;spatial SQL,QA (question answering) systems designated for answering in-depth geographic questions are highly demanded but not quite available. Previous research has visited various individual aspects of a QA system but few synergistic frameworks have been proposed. This paper investigates the nature of geographic question formation and observes their unique linguistic structures that can be semantically translated into a spatial query. We create a new task of solving non-trivial questions using GIS (Geographic Information System) and test it with an associated corpus. A dynamic programming algorithm is developed for classification and voting algorithm for verification. Two types of ontologies are integrated for disambiguating and discriminating spatial terms. PostGIS serves as the GIS backend to provide domain expertise for spatial reasoning. Results show that exact answers can be returned quickly and correctly by our system. Contrast classification results in improved accuracy compared with the baseline which proves the effectiveness of proposed methods.,2013,Yanjun Ma; Ying Liu,94,99,6,4,10.1109/ICSC.2013.25,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693500,IEEE Conferences,IEEE
Zernike's Feature Descriptors for Iris Recognition with SVM,Iris Recognition;Zernike Moments;Pseudo Zernike Moments;Feature extraction;Support Vector Machine,"Valuable information of the iris is intrinsically located in its natural texture, therefore preserve and extract the most relevant features for biometric recognition is of paramount importance. The iris pattern is subject to translation, scaling and rotation, consequently the variations produced by these artifacts must be minimized. The main contribution of this work consists on performing a comparison between the descriptive power of the Zernike and pseudo Zernike polynomials for the identification of iris images using a Support Vector Machine (SVM) as a classifier. Experiments with the iris data set obtained from the Bath University repository show that our proposal yields high levels of accuracy.",2011,Yuanqian Li; Wei Liu,283,288,6,5,10.1109/SCCC.2011.36,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363408,IEEE Conferences,IEEE
Comparison on the rule based method and statistical based method on emotion classification for Indonesian Twitter text,Emotion Classification;Indonesian Twitter text;rule based method;statistical based method;feature selection;Support Vector Machine;SMOTE,"In this study, we conducted experiments on emotion classification of Indonesian Twitter text. To conduct such experiments, we built a corpus of labeled Twitter data with size of 7622 Twitter text taken from 69 Twitter accounts, manually labeled by 5 native speakers. We used 6 basic emotion labels (angry, disgust, fear, joy, sad, surprise) and add one label of neutral emotion class. Here, we compared a rule based method with a statistical based method. In the rule based method, we employed the existing Synesketch algorithm with two types of emotion word list: a manually written and a translated WordNet-Affect list. In the statistical based method, we employed SVM (Support Vector Machine) algorithm with unigram feature and feature selection algorithms of Information Gain and Minimum Frequency. Other than a pure statistical based method, we also employed the manually built emotion word list in the SVM based classification. In the text pre-processing, we compared several methods such as the normalization, emotion conversion, stop words removal, number removal, and a one-character token removal. The experimental results showed that the statistical based method result of 71.740% accuracy score is higher than the rule based method of 63.172% accuracy score. To enhance the accuracy, we employed SMOTE in order to handle the imbalanced data and achieved best result with the f-measure of 83.203%. In another experiment, we combined the pure statistical method with the rule based method by employing the manually word list into the classification features. The f-measure for this experiment has only reached 81.592%.",2015,Z. Bu; Y. Asai; S. Uno; T. Ikeda,1,6,6,6,10.1109/ICITSI.2015.7437692,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437692,IEEE Conferences,IEEE
Spatio-temporal learning with arrays of analog nanosynapses,on-chip learning;spatiotemporal classification;reservoir computing;extreme learning machine;memristive devices;nanosynapses,"Emerging nanodevices such as resistive memories are being considered for hardware realizations of a variety of artificial neural networks (ANNs), including highly promising online variants of the learning approaches known as reservoir computing (RC) and the extreme learning machine (ELM). We propose an RC/ELM inspired learning system built with nanosynapses that performs both on-chip projection and regression operations. To address time-dynamic tasks, the hidden neurons of our system perform spatio-temporal integration and can be further enhanced with variable sampling or multiple activation windows. We detail the system and show its use in conjunction with a highly analog nanosynapse device on a standard task with intrinsic timing dynamics-the TI-46 battery of spoken digits. The system achieves nearly perfect (99%) accuracy at sufficient hidden layer size, which compares favorably with software results. In addition, the model is extended to a larger dataset, the MNIST database of handwritten digits. By translating the database into the time domain and using variable integration windows, up to 95% classification accuracy is achieved. In addition to an intrinsically low-power programming style, the proposed architecture learns very quickly and can easily be converted into a spiking system with negligible loss in performance-all features that confer significant energy efficiency.",2017,Z. El Maazouzi; B. E. El Mohajir; M. Al Achhab,125,130,6,1,10.1109/NANOARCH.2017.8053708,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8053708,IEEE Conferences,IEEE
DNS-IDS: Securing DNS in the Cloud Era,DNS;Intrusion detection system;Anomaly detection;Machine learning;Data mining;Supervised training,"Recently, there has been a rapid growth in cloud computing due to their ability to offer computing and storage on demand, its elasticity, and significant reduction in operational costs. However, cloud security is a grand obstacle for full deployment and utilization of cloud services. In this paper, we address the security of the DNS protocol that is widely used to translate the cloud domain names to correct IP addresses. The DNS protocol is prone to attacks like cache poisoning attacks and DNS hijacking attacks that can lead to compromising user's cloud accounts and stored information. We present an anomaly based Intrusion Detection System (IDS) for the DNS protocol (DNS-IDS) that models the normal operations of the DNS protocol and accurately detects any abnormal behavior or exploitation of the protocol. The DNS-IDS system operates in two phases, the training phase and the operational phase. In the training phase, we model the normal behavior of the DNS protocol as a finite state machine and we derive the normal temporal statistics of how normal DNS traffic transition within that state machine and store them in a database. To bound the normal event space, we also apply few known DNS attacks (e.g. Cache poisoning) and store the temporal statistics of the abnormal DNS traffic transition in a separate database. Then we develop an anomaly metric for the DNS protocol that is a function of the temporal statistics for both the normal and abnormal transitions of the DNS by applying classification algorithms like the Bagging algorithm. During the operational phase, the anomaly metric is used to detect DNS attacks (both known and novel attacks). We have evaluated our approach against a wide range of DNS attacks (DNS hijacking, Kaminsky attack, amplification attack, Birthday attack, DNS Rebinding attack). Our results show attack detection rate of 97% with very low false positive alarm rate (0.01397%), and round 3% false negatives.",2015,Z. Gong; P. Zhong; W. Hu,296,301,6,6,10.1109/ICCAC.2015.46,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312172,IEEE Conferences,IEEE
Emergent Control of MPSoC Operation by a Hierarchical Supervisor / Reinforcement Learning Approach,Backup-based reinforcement machine learning;MPSoC runtime management;hierarchical reflective control,"MPSoCs increasingly depend on adaptive resource management strategies at runtime for efficient utilization of resources when executing complex application workloads. In particular, conflicting demands for adequate computation performance and power-/energy-efficiency constraints make desired application goals hard to achieve. We present a hierarchical, cross-layer hardware/software resource manager capable of adapting to changing workloads and system dynamics with zero initial knowledge. The manager uses rule-based reinforcement learning classifier tables (LCTs) with an archive-based backup policy as leaf controllers. The LCTs directly manipulate and enforce MPSoC building block operation parameters in order to explore and optimize potentially conflicting system requirements (e.g., meeting a performance target while staying within the power constraint). A supervisor translates system requirements and application goals into per-LCT objective functions (e.g., core instructions-per-second (IPS). Thus, the supervisor manages the possibly emergent behavior of the low-level LCT controllers in response to 1) switching between operation strategies (e.g., maximize performance vs. minimize power; and 2) changing application requirements. This hierarchical manager leverages the dual benefits of a software supervisor (enabling flexibility), together with hardware learners (allowing quick and efficient optimization). Experiments on an FPGA prototype confirmed the ability of our approach to identify optimized MPSoC operation parameters at runtime while strictly obeying given power constraints.",2020,Z. Gong; Y. Zhang; G. Zhou,1562,1567,6,,10.23919/DATE48585.2020.9116574,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116574,IEEE Conferences,IEEE
Improving Allergenic Protein Prediction Using Physicochemical Features on Non-Redundant Sequences,Allergen prediction;Physicochemical features;Sequence patterns;Machine learning algorithms,"Despite extensive studies in allergen prediction, current approaches still have room for performance improvement and suffer from the problem of lack of interpretable biological features. Thus, developments of allergen prediction method from sequences have become highly important to facilitate in silico vaccine design. In this study, we propose a systematic approach to predict allergenic proteins by incorporating sequence and physicochemical properties in machine learning algorithms. In addition, predictive performance of previous studies could be overestimated due to high redundancy in the data sets. Therefore, we reduce sequence redundancy in the data set and experiment results show that we achieve better predictive performance when compared with other approaches. This study can help discover new prophylactic and therapeutic vaccines for diseases. Moreover, we analyze immunological features that can provide valuable insights into immunotherapies of allergy and autoimmune diseases in translational bioinformatics.",2019,Z. Ji; C. Chen; J. He; X. Guan,1,6,6,,10.1109/ICMLC48188.2019.8949197,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949197,IEEE Conferences,IEEE
A Generative Adversarial Neural Network for Beamforming Ultrasound Images : Invited Presentation,Deep Learning;Generative Adversarial Network;Ultrasound Image Formation;Beamforming;Image Segmentation;Machine Learning,"Plane wave ultrasound imaging is an ideal approach to achieve maximum real-time frame rates. However, multiple plane wave insonifications at different angles are often combined to improve image quality, reducing the throughput of the system. We are exploring deep learning-based ultrasound image formation methods as an alternative to this beamforming process by extracting critical information directly from raw radio-frequency channel data from a single plane wave insonification prior to the application of receive time delays. In this paper, we investigate a Generative Adversarial Network (GAN) architecture for the proposed task. This network was trained with over 50,000 FieldII simulations, each containing a single cyst in tissue insonified by a single plane wave. The GAN is trained to produce two outputs - a Deep Neural Network (DNN) B-mode image trained to match a Delay-and-Sum (DAS) beamformed B-mode image and a DNN segmentation trained to match the true segmentation of the cyst from surrounding tissue. We systematically investigate the benefits of feature sharing and discriminative loss during GAN training. Our overall best performing network architecture (with feature sharing and discriminative loss) obtained a PSNR score of 29.38 dB with the simulated test set and 14.86 dB with a tissue-mimicking phantom. The DSC scores were 0.908 and 0.79 for the simulated and phantom data, respectively. The successful translation of the feature representations learned by the GAN to phantom data demonstrates the promise that deep learning holds as an alternative to the traditional ultrasound information extraction pipeline.",2019,Z. Li; E. S. Chng; H. Li,1,6,6,12,10.1109/CISS.2019.8692835,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692835,IEEE Conferences,IEEE
Evaluating Techniques for Practical Cloud-based Network Intrusion Detection,network intrusion detection;anomaly detection;machine learning,"Machine learning and anomaly detection techniques are commonly used to perform network intrusion detection. Though a great deal of research exists in this domain, many publications focus on a single technique applied to a single dataset instead of demonstrating baseline results for a suite of techniques applied to multiple datasets. Variations in experimental procedures complicate comparison across research efforts. Furthermore, the limited scope of many research efforts often does not translate to usefulness in real-world environments. As services continue to be migrated to cloud-based infrastructures, attack surfaces increase in size, providing more opportunity for attackers and increasing the need for network-based protections. We present a set of experiments and insights demonstrating how commonly applied anomaly detection and machine learning techniques perform against three of the most frequently used and highly regarded intrusion detection datasets. In many cases, our results are comparable to those reported in prior work, but our results indicate how techniques generalize to other datasets.",2020,Z. Li; G. Liu,62,67,6,,10.1109/SmartCloud49737.2020.00020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265931,IEEE Conferences,IEEE
Optimization of sitting posture classification based on user identification,Sensory Intelligent Chair;Sitting Posture Classification;Machine Learning,"In a precursory work, an intelligent sensing chair prototype was developed to classify 12 standardized sitting postures using 8 pneumatic bladders (4 in the chair's seat and 4 in the backrest) connected to piezoelectric sensors to measure inner pressure. A Classification of around 80% was obtained using Neural Networks. This work aims to demonstrate how algorithmic optimization can be applied to a newly developed prototype to improve posture classification performance. The aforementioned optimization is based on the split of users by sex and use two different previously trained Neural Networks (one for Male and the other for Female). Results showed that the best neural network parameters had an overall classification 89.0% (from the 92.1% for Female Classification and 85.8% for Male, which translates into an overall optimization of around 8%). Automatic separation of these sets was achieved with Decision Trees with an overall classification optimization of 87.1%.",2015,Z. Liu; X. Xia; A. E. Hassan; D. Lo; Z. Xing; X. Wang,1,6,6,3,10.1109/ENBENG.2015.7088853,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7088853,IEEE Conferences,IEEE
Hand gesture recognition using fourier descriptors,Gesture Recognition;Fourier Descriptors (FD);Support Vector Machine (SVM),"Accurate, real-time hand gesture recognition is a challenging and crucial task due to the need of more natural human-computer interaction methods. The major problem lies in fining a good compromise between the accuracy of recognition and the computational load for the algorithm to run in real-time. In this paper we propose a method for static hand gesture recognition using Fourier descriptors for feature extraction with different classifiers. Fourier descriptors have the advantage of giving a set of features that are invariant to rotation, translation and scaling. They are also efficient in terms of speed as they only use a small number of points from the entire image. The proposed method is evaluated using images from the Cambridge Hand Gesture Dataset at different number of features and different classifiers. The effectiveness of the method is shown through simulation results.",2013,Z. Paliy; A. Romanyuk,274,279,6,10,10.1109/ICCES.2013.6707218,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707218,IEEE Conferences,IEEE
Two Problems in Knowledge Graph Embedding: Non-Exclusive Relation Categories and Zero Gradients,Relational Machine Learning;Knowledge Graph;Knowledge Graph Embedding,"Knowledge graph embedding (KGE) learns latent vector representations of named entities (i.e., vertices) and relations (i.e., edge labels) of knowledge graphs. Herein, we address two problems in KGE. First, relations may belong to one or multiple categories, such as functional, symmetric, transitive, reflexive, and so forth; thus, relation categories are not exclusive. Some relation categories cause non-trivial challenges for KGE. Second, we found that zero gradients happen frequently in many translation based embedding methods such as TransE and its variations. To solve these problems, we propose i) converting a knowledge graph into a bipartite graph, although we do not physically convert the graph but rather use an equivalent trick; ii) using multiple vector representations for a relation; and iii) using a new hinge loss based on energy ratio(rather than energy gap) that does not cause zero gradients. We show that our method significantly improves the quality of embedding.",2019,Z. Rahimi; K. Taghipour; S. Khadivi; N. Afhami,1181,1186,6,,10.1109/BigData47090.2019.9005966,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005966,IEEE Conferences,IEEE
Opinion Mining from Bangla and Phonetic Bangla Reviews Using Vectorization Methods,Opinion Mining;Restaurant Reviews;Phonetic Bangla;HashingVectorizer;CountVectorizer;TF-IDF;Machine Learning,"Opinion mining is the computational study of people's opinions, emotions and attitudes which is one of the key research field in Natural Language Processing (NLP). To cope with the competitive world, owners of business need to extract exact opinion of people about his/her business. Recently, people in Bangladesh are more interested to express their opinion in Bangla and most importantly in Phonetic Bangla rather than English. Since no specific work of Opinion mining introduced this criteria, in this paper, we have developed review analysis system on Bangla and Phonetic Bangla where we have used Restaurant reviews as case study and the dataset is created manually by us without using translator. Our approach starts by preprocessing raw data and then feature extraction with different N-gram techniques. Then vectorization is applied on that data with HashingVectorizer, CountVectorizer and TF-IDF vectorizer. Later machine learning based approaches namely Support Vector Machine (SVM), Decision Tree (DT) and Logistic Regression (LR) are applied to classify reviews. We have classified the reviews in three different classes, i.e. bad, good and excellent. Finally a comparison is shown between vectorizers in accordance with different classifiers where SVM provides better accuracy with 75.58%.",2019,Z. Rahimi; S. Khadivi,1,6,6,3,10.1109/EICT48899.2019.9068834,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068834,IEEE Conferences,IEEE
Semantic Similarity Calculation Based on Sememe Set,similarity;definition;sememe;connotation;machine-readable dictionary,"The calculation of semantic similarity is a key point in Chinese information processing. This paper presents a new method for calculating semantic similarity between two words. Different from previous methods, this paper focuses on the perspective of connotations, trying to highlight the essential attributes of words by which we can get the similarity value in words' conceptual level. Firstly, we get definitions from machine-readable dictionaries. Every definition will be translated into an interpretation vector. Then we use sememe, which is the least significant unit of concept in HowNet, as the unit of definition in the iterative process. Evaluations show that the method is effective and achieves good results.",2010,Z. Shiyang,423,428,6,2,10.1109/AICI.2010.95,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655634,IEEE Conferences,IEEE
Part of Speech Tagging for Kayah Language Using Hidden Markov Model,Part of Speech;Hidden Markov Model;Supervised Learning;Machine Learning;Tagging;Kayah Corpus,"Part of Speech tagging is one of the active research problem in Natural Language Processing involves language understanding, reasoning and the utilization of common sense of knowledge. This paper contributes the pioneer evaluation to the Kayah Language for tagging Part of Speech. Kayah language is one of the low resource languages in Myanmar. Kayah corpus used in this system is translated by Kayah people from Myanmar. The goal is to build the Kayah Language Part of Speech Tagging System based Hidden Markov Model. Sixteen tag sets are defined for this language. Hidden Markov Model is used to learn the Kayah corpus of words annotated with the correct Part of Speech tags and generated the model relating to the Initial, Transition and Emission probabilities for Kayah Language. Then the generated model is used to decode Viterbi algorithm. This Kayah Hidden Markov Model based POS tagging has been experimented and has overall accuracy of 87 % on test data.",2019,Z. T. Irwin; D. E. Thompson; K. E. Schroeder; D. M. Tat; A. Hassani; A. J. Bullard; S. L. Woo; M. G. Urbanchek; A. J. Sachs; P. S. Cederna; W. C. Stacey; P. G. Patil; C. A. Chestek,228,233,6,,10.1109/ICEECCOT46775.2019.9114552,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9114552,IEEE Conferences,IEEE
Optimized Backpropagation Neural Network Model For Brain Computer Interface System,Backpropagation Neural Network (BPN);Brain Computer Interface (BCI);Electroencephalogram (EEG);Support Vector Machine (SVM);Synergistic Fibroblast Optimization (SFO),"People with several disabilities face many challenges in personal communication with the external real-world environment. Brain Computer Interface (BCI) system offers promising solution for both communication and rehabilitation therapies which overcomes the difficulties faced by disabled people, especially fully non-speaking people. Noninvasive Electroencephalogram (EEG) based BCI system acts as a communication medium that translates brain-activity into commands for computer systems or other devices. EEG signals recorded from the scalp of aforementioned subjects are utilized to extract the meaningful patterns in the EEG-based BCI system. In this paper, an optimized Backpropagation Neural Network (BPN) based on Synergistic Fibroblast optimization (SFO) algorithm is proposed for the classification of EEG patterns in the design of robust BCI system. EEG signals collected from open repository database are employed to evaluate the efficiency of SFO based BPN classifier which is compared with Support Vector Machine (SVM) and conventional BPN method. Investigation of the results show that SFO based BPN method achieves highest classification accuracy compared to other conventional classifiers.",2019,Z. Tao; B. Dong; Z. Teng; Y. Zhao,420,425,6,,10.1109/ISC246665.2019.9071784,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071784,IEEE Conferences,IEEE
Investigating Deep Learning for Predicting Multi-linguistic Interactions with a Chatterbot,Machine Learning;Deep Learning;Neural Networks;RNN;TensorFlow;Keras;Yandex Predictor,"Deep Learning (DL) becomes a mainstream technique for Artificial Intelligence (AI) machine learning because of its success in performing many tasks, such as image recognition, speech interpretation, language prediction and translation. We are investigating the underlying principles of DL Neural Networks (NN) to design optimal DL NN for predicting human multi-linguistic conversations with a chatterbot. This research attempts to tackle the well-known open problem of finding optimal NN designs for data of various characteristics. We are in particular focusing on Recurrent Neural Networks (RNN) models with time progression, which takes into consideration the results from the previous steps plus the current input to predict the next step, i.e. it `remembers' what it has previously learnt. Through the experiments of tuning an RNN to achieve an optimal performance in terms of accuracy and training time, we found that characteristics such as word counts and layers of neurons could affect the training performance. We applied the tuned optimal model to a game implementation, inspired by IBM Watson, where users can guess the words to be generated by a computer, called â€œBeat AIâ€? to have human predict the machine prediction.",2020,Z. Yaghoubi; M. Eliasi; K. Faez; A. Eliasi,20,25,6,,10.1109/ICBDA50157.2020.9289710,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289710,IEEE Conferences,IEEE
Scalable effort hardware design: Exploiting algorithmic resilience for energy efficiency,Scalable Effort;Approximate Computing;Low Power Design;Support Vector Machines;Recognition;Mining,"Algorithms from several interesting application domains exhibit the property of inherent resilience to â€œerrorsâ€? from extrinsic or intrinsic sources, offering entirely new avenues for performance and power optimization by relaxing the conventional requirement of exact (numerical or Boolean) equivalence between the specification and hardware implementation. We propose scalable effort hardware design as an approach to tap the reservoir of algorithmic resilience and translate it into highly efficient hardware implementations. The basic tenet of the scalable effort design approach is to identify mechanisms at each level of design abstraction (circuit, architecture and algorithm) that can be used to vary the computational effort expended towards generation of the correct (exact) result, and expose them as control knobs in the implementation. These scaling mechanisms can be utilized to achieve improved energy efficiency while maintaining an acceptable (and often, near identical) level of quality of the overall result. A second major tenet of the scalable effort design approach is that fully exploiting the potential of algorithmic resilience requires synergistic cross-layer optimization of scaling mechanisms identified at different levels of design abstraction. We have implemented an energy-efficient SVM classification chip based on the proposed scalable effort design approach. We present results from post-layout simulations and demonstrate that scalable effort hardware can achieve large energy reductions (1.2X-2.2X with no impact on classification accuracy, and 2.2X-4.1X with modest reductions in accuracy) across various sets. Our results also establish that cross-layer optimization leads to much improved energy vs. quality tradeoffs compared to each of the individual techniques.",2010,Z. Yang; W. Chen; F. Wang; B. Xu,555,560,6,79,10.1145/1837274.1837411,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5523464,IEEE Conferences,IEEE
A Control Barrier Perspective on Episodic Learning via Projection-to-State Safety,Machine learning;Lyapunov methods;uncertain systems,"In this letter we seek to quantify the ability of learning to improve safety guarantees endowed by Control Barrier Functions (CBFs). In particular, we investigate how model uncertainty in the time derivative of a CBF can be reduced via learning, and how this leads to stronger statements on the safe behavior of a system. To this end, we build upon the idea of Input-to-State Safety (ISSf) to define Projection-to-State Safety (PSSf), which characterizes degradation in safety in terms of a projected disturbance. This enables the direct quantification of both how learning can improve safety guarantees, and how bounds on learning error translate to bounds on degradation in safety. We demonstrate that a practical episodic learning approach can use PSSf to reduce uncertainty and improve safety guarantees in simulation and experimentally.",2021,Z. Yang; W. U. Bajwa,1019,1024,6,,10.1109/LCSYS.2020.3009082,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139452,IEEE Journals,IEEE
De Novo Sequence-Based Method for ncRPI Prediction using Structural Information,RNA Protein Interaction;Computational Proteomics;Machine Learning;Classification Models,"Improving knowledge of RNA-binding protein targets is focusing the attention towards non-coding RNAs (ncRNAs), i.e., transcripts not translated into a protein; they are associated with a wide range of biological functions through different molecular mechanisms, usually concerning the interaction with one or more protein partners. Recent studies confirmed that the alteration of ncRNA-protein interactions (ncRPIs) may be linked to various pathologies, including autoimmune and metabolic diseases, neurological and muscular disorders and cancer. Unfortunately, the limited number of structurally characterized RNA-protein complexes available does not allow to accurately establish their role in cellular processes and diseases. Experimental analyses to identify ncRNA-protein interactions are providing a large amount of valuable data, but these experiments are expensive and time-consuming. For these reasons, computational approaches based on machine learning techniques appear very useful to predict ncRPIs. Yet, there are still few studies regarding the prediction of ncRPIs, especially including the use of higher-order structures, which are of vital importance for the ncRPI functions. In this work, a new computational method for non-coding RNA-protein interaction prediction is developed; from sequence data, it derives more accurate information about the secondary structure of the molecules involved in such interactions, which it then uses in the prediction. Obtained results suggest that the use of machine learning techniques, together with considering also information on higher-order structures of ncRNAs and proteins, can be useful to better predict ncRPIs.",2019,Z. Ye; Z. Jia; J. Huang; H. Yin,146,151,6,,10.1109/BIBE.2019.00034,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941858,IEEE Conferences,IEEE
Dichotomic Prediction of an Event using Non Deterministic Finite Automata,Machine learning algorithms;Regression algorithm;Non Deterministic finite automata;Neural Networks;Canonical Correlation,Prophecy about an imminent event is called prediction. This prediction can be used to equip with preparedness to face an event and come out successful by making right decisions at right time. To automate this process many machine learning algorithms which can predict with varying degrees with each having its own uniqueness. This paper introduces one such novel technique for prediction. This new technique encompasses the knowledge of the domain experts into single formulae and translates that formula into a state transition diagram which will predict the outcome of an event when given with new test parameters of an event. The prediction of an event from this algorithm will be dichotomy in nature and the parameters can also be weighted and also to detect the significance of the model canonical correlation technique is implemented.,2019,Z. Z. Hlaing; Y. K. Thu; T. Supnithi; P. Netisopakul,685,690,6,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8940517,IEEE Conferences,IEEE
SRP: A concise non-parametric similarity-rank-based model for predicting drug-target interactions,drug-target interaction;follow-on;machine learning;missing interactions,"The identification of drug-target interactions in web lab is costly and time-consuming. Computational approaches become important to help identifying potential candidates for laboratory experiments. However, they usually involve solving optimization problems or assuming statistical distribution based on prior knowledge, and may require estimating tunable parameters. This paper is motivated by the concepts behind â€œfollow-onâ€? drugs. They are the drugs developed by drug companies to substitute the pioneering drug which was firstly discovered and patented for a specific target and determined a new therapeutic class. There are three observations from â€œfollow-onâ€? drugs. The first observation has been used by many existing methods: drugs interacting with a common target usually have higher similar scores (e.g. the similarity score in terms of chemical structure). The second one is that a drug candidate for a specific target gains more attention if it is more similar to those drugs interacting with the target than other known drugs, even though the similarity score is low. Lastly, people intuitively tend to design a â€œfollow-onâ€? drug for the targets already having more drugs because of less cost and less risk. In our approach, the above observations are translated into more evidences for predicted drug-target interaction. Designing an interaction tendency index to characterize these observations, we propose the similarity-rank-based predictor (SRP). Unlike other models, SRP is a non-parametric model and requires neither solving an optimization problem nor prior statistical knowledge. Based on real benchmark datasets, we show that our model is able to achieve higher accuracy than the two most recent models and our approach is able to cope with two real predicting scenario of missing interactions.",2015,Z. Z. Linn; P. B. Patil,1636,1641,6,7,10.1109/BIBM.2015.7359921,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359921,IEEE Conferences,IEEE
Classification of mental tasks using S-transform based fractal features,Electroencephalogram;windowing;feature extraction;S-Transform;machine learning techniques,"Brain Computer Interface is a reliable communication interface between human brain and external world. It translates human brain electrical activity to useful command by extracting meaningful features from Electroencephalogram signals. In present work, feature extraction techniques and classification methods are proposed for implementation of Brain Computer Interface system. Proposed methodology is carried out in four methodological steps. At first step, segmentation and windowing of Electroencephalogram signals are performed. The S-transform of segmented Electroencephalogram signals is evaluated in second step. At third step, mean and maximum values of Katz's Fractal Dimension are calculated from S-transform coefficients as features. Classification of extracted features is carried out in the fourth step using three machine learning techniques viz. Random Forest, Artificial Neural Network and Support Vector Machine. Classification results reflect the efficiency of S-transform based feature extraction technique in Brain Computer Interface implementation.",2017,Z. Zhan; Z. Hou; Q. Yang; J. Zhao; Y. Zhang; C. Hu,38,43,6,2,10.1109/COMPTELIX.2017.8003934,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8003934,IEEE Conferences,IEEE
About possibilities of applying logical analysis of natural language in computer science,compositionality;logical analysis of natural language;montague intensional logic;semantic machine;transparent intensional logic,"This paper deals with the comparison of the most popular methods of a logical analysis of natural language Montague intensional logic and Transparent intensional logic. At first, these logical apparatuses are compared in terms of their founding theoretical principles. Later, the selected sentence is examined through the logical analysis. The aim of the paper is to identify a more expressive logical method, which will be a suitable basis for the future design of an algorithm for the automated translation of the natural language into a formal representation of its meaning through a semantic machine.",2019,Z. Zhang; S. Wu; G. Chen; D. Jiang,251,256,6,,10.1109/SACI46893.2019.9111507,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9111507,IEEE Conferences,IEEE
A novel brain computer interface based on Principle Component Analysis and Fuzzy Logic,Brain Computer Interface;Principle Component Analysis;Support Vector Machine;Wavelet Transform;EEG,"Brain computer interface (BCI) systems measure brain signal and translate it into control commands in an attempt to mimic specific human thinking activities. In recent years, many researchers have shown their interests in BCI systems, which has resulted in many experiments and applications. The main issue to build applicable Brain-Computer Interfaces is the capability to classify the Electroencephalograms (EEG). The purpose behind this research is to improve a model for brain signals analysis. We have used high pass filter to remove artifacts, discrete wavelet transform algorithms for feature extraction and statistical features like Mean Absolute Value, Root Mean Square, and Simple Square Integral are used, also we have used principle component analysis to reduce the size of feature vector and we used fuzzy Gaussian membership function to optimize the classification phase. It has been depicted from results that the proposed integrated techniques outperform a better performance than methods mentioned in literature.",2016,Z. Zheng; Z. He; Y. Meng; H. Yu,31,36,6,,10.1109/ICDIPC.2016.7470787,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470787,IEEE Conferences,IEEE
A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks,Computer vision;machine learning;convolutional neural networks;hardware acceleration;embedded vision system,"Deep networks are state-of-the-art models used for understanding the content of images, videos, audio and raw input data. Current computing systems are not able to run deep network models in real-time with low power consumption. In this paper we present nn-X: a scalable, low-power coprocessor for enabling real-time execution of deep neural networks. nn-X is implemented on programmable logic devices and comprises an array of configurable processing elements called collections. These collections perform the most common operations in deep networks: convolution, subsampling and non-linear functions. The nn-X system includes 4 high-speed direct memory access interfaces to DDR3 memory and two ARM Cortex-A9 processors. Each port is capable of a sustained throughput of 950 MB/s in full duplex. nn-X is able to achieve a peak performance of 227 G-ops/s, a measured performance in deep learning applications of up to 200 G-ops/s while consuming less than 4 watts of power. This translates to a performance per power improvement of 10 to 100 times that of conventional mobile and desktop processors.",2014,Z. Zheng; Z. Shu,696,701,6,154,10.1109/CVPRW.2014.106,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6910056,IEEE Conferences,IEEE
Automatic identification and multi-translatable translation of vocabulary terms with a combined approach,biomedical OOV terms;automatic identification and extraction of multi-translatable OOV terms;combined approach for translation;machine learning,"Automatic translation of out of vocabulary (OOV) terms has been extensively studied in the past, but multi-translatable OOV terms have received little attention. Multi-translatable OOV terms are OOV terms with some possible OOV synonyms, thus they have more than one correct translations. Traditional methods usually ignore such problem and neither identify/extract multi-translatable OOV terms nor translate them. This paper proposes a web-based OOV term translation method by utilizing a novel automatic multi-translatable OOV term identification and extraction approach. This approach integrates synonymous features and pattern matching to solve multi-translatable OOV term problems. A combined translation method is proposed for extracting translation candidates. To achieve high translation selection quality, we conducted statistical feature extraction, an artificial neural network combined with backward feature selection, and evolutionary parameter optimization is trained for selecting correct translations. Our method outperforms existing method with an accuracy of 82.61%.",2016,A. A. Khoroshilov; E. B. Kozerenko; Y. V. Nikitin; Y. P. Kalinin; A. A. Khoroshilov,342,348,7,2,10.1109/ICACI.2016.7449849,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449849,IEEE Conferences,IEEE
Negative expression translation in Japanese and Chinese machine translation,Negative expression;Japanese and Chinese;Machine Translation,"Because there are many differences between Chinese and Japanese about the nature, history, culture, life, manners and customs, it is natural that there are particular words in each language. It is necessary that these particular words meaning are mastered right and translated accurately in translation. Because of the complex corresponding relationship with Chinese in Chinese-Japanese machine translation, it is easy to occur a vagueness, due to the negative in the sentence, many mistranslations are caused by the commercial translation software. In this paper, we analyzed the negative expressionways in Chinese and Japanese languages to translate Chinese negative sentences by using the selection rules of Chinese negative words and position rules. If we translate the basic Japanese negative expression naide1 into Chinese, its meaning is mei2, bie. Translate nakute into Chinese, according to its negative meaning and grammatical rule, it may be translated into bu. In the current research, we investigated a rough use rules which abstracted from each typical examples including naide and nakute.",2008,A. D. McCarthy; L. Puzon; J. Pino,1,7,7,1,10.1109/NLPKE.2008.4906788,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906788,IEEE Conferences,IEEE
A Study of Myanmar (Burmese) to English Machine Translation Performance with Various Myanmar Translated Styles,Phrase-based Statistical Machine Translation (PBSMT);One to Many Parallel Corpus;Myanmar-English Machine Translation;Primary English Textbooks of Myanmar;Word Error Rate (WER),This paper contributes the first investigation of machine translation (MT) performance differences between Myanmar and English languages with the use of several possible Myanmar translations for the specific primary educational domain. We also developed both one to one and many Myanmar translations corpora (over 8K and 34K sentences) based on old and new English textbooks (including Grade 1 to 3) which are published by the Ministry of Education. Our developing parallel corpora were used for phrase-based statistical machine translation (PBSMT) which is the de facto standard of statistical machine translation. We measured machine translation performance differences among one-to-many English to Myanmar translation corpora. The differences range between 19.68 and 52.38 BLEU scores for English to Myanmar and between 50.17 and 75.12 BLEU scores for Myanmar to English translation. We expect this study can be applied in Myanmar-to-English automatic speech recognition (ASR) development for primary English textbooks. The main purpose is to translate primary English textbooks data correctly even if the children use in several Myanmar conversation styles.,2020,A. F. A. Nwesri; S. M. M. Tahaghoghi; F. Scholer,1,7,7,,10.1109/ICCA49400.2020.9022851,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022851,IEEE Conferences,IEEE
A Novel Framework for Neural Machine Translation of Indian-English Languages,Machine Translation (MT);Neural Machine Translation (NMT);Natural Language Processing (NLP);Deep Learning;Neural Machine Translation Framework;Indian-English Machine Translation;NLP Application,"The term 'Machine Translation' (MT) refers to computer systems that performs translation of natural language from one language to another. Machine Translation is especially necessitated in the Indian perspective because more than 50% of the data generated online is in English which is known by only 12%. Many systems has been proposed in the Indian perspective including rule-based, example-based, statistical based and a hybrid of these machine translation techniques. But, recent study has shown that Neural Machine Translation provides better results.In recent times Google and Facebook have developed Neural Machine Translation system. These systems are one-fits-all kind of systems which do not take into consideration the complexities in a language, like Indian languages. So, this paper proposes a broad framework for implementing Neural Machine Translation for Indian-English languages.",2020,A. Kupiyalova; R. Satybaldiyeva; S. Aiaskarov,676,682,7,,10.1109/ICICT48043.2020.9112513,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112513,IEEE Conferences,IEEE
Neural-Based Machine Translation System Outperforming Statistical Phrase-Based Machine Translation for Low-Resource Languages,Neural Machine Translation;Statistical Machine Translation;Keras;LSTM;MT-Hub;Sanskrit;Hindi,"Natural Language Processing(NLP) involves the development of computational models that aid in the development of automated tools for processing and generating natural language. Human developing these computational models require deep insight of linguistic knowledge and are a time consuming process. Hence, to automate this process and accelerate the computational science we use a data-driven approach i.e Statistical learning and Deep Learning. For devolving and sharing of information in natural language and making it accessible in other natural languages, Machine Translation(MT) is entailed. It is an application of NLP. Sanskrit being `father of informatics' [1] was considered as â€œlingua francaâ€? of world intellectuals [2]. It is also an important language in the Indo-European family and considered as truly â€œdonorâ€? language of India. It has vast knowledge reserves in different discipline of studies such as Ayurveda, astronomy, literature etc. MT makes this rich language available to others with help of the computer. We have proposed and presented the prominent Deep Neural-based MT system for translation of Sanskrit to Hindi. We also present a comparison of Neural MT outperforming Statistical baseline system for this language pair.",2019,A. Lavie; F. Pianesi; L. Levin,1,7,7,,10.1109/IC3.2019.8844915,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844915,IEEE Conferences,IEEE
Automatic Translation Repair Method for Improving Accuracy of Translated Sentences,machine translation;translation repair;Web search;multilingual,"In this study, we have developed an automatic translation repair method to automatically improve the accuracy of translations. Machine translation (MT) supports multilingual communication, however, it cannot achieve high accuracy. MT creates only one translated sentence, therefore, it is difficult to improve the accuracy of translated sentences. Our method creates multiple translations by adding personal pronouns to the source sentence and by using a word dictionary and a parallel corpus. In addition, it selects an accurate translation from among the multiple translations using the results of a Web search. As a result, the automatic translation repair method improved the accuracy of translated sentences, and its accuracy is greater than that of MT.",2012,A. M. Mon; K. M. Soe,43,49,7,,10.1109/KICSS.2012.17,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405507,IEEE Conferences,IEEE
Machine Translation Systems Analysis and Development Prospects,TRIZ-evolution;machine translation;rule-based translation;statistical translation;neural translation,"In the age of data and reactive knowledge sharing, when information generation time has been reduced from months and weeks to days and hours and the volume of information is growing at a blistering pace, the process of obtaining and systematizing relevant knowledge is rapidly becoming more complicated. Modern tools are required for searching, selecting and processing relevant data as well as for systematizing the acquired knowledge. The authors describe the TRIZ-evolutionary approach as a tool for describing and revealing trends of artificial systems development on the example of machine translation systems. Development of any system is headed to the increase of ideality, i.e. increase of utility while reducing costs. At that, contradictions in the system prevent the ideality from increasing. Development occurs after such contradictions are eliminated. As per the TRIZ-evolutionary approach, the evolution of systems is being described from contradiction to contradiction and indicates TRIZ tools that allowed eliminating the contradictions. Such a description allows not only to systematize knowledge on relevant systems, but also to offer new high-performance solutions. The article covers main generations and paradigms of machine translation such as word-for-word machine translation, rule-based translation, statistical and neural machine translation. The analysis by means of the TRIZ-evolutionary approach allowed to trace the evolution of these systems, define main performance parameters, reveal trends and prospects of development taking into account ideality increase. The process of obtaining new effective solutions by eliminating subsequent contradictions is shown. Tasks for further research into machine translation systems have been set.",2020,A. P. Wibawa,1,7,7,,10.1109/FarEastCon50210.2020.9271249,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9271249,IEEE Conferences,IEEE
Statistical machine translation of systems for Sinhala - Tamil,statistical machine translation;Sinhala;Tamil;machine translation;natural language processing,"One of the most promising and leading machine translation strategies would be Statistical Translation Approach. Being pertinent even to structurally dissimilar language pairs, it has confirmed its suitability for large text translation. Rising demand is present for automatic translation between Sinhala and Tamil for quite a lot of decades. Statistical approach is the best preference to resolve the unavailability of a machine translation tool for the languages concerned. Because of language similarity, statistical approach could thrive agreeably, exclusive of more concern on linguistic knowledge. A basic translation system has been modelled and implemented in this research, with the preparation of parallel corpora from parliament order papers. This paper demonstrates only the preliminary system runs of the research, devoid of various parameter refinements and actual design and evaluation strategies. Language Model, Translation Model and Decoder Configurations are done consistent with recent literature. To facilitate the improvement of output quality, MERT technique is integrated to tune the decoder. To stay away from sole dependence on BLEU, two other automatic metrics namely TER and NIST are utilised for the evaluation in different aspects. In addition, directions to future research are also recognized and specified for the refinements of this system.",2010,B. Bogacz; M. Klingmann; H. Mara,62,68,7,3,10.1109/ICTER.2010.5643268,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643268,IEEE Conferences,IEEE
Name-aware language model adaptation and sparse features for statistical machine translation,statistical machine translation;name translation;sparse features;language model adaptation,"We propose approaches improving statistical machine translation (SMT) performance, by developing name-aware language model adaptations and sparse features, in addition to extracting name-aware translation grammar and rules, adding name phrase table, and name translation driven decoding. Chinese-English translation experiments showed that our proposed approaches produce an absolute gain of +2.3 BLEU on top of our previous high-performing, name-aware machine translation system.",2015,B. Yuan; Z. Lu; J. -H. Xue; Q. Liao,324,330,7,,10.1109/ASRU.2015.7404812,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404812,IEEE Conferences,IEEE
Machine Translation of Telugu plural pronoun declensions to Sanskrit,Pronoun inflections;plural declensions;machine translation;morphological analysis,"Like any other language, formation of plurals is customary in Telugu also. Inflections of nouns and pronouns are called declensions. Declensions of plural pronouns of Telugu and Sanskrit are discussed in this paper. Telugu plural declensions of pronouns are analyzed and translated to Sanskrit using Machine Translation (MT). For analysis, identification and translation of pronoun inflections, an effective Morphological Analysis System (MAS) that can perform forward and reverse morphology is developed for MT. In this case Telugu is the Source Language (SL) and Sanskrit is the Target Language (TL). Details of handling of dual forms have not been discussed in this paper.",2016,B. Zhang; T. Zou; Y. Wang; B. Zhang,298,304,7,,10.1109/ICATCCT.2016.7912012,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7912012,IEEE Conferences,IEEE
A Hybrid Rules and Statistical Method for Arabic to English Machine Translation,Hybrid Approach;Expectation Maximisation;Arabic machine translation problems,"Arabic is one of the six major world languages. It originated in the area currently known as the Arabian Peninsula. Arabic is the joint official language in Middle Eastern and African states. Large communities of Arabic speakers have existed outside of the Middle East since the end of the last century, particularly in the United States and Europe. So finding a quick and efficient Arabic machine translator has become an urgent necessity, due to the differences between the languages spoken in the world's communities and the vast development that has occurred worldwide. Arabic combines many of the significant challenges of other languages like word order and ambiguity. The word ordering problem because of Arabic has four sentence structures which allow different word orders. Ambiguity in the Arabic language is a notorious problem because of the richness and complexity of Arabic morphology. The core problems in machine translation are reordering the words and estimating the right word translation among many options in the lexicon. The Rule-Based Machine translation (RBMT) approach is the way to reorder words, and the statistical approach, such as Expectation Maximisation (EM), is the way to select right word translations and count word frequencies. Combining RBMT with EM plays an impotent role in generating a good-quality MT. This paper presents a combination of the rule-based machine translation (RBMT) approach with the Expectation Maximisation (EM) algorithm. These two techniques have been applied successfully to word ordering and ambiguity problems in Arabic-to-English machine translation.",2019,C. Servan; N. Camelin; C. Raymond; F. BÃ©chet; R. De Mori,1,7,7,,10.1109/CAIS.2019.8769545,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769545,IEEE Conferences,IEEE
Rhonda: the architecture of a multilingual speech-to-speech translation pipeline,speech-to-speech translation;automatic speech recognition;machine translation;text-to-speech;multilingual,"Speech-to-speech translation can be described as converting a speech signal from a source language into a speech signal of the same meaning or intent into a target language. This process is achieved by the coordinated cooperation of individual Human Language Technology components, where the most important components to a speech translation system are automatic speech recognition, machine translation and text-to-speech. In this paper we present and discuss the design and architectural building blocks of the Rhonda speech-to-speech translation system, as well as their interactions with each other to facilitate speech-to-speech translation in a reliable, scalable and possibly distributed manner.",2018,Che-Yu Yang; Hua-Yi Lin,1,7,7,1,10.1109/ICONIC.2018.8601204,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601204,IEEE Conferences,IEEE
Factored phrase-based statistical machine translation,alignment;machine translation;MOSES decoder;language model;translation model,"We describe the results of a short-term SEE-ERAnet project the aim of which was to investigate the feasibility of machine translation (MT) research and development for several South Slavic and Balkan languages. The major tasks of the project were: compilation of a multilingual parallel corpus for the concerned languages, the XML mark-up of the corpus (tokenization, lemmatization, tagging), the sentence and word alignment of the corpus and the building of the statistical translation models. Additionally, based on the created resources and models, we conducted preliminary experiments on building prototype MT systems for Romanian <-> English, Greek <-> English and Slovene <-> English. We argue that by investing efforts in building accurate language resources, larger the better, as well as in fine-tuning of the statistical parameters, the current machine-learning technologies can be successfully used for a quick development of acceptable MT prototypes, valuable starting points in implementing working systems. We substantiate this claim with recent results from a follow-up national project, aiming at the development of a Romanian<->English translation system.",2009,Chiori Hori; Bing Zhao; S. Vogel; A. Waibel,1,7,7,,10.1109/SPED.2009.5156180,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5156180,IEEE Conferences,IEEE
Joint layer based deep learning framework for bilingual machine transliteration,Natural Language Processing;Computational Linguistics;Machine Transliteration;Artificial Intelligence;Deep Learning;Restricted Boltzmann Machine;Deep Belief Networks,"Between the growth of Internet or World Wide Web (WWW) and the emersion of the social networking site like Friendster, Myspace etc., information society started facing exhilarating challenges in language technology applications such as Machine Translation (MT) and Information Retrieval (IR). Nevertheless, there were researchers working in Machine Translation that deal with real time information for over 50 years since the first computer has come along. Merely, the need for translating data has become larger than before as the world was getting together through social media. Especially, translating proper nouns and technical terms has become openly challenging task in Machine Translation. The Machine transliteration was emerged as a part of information retrieval and machine translation projects to translate the Named Entities based on phoneme and grapheme, hence, those are not registered in the dictionary. Many researchers have used approaches such as conventional Graphical models and also adopted other machine translation techniques for Machine Transliteration. Machine Transliteration was always looked as a Machine Learning Problem. In this paper, we presented a new area of Machine Learning approach termed as a Deep Learning for improving the bilingual machine transliteration task for Tamil and English languages with limited corpus. This technique precedes Artificial Intelligence. The system is built on Deep Belief Network (DBN), a generative graphical model, which has been proved to work well with other Machine Learning problem. We have obtained 79.46% accuracy for English to Tamil transliteration task and 78.4 % for Tamil to English transliteration.",2014,D. D. Palmer,1737,1743,7,3,10.1109/ICACCI.2014.6968553,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968553,IEEE Conferences,IEEE
Using Statistical Machine Translation to Grade Training Data,statistical machine translation;bootstrap,"One of the main causes of errors in statistical machine translation are the erroneous phrase pairs that can find their way into the phrase table. These phrases are the result of poor word-to-word alignments during the training of the translation model. These word alignment errors in turn cause errors during the phrase extraction phase, and these erroneous bilingual phrase pairs are then used during the decoding process and appear in the output of the machine translation system. Machine translation training data is never perfect, often bilingual sentence pairs are incorrectly aligned sentence-by-sentence, or these pairs are poor translations of each other due to human error. Even when sentence pairs in the corpus are good translations of each other the translations may not be literal enough to admit to the sort of phrase-by-phrase translation necessary to make good training data for a phrase-based statistical machine translation (SMT) system. This is because such SMT systems operate on the assumption that source can be transformed into target simply by translating phrase-by-phrase with re-ordering. In the real world, many perfectly correct translations are not of this form, and these sentences even though correct translations, make poor training data for training the translation models of a phrase-based SMT system. This paper presents a technique in which preliminary machine translation systems are built with the sole purpose of indicating those sentence pairs in the training corpus that the systems are able to generate using their models, the hypothesis being that these sentence pairs are likely to make good training data for an SMT system of the same type. These sentences are then used to bootstrap a second SMT system, and those sentences identified as good training data are given additional weight during the training process for building the translation models. Using this technique we were able to improve the performance of a Japanese-to-English SMT system by 1.2-1.5 BLEU points on unseen evaluation data.",2008,D. Kelly; J. Mc Donald; C. Markham,113,119,7,,10.1109/ISUC.2008.20,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724449,IEEE Conferences,IEEE
Punjabi to English Machine Transliteration for Proper Nouns,Transliteration;Machine learning;n-gram;Gurumukhi script,Language transliteration is among the various fields in linguistic communication processing and additionally which has become intrinsic part of information processing across all the natural languages. Reliable and expeditious transliteration of named entities is very mandatory for the performance of computer to translate text from one language to another and procedures involving retrieving of data across two languages wherever proper nouns and scientific phrases are concerned. Main motive is to develop a Punjabi to English Transliteration system with more accuracy and to get rid of the language barrier for communication and make it easier for those who don't perceive English. It even has found its great application in fields of Artificial Intelligence. This paper describes n-gram based approach across source-target language pairs with accuracy of about 96%.,2018,D. L. Khabarov; V. V. Bazanov; A. V. Kuchebo; M. Zavgorodnii; A. Y. Rybakova,1,7,7,,10.1109/IoT-SIU.2018.8519877,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519877,IEEE Conferences,IEEE
Towards a model of statistical machine translation Arabic-French,statistcal machine translation;alignment;parallel corpora;statistical approach,"The automatic translation of texts of human origin is a very complex application called to apprehend the universe open text, without any constraint on their nature or diversity. To solve this problem, several attempts have been initiated, each having the objective to obtain a better translation quality of the parallel corpora. But before the various ambiguities of the natural language, the problem of translation is far from easy to solve. To do this, and in order to increase the translation quality, we propose a model for the generation of different semantic cases relating to different components of the sentence to determine the meaning first and then generate the translation into the language target. This allowed us to obtain satisfactory results compared to similar studies using other techniques. In our approach, we used a model guided by the semantics to learn the techniques of translation with a similar human performance. Our project is to translate source sentences from Arabic to French through a statistical approach that includes a dictionary and that is automatically evaluated by the BLEU metric to ensure encouraging results even if the tools that we use are very limited.",2014,D. Ourston; R. W. McBeth,1,7,7,4,10.1109/WCCAIS.2014.6916640,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916640,IEEE Conferences,IEEE
A study to find influential parameters on a Farsi-English statistical machine translation system,Statistical Machine Translation;SMT;Farsi - English;Farsi;Communication tool;Moses,"The aim of this paper is to analyze the Farsi-English statistical machine translation systems as a useful communication tool. Improvement of the nation's communication increases the need of easier way of translating between different languages in front of expensive human translators. In this work, a statistical phrase-based system is run on Farsi - English pair languages and the effect of its parameters on the translation quality has been deeply studied. Using BLEU as a metric of translation accuracy, the system achieves an improvement of 1.84%, relative to the baseline accuracy, which is increment from 16.97% to 18.81% in the best case.",2010,D. Tufis; A. Ceausu,985,991,7,,10.1109/ISTEL.2010.5734165,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734165,IEEE Conferences,IEEE
An Empirical Study on Ensemble Learning of Multimodal Machine Translation,Multimodal machine translation;Transformer;Ensemble learning;Synonym-replacing;Deep learning,"With the increasing availability of images, multimodal machine translation (MMT) is leading a vibrant field. Model structure and multimodal information introduction are the hotspot focused by MMT researchers nowadays. Among the existing models, transformer model has reached the state-of-the-art performance in many translation tasks. However, we observe that the performance of MMT based on transformer is highly unstable since transformer model is sensitive to the fluctuation of hyper-parameters especially the number of layers, the dimension of word embeddings and hidden states, the number of multi-heads. Moreover, different ways of introducing image information also have significant influence on the performance of MMT. In this paper, we exploit some integration strategies which depend on different tasks to make collaborative decisions on the final translation results to enhance the stability of MMT based on transformer. Furthermore, we combine different ways of introducing image information to improve the semantic expression of input. Extensive experiments on Multi30K dataset demonstrate that ensemble learning in MMT which integrates text and image features exactly obtain more stable and better translation performance and the best result yields improvement of 5.12 BLEU points over the strong Transformer baseline set in our experiments.",2020,D. Zhou; D. Petrovska-DelacrÃ©taz; B. Dorizzi,63,69,7,,10.1109/BigMM50055.2020.00019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232493,IEEE Conferences,IEEE
Machine Translation of English Videos to Indian Regional Languages using Open Innovation,machine translation;text-to-speech;speech-to-text;concatenation;open innovation,"In spite of many languages being spoken in India, it is difficult for the people to understand foreign languages like English, Spanish, Italian, etc. The recognition and synthesis of speech are prominent emerging technologies in natural language processing and communication domains. This paper aims to leverage the open source applications of these technologies, machine translation, text-to-speech system (TTS), and speech-to-text system (STT) to convert available online resources to Indian languages. This application takes an English language video as an input and separates the audio from video. It then divides the audio file into several smaller chunks based on the timestamps. These audio chunks are then individually converted into text using IBM Watson's speech-to-text (STT) module. The obtained text chunks are then concatenated and passed to Google's machine translate API for conversion to the requested Indian language. After this translation, a TTS system is required to convert the text into the desired audio output. Not many open source TTS systems are available for Indian regional languages. One such available application is the flite engine (a lighter version of Festival engine developed by Prof. Alan Black at Carnegie Mellon University (CMU)). This flite engine is used as TTS for generating audio from translated text. The accuracy of the application developed can be as high as 91 percent for a single video and averages about 79 percent. This accuracy is verified by comparing naturality of the audio with the general spoken language. This application is beneficial to visually impaired people as well as individuals who are not capable of reading text to acquire knowledge in their native language. In future, this application aims to achieve ubiquitous communication enabling people of different regions to communicate with each other breaking the language barriers.",2019,D. Zhu; B. Chang,1,7,7,,10.1109/ISTAS48451.2019.8937988,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937988,IEEE Conferences,IEEE
Neural Machine Translation between Myanmar (Burmese) and Dawei (Tavoyan),neural machine translation;Myanmar-Dawei parallel corpus;Recurrent Neural Network and Transformer,"This work explores the first evaluation of the quality of neural machine translation between Myanmar (Burmese) and Dawei (Tavoyan). We also developed Myanmar-Dawei parallel corpus (around 9K sentences) based on the Myanmar language of ASEAN MT corpus. We implemented two prominent neural machine translation systems: Recurrent Neural Network (RNN) and Transformer with syllable segmentation. We also investigated various hyper-parameters such as batch size, learning rate and cell types (GRU and LSTM). We proved that LSTM cell type with RNN architecture is the best for Dawei-Myanmar and Myanmar-Dawei neural machine translation. Myanmar to Dawei NMT achieved comparable results with PBSMT and HPBSMT. Moreover, Dawei to Myanmar RNN machine translation performance achieved higher BLEU scores than PBSMT (+1.06 BLEU) and HPBSMT (+1.37 BLEU) even with the limited parallel corpus.",2020,D. Zhu; Q. Guo; D. Zhang; F. Wan,1,7,7,,10.1109/ICCA49400.2020.9022813,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022813,IEEE Conferences,IEEE
Improving the rule based machine translation system using sentence simplification (english to tamil),machine translation;reordering;morphological transfer rule;sentence simplification;pos tag,"The ultimate aim of this research is to develop a Rule Based Machine Translation System (RBMT) using sentence simplification. The sentence pattern for English is SVO and Tamil is SOV. Complex and larger sentence are not easy to parse and translate. So, the sentence simplifier is also accommodated in the rule based system to split a large sentence into simple multiple sentences. Machine translation is the process of translating sentence from one language to another language. Here, English is the source language for the translation system and Tamil is the target language. During the translation process, the system need to learn and get trained by linguistic rules. These rules are classified into two types, namely reordering rules and morphological rules. A bilingual dictionary has been created to support this automatic translation. Linguistic information act as a backbone for the proposed system. To evaluate the performance of the system, we have experimented by testing 250 sentence patterns and we got the overall accuracy about 0.7186. Module wise human evaluation has been done to understand the issues in each modules.",2017,E. Jan; N. Ge; S. Lin; S. Roukos; J. Sorensen,957,963,7,2,10.1109/ICACCI.2017.8125965,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125965,IEEE Conferences,IEEE
Multilingual Semantic Relatedness Using Lightweight Machine Translation,Multilingual Distributional Semantic Models;Machine Translation;Semantic Similarity;Semantic Relatedness,"Distributional semantic models are strongly dependent on the size and the quality of the reference corpora, which embeds the commonsense knowledge necessary to build comprehensive models. While high-quality texts containing large-scale commonsense information are present in English, such as Wikipedia, other languages may lack sufficient textual support to build distributional models. This paper proposes using the combination of a lightweight (sloppy) machine translation model and an English Distributional Semantic Model (DSM) to provide higher quality word vectors for languages other than English. Results show that the lightweight MT model introduces significant improvements when compared to language-specific distributional models. Additionally, the lightweight MT outperforms more complex MT methods for the task of word-pair translation.",2018,E. Matusov; S. Kanthak; H. Ney,108,114,7,,10.1109/ICSC.2018.00024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334447,IEEE Conferences,IEEE
Neural Machine Translation with Acoustic Embedding,Neural machine translation;acoustic and semantic embedding representation,"Neural machine translation (NMT) has successfully redefined the state of the art in machine translation on several language pairs. One popular framework models the translation process end-to-end using attentional encoder-decoder architecture and treats each word in the vectors of intermediate representation. These embedding vectors are sensitive to the meaning of words and allow semantically similar words to be near each other in the vector spaces and share their statistical power. Unfortunately, the model often maps such similar words too closely, which complicates distinguishing them. Consequently, NMT systems often mistranslate words that seem natural in the context but do not reflect the content of the source sentence. Incorporating auxiliary information usually enhances the discriminability. In this research, we integrate acoustic information within NMT by multi-task learning. Here, our model learns how to embed and translate word sequences based on their acoustic and semantic differences by helping it choose the correct output word based on its meaning and pronunciation. Our experiment results show that our proposed approach provides more significant improvement than the standard text-based transformer NMT model in BLEU score evaluation.",2019,F. -. Lang,578,584,7,1,10.1109/ASRU46091.2019.9003802,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003802,IEEE Conferences,IEEE
Domain adaptation for statistical machine translation,Statistical Machine Translation;Topic Model;Domain Adaptation,"Statistical machine translation (SMT) plays more and more important role now. The performance of the SMT is largely dependent on the size and quality of training data. But the demands for translation is rich, how to make the best of limited in-domain data to satisfy the needs of translation coming from different domains is one of the hot focus in current SMT. Domain adaption aims to obviously improve the specific-domain performance by bringing much out-of-domain parallel corpus at the absence of in-domain parallel corpus. Domain adaption is one of the keys to get the SMT into practical application. This paper introduces mainstream methods of domain adaption for SMT, compares advantages and disadvantages of representative methods based on the result of the same data and shows personal views about the possible future direction of domain adaption for SMT.",2016,F. Farhath; S. Ranathunga; S. Jayasena; G. Dias,1652,1658,7,,10.1109/FSKD.2016.7603425,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603425,IEEE Conferences,IEEE
Using Accessor Variety Features of Source Graphemes in Machine Transliteration of English to Chinese,named entity;machine transliteration;direct orthographical mapping;expectation maximization;conditional random fields;accessor variety,"This work describes a grapheme-based approach of English-to-Chinese (E2C) transliteration, which includes many-to-many alignment models and conditional random fields using accessor variety (AV) as an additional feature based on source graphemes. Experimental results indicate that the AV of a given English segment can generally improve effectiveness of E2C transliteration.",2011,F. Ren,132,138,7,,10.1109/TAAI.2011.30,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120732,IEEE Conferences,IEEE
Integrating source-side semantic roles into a phrase-based statistical machine translation,Statistical machine translation;Predicate-argument structure;Semantic role labeling;N-best re-ranking,"Most of the statistical machine translation (SMT) systems suffer from lack of proper understanding about the meaning of input sentence, confusion of semantic roles or semantic ambiguities. In this paper, we propose semantic features for phrase-based SMT (PB-SMT) using source-side semantic roles. The objective of proposed features is to employ predicate-argument information in an English-Persian SMT, which is a sample of low-resource language pairs. Then these features serve to re-rank list of n-best translations produced by the translation system. The first proposed feature tries to preserve the correlation between predicate-argument structures (PAS) among two languages, while the second one aims to preserve the internal cohesion of semantic roles. Both of these features use direct annotation projection to transfer semantic roles from the source to the target language. For extracting the last feature, the Persian Semantic Role Labeling (SRL) is used which is trained on Persian semantic annotated data. We create the training data by automatically projecting the annotation from English to Persian using in-house parallel data, filtering out uncertain labels and also by bootstrapping. To our knowledge, this is the largest Persian corpus annotated with the semantic roles. Evaluations show that these features cause an improvement of 0.65 BLEU score over the baseline. Human evaluation of the translation results also shows the positive influence of these features on translation quality. Preliminary results from experiments demonstrate the importance of predicate-argument semantics in machine translation.",2017,F. Yan; W. Mei; Z. Chunqin,2140,2146,7,,10.1109/IranianCEE.2017.7985415,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985415,IEEE Conferences,IEEE
Optimizing Attention Mechanism for Neural Machine Transltion,machine translation;attention mechanism;attention regularization;tagging,"Nowadays, Neural Machine Translation (NMT) has become the mainstream approach for machine translation, and has got considerable improvement after attention mechanism is introduced. However, usage of attention is insufficient, some defects such as rare word problem still remain in end-to-end NMT approach, which is limited by the training targets and priori knowledge. Traditionally, words out of vocabulary (OOV words) are simply represented with a signal `UNK' or cut into sub-words. In this paper, we consider some optimizations on the alignment feature of attention mechanism, which is appropriate not only to guide every output to find the best match in input sentence, but also to help overall quality of the translation. We build English-Chinese and Chinese-English NMT systems based on our algorithm, and experiment on casia2015 corpus from WMT17. The result shows that the translation of our model gets a considerable improvement respectively.",2018,G. Huang; A. Gorin; J. Gauvain; L. Lamel,2398,2404,7,1,10.1109/CompComm.2018.8780734,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780734,IEEE Conferences,IEEE
An English part-of-speech tagger for machine translation in business domain,English POS tagging;maximum entropy;rule-based approach;machine translation;business domain,"Part-of-speech tagging is a crucial preprocessing step for machine translation. Current studies mainly focus on the methods, linguistic, statistic, machine learning or hybrid. But so far not many serious attempts have been performed to test the reported accuracy of taggers on different, perhaps domain-specific, corpora. Therefore, this paper presents an English POS tagger for English-Chinese machine translation in business domain, demonstrating how a present tagger can be adapted to learn from a small amount of data and handle unknown words for the purpose of machine translation. A small size of 998k English annotated corpus in business domain is built semi-automatically based on a new tagset, the maximum entropy model is adopted and rule-based approach is used in post-processing. Experiments show that our tagger achieves an accuracy of 99.08% in closed test and 98.14% in open test, which is a quite satisfactory result, compared with the reported best open test result of 97.18% of Stanford English tagger.",2011,G. Lin; S. Wen; Q. -L. Han; J. Zhang; Y. Xiang,183,189,7,3,10.1109/NLPKE.2011.6138191,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138191,IEEE Conferences,IEEE
Language Model Bootstrapping Using Neural Machine Translation for Conversational Speech Recognition,speech recognition;neural machine translation;domain adaptation;code-switching,"Building conversational speech recognition systems for new languages is constrained by the availability of utterances capturing user-device interactions. Data collection is expensive and limited by speed of manual transcription. In order to address this, we advocate the use of neural machine translation as a data augmentation technique for bootstrapping language models. Machine translation (MT) offers a systematic way of incorporating collections from mature, resource-rich conversational systems that may be available for a different language. However, ingesting raw translations from a general purpose MT system may not be effective owing to the presence of named entities, intra sentential code-switching and the domain mismatch between the conversational data being translated and the parallel text used for MT training. To circumvent this, we explore following domain adaptation techniques: (a) sentence embedding based data selection for MT training, (b) model finetuning, and (c) rescoring and filtering translated hypotheses. Using Hindi language as the experimental testbed, we supplement transcribed collections with translated US English utterances. We observe a relative word error rate reduction of 7.8-15.6%, depending on the bootstrapping phase. Fine grained analysis reveals that translation particularly aids the interaction scenarios underrepresented in the transcribed data.",2019,G. R. Ranganathan; Y. Biletskiy; D. MacIsaac,487,493,7,,10.1109/ASRU46091.2019.9003982,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003982,IEEE Conferences,IEEE
Translation russian cyrillic to latin alphabet using SVM (support vector machine),Russia;Cyrillic;Capture to Translate;Image Processing;edges detection;findcontours;Artificial Intelligence;Support Vector Machine (SVM);Android;Preprocessing,"Russian is a language that is widely used by people in the world for various purposes because it is ranked 6th in the world as the language with the most speakers. This is one of the foundations of this study in addition to the high interest of the world population to use and learn the language. Russian language does not use alphabets but uses Cyrillic script, where the font is different from the letters in general so there are some obstacles to learn, understand and pronounce it. Capture to translate is one of the media that built to be a solution of this problem, built on image processing, feature extraction process with edges detection findcontours method and artificial intelligence using Support Vector Machine (SVM) classification algorithm with android mobile application interface that utilizes camera device as its input. In this study, Capture to translate using the Support Vector Machine (SVM) classification algorithm is able to produce a level of word classification accuracy of 93.8% in three syllable based on test that has been done, which is related to preprocessing, feature extraction and classification.",2017,H. A. Wibowo; T. A. Prawiro; M. Ihsan; A. F. Aji; R. E. Prasojo; R. Mahendra; S. Fitriany,59,65,7,4,10.1109/APWiMob.2017.8284005,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284005,IEEE Conferences,IEEE
An experiment of word sense disambiguation in a machine translation system,Machine Translation;Word Sense Disambiguation;Persian Language,"In this paper, we demonstrate an experiment of a machine translation (MT) system for two different languages, English and Persian. We also describe a model for word sense disambiguation (WSD) task inside the MT system, which uses decision trees automatically learned from a training data set, as its disambiguation formalism. Our evaluations can be divided into two different categories: evaluation on the whole MT system and evaluation on the WSD component. The experiments on the whole MT, shows that this system gets 16% with respect to NIST measure, while the evaluation on WSD using a corpus contains 860 aligned sentences shows that this component disambiguates 81.4% of ambiguous word correctly.",2008,H. Fukuda; T. Tsunakawa; J. Oshima; R. Oshima; M. Nishida; M. Nishimura,1,7,7,4,10.1109/NLPKE.2008.4906781,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906781,IEEE Conferences,IEEE
Translate Chinese organization names using examples and web,Chinese organization names translation;named entity translation;examples-based machine translation method;web assistant translation method;machine translation,"This paper proposes a new approach for translating Chinese organization names that uses example-based method along with Web assistance. It consists of two phases, first, it generates a translation candidate for the input Chinese organization name by an example-based translation method; and secondly, it uses the Web to amend this translation candidate so as to finish such tasks: translation candidate reordering, word selection revising, and adjustment of the use of function words. Experimental results show that our method outperforms competing traditional statistical translation method in the task of translating Chinese ONs.",2009,H. Ney,1,7,7,4,10.1109/NLPKE.2009.5313760,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313760,IEEE Conferences,IEEE
Real-time direct translation system for Sinhala and Tamil languages,Statistical machine translation;Natural language processing;Sinhala;Tamil;Machine Translation,"Language barriers in day to day communication are common in all countries. In Sri Lanka we have a rising need for translation for Sinhala and Tamil to reduce language barriers and the statistical machine translation approach is more suitable for the concerned languages. Statistical machine translation method is one of the most promising and efficient method to perform machine translation for Sri Lankan languages likes Sinhala and Tamil. Statistical approach is more suitable for structurally dissimilar pairs of languages and efficient solution for large text translation. Sinhala and Tamil have a similarity in grammar and statistical approach will help to obtain more accurate results. We have developed a Real-time bi-directional translation system for both Tamil to Sinhala and Sinhala to Tamil for this research. We have used the Sri Lankan parliament corpus to train the language model. We have critically evaluated the both systems with parameter optimizations and have obtained the most accurate and efficient system. We have also utilized the scoring techniques like BLEU [2, 8] & NIST [2] for the system evaluation and we have integrated the MERT technique to tune the decoder.",2015,HongPeng Yu; HongWei Xu,1437,1443,7,,10.15439/2015F113,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321615,IEEE Conferences,IEEE
Automatic Translation of Spanish Natural Language Commands to Control Robot Comands Based on LSTM Neural Network,"robotic architecture, neural machine translation, object model system, interface layer, complex tasks, reasoning and planning layer, physical control layer","In this paper, we propose a high level layer able to translate motion commands in natural spanish language to a formal intermediate representation called Robot Control Language (RCL). The layer was built by using the seq2seq TensorFlow library, with a single forward LSTM for encoder and decoder respectively. We were able to achieve a 4.3e-08 loss employing a manually generated corpus in Spanish.",2019,Hongyang Zhang; Muyun Yang; Tiejun Zhao,125,131,7,1,10.1109/IRC.2019.00026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675641,IEEE Conferences,IEEE
Semantic natural language translation based on ontologies combination,natural language;automatic translation;dictionary;ontology;semantics,"One of the most important and difficult tasks is the automatic translation of human languages; is essentially due to the diversity of the contextual interpretation between diverse languages. In this paper we propose a new approach based on ontologies combination to translate a given text from a source language to another. The novelty of the proposed approaches is that it finds and resolves words' ambiguities by matching the contextual meaning of a given word in the source language by its equivalent word in the receiver language. Finally, we validate the proposed system by testing it on real data texts and the results are very encouraging especially on the disambiguation and interpretation steps.",2017,Hui Luo; Wei Hao; D. H. Foos; C. W. Cornelius,315,321,7,,10.1109/ICITECH.2017.8080019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8080019,IEEE Conferences,IEEE
Language Translation Tools Drive Productivity Improvements for Global Delivery of Services,translation assistance;machine translation,"Efficient utilization of global resources is crucial for globally integrated enterprises to improve their business performance. Rising costs of language translation by professional translators are inhibiting the growth of global delivery of services from and to countries and geographies where most documents need to be translated. The quality levels of current machine translation engines are inadequate for such business processes, since translation errors may cause significant business problems. Human-quality translations are needed, and we need tools for enhancing these human translation efforts. We have developed an architecture and some tools to help people create translations more efficiently. The framework provides tools for interactively creating translations by aggregating the information necessary for translating the documents, for checking the quality of the source documents to be translated, and for effectively gathering translation-related resources from existing documents. We conducted several experiments to evaluate the performance of the tools, and confirmed that the framework and tools are valuable in assisting human translation work.",2011,J. A. Todase; S. Shelke,465,471,7,,10.1109/SRII.2011.55,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5958122,IEEE Conferences,IEEE
A simple present and past sentences machine translation from Arabic language (AL) to English language,Modern Standard Arabic (MSA);lexicon;Natural language processing;parsing,"The Arabic language is a collection of spoken dialects and a standard written language. The dialects show phonological, morphological, lexical, and syntactic. Differences, although the standard written language is the same throughout the Arab world. The present work reports our attempt in developing a bi-lingual Machine Translation tool for simple present and past sentences in an elementary school domain. The work described here is part of an ongoing research to automate the translation of user interfaces of knowledge-based systems. Our project tries to translate from a well-structured Arabic simple present and past sentence into a well-structured English sentence, by using a dictionary to translate a single word, and a simple lexicon consists of word categories and the meaning relative to categories in appropriate format. The domain area is an Arabic-English dictionary and a set of well-structured Arabic sentences from many textbooks in an elementary school.",2016,J. Park; H. Zhao,1,7,7,1,10.1109/ICEMIS.2016.7745302,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745302,IEEE Conferences,IEEE
Generating Noun Declension-case markers for English to Indian Languages in Declension Rule based MT Systems,Machine Translation;Rule Based Machine Translation;Declension Rules;Indian languages;Karaka;Vibhakti;Case Rules,"Machine Translation is a branch of re- search under Computational Linguistics that deais with the automatic/semi-automatic translation of a natu- ral/human language into another. The language that is being translated is termed as Source Language(SL) and the language into which translation is done, is termed Target Language(TL). This paper presents an English to Indian Languages Machine Translation technique that is based on the rules of grammar, namely word deelensions or inflections, and sentence formation rules of the target languages, i.e. Indian Languages. Declensions are variations or inflections of words in language and Indian languages are richly declensional or inflectional languages. This study is on generating Noun Declension-case markers for English to Indian languages in Declension Rule based Machine Translation. This paper also describes about the various approaches to machine translation along with their system architectures. The proposed Declension based RBMT is explained with its architecture and each of the modules and their functionalities are elaborated in detail. The input and output, to and from the System are also described with an example. The research works that are similar with the proposed system, such as ANUSAARAKA and ANGLABHARATI are also explored.",2018,Jie Wu; Jianjiang Zhou; Qiangye Gao,296,302,7,1,10.1109/IADCC.2018.8692136,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692136,IEEE Conferences,IEEE
Automatic Parallel Corpus Creation for Hindi-English News Translation Task,Natural language processing;Parallel corpus;News translation;Fuzzy string matching algorithm,"Parallel corpus for multilingual NLP tasks, deep learning applications like Statistical Machine Translation Systems is very important. The parallel corpus of Hindi-English language pair available for news translation task till date is of very limited size as per the requirement of the systems are concerned. In this work we have developed an automatic parallel corpus generation system prototype, which creates Hindi-English parallel corpus for news translation task. Further to verify the quality of generated parallel corpus we have experimented by taking various performance metrics and the results are quiet interesting.",2018,K. Chen,1069,1075,7,,10.1109/ICACCI.2018.8554461,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554461,IEEE Conferences,IEEE
TCM Translator: A Sequence Generation Approach for Prescribing Herbal Medicines,traditional Chinese medicine;herbal prescription;deep learning;machine translation;sequence-to-sequence,"In traditional Chinese medicine (TCM), herbal prescriptions are accumulated from doctors' clinical experience and play an essential role in treatment process for more than thousands of years. Mining their containing many-to-many relationship between symptoms and herbs are important for both clinical practice and novel prescriptions development. Previously, the research attention in this field is attracted by topic models and multi-label classification approaches, but they don't fully capture the correlations of labels and achieve very promising performance. Alternatively, we problematic it as a machine translation problem, that the source sentence is formed by symptoms and the target sentence consists of herbs. Two sentences are both in weakly order. In terms of this assumption, we propose a novel sequence-to-sequence (seq2seq) architecture, namely TCM translator, to translate symptoms to herbs. Seq2seq, consisting of an encoder and a decoder, is a well known framework for resolving the machine translation problem in natural language processing (NLP) community. It maps a bag of symptoms to the latent space, which is decoded to the target sentence, i.e., herbs. In this paper, transformer is used as our encoder to explore the latent correlations of symptoms and LSTM is implemented as the decoder to generate the herbs sequentially. The experimental results demonstrate that our proposed approach is effective and outperforms other baseline models by a substantial margin.",2019,K. Song; X. Zhou; H. Yu; Z. Huang; Y. Zhang; W. Luo; X. Duan; M. Zhang,2474,2480,7,1,10.1109/BIBM47256.2019.8983384,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983384,IEEE Conferences,IEEE
Neural Network Language Models for Translation with Limited Data,continous space language model;machine translation;language models;neural networks,"In this paper we present how to estimate a continuous space language model with a neural network to be used in a statistical machine translation system. We report results for an Italian-English translation task obtained on a small corpus (about 150 K tokens), that can be considered a task with a lack of training data. Different word history length included in the connectionist language model (n-gram order) and distinct continuous space representation (i.e. words appearing in the training corpus more than k times) are considered in the study. The experimental results are evaluated by means of automatic evaluation metrics correlated with fluency and adequacy of the generated translations.",2008,L. Bentivogli; N. Bertoldi; M. Cettolo; M. Federico; M. Negri; M. Turchi,445,451,7,3,10.1109/ICTAI.2008.35,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4669807,IEEE Conferences,IEEE
CSG-Tag: Constraint based Synchronous Grammar Tree Annotation System,Tree Annotation system;Constraint Synchronous Grammar;Translation Corresponding Tree;Machine Translation,"The construction of grammars and the acquisition of syntactic structures from corpora are always considered as a time consuming task. Moreover, according to the purpose of the application, different standards have to be defined. In Machine Translation (MT), the situation is even more complicated since it covers two languages. In this paper, CSG-Tag, a Constraint based Synchronous Grammar (CSG) Tree Annotation System is proposed. This system provides a semi-automatic annotation process in the creation of syntactic structure of the source sentence linked with the corresponding target sentential patterns. All learned information are stored in Extensible Markup Language (XML) format and can be converted into grammar rules in application to MT. Moreover, the system has a function to import monolingual skeletal bracketing syntactic tree and Translation Corresponding Tree (TCT) structures in the creation of CSG rules.",2011,M. Iwazume; T. Iwase; K. Tanaka; H. Fujii; M. Hijiya; H. Haraguchi,1472,1478,7,,10.1109/ICMLC.2011.6017024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6017024,IEEE Conferences,IEEE
An approach for translating mathematics problems in natural language to specification language COKB of intelligent education software,Artificial intelligence;Education software;knowledge base system;automatic problem solving system,"Nowadays the research on intelligent systems for Problem solving in education has had lots of practical applications. A system based on ECOKB model and a specification language can process and produce gradual guide ways for full problem solving explanation. However, these systems limit users because they require the data input and the result output both not in natural language but specification language, which few users knows how to use this language input to the systems. Therefore, to improve ability of interacting by natural language, this paper proposes a new approach for translating mathematics problems in natural language to specification language as well as bringing out the model of natural language translating method associated with knowledge base domain for effective translation. Besides, this paper shows the ability of this approach applied in different knowledge domains.",2010,M. Jahan; I. Ahamed; M. R. Bishwas; S. Shatabda,324,330,7,,10.1109/ICAIE.2010.5641043,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5641043,IEEE Conferences,IEEE
Big data in memory: Benchimarking in memory database using the distributed key-value store for machine to machine communication,Big Data;In Memory Database;Key-Value Store;Machine to Machine Communication,"The Universal Communication Research Institute (UCRI), NICT conducts research and development on universal communication technologies: multi-lingual machine translation, spoken dialogue, information analysis and ultra-realistic interaction technologies, through which people can truly interconnect, anytime, anywhere, about any topic, and by any method, transcending the boundaries of language, culture, ability and distance. To enhance the universal communication technology, we are trying to develop a large-scale information infrastructure which collects and stores diverse information including huge volumes of web pages from the networks. The one of most important key technologies to realize a large-scaled information infrastructure is a distributed in memory database system. In this paper, we introduced a large-scale information infrastructure, mainly explaining a distributed in-memory database system â€œokuyamaâ€? which is a key technology on our project. We examined the I/O performance of the in memory storage, which verified whether if â€œokuyamaâ€? meet requirements for the infrastructure. Furthermore we give a blueprint of cluster systems on which the infrastructure will be constructed.",2014,M. KrÃ³tkiewicz; M. JodÅ‚owiec; K. Wojtkiewicz,1,7,7,2,10.1109/SNPD.2014.6888748,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6888748,IEEE Conferences,IEEE
A Context-Aware Automatic Chinese Transliterated Person Names Recognition Approach,transliterated person name recognition;probability model;name entity recognition,"Chinese Transliterated Person Name (TP-Name) recognition is a special challenging task in Chinese unknown word recognition and Chinese word segmentation. Most of existing researches mainly focus on recognizing the names of Chinese person while seldom specialize in recognizing transliterated person names. In this paper, we proposed a hybrid method for TP-Name recognition based on both the context of person names exiting in and the reliability model. Besides, partial frequency statistics and proliferation option are also used to correct the misrecognized names and unrecognized names. Experiments based on a true dataset show that our approach is efficient in recognizing the TP-Names from Chinese texts. The precision rate, recall rate and F-measure are 93.81%, 98.14%, 95.92% respectively.",2012,M. Singh; R. Kumar; I. Chana,143,149,7,1,10.1109/SKG.2012.2,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6391822,IEEE Conferences,IEEE
A discriminative latent model for Chinese multiword expression extraction,Discriminative Model;Multiword Expression Extraction;Global Feature;Super Function;Machine Translation,"In this paper, we propose a discriminative latent model to extract Chinese multiword expressions from corpus resources as part of a larger research effort to improve machine translation(MT) system such as Super Function based Machine Translation(SFBMT). For existing MT systems, especially Statistic based MT(SBMT), the issue of multiword expressions (MWEs) detection and accurate correspondence from source to target language remains an unsolved problem. Template or Super Function based machine translation system suffer less from the existance of MWEs, but MWEs are still main holdback of MT systems. Our initial experiments on the Chinese-Japanese MT systems reveal that, where MWEs exist, SFBMT system suffer in terms of both efficiency ,comprehensibility and adequacy of finding the translation functions. Statistic based Machine Translation suffers more than SFBMT. For SFBMT systems to become of further practical use, they need to be enhanced with MWEs processing capability. As part of our study towards this goal, we proposed a discriminative latent model, which was developed for sequence labeling task, for identifying and extracting Chinese MWEs. In our evaluation, the tool achieved precisions ranging from 71.46% to 95.87% for different types of MWEs. Such results demonstrate that it is feasible to automatically identify many Chinese MWEs using our tool, Super Function based MT will be further improvement after the Chinese MWEs have been detected.",2011,M. Sohrawordi; M. Al Mehedi Hasan,253,259,7,,10.1109/NLPKE.2011.6138204,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138204,IEEE Conferences,IEEE
Polarity Detection in a Cross-Lingual Sentiment Analysis using spaCy,Sentiment Analysis;Opinion Mining;CrossLingual Sentiment Analysis;Polarity Detection;Machine Translation;NLP;Twitter Sentiment Analysis,"This paper presents a comparison of sentiment analyses performed on a dataset of French tweets and it's machine translated version (in English) using Google Translate. In recent years, a fairly new Python library called spaCy has gained significant traction in performing sentiment analyses in languages other than English due to its multilingual support. There still haven't been major publications on evaluating its usage for the said purpose. In this research, TFIDF features are extracted from three different N-grams (Unigrams, Bigrams and Trigrams) in the corpus after preprocessing to remove irrelevant details. These are then trained and tested using three machine learning algorithms - Logistic Regression, NaÃ¯ve Bayes Algorithm and Stochastic Gradient Descent. A comparative study then put forth will help future researchers in the following three areas - the capability of performing sentiment analyses in languages other than English, reliability of machine translation tools in performing cross-lingual sentiment analyses and the evaluation of Python's library, spaCy for performing multilingual sentiment analyses.",2020,M. Yang; J. Zhu; J. Li; L. Wang; H. Qi; S. Li; L. Daxin,490,496,7,,10.1109/ICRITO48877.2020.9197829,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197829,IEEE Conferences,IEEE
A supervised approach for word sense disambiguation based on Arabic diacritics,Arabic natural language processing;Machine learning;Machine translation;NaÃ¯ve Bayes Classifier;word sense disambiguation,"Since the last two decades' Arabic natural language processing (ANLP) has become increasingly much more important. One of the key issues related to ANLP is ambiguity. In Arabic language different pronunciation of one word may have a different meaning. Furthermore, ambiguity also has an impact on the effectiveness and efficiency of Machine Translation (MT). The issue of ambiguity has limited the usefulness and accuracy of the translation from Arabic to English. The lack of Arabic resources makes ambiguity problem more complicated. Additionally, the orthographic level of representation cannot specify the exact meaning of the word. This paper looked at the diacritics of Arabic language and used them to disambiguate an ambiguous word. The proposed approach of word sense disambiguation used Diacritizer application to Diacritize Arabic text. Then find the most accurate sense of an ambiguous word using NaÃ¯ve Bayes Classifier. Our system gets 91% precision, and 12.11% error rate. This experimental study proves that using Arabic Diacritics with NaÃ¯ve Bayes Classifier enhances the accuracy of choosing the appropriate sense for ambiguous Arabic words.",2016,M. Yang; S. Liu; K. Chen; H. Zhang; E. Zhao; T. Zhao,1015,1021,7,,10.1109/ICIEV.2016.7760152,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7760152,IEEE Conferences,IEEE
Computing Semantic Similarities Based on Machine-Readable Dictionaries,semantic similarity;machine readable dictionary,"The measurement of semantic similarity is a foundation work in semantic computing. In this paper the authors study the similarity measure between two words. Different from previous works, this paper suggests a novel method that relies on machine-readable dictionaries for measuring similarities. Machine-readable dictionaries are more widely available than other kinds of lexical resources. If two words have similar definitions, they are semantically similar. A definition is represented by a definition vector. Each dimension represents a word in the dictionary. The score of each dimension in the vector is calculated by a variation of tf*idf. Evaluations show that this method achieves competitive results in both Chinese and English.",2008,Mrinalini K; Vijayalakshmi P,8,14,7,6,10.1109/WSCS.2008.9,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4570807,IEEE Conferences,IEEE
The Impact of a Dot: Case Studies of a Noise Metamorphic Relation Pattern,Metamorphic testing;metamorphic relation pattern;oracle problem;noise;machine translation;machine recognition;artificial intelligence,"We propose a ""noise"" metamorphic relation pattern (MRP), which is a sub-pattern under the more general MRP ""symmetry."" We conduct case studies with real-life systems in three different application domains (obstacle perception in autonomous systems, machine translation, and named entity recognition) to show the usefulness of the ""noise"" MRP for software verification and validation.",2019,N. Arivazhagan; C. Cherry; I. Te; W. Macherey; P. Baljekar; G. Foster,17,23,7,2,10.1109/MET.2019.00011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785517,IEEE Conferences,IEEE
Prototype for Learning and Teaching Arabic Sign Language Using 3D Animations,Automatic translation;Arabic Sign language;Parallel corpus;3D animation;Signing Software;Prototype,"This paper presents the improvement and the enhancement of a prototype for learning and teaching Arabic Sign Language (ArSL) based on high-performance translation system from Arabic texts to their equivalent in ArSL using 3D animations; a hybrid translation approach combining rulebased and statistical techniques is supposed to be used. Previous efforts conducted by the team were devoted to the development of the prototype and the preparation of linguistic resources, including bilingual parallel corpus and an animated sign-dictionary (3D animations). In this phase, we focused in the sign visualization of the end-user application, the new eSign software version â€œJASigningâ€? is used as 3D avatar player to illustrate the translation result; it is also used to create the 3D animations.",2018,N. Li; W. Su; Y. Li; H. Yu; W. Xu; B. Gao,51,57,7,,10.1109/ICoIAS.2018.8493979,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493979,IEEE Conferences,IEEE
A Machine Learning Approach to Classifying Self-Reported Health Status in a Cohort of Patients With Heart Disease Using Activity Tracker Data,Clinical diagnosis;machine learning;patient monitoring;telemedicine;wearable sensors,"Constructing statistical models using personal sensor data could allow for tracking health status over time, thereby enabling the possibility of early intervention. The goal of this study was to use machine learning algorithms to classify patient-reported outcomes (PROs) using activity tracker data in a cohort of patients with stable ischemic heart disease (SIHD). A population of 182 patients with SIHD were monitored over a period of 12 weeks. Each subject received a Fitbit Charge 2 device to record daily activity data, and each subject completed eight Patient-Reported Outcomes Measurement Information Systems short form at the end of each week as a self-assessment of their health status. Two models were built to classify PRO scores using activity tracker data. The first model treated each week independently, whereas the second used a hidden Markov model (HMM) to take advantage of correlations between successive weeks. Retrospective analysis compared the classification accuracy of the two models and the importance of each feature. In the independent model, a random forest classifier achieved a mean area under curve (AUC) of 0.76 for classifying the physical function PRO. The HMM model achieved significantly better AUCs for all PROs (p <; 0.05) other than Fatigue and Sleep Disturbance, with a highest mean AUC of 0.79 for the physical function-short form 10a. Our study demonstrates the ability of activity tracker data to classify health status over time. These results suggest that patient outcomes can be monitored in real time using activity trackers.",2020,N. Rubens; T. Okamoto; D. Kaplan,878,884,7,3,10.1109/JBHI.2019.2922178,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734713,IEEE Journals,IEEE
Multilingual collaborative design support system,component;Multilingual collaborative design;UML specification;automatic translation;Eclipse plug-in,"In this paper, we first present an analysis of a multi-language application from a cross-cultural point of view. Then we analyze the specific activities of a multilingual collaborative design and the automatic translation system that it requires. We also propose an architecture of a design support system producing the UML design of applications and allowing a multilingual collaboration. We present the first results of an experiment with such a system.",2009,O. Kouhei; O. Yasuhiro; N. Makoto; O. Tomohiro; T. Katsuhiko,312,318,7,5,10.1109/CSCWD.2009.4968077,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4968077,IEEE Conferences,IEEE
A seq2seq Neural Network based Conversational Agent for Gulf Arabic Dialect,Chatbots;Deep Learning;Conversational Agent;Neural Machine Translation;Transformer,"A Conversational Agent (CA), or dialogue system, is a computer system that has the ability to respond to humans automatically using natural language. CAs offer instant responses and can concurrently assist a potentially unlimited number of users. The modeling of CAs in Arabic has so far received less attention when compared with other languages due to the complexity of the Arabic language, the existence of several dialects, and a lack of data resources. The literature contends that modeling a CA in Arabic mostly done using pattern-matching and information retrieval, employing classification approaches with a closed-domain data source. There is extremely limited research so far on modeling an open-domain CA in the Arabic dialect. This research has utilized a deep-learning architecture, known as the Seq2Seq neural network, to build a CA in the Arabic Gulf dialect. We formulated the CA problem as a machine translation problem and, therefore, built our corpus from tweets, in the post-reply format, to train and evaluate the model. We investigated the effects of pretrained embeddings on the performance of the CA. For our evaluation, a Bilingual Evaluation Understudy (BLEU) score and human evaluators were used. The performance of the model was found to be comparable with existing deep learning models that have been trained on much larger corpora and in other languages. Our results present a promising first step towards building an open-domain CA in the Gulf Arabic dialect.",2020,P. Gupta; S. Shekhawat; K. Kumar,1,7,7,,10.1109/ACIT50332.2020.9300059,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300059,IEEE Conferences,IEEE
Pattern based pruning of morphological alternatives of Bengali wordforms,morphological analysis;pruning;syntactic analysis;chunking;machine translation,"Multiple morphological interpretations of wordforms is a bottleneck for different level of syntactico-semantic analyses of Natural Language (NL) sentences. Common vocabulary words of morphologically rich languages typically have more than one morphological analyses. However, if a word contains multiple morphological alternatives, one of them is appropriate with respect to the context where the word is used. Different text processing tasks including rule-based Machine Translation (MT) require morphological features of each surface word-form of the sentence. Therefore, given a context, an efficient procedure is needed to choose the appropriate morphological analysis of each word having multiple alternatives. In this paper, we propose a method to identify correct morphological analysis of each Bengali word-form by cancelling (or pruning) all such analyses which show context incompatibility.",2014,P. Heracleous; H. Ishiguro; N. Hagita,1724,1730,7,1,10.1109/ICACCI.2014.6968551,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968551,IEEE Conferences,IEEE
Introduction to Semantic Knowledge Base: Multilanguage Support of Linguistic Module,semantic knowledge base;information ambiguity;automatic translation;concept meaning,The following paper is a description of an approach adopted in the Semantic Knowledge Base in regard to the identification of meaning across multiple languages. The solution proposed separates the meaning from the text strings identifying it in a particular language. This solutions allows to create information collections that are subject to low risk of semantic ambiguity.,2016,P. Leong,188,194,7,2,10.1109/ENIC.2016.035,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838064,IEEE Conferences,IEEE
An Augmented Transformer Architecture for Natural Language Generation Tasks,Natural language processing;Neural machine translation;Sequence-to-sequence;Temporal dynamics;Transformer attention model,"The Transformer based neural networks have been showing significant advantages on most evaluations of various natural language processing and other sequence-tosequence tasks due to its inherent architecture based superiorities. Although the main architecture of the Transformer has been continuously being explored, little attention was paid to the positional encoding module. In this paper, we enhance the sinusoidal positional encoding algorithm by maximizing the variances between encoded consecutive positions to obtain additional promotion. Furthermore, we propose an augmented Transformer architecture encoded with additional linguistic knowledge, such as the Part-of-Speech (POS) tagging, to boost the performance on some natural language generation tasks, e.g., the automatic translation and summarization tasks. Experiments show that the proposed architecture attains constantly superior results compared to the vanilla Transformer.",2019,P. Malik; A. Singh Baghel,1,7,7,,10.1109/ICDMW48858.2019.9024754,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9024754,IEEE Conferences,IEEE
Auto-correlation wavelet support vector machine and its applications to regression,Wavelets;support vector machine;machine learning;function regression,"A support vector machine (SVM) with the autocorrelation of compactly supported wavelet as kernel is proposed in this paper. It is proved that this kernel is an admissible support vector kernel. The main advantage of the auto-correlation of a compactly supported wavelet is that it satisfies the translation invariant property, which is very important for signal processing. Also, we can choose a better wavelet from different choices of wavelet families for our auto-correlation wavelet kernel. Experiments on signal regression show that this method is better than the existing SVM function regression with the scalar wavelet kernel, the Gaussian kernel, and the exponential radial basis function kernel It can be easily extended to other applications such as pattern recognition by using this newly developed auto-correlation wavelet SVM.",2005,P. Prinetto; G. Tiotto; A. Del Principe,246,252,7,8,10.1109/CRV.2005.19,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1443136,IEEE Conferences,IEEE
An automatic non-native speaker recognition system,non-native;accent recognition;speaker recognition;Hidden Markov Model;Gaussian Mixture Model;neural network;discriminative training;fusion,"Identification of non-native personnel is a critical piece of information for making crucial on-the-spot decisions for security purposes. Identification of a non-native speaker is often readily apparent in normal conversation with a native speaker through speech content and accent. Such identification which requires familiarity with language nuances may not be possible for a non-native interrogator or intelligence analyst or when conversing or listening through a machine language translator. Developing an automatic system to identify speakers as native or non-native, as well as their native language, including dialect, within input audio streams, is the major goal of this project. Such a system may be used alone or with other downstream applications such as machine language translation systems. In this paper we present four approaches to identify native and non-native speakers as a binary recognition problem. The approaches can be further categorized into phonetic-based approaches and non-phonetic-based approaches. These approaches were tested on two separate databases, including text-dependent read speech and text-independent spontaneous speech. The results show that our system is competitive in comparison with other published, state-of-the-art non-native speaker recognition systems. Key metrics for automated non-native recognition systems include: 1) positive identification rates, 2) false alarm/identification rates, and 3) length of captured speech sample required to reach a decision.",2010,P. Sanjanaashree; M. Anand Kumar,77,83,7,3,10.1109/THS.2010.5655088,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655088,IEEE Conferences,IEEE
Fusing images with different focuses using support vector machines,Image fusion;support vector machines;wavelet transform,"Many vision-related processing tasks, such as edge detection, image segmentation and stereo matching, can be performed more easily when all objects in the scene are in good focus. However, in practice, this may not be always feasible as optical lenses, especially those with long focal lengths, only have a limited depth of field. One common approach to recover an everywhere-in-focus image is to use wavelet-based image fusion. First, several source images with different focuses of the same scene are taken and processed with the discrete wavelet transform (DWT). Among these wavelet decompositions, the wavelet coefficient with the largest magnitude is selected at each pixel location. Finally, the fused image can be recovered by performing the inverse DWT. In this paper, we improve this fusion procedure by applying the discrete wavelet frame transform (DWFT) and the support vector machines (SVM). Unlike DWT, DWFT yields a translation-invariant signal representation. Using features extracted from the DWFT coefficients, a SVM is trained to select the source image that has the best focus at each pixel location, and the corresponding DWFT coefficients are then incorporated into the composite wavelet representation. Experimental results show that the proposed method outperforms the traditional approach both visually and quantitatively.",2004,P. Zhang; J. Fang; C. Yang; C. Huang; T. Tang; Z. Wang,1555,1561,7,93,10.1109/TNN.2004.837780,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1353290,IEEE Journals,IEEE
Software and machine learning tools for monitoring railway track switch performance,Track switch;condition monitoring;statistical FDI methods;classification,"Trackside data logging hardware is often used in the UK, and increasingly elsewhere in the world, to record and transmit processed condition data from track switching equipment (points) in order to gauge asset health. This paper presents a novel implementation of three tools which can be used together to make the analysis and handling of this data easier. The first of these tools is a statistical classifier which automatically assigns labels to the process data. The classifier is trained using historical data containing examples of events of interest, such as recordings taken when maintenance activity or failures have developed. In practice, the labels are used to pre-filter the data, to bring swift attention to events of interest, and to automatically create categorised datasets which can be used to analyse historical performance. Two different types of classifier are presented: a Gaussian NaÃ¯ve Bayes classifier and a neural network classifier. The second tool is a simple pattern recognition algorithm which can determine when the different phases of mechanical operation in a single track switch movement occur, for example locking, unlocking, and moving. The final tool is a statistical technique which is used to extract simple features from the data and raise alarms if they indicate poor track switch performance. The effectiveness of these tools is tested using real world data taken from three different railways.",2016,Q. Liu; Z. He,1,7,7,,10.1049/cp.2016.1210,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920684,IET Conferences,IET
Metrics for evaluating phonetics machine translation in Natural Language Processing through modified Edit Distance algorithm-A naÃ¯ve approach,Ambiguity;Edit distance;Natural Language Processing (NLP);Phonetics,"Uninhabited mistakes while writing happens are unstoppable. There are certain common errors that occur during writing such as missing letters, extra letters, disordered letters, and misspelled letters. These kind of common spelling errors are called phonetics spelling errors. These are of a major concern while dealing with phonetics. Out of various problems that the phoneticians are trying to solve, major portion of it concentrates on varieties of spelling errors. Phonetic structures are greatly emphasized based on the effectiveness, appropriateness and accuracy. In order to keep abreast with the changing and challenging trends of Natural Language Processing (NLP), it is of great importance that one should resolve the problems of spelling errors. To achieve the goal, numerous realistic and practical approaches have to be adopted that make use of spelling correction algorithms such as Edit distance, Habit distance, Soundex and Asoundex. Through the analysis of these algorithms, a new interface is put forward that calculates the Edit distance, thereby showing the overall comparative study of phonetic algorithms with the proposed modified Edit Distance algorithm. The interface computes the Edit distance between two strings in appropriate and intuitive way, contemplating with the comparisons shown in the distance table. The Results show that an average of 0.937 recall and 0.947 precision have been achieved with the F-measure 0.9417. Through these results, it is evident that the recall and F-measures are improved in the proposed Edit-Distance algorithm. The revised version of the edit distance algorithm consistently attains finer quality results in comparison with the traditional edit distance algorithm.",2015,Q. Yanghua; N. Kapre; H. Ng; K. Teo,1,7,7,1,10.1109/ICCCI.2015.7218113,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7218113,IEEE Conferences,IEEE
A Real Time Approach for Bangla Text Extraction and Translation from Traffic Sign,Optical Character Recognition;Image Processing;Machine Translation;Language Model,The following topics are dealt with: learning (artificial intelligence); natural language processing; text analysis; feature extraction; Internet; pattern classification; support vector machines; neural nets; mobile computing; convolutional neural nets.,2018,R. Gu; M. Chen; W. Yang; C. Yuan; Y. Huang,1,7,7,,10.1109/ICCITECHN.2018.8631966,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8631966,IEEE Conferences,IEEE
"Feature Extraction from Smartphone Images by Using Elliptical Fourier Descriptor, Centroid and Area for Recognizing Indonesian Sign Language SIBI (Sistem Isyarat Bahasa Indonesia)",feature extraction;computer vision;machine learning;deep learning;image processing;sign language,"Sistem Isyarat Bahasa Indonesia (SIBI) is the official sign language in Indonesia. This research aims to create a translator for SIBI to be installed on a smartphone. The translator will analyze gestures for inflectional words, which are root words combined with prefixes, and/or suffixes. The feature extraction method that was used in this research is Elliptical Fourier Descriptor (EFD), additionally centroid and area data were added to retain information on hand orientation, position and shape. The extracted features will be fed into, a Long Short-Term Memory (LSTM) model which will then recognize gestures into text. The method used in this research produced 99% accuracy for root word gestures, 71% accuracy for prefix gestures, 86% accuracy for suffix gestures.",2019,R. Tchoua; A. Ajith; Z. Hong; L. Ward; K. Chard; D. Audus; S. Patel; J. d. Pablo; I. Foster,8,14,7,,10.1109/ICoIAS.2019.00008,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782484,IEEE Conferences,IEEE
Bootstrapping word alignment by automatically generated bilingual dictionary,Machine Learning;Word Alignment;Bootstrapping,"This paper presents a new approach to improve the word alignment. Building a bilingual dictionary is one of the main applications for word alignment. However, the research of using the bilingual dictionary to improve the word alignment is not enough. There are two bottlenecks. The first is that large bilingual dictionary is hard to get. The second is that the normal approach of using bilingual dictionary does not make full use of the dictionary. We designed a bootstrapping algorithm to conquer the bottlenecks, achieving a good result.",2008,R. Wang; M. Utiyama; A. Finch; L. Liu; K. Chen; E. Sumita,1,7,7,1,10.1109/NLPKE.2008.4906750,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906750,IEEE Conferences,IEEE
A Study on Machine Learning for Imbalanced Datasets with Answer Validation of Question Answering,Answer Validation;Imbalanced Datasets;Machine Learning;Question Answering;QA-Lab;Support Vector Machine,"Question Answering is a system that can process and answer a given question. In recent years, an enormous number of studies have been made on question answering, little is known about the effects of imbalanced datasets with answer validation of question answer system. The objective of this paper is to provide a better understanding of the effects of imbalanced datasets model for answer validation in a real world university entrance exam question answering system. In this paper, we proposed a question answer system and provided a comprehensive analysis of imbalanced datasets and balanced datasets model with Answer Validation of Question Answering system using NTCIR-12 QA-Lab2 Japanese university entrance exams English translation development and test datasets. As a result, our system achieved 90% accuracy with imbalanced datasets machine learning model for the NTCIR-12 QA-Lab2 development datasets.",2016,Reji Rahmath K; P. C. R. Raj,513,519,7,1,10.1109/IRI.2016.76,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785785,IEEE Conferences,IEEE
Machine learning identification of diabetic retinopathy from fundus images,Diabetic retinopathy;fundus images;Gaussian filtering;texture;contrast;fractal dimension;lacunarity;machine learning;artificial neural network;support vector machines,"Diabetic retinopathy may potentially lead to blindness without early detection and treatment. In this research, an approach to automate the identification of the presence of diabetic retinopathy from color fundus images of the retina has been proposed. Classification of an input fundus image into one of the three classes, healthy/normal, Non-Proliferative Diabetic Retinopathy (NPDR) and Proliferative Diabetic Retinopathy (PDR) has been achieved. Blood vessel segmentation from the input image is achieved by Gaussian filtering. An adaptive, input - driven approach is considered for the mask generation and thresholding is accomplished using local entropy. The processed image obtained is characterized by second order textural feature, contrast, in four different orientations- 0Â°, 45Â°, 90Â° and 135Â° and structural features namely, fractal dimension and lacunarity. The research incorporates a three layered artificial neural network (ANN) and support vector machines (SVM) to classify the retinal images. The efficiency of the proposed approach has been evaluated on a set of 106 images from the DRIVE and DIARETB1 databases. The experimental results indicate that this method can produce a 97.2% and 98.1% classification accuracy using ANN and SVM respectively invariant of rotation, translation and scaling in input retinal images as opposed to a fixed mask based on the matched filter method.",2014,Rile Hu; Chengqing Zong; Bo Xu,1,7,7,12,10.1109/SPMB.2014.7002949,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7002949,IEEE Conferences,IEEE
Automatic Detection of Compensation During Robotic Stroke Rehabilitation Therapy,Motion compensation;posture classification;rehabilitation robotics;stroke rehabilitation,"Robotic stroke rehabilitation therapy can greatly increase the efficiency of therapy delivery. However, when left unsupervised, users often compensate for limitations in affected muscles and joints by recruiting unaffected muscles and joints, leading to undesirable rehabilitation outcomes. This paper aims to develop a computer vision system that augments robotic stroke rehabilitation therapy by automatically detecting such compensatory motions. Nine stroke survivors and ten healthy adults participated in this study. All participants completed scripted motions using a table-top rehabilitation robot. The healthy participants also simulated three types of compensatory motions. The 3-D trajectories of upper body joint positions tracked over time were used for multiclass classification of postures. A support vector machine (SVM) classifier detected lean-forward compensation from healthy participants with excellent accuracy (AUC = 0.98, F1 = 0.82), followed by trunk-rotation compensation (AUC = 0.77, F1 = 0.57). Shoulder-elevation compensation was not well detected (AUC = 0.66, F1 = 0.07). A recurrent neural network (RNN) classifier, which encodes the temporal dependency of video frames, obtained similar results. In contrast, F1-scores in stroke survivors were low for all three compensations while using RNN: lean-forward compensation (AUC = 0.77, F1 = 0.17), trunk-rotation compensation (AUC = 0.81, F1 = 0.27), and shoulder-elevation compensation (AUC = 0.27, F1 = 0.07). The result was similar while using SVM. To improve detection accuracy for stroke survivors, future work should focus on predefining the range of motion, direct camera placement, delivering exercise intensity tantamount to that of real stroke therapies, adjusting seat height, and recording full therapy sessions.",2018,S. Abdul-Rauf; H. Schwenk; P. Lambert; M. Nawaz,1,7,7,4,10.1109/JTEHM.2017.2780836,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8214256,IEEE Journals,IEEE
Feature Extraction Based Machine Learning for Human Burn Diagnosis From Burn Images,Image preprocessing;burn;classification;graft;SVM,"Burn is one of the serious public health problems. Usually, burn diagnoses are based on expert medical and clinical experience and it is necessary to have a medical or clinical expert to conduct an examination in restorative clinics or at emergency rooms in hospitals. But sometimes a patient may have a burn where there is no specialized facility available, and in such a case a computerized automatic burn assessment tool may aid diagnosis. Burn area, depth, and location are the critical factors in determining the severity of burns. In this paper, a classification model to diagnose burns is presented using automated machine learning. The objective of the research is to develop the feature extraction model to classify the burn. The proposed method based on support vector machine (SVM) is evaluated on a standard data set of burns-BIP_US database. Training is performed by classifying images into two classes, i.e., those that need grafts and those that are non-graft. The 74 images of test data set are tested with the proposed SVM based method and according to the ground truth, the accuracy of 82.43% was achieved for the SVM based model, which was higher than the 79.73% achieved in past work using the multidimensional scaling analysis (MDS) approach.",2019,S. Ananthakrishnan; S. Tsakalidis; R. Prasad; P. Natarajan; A. Namandi Vembu,1,7,7,7,10.1109/JTEHM.2019.2923628,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766148,IEEE Journals,IEEE
Multi-label Classification of Indonesian Hate Speech on Twitter Using Support Vector Machines,classification;hate speech;social media;support vector machine,"Hate speech has become a hot issue as it spreads massively on today's social media with specific targets, categories, and levels. In addition, hate speech can cause social conflict and even genocide. This research proposes a system that classifies hate speech written in Indonesian language on Twitter. It also handles the noisiness of twitter data, such as mixed languages and non-standard text. We not only use Support Vector Machines (SVM) as a classifier, but also compare it with other methods, such as deep learning, CNN and DistilBERT. Apart from standard text preprocessing, we propose to accommodate the effect of translating in handling the multilingual content. The data transformation methods used in the SVM model are Label Power-set (LP) and Classifier Chains (CC). The experiment result shows that the classification using the SVM and CC without stemming, stopword removal, and translation provides the best accuracy of 74.88%. The best SVM hyperparameter on multilabel classification is the sigmoid kernel, the regularization parameter value of 10, and the gamma value of 0.1. Stemming, stopword removal, and translation preprocessing are less effective in this research. Moreover, CNN has a flaw in predicting labels for the training data with a low occurrence rate.",2020,S. Ã–zkan; G. B. Akar,1,7,7,,10.1109/ICoDSA50139.2020.9212992,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212992,IEEE Conferences,IEEE
An independent-domain natural language interface for relational database: Case Arabic language,Relational Databases;Arabic Natural Language;Natural Language Processing (NLP);XML schema;Extended Context Free Grammar (ECFG);Machine Learning,"Making information stored in database accessible for non expert users, has become one of the problems of great interest for the research community of database querying system. Hence for overriding the complexity of using database language such as Structured Query Language (SQL), the using of natural language can be a very important and simple method. But without helps computer cannot understand this language. For that its necessary to develop an interface able to translate natural language query into database query language. In this paper we present the architecture of generic interface for querying database using Arabic language. This interface functions independently of database domain and has the capacity to improve through experience its knowledge base.",2016,S. B. Pham; G. B. Tran; D. D. Pham; K. C. Phung; K. T. Nguyen,1,7,7,,10.1109/AICCSA.2016.7945786,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7945786,IEEE Conferences,IEEE
OCRMPD: OCR system for Myanmar printed document image with a novel segmentation method and hierarchical classification scheme,machine printed;OCR;OCRMPD;Myanmar scripts;Support vector machine,"As large quantity of document images is getting archived by the digital libraries, an efficient strategy that can convert Myanmar document image into machine understandable text format is needed. And Myanmar language contains many words, and most of them are similar, especially for small fonts, the accuracy of the Optical Character Recognition, OCR system for Myanmar may be low. Therefore, this paper designs an OCR system for Myanmar Printed Document (OCRMPD) with several proposed methods that can automatically convert Myanmar printed text to machine understandable text. In order to get more accurate system, enhance the input image by removing noise and making some correction on variants. A method for isolation of the character image is proposed by using connected component analysis for wrongly segmented characters produced by projection only. Finally, hierarchical mechanism is used for SVM classifier for recognition of the character image. The proposed algorithms have been tested on a variety of Myanmar printed documents and the results of the experiments indicate that the methods can increase the segmentation accuracy as well as recognition rates.",2011,S. Cai; Y. LÃ»; Q. Liu,285,291,7,1,10.1109/ICCP.2011.6047882,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6047882,IEEE Conferences,IEEE
Early and late integration of audio features for automatic video description,video description;audio feature;SoundNet;MFCC;encoder-decoder;deep learning,"This paper presents our approach to improve video captioning by integrating audio and video features. Video captioning is the task of generating a textual description to describe the content of a video. State-of-the-art approaches to video captioning are based on sequence-to-sequence models, in which a single neural network accepts sequential images and audio data, and outputs a sequence of words that best describe the input data in natural language. The network thus learns to encode the video input into an intermediate semantic representation, which can be useful in applications such as multimedia indexing, automatic narration, and audio-visual question answering. In our prior work, we proposed an attention-based multi-modal fusion mechanism to integrate image, motion, and audio features, where the multiple features are integrated in the network. Here, we apply hypothesis-level integration based on minimum Bayes-risk (MBR) decoding to further improve the caption quality, focusing on well-known evaluation metrics (BLEU and METEOR scores). Experiments with the YouTube2Text and MSR-VTT datasets demonstrate that combinations of early and late integration of multimodal features significantly improve the audio-visual semantic representation, as measured by the resulting caption quality. In addition, we compared the performance of our method using two different types of audio features: MFCC features, and the audio features extracted using SoundNet, which was trained to recognize objects and scenes from videos using only the audio signals.",2017,S. Chand,430,436,7,6,10.1109/ASRU.2017.8268968,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268968,IEEE Conferences,IEEE
Tile Art Image Generation Using Conditional Generative Adversarial Networks,tile art;machine learning;image-to-image translation;conditional GAN,"Image-to-image translation is a task of mapping an image in one domain to a corresponding image in another domain. The task includes various types of problems such as super-resolution, colorization, and artistic style transfer. In recent years, with the advent of deep learning, the technology has been rapidly advanced. The main purpose of this paper is to propose a tile art image generation method using machine learning approach based on conditional generative adversarial networks. To make the training data set of tile art images, we adopted a square-pointillism image generation method using the greedy approach. After training, the proposed network can generate tile art images that have the structure of tiles and reproduce the original images well. As regards generating time, the greedy approach takes 1322 seconds to generate tile art image of size 4096Ã—3072, while the proposed machine learning approach takes 0.593 seconds.",2018,S. Jiang,209,215,7,3,10.1109/CANDARW.2018.00047,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590901,IEEE Conferences,IEEE
Algorithms and a Tool for Automatic Decryption of Clinical Notes,natural language processing;clinical notes;information extraction;parsers,"Natural Language Processing (NLP) presents a set of techniques that are finding applications in modern healthcare, for the extraction and generation text. Clinical notes are classically originated and derived from various sources of narratives such as reports, referral letters, discharge notes and clinical summaries. In this paper, we present algorithms and a tool for enabling each member of a medical team to read and understand each others medical notes, using NLP techniques. We refer to this process as the decryption, or the deciphering, of complex clinical notes into simple readable language. We have presented a tool called the Clinical Note Translator (CNT). Based on the replacement of technical terms in clinical notes, CNT translates these notes to plain text. This solution is expected to assist multidisciplinary medical teams in understanding peer-to-peer expert notes.",2019,S. M. Kamrul Hasan; M. Ahmad,137,143,7,,10.1109/ISCMI47871.2019.9004426,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004426,IEEE Conferences,IEEE
Convex Representations Using Deep Archetypal Analysis for Predicting Glaucoma,Glaucoma prediction;archetypal analysis;deep archetypal analysis;artificial intelligence;machine learning,"Goal: The purpose of this study was to identify clinically relevant patterns of glaucomatous vision loss through convex representation to predict glaucoma several years prior to disease onset. Methods: We developed a deep archetypal analysis to identify patterns of glaucomatous vision loss, and then projected visual fields over the identified patterns. Projections provided a representation that was more accurate in detecting glaucomatous vision loss, thus, more appropriate for recognizing preclinical signs of glaucoma prior to disease development. To overcome the class imbalance in prediction, we implemented a class-balanced bagging with neural networks. Results: Using original visual field as features of the class-balanced bagging classification provided an area under the receiver-operating characteristic curve (AUC) of 0.55 for predicting glaucoma approximately four years prior to disease development. Using convex representation of the visual fields as input features provided an AUC of 0.61 while using deep convex representation as input features improved the AUC to 0.71. Relevance vector machine (RVM) achieved an AUC of 0.64. Conclusion: Deep archetypal analysis representation of visual functional features with balanced bagging classification could serve as an automated tool for predicting glaucoma. Significance: Glaucoma is the second leading cause of worldwide blindness. Most people with glaucoma have no early symptoms or pain, delaying diagnosis in many patients until they reach late irreversible vision loss stages. In fact, about 50% of people with glaucoma are unaware they have the disease. Deep archetypal analysis models may impact clinical practice in effectively identifying at-risk glaucoma patients well prior to disease development.",2020,S. Mallat; A. Zouaghi; E. Hkiri; M. Zrigui,1,7,7,1,10.1109/JTEHM.2020.2982150,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102996,IEEE Journals,IEEE
Cross-language sentiment classification based on Support Vector Machine,Cross-language;Sentiment Classification;Joint Training Set;Support Vector Machine,"This paper presents a cross-language sentiment classification method that based on the Support Vector Machine model. The method is based on the research about English training corpus, first of all, we use statistical methods extract feature words in English, and use machine translation tools build an â€œEnglish-Chineseâ€? feature word bank. Then, we put forward a feature word weighting method which combined TF-IDF with sentimental intensity of sentiment words, after that, we constructed a vector space model. Finally, we optimized the Support Vector Machine classification model by using a joint training set. Experimental results show the effectiveness of this method.",2015,S. -P. Chuang; A. H. Liu; T. -W. Sung; H. -y. Lee,507,513,7,,10.1109/ICNC.2015.7378040,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378040,IEEE Conferences,IEEE
Automatic classification of cotton boll using signature curve and boundary descriptors,Feature extraction;Fuzzy based classifier;Cotton boll,"The correlation between the environmental features and image features of cotton bolls is the necessary step for the pattern recognition and translate those features for machine understanding is the main challenge to distinguish mature cotton boll from immature one. Present work is tried to solve this problem using shape based features. The fuzzy based classifier is introduced for the decision making. Any improper acquisition of images of cotton bolls, like intense illumination or deep shadows (which is of course absent in natural settings) will produce improper results.",2015,S. Shreya; Y. Upadhyay; M. Manchanda; R. Vohra; G. D. Singh,1599,1605,7,,10.1109/ICACCI.2015.7275842,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275842,IEEE Conferences,IEEE
Automatic Design of Ensembles of Window Operators for Ocular Image Segmentation,Classification;Ensemble of Classifiers;Image Processing;Mathematical Morphology;Neural Networks;Ocular Images;Segmentation;Wavelet Transform,"W-operators are a nonlinear class of locally defined and translation invariant image operators. A W-operator is completely defined and represented by a characteristic function, or classifier, that maps a set of window observations to a set of labels. In this work, we propose a new approach to design W-operators for grayscale image processing. In the proposed approach, we constrain both the space of characteristic functions using artificial feed-forward neural networks and the space of observations using the 2-D Haar wavelet transform. The goal of these constraints is to reduce the cost of design and improve the performance of W-operators for practical applications. Based on this approach, a family or set of W-operators is designed and then combined into a single operator using an ensemble method. We evaluated the performance of this approach in the segmentation of blood vessels in ocular images of the DRIVE database. The results show the suitability of this approach: It outperforms W-operators based on logistic regression without any constraint in the space of observations; aperture filters designed using support vector machines and pyramidal multiresolution, and a fast segmentation using the local thresholding method of Otsu.",2014,Shui Liu; Sheng Li; Tiejun Zhao; Shiqi Li,935,941,7,,10.1109/TLA.2014.6872909,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6872909,IEEE Journals,IEEE
Slippage Detection Generalizing to Grasping of Unknown Objects Using Machine Learning With Novel Features,Slippage detection;perception for grasping and manipulation;learning and adaptive systems,"Real-time grasp stability is based on successful slippage detection. In this work, we consider slippage detection as a binary problem (slip, stable) and we propose a novel set of temporal and frequential features, extracted from force norm profiles and collected during reliable ground truth labeling processes, finally employed within the machine learning classification techniques. Classification performance of the proposed scheme, with respect to its success and generalization ability, is assessed systematically utilizing different performance metrics that clarify class predictions as opposed to most of the reported works. We show that our proposed feature extraction method improves classification performance over the commonly used feature sets, even when trained with one surface, and generalizes successfully to unseen ones. The trained classifier is tested on a completely new task and object, for real-time slippage detection, showing high detection accuracy. Finally, the classifier is tested in a different experimental layout with a different force sensor. Experiments are conducted on unseen surfaces for a variety of sampling frequencies, for both translational and rotational slippage, with the proposed approach showing fast and accurate detection in all cases.",2018,T. Fonseka; R. Naranpanawa; R. Perera; U. Thayasivam,942,948,7,5,10.1109/LRA.2018.2793346,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258901,IEEE Journals,IEEE
Probabilistic Determination Of Down's Syndrome Using Machine Learning Techniques,DS;k-means;k-medoids;Naive Bayes;random forest;ANN,"Down's Syndrome (DS) is a genetic birth disorder that occurs in fetuses, which is typically associated with physical growth delays, mild to moderate mental disability, characteristic facial features and a short life expectancy rate. The paper focuses on extracting markers from the Prenatal Screening (first trimester test) reports of patients. Few of the attributes are crown rump length, nuchal translucency, age, smoking habits, history of previous pregnancies with Trisomy 21 and presence of the nasal bone, extracted using Optical Character Recognition. The collection of reports is subjected to various clustering techniques like K-means, K-medoids, DBSCAN (Density-based spatial clustering of applications with noise), Hierarchical clustering in order to deal with the problem of lack of labels of training data-set since it is bound by confidentiality and ethical issues. The paper is pivoted around the novel technique of handling skewed data-set using ADASYN (Adaptive Synthetic Sampling Approach) over-sampling approach to overcome class bias because the data set in hand has only rare cases of `High Risk' DS. The reports are further subjected to ML (Machine Learning) ensemble of supervised learning methodologies like Naive Bayes, Random Forest and ANN (Artificial Neural Network) to determine the posterior probability of the foetus suffering from Down's Syndrome. The paper envisions building an architecture that can be used as a tool to aid gynecologists by providing numerical probability measure that is representative of the Down Syndrome risk in the foetus and on the basis of this value, the gynecologist can recommend whether the patient should take up further invasive [amniocentesis and CVS (Chorionic Villus Sampling)] tests that are clear indicators of DS. The paper utilizes a live Indian data set and hence is reflective of the current scenario of DS in India. The paper aims to provide a groundbreaking idea in the field of prenatal diagnostics using ML methodologies ensemble.",2018,T. Jabid; F. Anwar; S. M. Baker; M. Shoyaib,126,132,7,,10.1109/ICACCI.2018.8554392,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554392,IEEE Conferences,IEEE
Recognizing Indonesian Sign Language Gestures Using Features Generated by Elliptical Model Tracking and Angular Projection,Computer Vision;Pattern Recognition;Image Processing;Machine Learning;Deep Learning;Sign Language;Feature Extraction,"In this paper, we propose a method of feature extraction applied to the hands, fingers and arms, intended to improve the accuracy of Sistem Isyarat Bahasa Indonesia (SIBI) gesture recognition. Using common smartphone camera, we recorded multiple sequence of gestures used to sign for affixes and root words in SIBI then applied image processing and tracking methods to extract features from the shape and location of the hands. To extract the features, skin color segmentation was applied to separate hands and face blob from the background. Then the object would be registered to an ellipse model and tracked through the videos using elliptical model tracking. Finally, the video was then processed frame by frame, and each successfully tracked object is subjected to angular projection to generate the aforementioned features. The model that was used to recognize SIBI gestures is 2-layers Long Short-Term Memory (LSTM) neural network. Accuracy of the proposed method is measured by comparing the prediction with the actual gesture of the testing data. The highest level of accuracy achieved for the prefix, root and suffix datasets are 91.74%, 98.94%, and 97.71% respectively.",2019,T. K. Rao; T. V. Prasad,25,31,7,,10.1109/ICoIAS.2019.00011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782535,IEEE Conferences,IEEE
Automated Generation of Test Models from Semi-Structured Requirements,"machine learning, model-based testing, natural language requirements","Context: Model-based testing is an instrument for automated generation of test cases. It requires identifying requirements in documents, understanding them syntactically and semantically, and then translating them into a test model. One light-weight language for these test models are Cause-Effect-Graphs (CEG) that can be used to derive test cases. Problem: The creation of test models is laborious and we lack an automated solution that covers the entire process from requirement detection to test model creation. In addition, the majority of requirements is expressed in natural language (NL), which is hard to translate to test models automatically. Principal Idea: We build on the fact that not all NL requirements are equally unstructured. We found that 14% of the lines in requirements documents of our industry partner contain ""pseudo-code""-like descriptions of business rules. We apply Machine Learning to identify such semi-structured requirements descriptions and propose a rule-based approach for their translation into CEGs. Contribution: We make three contributions: (1) an algorithm for the automatic detection of semi-structured requirements descriptions in documents, (2) an algorithm for the automatic translation of the identified requirements into a CEG and (3) a study demonstrating that our proposed solution leads to 86% time savings for test model creation without loss of quality.",2019,T. L. Mahyari; R. M. Dansereau,263,269,7,2,10.1109/REW.2019.00053,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933802,IEEE Conferences,IEEE
Automatic tracking of cervical spine using fluoroscopic sequences,Cervical vertebrae;range of motion;flexion-extension;segmentation;annotated data,"In this paper an automatic tracking approach is proposed for the measurement of the cervical spine using Kanade-Lucas-Tomasi (KLT) feature tracking algorithm through fluoroscopic sequences. Previous research related to cervical vertebrae shows that abnormalities in the cervical vertebrae structures may affect the movement of the cervical spine. The aim of this paper is to automate the detection of range of movement in a lateral view of the spine during a flexion-extension cycle. The parameters analyzed were translation and in-plane rotation of the individual vertebrae. For analysis of these parameters, fluoroscopic recordings of three individuals were used. The algorithm marked landmarks on first frame, considered them as reference position and extracted translation and rotation of these vertebrae landmarks in the successive frames using Harris corner detector and use link motion vector for trajectory. Manual selection of vertebrae C3 to C6 (annotated data) were used for the validation of the proposed algorithm. The automated results are very close and uniform to the manual selection.",2017,T. T. Zin,592,598,7,,10.1109/IntelliSys.2017.8324355,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8324355,IEEE Conferences,IEEE
T2K2: A Type II KASER,Computing with Words;Machine Learning;Natural Language;Randomization;Translation,"The transformational methodology described in this paper induces new knowledge, which may be open under any deductive process. The method of transposition is used to maintain a maximum size for the application as well as meta-rule bases. The ""move to head"" method is used by both the application and metarule bases for hypotheses formation. Whenever an application rule is fired, it is transposed on the transposition list and also moved to the head on the other list. If any meta-rule on a solution path individually leads to a contradiction on the application rule base, then the offending meta-rule is expunged. Then, when the system is idle enter dream mode, whereby rule i rArr rule j is generated by the 3-2-1 skewed twister as a candidate most-specific meta-rule. Candidate most-specific meta-rules are ""cored"" to create one generalization per candidate. These candidate meta-rules are tested for application to each rule in the application domain rule base. In order to be saved in the meta base, they may not map any existing rule in the application domain rule base to one having the same antecedent as another in this base, but a different consequent (as found by hashing). In addition, all candidate meta-rules must map at least one rule in the application base to another distinct one there, or be symmetrically induced from meta-rules that so map",2006,T. Wang,147,153,7,,10.1109/IRI.2006.252404,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4018481,IEEE Conferences,IEEE
An automatic noun compound extraction from Arabic corpus,hybrid method;Arabic noun compund;Association measures;morphological variations;lemmatization;n-best evaluation method,"The identification of noun compound as multi-word lexical units is very important task in natural language processing applications that require some degree of semantic interpretation such as, machine translation, information retrieval and text summarization. In this paper, we used the hybrid method for extracting the noun compound from Arabic corpus that is based on linguistic knowledge and statistical measures. For the candidate identification, we have used some linguistic analysis tools such as lemmatization and POS in order to filter the candidates and determine the variations. The association measures have been computed for each candidate to rank the candidates. After that, we have evaluated the association measures by using the n-best evaluation method. We reported the precision values for each association measure in each n-best list. The experimental results showed that the log-likelihood ratio is the best association measure that achieved highest precision.",2011,W. Chen; S. Ananthakrishnan; R. Kumar; R. Prasad; P. Natarajan,224,230,7,3,10.1109/STAIR.2011.5995793,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995793,IEEE Conferences,IEEE
Automatic Classification of Spider Images in Natural Background,classification of spider images;image preprocessing;deep convolutional neural networks;transfer learning;contour detection,"Spiders are the most abundant predatory natural enemies in terrestrial ecosystems. As an important natural enemy of many agricultural and forestry pests, spiders play a very significant role in the biological control of pests. In order to make rational use of spider resources, it is necessary to observe and study the population characteristics of it. Direct observation method is time-consuming and laborious. If we can take the videos or images of spiders by surveillance cameras, and then use computer vision technology to identify and classify automatically, the efficiency of image data acquisition and pest biological control will be greatly improved. Motivated by this, we studied the classification and recognition of spider images in natural background obtained by common surveillance equipment. However, the images of some species of spiders in natural background are difficult to be collected, and the inadequate clarity and contrast of the subjects in images will also affect the recognition accuracy. So, firstly, histogram equalization was used to enhance the contrast of the image; the dataset of spider images was expanded by image rotation, reflection, flipping, zooming, translating and increasing the pixel noise appropriately, and so on; the contour detection was carried out for assistant recognition. Secondly, taken the deep convolutional neural networks (CNN) as our basic framework, two automatic recognition models of spider images, that is the 8-layer deep CNN model and the transfer learning model based on Inception-v3, were constructed. After that, the two models were trained, evaluated and compared under a dataset with 4478 pre-processed images. The experimental results show that the first model has a limited effect on image feature extraction of spiders in natural background, while the second model based on transfer learning can achieve better recognition accuracy when combining image contour features as an auxiliary input. In the second model, the accuracy of training set and testing set can reach more than 90%, and the recognition speed can be controlled within 1 second, which meets the practical requirements of automatic classification and recognition of spider images in natural background.",2019,W. Huo; P. Angeles; Y. F. Tai; N. Pavese; S. Wilson; M. T. Hu; R. Vaidyanathan,158,164,7,,10.1109/SIPROCESS.2019.8868601,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868601,IEEE Conferences,IEEE
Plant Species Classification Using a 3D LIDAR Sensor and Machine Learning,plant classification;supervised learning;3D laser sensor;agricultural robotics,"In the domain of agricultural robotics, one major application is crop scouting, e.g., for the task of weed control. For this task a key enabler is a robust detection and classification of the plant and species. Automatically distinguishing between plant species is a challenging task, because some species look very similar. It is also difficult to translate the symbolic high level description of the appearances and the differences between the plants used by humans, into a formal, computer understandable form. Also it is not possible to reliably detect structures, like leaves and branches in 3D data provided by our sensor. One approach to solve this problem is to learn how to classify the species by using a set of example plants and machine learning methods. In this paper we are introducing a method for distinguishing plant species using a 3D LIDAR sensor and supervised learning. For that we have developed a set of size and rotation invariant features and evaluated experimentally which are the most descriptive ones. Besides these features we have also compared different learning methods using the toolbox Weka. It turned out that the best methods for our application are simple logistic regression functions, support vector machines and neural networks. In our experiments we used six different plant species, typically available at common nurseries, and about 20 examples of each species. In the laboratory we were able to identify over 98% of these plants correctly.",2010,X. Yan,339,345,7,17,10.1109/ICMLA.2010.57,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708854,IEEE Conferences,IEEE
Solving Arithmetic Word Problems Automatically Using Transformer and Unambiguous Representations,Machine Learning;NLP;Question Answering;Natural Languge Processing;Math Word Problems,"Constructing accurate and automatic solvers of math word problems has proven to be quite challenging. Prior attempts using machine learning have been trained on corpora specific to math word problems to produce arithmetic expressions in infix notation before answer computation. We find that custom-built neural networks have struggled to generalize well. This paper outlines the use of Transformer networks trained to translate math word problems to equivalent arithmetic expressions in infix, prefix, and postfix notations. In addition to training directly on domain-specific corpora, we use an approach that pre-trains on a general text corpus to provide foundational language abilities to explore if it improves performance. We compare results produced by a large number of neural configurations and find that most configurations outperform previously reported approaches on three of four datasets with significant increases in accuracy of over 20 percentage points. The best neural approaches boost accuracy by almost 10% on average when compared to the previous state of the art.",2019,Y. R. Fatmehsari; A. Ghahari; R. A. Zoroofi,526,532,7,,10.1109/CSCI49370.2019.00101,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071054,IEEE Conferences,IEEE
Combining local and global feature for object recognition using SVM-KNN,Support Vector Machine;Moment Invariant;Hessian-Laplace;K nearest neighbor;Object Recognition,"In this paper, a framework for recognizing an object from the given image based on the local and global feature is discussed. The proposed method is based on the combination of the two methods in the literature, K-Nearest Neighbor (KNN) and Support Vector Machine (SVM). For feature vector formation, Hu's Moment Invariant is computed to represent the image, which is invariant to translation, rotation and scaling as a global feature and Hessian-Laplace detector and PCA-SIFT descriptor as local feature. In this framework, first the KNN is applied to find the closest neighbors to a query image and then the local SVM is applied to find the object that belongs to the object set. The proposed method is implemented as two stage process. In the first stage, KNN is utilized to compute distances of the query to all training and pick the nearest K neighbors. During the second stage SVM is applied to recognize the object. The proposed method is experimented in MATLAB and tested with the COIL-100 database and the results are shown. To prove the efficiency of the proposed method, Neural Network model (BPN) is performed and the comparative results are given.",2012,Y. Rossikova; J. J. Li; P. Morreale,1,7,7,6,10.1109/ICPRIME.2012.6208278,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6208278,IEEE Conferences,IEEE
A Non-Intrusive Appliance Recognition System,Load Monitoring;Machine Learning;Energy Management;Appliance Recognition,"Depleting energy resources and the unstable supply of raw materials call for innovations in the energy industry, such as in energy generation, distribution, and management. Moreover, increasing electricity prices take a toll on consumers that operates within a strict budget. This study in particular focuses on the proper management and utilization of energy from the consumer's perspective. The objective is to develop a non-intrusive appliance recognition system that can identify the appliances that are being used and calculate how much each of these appliances contribute to the total electricity consumption. Installation of the monitoring system, which utilizes a single sensor clamped to the main power line and used to measure the total energy consumption, does not alter the electrical system, thus, non-intrusive. With this system, the homeowner can monitor which appliances are in use and how much energy they consume. Also, this translates to savings for the household when data provided by the system lead to smarter energy-management choices. For this study to be deployable in households, a data-acquisition system to streamline the data-gathering procedure was needed. Also, a machine learning algorithm was trained and implemented to perform the appliance recognition task given input features from the frequency domain of the measured aggregate data from the main power line. Lastly, the system was tested for prediction accuracy and characterized; and then necessary optimizations were implemented.",2019,Z. J. Zheng; C. H. C. Leung,141,147,7,,10.1109/IoTaIS47347.2019.8980438,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8980438,IEEE Conferences,IEEE
Classification of G-protein Coupled Receptors Based on Semi-navÃ¯e Bayesian Inference,Machine Learning;Classification;Sequence Alignment,"In this paper, we propose a novel protein classification strategy for the hierarchical classification of G-protein Coupled Receptors (GPCRs) based on a feature enhanced protein classification approach considering the rich synthesis of multiple sequences alignment (MSA) and a semi-naive Bayesian inference algorithm. The output of MSA on the specific protein family used in further processing to extract features is translated into feature vectors that are presented to a semi-naive Bayesian classifier. MSA identifies positions that are indicative of functional differences by alignment within a group of sequences, thus we can ascertain whether a query sequence belongs to this family according to the alignment result presented to the classifier. The experimental result indicates that the proposed method makes significant improvements over the previous methods, which attains an accuracy of up to 100% at family level and 98.14% at level I sub-family and level II sub-subfamily. The proposed method has valuable implications for future research on the classification of protein sequences.",2018,Z. Liu; Y. Jin; Y. Chi,2262,2268,7,,10.1109/BIBM.2018.8621398,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621398,IEEE Conferences,IEEE
Incremental learning from several different microarrays,microarray;regression;leave-one-out;relevance vector machine;regularization;random permutations,"A common phenomenon in biological experiments is that it is not possible to obtain complete measurements for all the samples. Note that some microarrays are very informative, but very expensive to have them for all the samples. However, we can use publicly available background knowledge about the potential links between the components of different microarrays (known, also, as genes). As a result, we shall translate all the selected genes in the terms of other genes. In line with the most fundamental principles of the incremental learning, those secondary genes are to be included in the regression models automatically to give the learning processes the right initial directions. The proposed method was tested online during the e-LICO data-mining Contest, where we had achieved second best score.",2013,Z. Sun; J. M. Zhang; M. Harman; M. Papadakis; L. Zhang,1,7,7,,10.1109/IJCNN.2013.6706780,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6706780,IEEE Conferences,IEEE
Hybrid machine translation for English to Marathi: A research evaluation in Machine Translation: (Hybrid translator),Machine Translation;Rule based Translation;Statistical Translation;Mapping Rules;hybrid translation;Google Translator,"Information Present in Different language and Structure gives Rise to language as barrier in information retrieval. Informative Document on queen Elizabeth is been writing by foreign language English which makes its difficult for a Marathi reader to understand and seek History of England, on Similar lines Literature Work on Shivaji is mostly documented in Marathi which makes foreign Historians difficult to gain know, in both case user is at times unknown of facts due to language and may lose interest on information. Vital information on current happing on village and taluka level are been published in newspaper with local language which setback information spread among other Masses. Many Time government documents and forms are been presented in English Language where a lay man from Marathi language background finds difficulty to understand information and even avoid such procedures therefore it highly urges for need of automated Software based Translation system which would assist in cross Domain information Retrieval. Machine Translation assist to translate Information presented in one language to other language. Information can be present in form of text, speech and image translating this information helps for sharing of information and ultimately information gain. A lot of work has been done on Translation of English to Hindi, Tamil Bangla and other foreign languages also. Machine Translation is challenging Research Area with numerous issues due to language ambiguity like grammar, Structure and even fluency of use. Numerous Methodologies have been proposed and developed which have uplifts and downfalls also, Although statistical and rule based at core with each having limitations, rule based produce accurate mapped translation and are trainable system but costly, whereas statistical produce fluent translation but lack accuracy and sense. Hybrid is combine approach which integrated approach and helps to optimize translation output. The research manuscript we present hybrid machine Translator for English to Marathi language which translated Web pages, text Documents on Agriculture (crops fruits for farmer), Medical reports in Marathi and tourism related information. Proposed System consists of Parallel Multi-Engines which process statistical and rule based Translation for same input document and produce a optimized result by performing statistical over rule based which give fluent language sense outputs. Mapper algorithm is been used in rule based Translation, with Agriculture corpus, medical and tourism corpus for statistical evaluation. Marathi wordnet has been implemented to enhance dictionary and incorporate better translation result Currently System has been proposed for text Document which can be extended to speech and voice. Comparative analysis for point view in one dimension of only limited set of Queries is done with Google Translator. Holding hybrid approach as better methodology. A Systematic survey of only 10 key articles used in research has been done. This research article is extension of our previous research surveys and partial implementations. And innovative S-measure has been new parameter proposed and evaluated by our research team.",2016,A. Ali; P. Nakov; P. Bell; S. Renals,924,931,8,8,10.1109/ICEEOT.2016.7754822,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7754822,IEEE Conferences,IEEE
Classification techniques for automatic speech recognition (ASR) algorithms used with real time speech translation,AF (Acoustic Feature);AM (Acoustic Model);ANN (Artificial Neural Network);ASR (Automatic Speech Recognition);BN (Bayesian Network);CNN (Convolutional Neural Networks);CVC (Consonant-Vowel-Consonant);DAG (Direct Acyclic Graph);DBN (Dynamic Bayesian Networks);DCT (Discrete Cosine Transformation);DNN (Deep Neural Network);DTW (Dynamic Time wrapping);HMM (Hidden Markov Model);JPD (Joint Probability Distribution);LM (Language Model);LPCC (Linear Predictive Cepstral Coefficients);MFCC (Mel Frequency Cepstral Coefficients);MT (Machine Translation);PD (Punctuation Dictionary);PLP (Perceptual Linear Prediction Coefficient);QV (Quantization Vector);RV (Random Variables);SLT (Spoken Language Translation);SVM (Support Vector Machine);WER (Word Error Rate);WRR (Word Recognition Rate),"Speech processing is considered to be one of the most important application area of digital signal processing. Speech recognition and translation systems have consisted into two main systems, the first system represents an ASR system that contains two levels which are level one the feature extraction level As well as, level two the classification technique level using Data Time Wrapping (DTW), Hidden Markov Model (HMM), and Dynamic Bayesian Network (DBN). The second system is the Machine Translation (MT) system that mainly can be achieved by using three approaches which are (A) the statistical-based approach, (B) rule-approach, and (C) hybrid-based approach. In this study, we made a comparative study between classification techniques from ASR point of view, as well as, the translation approaches from MT point of view. The recognition rate was used in the ASR level and the error rate was used to evaluate the accuracy of the translated sentences. Furthermore, we classified the sample text audio files into four categories which were news, conversational, scientific phrases, and control categories.",2017,A. BÃ©rard; L. Besacier; A. C. Kocabiyikoglu; O. Pietquin,200,207,8,2,10.1109/SAI.2017.8252104,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252104,IEEE Conferences,IEEE
Syntax-Informed Interactive Neural Machine Translation,machine translation;neural machine translation;interactive neural machine translation,"In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, and this is an effective way to improve productivity gain in translation. Phrase-based statistical MT (PB-SMT) has been the mainstream approach to MT for the past 30 years, both in academia and industry. Neural MT (NMT), an end-to-end learning approach to MT, represents the current state-of-the-art in MT research. The recent studies on interactive MT have indicated that NMT can significantly outperform PB-SMT. In this work, first we investigate the possibility of integrating lexical syntactic descriptions in the form of supertags into the state-of-the-art NMT model, Transformer. Then, we explore whether integration of supertags into Transformer could indeed reduce human efforts in translation in an interactive-predictive platform. From our investigation we found that our syntax-aware interactive NMT (INMT) framework significantly reduces simulated human efforts in the French-to-English and Hindi- to-English translation tasks, achieving a 2.65 point absolute corresponding to 5.65% relative improvement and a 6.55 point absolute corresponding to 19.1% relative improvement, respectively, in terms of word prediction accuracy (WPA) over the respective baselines.",2020,A. R. Babhulgaonkar; S. V. Bharad,1,8,8,,10.1109/IJCNN48605.2020.9207491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207491,IEEE Conferences,IEEE
MEE : An Automatic Metric for Evaluation Using Embeddings for Machine Translation,MT Evaluation;Automatic Metrics;Semantic Evaluation;Morphological Languages;Embeddings,"We propose MEE, an approach for automatic Machine Translation (MT) evaluation which leverages the similarity between embeddings of words in candidate and reference sentences to assess translation quality. Unigrams are matched based on their surface forms, root forms and meanings which aids to capture lexical, morphological and semantic equivalence. We perform experiments for MT from English to four Indian Languages (Telugu, Marathi, Bengali and Hindi) on a robust dataset comprising simple and complex sentences with good and bad translations. Further, it is observed that the proposed metric correlates better with human judgements than the existing widely used metrics.",2020,Bowen Zhou; Rong Zhang; Yuqing Gao,292,299,8,,10.1109/DSAA49011.2020.00042,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260045,IEEE Conferences,IEEE
Towards a Bidirectional Machine Translator Generator for Multilingual Communication,"lexical functional grammars, conversational text translation, logic programming, machine translation, natural language processing","Machine Translation (MT) systems are typically quite complex, especially those used in production environments where high-quality conversational text or speech translation from one language to another is important. As a result, the vast majority of MT systems support translation between a single language pair, often uni-directionally. This research study extends previous work to assess the efficacy of developing a bidirectional translator generator in Prolog programming language using Lexical Functional Grammars. The main research objective is building a machine translator generator for multilingual communication, i.e. developing a system whose inputs are linguistic descriptions of a desired source and target language and whose output is a program that translates between the two natural languages. The implementation of a bidirectional machine translator between English and Hungarian, developed as a proof-of-concept case study, is discussed and assessed in terms of four general classes of translation. The benefits and drawbacks of this approach as generalized to MT systems are also discussed, along with possible areas of future work.",2019,C. Liu; H. Xie; Z. Zha; L. Yu; Z. Chen; Y. Zhang,25,32,8,,10.1109/CDKE46621.2019.00011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949379,IEEE Conferences,IEEE
Seal: Efficient Training Large Scale Statistical Machine Translation Models on Spark,statistical machine translation;parallel word alignment algorithm;parallel translation algorithm;parallel language model algorithm;distributed data-parallel system,"Statistical machine translation (SMT) is an important research branch in natural language processing (NLP). Similar to many other NLP applications, large scale training data can potentially bring higher translation accuracy for SMT models. However, the traditional single-node SMT model training systems can hardly cope with the fast-growing amount of large scale training corpus in the big data era, which makes the urgent requirement of efficient large scale machine translation model training systems. In this paper, we propose Seal, an efficient, scalable, and end-to-end offline SMT model training toolkit based on Apache Spark which is a widely-used distributed data-parallel platform. Seal parallelizes the training process of the entire three key SMT models that are the word alignment model, the translation model, and the N -Gram language model, respectively. To further improve the performance of the model training in Seal, we also propose a number of system optimization methods. In word alignment model training, by optimizing the block size tuning, the overhead of IO operation and communication is greatly reduced. In translation model training, by well encoding the training corpus, the data size transferred over the network can be reduced significantly, thus improving the overall training efficiency. We also optimize the maximum likelihood estimation (MLE) algorithm to solve the data skew issue on the join operation which is adopted both in the translation model training and the language model training. The experiment results show that Seal outperforms the well-known SMT training system Chaski with about 5Ã— speedup for word alignment model training. For the syntactic translation model and language model training, Seal outperforms the existing cutting-edge tools with about 9~18Ã— speedup and 8~9Ã— speedup on average, respectively. On the whole, Seal outperforms the existing distributed system with 4~6Ã— speedup and the single-node system with 9~60Ã— speedup on average respectively. Besides, Seal achieves near-linear data and node scalability.",2018,C. Liu; S. Han,118,125,8,,10.1109/PADSW.2018.8644562,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8644562,IEEE Conferences,IEEE
Studying the SPEA2 algorithm for optimising a pattern-recognition based machine translation system,Machine Translation;Evolutionary Computation;Multiobjective Optimisation;Genetic Algorithms;SPEA2,"In this article, aspects regarding the optimisation of machine translation systems via evolutionary computation algorithms are examined. The article focuses on pattern-recognition based machine translation systems that use large monolingual corpora in the target language from which statistical information is extracted. The research reported here uses a specific machine translation as a representative for experimentation. Based on previous studies, SPEA2 is selected as the optimisation method. Issues examined in this article include the effect of population size on the optimisation process and the number of epochs required for the algorithm to settle to near-optimal results. In addition, the effects of different parameters on the translation process are examined, with the aim of reducing the set of system parameters that are actively involved in the optimisation process and thus reducing the optimisation processing time.",2011,C. Mi; Y. Yang; X. Zhou; L. Wang; T. Jiang,97,104,8,1,10.1109/SMDCM.2011.5949279,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949279,IEEE Conferences,IEEE
Machine translation model using inductive logic programming,Machine translation;Inductive logic programming;rule based machine translation;example based machine translation;rule Induction;Arabic to English,"Rule based machine translation systems face different challenges in building the translation model in a form of transfer rules. Some of these problems require enormous human effort to state rules and their consistency. This is where different human linguists make different rules for the same sentence. A human linguist states rules to be understood by human rather than machines. The proposed translation model (from Arabic to English) tackles the mentioned problem of building translation model. This model employs Inductive Logic Programming (ILP) to learn the language model from a set of example pairs acquired from parallel corpora and represent the language model in a rule-based format that maps Arabic sentence pattern to English sentence pattern. By testing the model on a small set of data, it generated translation rules with logarithmic growing rate and with word error rate 11%.",2009,C. V. Alexandru; S. Panichella; H. C. Gall,1,8,8,4,10.1109/NLPKE.2009.5313850,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313850,IEEE Conferences,IEEE
"AwezaMed: A Multilingual, Multimodal Speech-To-Speech Translation Application for Maternal Health Care",speech-to-speech translation;machine translation;automatic speech recognition;text-to-speech;mobile application,"The language contexts of multilingual developing countries such as South Africa are often characterised by communication challenges resulting from language differences. AwezaMed is a multilingual, multimodal speech-to-speech translation application for the health care domain, which was designed to assist in bridging communication barriers and mitigate the risks of miscommunication. The application focuses on the domain of maternal health care. It uses English as source language and Afrikaans, isiXhosa and isiZulu as target languages to enable health care providers to communicate with patients in their own language. It incorporates automatic speech recognition, machine translation and text-to-speech to deliver speech-to-speech translation functionality in a scalable way via a REST API to an Android mobile application. It is being piloted at various health care facilities across South Africa.",2020,D. Fan; R. Chen; J. Xue; Y. Zhao,1,8,8,,10.23919/FUSION45008.2020.9190240,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190240,IEEE Conferences,IEEE
A Monte Carlo Method for Metamorphic Testing of Machine Translation Services,machine translation quality;oracle problem;metamorphic testing;Monte Carlo method;natural languages,"With the growing popularity of machine translation services, it has become increasingly important to be able to assess their quality. However, the test oracle problem makes it difficult to conduct automated testing. In this paper, we propose a Monte Carlo method, in combination with metamorphic testing, to overcome the oracle problem. Using this method, we assessed the quality of three popular machine translation services - namely, Google Translate, Microsoft Translator, and Youdao Translate. We set the source language to be English, and the target languages included Chinese, French, Japanese, Korean, Portuguese, Russian, Spanish, and Swedish. A sample of 33,600 observations (involving a total of 100,800 actual translations) was collected and analyzed using a 3 x 56 factorial design. Based on this data, our model found Google Translate to be the best (in terms of the metamorphic relation used) for each and every target language considered. A trend for Indo-European languages producing better results was also identified.",2018,D. Holanda Noronha; K. Gibson; B. Salehpour; S. J. E. Wilton,38,45,8,1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457612,IEEE Conferences,IEEE
Extended super function based Chinese Japanese machine translation,Natural language processing;machine translation;super function;Levenshtein Distance,"Research on machine translation has a long history and many methods and techniques have been proposed and developed. However, low quality of translation is still a major problem and many related problems remain unresolved. Super function based machine translation was proposed to perform translation without going through syntactic and semantic analysis as many machine translation systems usually do. In such way, the import of the errors caused by the syntactic and semantic analysis could be avoided and the readability of the translation is also guaranteed. We continue to extend the super function for the Chinese Japanese machine translation. The super function is divided into the super function for sentences and super function for phrases. The existing scope and definition of the variable for super function is also expanded. The base noun phrases and base verbal phrases are detected and considered when building the super function. The head noun in base noun phrase is treated as variable but the determinative modifiers in base noun phrases are treated as modificatory variables, meanwhile the determinative modifiers in base verb phrases are treated as modificatory variables to build the super function. The revised Levenshtein distance algorithm is proposed for evaluate and find the matching super functions in database for input sentences and the determinative modifiers. The proposed extended super function keeps the advantages of the super function but has less number of super functions for Chinese Japanese machine translation. From the experiment results, the extended super function is not only effective but also feasible and with considerable precision for Chinese Japanese machine translation. The extended super function can even translate long sentences with complex structure for which the completely matching super functions can not be found for translation.",2009,D. Xiong; M. Zhang; H. Li,1,8,8,3,10.1109/NLPKE.2009.5313817,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313817,IEEE Conferences,IEEE
An approach to automatic acquisition of translation templates based on phrase structure extraction and alignment,Bilingual grammar induction;machine translation;structure alignment;translation template acquisition,"In this paper, we propose a new approach for automatically acquiring translation templates from unannotated bilingual spoken language corpora. Two basic algorithms are adopted: a grammar induction algorithm, and an alignment algorithm using bracketing transduction grammar. The approach is unsupervised, statistical, and data-driven, and employs no parsing procedure. The acquisition procedure consists of two steps. First, semantic groups and phrase structure groups are extracted from both the source language and the target language. Second, an alignment algorithm based on bracketing transduction grammar aligns the phrase structure groups. The aligned phrase structure groups are post-processed, yielding translation templates. Preliminary experimental results show that the algorithm is effective",2006,E. Garcia-Ceja; Ã…. Hugo; B. Morin; P. O. Hansen; E. Martinsen; A. N. Lam; Ã˜. Haugen,1656,1663,8,5,10.1109/TSA.2005.858521,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1677985,IEEE Journals,IEEE
SentiWordNet for New Language: Automatic Translation Approach,Sentiment lexicon;Translation approach;Machine learning;Sentiment analysis,"This paper proposes an automatic translation approach to create a sentiment lexicon for a new language from available English resources. In this approach, an automatic mapping is generated from a sense-level resource to a wordlevel by applying a triple unification process. This process produces a single polarity score for each term by incorporating all sense polarities. The major idea is to deal with the sense ambiguity during the lexicon transfer and provide a general sentiment lexicon for languages like Turkish which do not have a freely available machine-readable dictionary. On the other hand, the translation quality is critical in the lexicon transfer due to the ambiguity problem. Thus, this paper also proposes a multiple bilingual translation approach to find the most appropriate equivalents for the source language terms. In this approach, three parallel, series and hybrid algorithms are used to integrate the translation results. Finally, three lexicons are achieved for the target language with different sizes. The performance of three lexicons is evaluated in the lexicon-based sentiment classification task and compared with the results achieved by the supervised approach. According to experimental results, the proposed approach can produce reliable sentiment lexicons for the target language.",2016,E. YÄ±lmaz; I. D. El-Kahlout,308,315,8,5,10.1109/SITIS.2016.57,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907484,IEEE Conferences,IEEE
Exploring the use of acoustic embeddings in neural machine translation,Neural Machine Translation;LDA topics;Acoustic Embeddings,"Neural Machine Translation (NMT) has recently demonstrated improved performance over statistical machine translation and relies on an encoder-decoder framework for translating text from source to target. The structure of NMT makes it amenable to add auxiliary features, which can provide complementary information to that present in the source text. In this paper, auxiliary features derived from accompanying audio, are investigated for NMT and are compared and combined with text-derived features. These acoustic embeddings can help resolve ambiguity in the translation, thus improving the output. The following features are experimented with: Latent Dirichlet Allocation (LDA) topic vectors and GMM subspace i-vectors derived from audio. These are contrasted against: skip-gram/Word2Vec features and LDA features derived from text. The results are encouraging and show that acoustic information does help with NMT, leading to an overall 3.3% relative improvement in BLEU scores.",2017,E. Yulianti; M. Adriani; H. M. Manurung; I. Budi; A. N. Hidayanto,450,457,8,2,10.1109/ASRU.2017.8268971,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268971,IEEE Conferences,IEEE
A Sentiment Classification in Bengali and Machine Translated English Corpus,sentiment classification;machine translation;bilingual corpus,"The resource constraints in many languages have made the multi-lingual sentiment analysis approach a viable alternative for sentiment classification. Although a good amount of research has been conducted using a multi-lingual approach in languages like Chinese, Italian, Romanian, etc. very limited research has been done in Bengali. This paper presents a bilingual approach to sentiment analysis by comparing machine translated Bengali corpus to its original form. We apply multiple machine learning algorithms: Logistic Regression (LR), Ridge Regression (RR), Support Vector Machine (SVM), Random Forest (RF), Extra Randomized Trees (ET) and Long Short-Term Memory (LSTM) to a collection of Bengali corpus and corresponding machine translated English version. The results suggest that using machine translation improves classifiers performance in both datasets. Moreover, the results show that the unigram model performs better than higher-order n-gram model in both datasets due to linguistic variations and presence of misspelled words results from complex typing system of Bengali language; sparseness and noise in the machine translated data, and because of small datasets.",2019,F. Agakov; E. Bonilla; J. Cavazos; B. Franke; G. Fursin; M. F. P. O'Boyle; J. Thomson; M. Toussaint; C. K. I. Williams,107,114,8,3,10.1109/IRI.2019.00029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843450,IEEE Conferences,IEEE
CAPTCHA Using Strangeness in Machine Translation,advanced human cognitive processing abilities;strangeness;machine translated sentences;SS-CAPTCHA,"CAPTCHA is a technique that is used to prevent automatic programs from being able to acquire free e-mail or online service accounts. However, as many researchers have already reported, conventional CAPTCHA could be overcome by state-of-the-art malware since the capabilities of computers are approaching those of humans. Therefore, CAPTCHA should be based on even more advanced human-cognitive-processing abilities. We propose using the human ability of recognizing â€œstrangenessâ€? to achieve a new CAPTCHA. This paper focuses on strangeness in machine-translated sentences as an example, and proposes CAPTCHA using Strangeness in Sentences (SS-CAPTCHA), which detects malware by checking if users can distinguish natural sentences created by humans from machine-translated sentences. We discuss possible threats to SS-CAPTCHA and countermeasures against these threats. We also carried out basic experiments to confirm its usability by human users.",2010,F. Neri; P. Geraci,430,437,8,14,10.1109/AINA.2010.55,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5474731,IEEE Conferences,IEEE
Can Real-Time Machine Translation Overcome Language Barriers in Distributed Requirements Engineering?,machine translation;cultural distance;language barrier;distributed development;requirements engineering;simulation,"In global software projects work takes place over long distances, meaning that communication will often involve distant cultures with different languages and communication styles that, in turn, exacerbate communication problems. However, being aware of cultural distance is not sufficient to overcome many of the barriers that language differences bring in the way of global project success. In this paper, we investigate the adoption of machine translation (MT) services in synchronous text-based chat in order to overcome any language barrier existing among groups of stakeholders who are remotely negotiating software requirements. We report our findings from a simulated study that compares the efficiency and the effectiveness of two MT services, Google Translate and apertium-service, in translating the messages exchanged during four distributed requirements engineering workshops. The results show that (a) Google Translate produces significantly more adequate translations than Apertium from English to Italian; (b) both services can be used in text-based chat without disrupting real-time interaction.",2010,F. Yu; Z. Xu; C. Liu; X. Chen,257,264,8,6,10.1109/ICGSE.2010.37,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581516,IEEE Conferences,IEEE
A dependency-based word reordering approach for Statistical Machine Translation,Natural language processing;statistical machine translation;preprocessing;word reordering;transformation;dependency parser,"Reordering is of crucial importance for machine translation. Solving the reordering problem can lead to remarkable improvements in translation performance. In this paper, we propose a novel approach to solve the word reordering problem in statistical machine translation. We rely on the dependency relations retrieved from a statistical parser incorporating with linguistic hand-crafted rules to create the transformations. These dependency-based transformations can produce the problem of word movement on both phrase and word reordering which is a difficult problem on parse tree based approaches. Such transformations are then applied as a preprocessor to English language both in training and decoding process to obtain an underlying word order closer to the Vietnamese language. About the hand-crafted rules, we extract from the syntactic differences of word order between English and Vietnamese language. This approach is simple and easy to implement with a small rule set, not lead to the rule explosion. We describe the experiments using our model on VCLEVC corpus [18] and consider the translation from English to Vietnamese, showing significant improvements about 2-4% BLEU score in comparison with the MOSES phrase-based baseline system [19].",2008,G. Gao; G. Jiang,120,127,8,2,10.1109/RIVF.2008.4586343,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4586343,IEEE Conferences,IEEE
Modelling of Multiple Target Machine Translation of Controlled Languages Based on Language Norms and Divergences,Controlled language;Machine translation;Norms;Micro-system;Systemic linguistic analysis,"In the context of crises in which emergency services or the general population are of different languages, effective interoperability requires not only that translations of messages and alerts be done rapidly but also, being safety critical, that there be no errors. We have developed a methodology based on linguistic norms and a supporting mathematical model for the construction of a single source controlled language to be machine translated to specific target controlled languages. In this paper we discuss in particular the architecture of our machine translation system which is based on the `canonicalÂ¿ case where there are no language divergences (identical source and target languages), and the `variantÂ¿ cases encompassing the divergences between each target controlled language and our source controlled language. We explain the way that we classify and organize the divergences in a declarative manner so as to be incorporated in the machine translation process.",2008,G. H. Ngo; M. Nguyen; N. F. Chen,322,329,8,3,10.1109/ISUC.2008.13,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724480,IEEE Conferences,IEEE
Challenge Training to Simulate Inference in Machine Translation,neural machine translation;exposure bias;evaluation discrepancy;schedule sampling,"Despite much success has been achieved, neural machine translation (NMT) suffers from exposure bias and evaluation discrepancy. To be specific, the generation inconsistency between the training and inference process further causes error accumulation and distribution disparity. Furthermore, NMT models are generally optimized on word-level cross-entropy loss function but evaluated by sentence-level metrics. This evaluation-level mismatch may mislead the promotion of translation performance. To address these two drawbacks, we propose to challenge training to gradually simulate inference. Namely, the decoder is fed with inferred words rather than ground truth words during training with a dynamic probability. To ensure accuracy and integrity, we adopt alignment and tailoring on the inferred words. Therefore, these words can leverage inferred information to help improve the training process. As for the dynamic simulation, we define a novel loss-sensitive probability that can sense the converge of training and finetune itself in turn. Experimental results on IWSLT 2016 German-English and WMT 2019 English-Chinese datasets demonstrate that our methodology can significantly improve translation quality. The approach of alignment and tailoring outperforms previous works. Meanwhile, the proposed loss-sensitive sampling is also useful for other state-of-the-art scheduled sampling methods to achieve further promotion.",2020,G. Jose; N. S. Raj,1,8,8,,10.1109/IJCNN48605.2020.9206915,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206915,IEEE Conferences,IEEE
Following directions using statistical machine translation,Human-robot interaction;instruction following;navigation;statistical machine translation;natural language,"Mobile robots that interact with humans in an intuitive way must be able to follow directions provided by humans in unconstrained natural language. In this work we investigate how statistical machine translation techniques can be used to bridge the gap between natural language route instructions and a map of an environment built by a robot. Our approach uses training data to learn to translate from natural language instructions to an automatically-labeled map. The complexity of the translation process is controlled by taking advantage of physical constraints imposed by the map. As a result, our technique can efficiently handle uncertainty in both map labeling and parsing. Our experiments demonstrate the promising capabilities achieved by our approach.",2010,G. -M. Lin; H. H. -S. Lu,251,258,8,26,10.1109/HRI.2010.5453189,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453189,IEEE Conferences,IEEE
Improving Low-Resource Neural Machine Translation With Teacher-Free Knowledge Distillation,Neural machine translation;knowledge distillation;prior knowledge,"Knowledge Distillation (KD) aims to distill the knowledge of a cumbersome teacher model into a lightweight student model. Its success is generally attributed to the privileged information on similarities among categories provided by the teacher model, and in this sense, only strong teacher models are deployed to teach weaker students in practice. However, in low-resource neural machine translation, a stronger teacher model is not available. To counteract this, We therefore propose a novel Teacher-free Knowledge Distillation framework for low-resource neural machine translation, where the model learns from manually designed regularization distribution as a virtual teacher model. The prior distribution of artificial design can not only obtain the similarity information between words, but also provide effective regularity for model training. Experimental results show that the proposed method has improved performance in low-resource language effectively.",2020,G. Wang,206638,206645,8,1,10.1109/ACCESS.2020.3037821,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257421,IEEE Journals,IEEE
Sanskrit-Gujarati Constituency Mapper for Machine Translation System,constituent;rule base;Machine Translation,"Looking at vastness, depth and precise nature of Sanskrit grammar and geographically wide proliferation of Gujarati language and its native speaker, it becomes necessary to spotlight on constituency characteristics and features of Sanskrit and Gujarati. Both the languages fall under Indo-Iranian language sub-tree, but there are grammatical divergences which are discussed here so as to reflect in implementation of Machine Translation System (MTS). The content revolves around divergence pattern for a rule base MT system, due to scarce or unavailability of parallel aligned corpora to incorporate statistical or Example based methodology. The Sanskrit grammatical constituents like indeclinables, pronouns, verbs and nouns are analyzed. The Sanskrit inflectional affixes are mapped to its Gujarati inflectional affixes for each equivalent grammar constituent.",2019,H. Fudaba; Y. Oda; K. Akabe; G. Neubig; H. Hata; S. Sakti; T. Toda; S. Nakamura,1,8,8,1,10.1109/IBSSC47189.2019.8972989,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972989,IEEE Conferences,IEEE
Bilingual Segmenter for Statistical Machine Translation,bilingual segmenter;machine translation;conditional random fields;word alignment;phrase-based decoder,"We propose a bilingually-motivated segmenting framework for Chinese which has no clear delimiter for word boundaries. It involves producing Chinese tokens in line with word-based languagesÂ¿ words using a bilingual segmenting algorithm, provided with bitexts, and deriving a probabilistic tokenizing model based on previously annotated Chinese sentences. In the bilingual segmenting algorithm, we first convert the search for segmentation into a sequential tagging problem, allowing for a polynomial-time dynamic programming solution, and incorporate a control to balance mono- and bi-lingual information in tailoring Chinese sentences. Experiments show that our framework, applied as a pre-tokenization component, significantly outperforms existing segmenters in translation quality, suggesting our methodology supports better segmentation for bilingual NLP applications involving isolated languages such as Chinese.",2008,H. GonÃ§alves; J. A. GonÃ§alves; L. Corte-Real,97,104,8,,10.1109/ISUC.2008.10,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724447,IEEE Conferences,IEEE
Combining Modern Machine Translation Software with LSI for Cross-Lingual Information Processing,cross-lingual;latent semantic indexing;machine translation;multilingual;parallel corpora,"The growing internationalization of business and social interactions poses significant challenges in implementing multilingual information systems. For applications requiring retrieval, clustering, and categorization of multilingual document collections, cross-lingual application of latent semantic indexing (LSI) has a number of characteristics that make it potentially attractive. However, this technique is dependent upon the availability of applicable parallel corpora. Historically, such corpora have been quite limited in size and scope. In this paper, we provide new results regarding implementation of cross-lingual LSI text processing systems employing parallel corpora produced using modern machine translation (MT) products. We present measurements using the Reuters 21578 test set to demonstrate three key points regarding this combined LSI/modern MT approach: (1) for some languages, this approach can create parallel corpora of sufficient fidelity to support effective multilingual and cross-lingual LSI applications, (2) the technique is not particularly sensitive to details of LSI parameters, and (3) multiple languages can be represented in a single LSI space with little degradation in performance.",2014,H. H. O. Nasereddin; A. A. R. Omari,65,72,8,2,10.1109/ITNG.2014.52,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822177,IEEE Conferences,IEEE
Computational Linguistic Models and Language Technologies for Croatian,computational linguistics;natural language processing;Croatian language;corpus linguistics;POS/MSD tagging;lemmatization;parsing;WordNet;machine translation;machine aided translation;computer assisted language learning;automatic document indexing;document classification;document summarization,"This paper gives an overview of the scientific program ""Computational linguistic models and language technologies for Croatian "" that has been launched recently. Its short and long term goals, its composition as well as methodology and expected results are presented.",2007,H. Li; J. Sha; C. Shi,521,528,8,,10.1109/ITI.2007.4283826,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4283826,IEEE Conferences,IEEE
Combining Discrete Lexicon Probabilities with NMT for Low-Resource Mongolian-Chinese Translation,Mongolian Chinese Neural Machine Translation;Statistical Machine Translation;Discrete Lexicon Probabilities;Low-resource.,"Mongolian-Chinese neural machine translation (NMT) models often make mistakes in translating low-frequency words. We propose a method to alleviate this problem by improve NMT models with discrete translation lexicons that efficiently encode these low-frequency words. We describe a method to calcu-late the lexicon probability of generating the next word in the translation candi-date by using the attention vector of the NMT model to select which source word lexical probabilities the model should focus on. The method use this probabil-ity as a bias to combine with the stand-ard NMT probability. Experiments show an improvement of 4.02 BLEU score. We apply this method to large-scale corpus and improve the BLEU score. In addition, we also propose a novel approach to combine discrete probabilistic lexicons obtained from large-scale Mongolian - Chinese bilin-gual parallel corpus into NMT of small-scale corpus and enhance the perfor-mance of the system effectively.",2017,H. Liu; M. Li; J. Zhang; L. Chen,104,111,8,,10.1109/PDCAT.2017.00026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327074,IEEE Conferences,IEEE
BRAPT: A New Metric for Translation Evaluation Based on Psycholinguistic Perspectives,Automatic Text Translation;Text mining;BLEU;BRAPT,"There are some metrics to evaluate automatic text translations in the literature. However, the state-of-the-art of these metrics still has limitations. One of them is the dependence of an exact and ordered pairing of words for evaluating similarity among texts. Another, is the non-consideration of the semantics of the text in such comparison. Previous studies point out the need to analyze the semantics of words in the evaluation of translations. In this scenario, this paper presents a novel metric capable of evaluating the differences in automatic text translations that takes into account the semantics of the words presented in the texts. As a proof of concept, we selected ten journalistic texts written in English. These texts have been translated to Portuguese by specialists and by automatic text translation tools. Experimental results show the potential of the proposed metric in evaluating these translations, indicating it can perform better than the state-of-the-art metric.",2020,H. Su; C. Wu,1264,1271,8,,10.1109/TLA.2020.9099768,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099768,IEEE Journals,IEEE
Transzaar: Empowers Human Translators,Machine Translation;Pre-editing;Post-editing;Text analysis;Translation Memory;CAT Tool;Concordance,"In this paper, we describe Transzaar - an AI powered tool that offers computer aided translation (CAT) functionality: pre-translation analysis, post-editing machine translated content, translation prediction, text aligning, extensive logging and integration with several machine translation (MT) systems. Transzaar aids a human translator to perform various language processing tasks, viz., Translation, Transliteration, Localization, and other kinds of Text Analysis tasks. Using Transzaar, human translators can post-edit the machine translated content, to improve fluency and accuracy of the translated content to match the naturalness of human translation while delivering with better turn-around time. Transzaar aids the process of post-editing, thereby increasing the productivity of human translators by 2-3 folds within couple of months of usage for certain language pairs. It collects feedback continuously, which helps the MT system to further learn and improve periodically, with the additional new generated data-set.",2018,H. Yeo,1,8,8,,10.1109/ICCSA.2018.8439292,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439292,IEEE Conferences,IEEE
Automatic registration of images with simulated rotation and translation estimation using HAIRIS,Histogram;Image registration;Automatic Image registration;image segmentation;matching;wiener filter;second-order Butterworth LPF,"Image registration is the most important fundamental phenomenon in the image processing system. In which Automatic image registration is a challenging aspect. Although enormous methods for automatic image registration have been developed and implemented in ancient days, it is still a broad use in plenty applications, such as in remote sensing. In my work, I have proposed a method for automatic image registration through histogram-based image segmentation (HAIRIS). This new approach is designed by combining several segmentations of the pair of images to be registered, according to a relaxation parameter based on the delineating histogram modes, following the characterization of the objects extracted - via the objects area, axis ratio, perimeter and fractal dimension - and a statistical procedure for objects matching is applied to each object. Finally, the simulated rotation and translation are illustrated for this proposed methodology. The first and foremost dataset consists of a photograph and a rotated and shifted version of this photograph is developed, with different levels of added Gaussian white noise. This can also be applied to satellite images which are in pair, with different spectral content and simulated translation and rotation is estimated, and also for various remote sensing applications comprising of different viewing angles, different acquisition dates and different sensors. Histogram-based image segmentation allows the registration of pairs of multitemporal and multisensor images with their differences in rotation and translation parameters, with small spectral content differences whereas, leading to sub pixel accuracy.",2013,Hasi; Nasun-Urt,1,8,8,,10.1109/ICCCNT.2013.6726537,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726537,IEEE Conferences,IEEE
A novel Chinese-English on translation method using mix-language web pages,Chinese organization names translation;named entity translation;web assistant translation method;machine translation,"In this paper, we propose a novel Chinese-English organization name translation method with the assistance of mix-language web resources. Firstly, all the implicit out-of-vocabulary terms in the input Chinese organization name are recognized by a CRFs model. Then the input Chinese organization name is translated without considering these recognized out-of-vocabulary terms. Secondly, we construct some efficient queries to find the mix-language web pages that contain both the original input organization name and its correct translation. At last, a similarity matching and limited expansion based translation identification approach is proposed to identify the correct translation from the returned web pages. Experimental results show that our method is effective for Chinese organization name translation and can improve performance of Chinese organization name translation significantly.",2010,I. Hmeidi; A. Al-Aiad; S. Al-Momani; M. Ibnian,1,8,8,,10.1109/NLPKE.2010.5587832,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587832,IEEE Conferences,IEEE
Automatic exploitation of multilingual information for military intelligence purposes,Statistical machine translation;natural language processing;open source intelligence;military intelligence,"Intelligence plays an important role in supporting military operations. In the course of military intelligence a vast amount of textual data in different languages needs to be analyzed. In addition to information provided by traditional military intelligence, nowadays the internet offers important resources of potential militarily relevant information. However, we are not able to manually handle this vast amount of data. The science of natural language processing (NLP) provides technology to efficiently handle this task, in particular by means of machine translation and text mining. In our research project ISAF-MT we created a statistical machine translation (SMT) system for Dari to German. In this paper we describe how NLP technologies and in particular SMT can be applied to different intelligence processes. We therefore argue that multilingual NLP technology can strongly support military operations.",2012,I. Lyu; S. H. Kim; N. D. Woodward; M. A. Styner; B. A. Landman,1,8,8,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6387890,IEEE Conferences,IEEE
Web-based technical term translation pairs mining for patent document translation,Term translation;patent document translation;web-based;key word extraction;key word selection;machine translation,"This paper proposes a simple but powerful approach for obtaining technical term translation pairs in patent domain from Web automatically. First, several technical terms are used as seed queries and submitted to search engineering. Secondly, an extraction algorithm is proposed to extract some key word translation pairs from the returned web pages. Finally, a multi-feature based evaluation method is proposed to pick up those translation pairs that are true technical term translation pairs in patent domain. With this method, we obtain about 8,890,000 key word translation pairs which can be used to translate the technical terms in patent documents. And experimental results show that the precision of these translation pairs are more than 99%, and the coverage of these translation pairs for the technical terms in patent documents are more than 84%.",2010,I. S. M. Dissanayake; P. J. Wickramanayake; M. A. S. Mudunkotuwa; P. W. N. Fernando,1,8,8,1,10.1109/NLPKE.2010.5587775,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587775,IEEE Conferences,IEEE
Automatic Stopword Detection Using Term Ranking between Written and Machine Speech Recognition Transcribed Reviews,Term Ranking;TFIDF;Machine Speech Recognition (MSR);stop words;marketing;reviews.,"Video feedback and machine speech recognition are fast-becoming a popular choice for companies to gain insight into their products. In conjunction with this, text analytics can be used to extract insight from these video translations. Currently, there is little work in the area to analyse and compare techniques for natural language processing, information retrieval and information extraction. A commonly practiced technique in text analytics is the extraction of stop words; words whose presence do not contribute context or information to a document. In this paper, we explore statistical techniques for the automated extraction of stop words, comparing 4 datasets from written and translated reviews. Using statistical variations of the successful technique `term ranking', we evaluate their performance using a common list of stop words. Results suggest that variation, TFnormIDFnorm, was the most successful with a best performing precision rate of 46.7% and a recall rate of 86.6%. The best results were seen in the largest dataset using written reviews, however comparison of the remaining 3 datasets revealed that spoken text performed 0.4% better in precision than the next best dataset and 2.6% better in recall. Initial results show marginally better performance in machine speech recognition transcribed texts from videos in comparison to comparably size datasets of written reviews.",2019,J. Frattini; M. Junker; M. Unterkalmsteiner; D. Mendez,301,308,8,,10.1109/DeSE.2019.00063,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073508,IEEE Conferences,IEEE
A Tool for Translating Sequential Source Code to Parallel Code Written in C++ and OpenACC,Sequential Code Translation;Parallel code;OpenACC;C++;Automatic code translation,"In this paper, we introduce a translation tool that translates any sequential C++ source code into parallel source code written in C++ and OpenACC programming model. The tool generates different types of dependency graphs: class, method, loop, and block-of-statements graphs. The class and method dependency graphs are created for the sequential code, and the loop and block-of-statements dependency graphs are created for each method. From the class dependency graph, the dependency analyser identifies the independent classes, where the objects of the independent classes can run in parallel, and from the method dependency graph, the method analyser detects the methods that can run in parallel. For each block, the analyser detects the statements that run in parallel, where there is no data dependency between statements, and the loop analyser detects the type of parallelism in the loop-block: parallel statements, pipeline, or data partitions.",2019,J. Zhang; Y. Wu,1,8,8,,10.1109/AICCSA47632.2019.9035292,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035292,IEEE Conferences,IEEE
Using translational score maps to aid MT evaluation,Machine Translation;evaluative systems;Meteor;Bleu,"Compared with human evaluators, machine translation (MT) evaluation tools have demonstrated that they are faster, cheaper, and more consistent in scoring the correctness of translated text. The metrics they generate can adequately compare MT-generated translations to a gold standard, but they fail to address the challenge of choosing the most appropriate path through intermediate languages in a multi-stage translation; in other words, they do not take MT transitivity into account. We propose a novel approach called translational score maps to extend the power of these evaluation tools. The purpose of a translational score map is to assess and choose the most appropriate path through a given set of languages. Using our method in multi-stage translations makes a significant improvement in translation quality.",2011,J. Zhao; H. Guo; Z. Zheng; N. Jiang,15,22,8,,10.1109/NLPKE.2011.6138163,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138163,IEEE Conferences,IEEE
Generating Predicate Logic Expressions from Natural Language,machine learning;neural machine translation;NLP;predicate logic,"Formal logic expressions are commonly written in standardized mathematical notation. Learning this notation typically requires many years of experience and is not an explicit part of undergraduate academic curricula. Constructing and comprehending logical predicates can feel difficult and unintuitive. We hypothesized that this process can be automated using neural machine translation. Most machine translation techniques involve word-based segmentation as a preprocessing step. Given the nature of our custom dataset, hosts first-order-logic (FOL) semantics primarily in unigram tokens, the word-based approach does not seem applicable. The proposed solution was to automate the translation of short English sentences into FOL expressions using character-level prediction in a recurrent neural network model. We trained four encoder-decoder models (LSTM, Bidirectional GRU with Attention, and two variants of Bi-directional LSTM with Attention). Our experimental results showed that several established neural translation techniques can be implemented to produce highly accurate machine translators of English sentences to FOL formalisms, given only characters as markers of semantics. We also demonstrated that attention-based enhancement to the encoder-decoder architecture can vastly improve translation accuracy. Most machine translation techniques involve word-based segmentation as a preprocessing step. Given the nature of our custom dataset, hosts first-order-logic (FOL) semantics primarily in unigram tokens, the word-based approach does not seem applicable. The proposed solution was to automate the translation of short English sentences into FOL expressions using character-level prediction in a recurrent neural network model. We trained four encoder-decoder models (LSTM, Bidirectional GRU with Attention, and two variants of Bi-directional LSTM with Attention). Our experimental results showed that several established neural translation techniques can be implemented to produce highly accurate machine translators of English sentences to FOL formalisms, given only characters as markers of semantics. We also demonstrated that attention-based enhancement to the encoder-decoder architecture can vastly improve translation accuracy. We trained four encoder-decoder models (LSTM, Bidirectional GRU with Attention, and two variants of Bi-directional LSTM with Attention). Our experimental results showed that several established neural translation techniques can be implemented to produce highly accurate machine translators of English sentences to FOL formalisms, given only characters as markers of semantics. We also demonstrated that attention-based enhancement to the encoder-decoder architecture can vastly improve translation accuracy.",2021,K. G. Hartmann; R. T. Schirrmeister; T. Ball,1,8,8,,10.1109/SoutheastCon45413.2021.9401852,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401852,IEEE Conferences,IEEE
Back-Translation-Style Data Augmentation for end-to-end ASR,automatic speech recognition;end-to-end;data augmentation;back-translation,"In this paper we propose a novel data augmentation method for attention-based end-to-end automatic speech recognition (E2E-ASR), utilizing a large amount of text which is not paired with speech signals. Inspired by the back-translation technique proposed in the field of machine translation, we build a neural text-to-encoder model which predicts a sequence of hidden states extracted by a pre-trained E2E-ASR encoder from a sequence of characters. By using hidden states as a target instead of acoustic features, it is possible to achieve faster attention learning and reduce computational cost, thanks to sub-sampling in E2E-ASR encoder, also the use of the hidden states can avoid to model speaker dependencies unlike acoustic features. After training, the text-to-encoder model generates the hidden states from a large amount of unpaired text, then E2E-ASR decoder is retrained using the generated hidden states as additional training data. Experimental evaluation using LibriSpeech dataset demonstrates that our proposed method achieves improvement of ASR performance and reduces the number of unknown words without the need for paired data.",2018,K. Jiang; X. Lu,426,433,8,18,10.1109/SLT.2018.8639619,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639619,IEEE Conferences,IEEE
Relating the Semantics of Dialogue Acts to Linguistic Properties: A Machine Learning Perspective through Lexical Cues,dialogue act;Switchboard corpus;SWBD-DAMSL;automatic classification;ISO dialogue annotation standard,"This paper describes a corpus-based investigation of dialogue acts. In particular, it attempts to answer questions about the empirical distribution of dialogue acts and to what extent dialogue acts can be automatically predicted from their lexical features. The Switchboard Dialogue Act Corpus is adopted and the SWBD-DAMSL tags used for automatic prediction. We show that 60-70% of the dialogue acts can be predicted from lexical features alone depending on different levels of granularity. We also present a mapping from SWBD-DAMSL tags to the tags of the new ISO standard for dialogue act annotation, as part of an ongoing investigation into the relationship between the structure and granularity of the tag set and classification accuracy. The paper concludes with discussions and suggestions for future work.",2011,K. Macherey; O. Bender; H. Ney,490,497,8,2,10.1109/ICSC.2011.32,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6061505,IEEE Conferences,IEEE
Learning Better Classification-Based Reordering Model for Phrase-Based Translation,statistical machine translation;word reordering;log linear model;feature selection,"Reordering is of a challenging issue in phrase-based statistical machine translation systems. This paper proposed three techniques to optimize classification-based reordering models for phrase-based translation under the bracket transduction grammar framework. First, a forced decoding technique is adopted to learn reordering samples for maximum entropy model training. Secondly, additional features are learned from the context of two consecutive phrases to enhance the prediction ability of the reordering classifier. Thirdly, the reordering model score is integrated as two feature functions (STRAIGHT and INVERTED) into the log-linear model to improve its discriminative ability. Experimental result demonstrates significant improvements over the baseline in two translation tasks such as Chinese to English and Chinese to Japanese translation.",2017,M. A. Hasan; F. Alam; S. A. Chowdhury; N. Khan,190,197,8,,10.1109/ICCNEA.2017.82,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128556,IEEE Conferences,IEEE
Self-Attention and Dynamic Convolution Hybrid Model for Neural Machine Translation,NMT;seq2seq;self-attention;convolution,"In sequence-to-sequence learning, models based on the self-attention mechanism dominate the network structures used for neural machine translation. Recently, convolutional networks have been demonstrated to perform excellently on various translation tasks. Despite the fact that self-attention and convolution have different strengths in modeling sequences, few efforts have been devoted to combining them. In this work, we propose a hybrid model that benefits from both mechanisms. We combine a self-attention module and a dynamic convolution module by taking a weighted sum of their outputs where the weights can be dynamically learned by the model during training. Experimental results show that our hybrid model outperforms baseline models built solely on either of these two mechanisms. And we produce new state-of-the-art results on IWSLT'15 English-German dataset.",2020,M. Akter; M. Shahidur Rahman; M. Zafar Iqbal; M. Reza Selim,352,359,8,,10.1109/ICBK50248.2020.00057,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194516,IEEE Conferences,IEEE
Applying PSO to natural language processing tasks: Optimizing the identification of syntactic phrases,parsing of natural language;machine translation;syntactically-derived phrasing;particle swarm optimization;parameter optimization,"The present article discusses the use of Particle Swarm Optimisation (PSO) in a natural language processing task, namely the creation of a phrasing model which splits any sentence into linguistically-motivated phrases. This involves taking a limited-size training dataset, where sentences are split into syntactically motivated sentences, and learning how to best segment arbitrary sentences into their corresponding phrases. The extrapolation of phrases is needed in numerous applications involving the generation of texts in natural language. One such application is machine translation, namely the automatic translation of unconstrained text from a source language to a target language. The phrasing model to be learnt comprises a number of parameters which need to be optimized based on the training data. To that end, a machine learning approach has been developed, which is based on the concept of attractive and repulsive forces. Instead of previous efforts using manual tuning of the parameters, here PSO is used to achieve the optimization of the model parameters. Experimental results indicate that the proposed PSO approach is promising, giving the most accurate phrasing in this specific application, with statistically significant improvements over earlier results.",2016,M. Chen; R. Luo,1831,1838,8,4,10.1109/CEC.2016.7744011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744011,IEEE Conferences,IEEE
Comparative analysis of SMT and DSA on Tagalog corpus,Tagalog;Statistical Machine Translation;Dictionary Substitution Approach;machine translation;Non-Standard Words,"Text is the fundamental element in document classification in many natural language applications. Filipinos are fond of using social networking sites. With the rapid increase in the usage of social networking sites such as Twitter and blogs, there is also an increase in the use of casual language which often does not conform to the rules of spelling, structure and grammar of the specific language of the Filipinos, Tagalog. In this study, those shortened words or Non-Standard Words (NSW) were normalized in order to be easily understand by its readers. In this paper, we discussed the effectiveness of Dictionary Substitution Approach (DSA) and Statistical Machine Translation (SMT) on Tagalog Corpus. The way these machine translations treat the corpus are tackled. The final goal is to determine which machine translation is better. Results identified in this study that DSA and SMT both have advantages and disadvantages.",2017,M. Davydov; O. Lozynska,1,8,8,,10.1109/HNICEM.2017.8269491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269491,IEEE Conferences,IEEE
Toward End-to-End Neural Cascading Strategies for Grammatical Error Correction,Grammatical Error Correction;Neural Machine Translation;Machine Translation;Natural Language Processing,"Neural sequence-to-sequence (seq2seq) grammatical error correction (GEC) models are usually computationally expensive both in training and in translation inference. Also, they tend to suffer from poor generalization and arrive at inept capabilities due to limited error-corrected data, and thus, incapable of effectively correcting grammar. In this work, we propose the use of neural cascading strategies in enhancing the effectiveness of neural sequence-to-sequence grammatical error correction models as inspired by post-editing processes of neural machine translations. The findings of our experiments show that adapting cascading techniques in low resource NMT models unleashes performances that is comparable to high setting NMT models. We extensively exploit and evaluate multiple cascading learning strategies and establish best practices toward improving neural seq2seq GECs.",2019,M. H. Nur Fauzan; E. Rakun; D. Hardianto,1265,1272,8,,10.1109/ISKE47853.2019.9170364,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170364,IEEE Conferences,IEEE
Adjacent reordering phrase-based translation models,Adjacent reordering;decoding algorithm;phrase;machine translation,"We study a number of statistical phrase-based translation models that are constrained by adjacent reordering. Under this constraint, we derive polynomial decoding algorithms respectively for basic and Koehn's phrase-based models, with an implication that many statistical phrase-based models may also be decodable in polynomial time. Using NIST as a metric, we show that the presented decoding algorithms can achieve a relative improvement of about 2.7% over Pharaoh under the same experimental conditions.",2010,M. Kasthuri; S. B. R. Kumar,1,8,8,,10.1109/NLPKE.2010.5587795,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587795,IEEE Conferences,IEEE
A Fast Decoder Using Less Memory,statistical machine translation;decoding algorithm;improve decoding;mobile application;embedded system,"Statistical Machine Translation (SMT) uses large amount of text corpus and complex calculation operation for translation process, which makes this method require more system resources for fast translation. In this paper, we introduce an approach of decoding in SMT using less memory but translating faster, which is more suitable for mobile applications and embedded systems. In our approach, the SMT models are stored in tree structures in order to speed up the loading process and the decoding algorithm is optimized to reduce operations. We apply our approach to English-Vietnamese and Vietnamese-English SMT systems. When translating 20,000 English sentences, which are 7.45 word lengths in average, we achieve 37.8 BLEU score, the average speed is 0.052 s. In case of Vietnamese-English system, we translate 20,000 Vietnamese sentences, which are 8.42 word lengths in average, the BLEU score is 34.63 with an average speed of 0.091 s.",2012,M. M. Hasan; H. Kurata,173,180,8,,10.1109/KSE.2012.11,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299416,IEEE Conferences,IEEE
Sign Language to Speech Translation,Indian Sign Language;real-time;gesture recognition;neural networks;machine learning;text-to-speech algorithms,"Although a certain fraction of the world suffers from speech and hearing disabilities, sign language is not a widespread language across the world. In today's oral world, a gesture-based language is not particularly popular with the general masses. However, sign language itself is a fully developed language with multiple regional dialects across the globe. Therefore, to aid with a smoother communication between the speaking and non-speaking world, technical developments can be introduced. A considerable amount of work has been done in this direction. The basic need of the hour is for an application that can function in real-time and can facilitate real-time conversations between a person who can sign in sign language and one that cannot. This paper proposes an application that works on this problem statement. In order to construct such an application designed to respond in real-time and aid a live conversation between a speaking and nonspeaking individual, it is necessary to allow for live video inputs to be made to the app which would then be translated to speech. This paper proposes the use of convolutional neural networks (CNN) alongside the use of Text-to-Speech translator. By use of the CNN algorithm, the gestures can be identified by the proposed application and converted to text, which can then be converted into speech.",2020,M. Macas; L. Lagla; W. Fuertes; G. Guerrero; T. Toulkeridis,1,8,8,,10.1109/ICCCNT49239.2020.9225422,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225422,IEEE Conferences,IEEE
Improving phrase-based SMT model with Flattened Bilingual Parse Tree,Statistical machine translation;formally syntax-based method;bilingual parse structure,"Phrase orders influence much on translation quality. However, general phrase based methods take only the source side information for phrase orderings. We instead propose a bilingual parse structure, Flattened Bilingual Parse Tree (FBPT), for better describing the inner structure of bilingual sentences and then for better translations. The main idea is to extract phrase pairs with orientation features under the help of FBPT structure. Such features can help maintain better sentence generations during translation. Furthermore, the FBPT structure can be learned automatically from parallel corpus with lower costs without the need of complex linguistic parsing. Evaluations on MT08 translation task indicate that 7% relative improvement on BLEU can be achieved compared to distortion based method (like Pharaoh).",2010,M. S. Arefin; M. M. Hoque; M. O. Rahman; M. S. Arefin,1,8,8,,10.1109/NLPKE.2010.5587836,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587836,IEEE Conferences,IEEE
Machine Learning Approach for Prediction of Hematic Parameters in Hemodialysis Patients,Artificial neural network;hematocrit;hemodialisys;machine learning;non-invasive;oxygen saturation;SVM;visible spectroscopy,"Objective: This paper shows the application of machine learning techniques to predict hematic parameters using blood visible spectra during ex-vivo treatments. Methods: A spectroscopic setup was prepared for acquisition of blood absorbance spectrum and tested in an operational environment. This setup is non invasive and can be applied during dialysis sessions. A support vector machine and an artificial neural network, trained with a dataset of spectra, have been implemented for the prediction of hematocrit and oxygen saturation. Results & Conclusion: Results of different machine learning algorithms are compared, showing that support vector machine is the best technique for the prediction of hematocrit and oxygen saturation.",2019,M. S. TÅ¡oeu; S. Maxaku; T. Chemvura; N. Ramchunder; Z. Mabuza,1,8,8,3,10.1109/JTEHM.2019.2938951,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839068,IEEE Journals,IEEE
Building a neural network-based English-to-Arabic transfer module from an unrestricted domain,Natural language processing;Machine Translation Transfer;Neural Networks;Bilingual Corpora;Tagging;Arabic,This paper presents a Transfer Module for an English-to-Arabic Machine Translation System (MTS) using an English-to-Arabic Bilingual Corpus. We propose an approach to build a transfer module by building a new transfer-based system for machine translation using Artificial Neural Networks (ANN). The idea is to allow the ANN-based transfer module to automatically learn correspondences between source and target language structures using a large set of English sentences and their Arabic translations. The paper presents the methodology for corpus building. It then introduces the approach that has been followed to develop the transfer module. It finally presents the experimental results which are very encouraging.,2010,N. WeiÃŸkirchen; M. V. Reddy; A. Wendemuth; I. Siegert,94,101,8,1,10.1109/ICMWI.2010.5648157,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5648157,IEEE Conferences,IEEE
Unwritten languages demand attention too! Word discovery with encoder-decoder models,Word Discovery;Computational Language Documentation;Neural Machine Translation;Attention models,"Word discovery is the task of extracting words from un-segmented text. In this paper we examine to what extent neural networks can be applied to this task in a realistic unwritten language scenario, where only small corpora and limited annotations are available. We investigate two scenarios: one with no supervision and another with limited supervision with access to the most frequent words. Obtained results show that it is possible to retrieve at least 27% of the gold standard vocabulary by training an encoder-decoder neural machine translation system with only 5,157 sentences. This result is close to those obtained with a task-specific Bayesian nonparametric model. Moreover, our approach has the advantage of generating translation alignments, which could be used to create a bilingual lexicon. As a future perspective, this approach is also well suited to work directly from speech.",2017,O. Dhariya; S. Malviya; U. S. Tiwary,458,465,8,2,10.1109/ASRU.2017.8268972,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268972,IEEE Conferences,IEEE
Towards a Modular Brain-Machine Interface for Intelligent Vehicle Systems Control â€“ A CARLA Demonstration,Assistive technology;brain-machine interface;steering control;velocity control;intelligent vehicle systems,"Objective: Individuals with paralysis often have mobility and dexterity impairments that limit their ability to operate motor vehicle controls. Integrating brain-machine interface (BMI) neurotechnology with vehicle control systems (VCS) provides a novel solution to this problem. In this proof-of-concept study, we show that an intracortical BMI developed to restore voluntary grasp can be repurposed to decode motor intention for vehicle velocity and steering control. Methods: The BMI-VCS consists of four components: 1) implanted motor cortex microelectrode array and NeuroPort data acquisition system, 2) machine learning workstation, 3) Python interface to generate control signals, and 4) vehicle control system. Results: Direct cortical steering and velocity control were achieved through accurate decoding of movement intention (supination, pronation, hand open, hand close) from the participant's motor cortex, translating intention into vehicle commands (turn right, turn left, accelerate, decelerate, respectively), and dynamically switching between commands to turn corners, start and stop, shift from forward to reverse, and parallel park. Conclusion: By translating BMI decoder outputs into high-level vehicle commands, a participant with tetraparesis from C5 ASIA A spinal cord injury successfully navigated CARLA driving simulator courses in real time. These decoder outputs could also be used offline for shared control of a scale model car. Significance: High-level, shared vehicle control with BMI-VCS offers an innovative way to return independent driving abilities to those with disability. BMI systems that can control multiple end-effectors may be particularly useful to those with paralysis.",2019,O. Scharenborg; L. Besacier; A. Black; M. Hasegawa-Johnson; F. Metze; G. Neubig; S. StÃ¼ker; P. Godard; M. MÃ¼ller; L. Ondel; S. Palaskar; P. Arthur; F. Ciannella; M. Du; E. Larsen; D. Merkx; R. Riad; L. Wang; E. Dupoux,277,284,8,,10.1109/SMC.2019.8914317,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914317,IEEE Conferences,IEEE
Multilingual Sentiment Analysis Using Latent Semantic Indexing and Machine Learning,Sentiment analysis;latent semantic analysis;machine learning;multilingual;parallel corpora,"We present a novel approach to predicting the sentiment of documents in multiple languages, without translation. The only prerequisite is a multilingual parallel corpus wherein a training sample of the documents, in a single language only, have been tagged with their overall sentiment. Latent Semantic Indexing (LSI) converts that multilingual corpus into a multilingual ``concept space''. Both training and test documents can be projected into that space, allowing cross-lingual semantic comparisons between the documents without the need for translation. Accordingly, the training documents with known sentiment are used to build a machine learning model which can, because of the multilingual nature of the document projections, be used to predict sentiment in the other languages. We explain and evaluate the accuracy of this approach. We also design and conduct experiments to investigate the extent to which topic and sentiment separately contribute to that classification accuracy, and thereby shed some initial light on the question of whether topic and sentiment can be sensibly teased apart.",2011,O. Starostenko; C. K. Cruz; A. Chavez-Aragon; R. Contreras,45,52,8,7,10.1109/ICDMW.2011.185,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6137359,IEEE Conferences,IEEE
Pensieve: a Machine Learning Assisted SSD Layer for Extending the Lifetime,Machine learning;Flash translation layer;SSD;Compression,"As the capacity per unit cost dropping, flash-based SSDs become popular in various computing scenarios. However, the restricted program-erase cycles still severely limit cost-effectiveness of flash-based storage solutions. This paper proposes Pensieve, a machine-learning assisted SSD firmware layer that transparently helps reduce the demand for programs and erases. Pensieve efficiently classifies writing data into different compression categories without hints from software systems. Data with the same category may use a shared dictionary to compress the content, allowing Pensieve to further avoid duplications. As Pensieve does not require any modification in the software stack, Pensieve is compatible with existing applications, file systems and operating systems. With modern SSD architectures, implementing a Pensieve-compliant SSD also requires no additional hardware, providing a drop-in upgrade for existing storage systems. The experimental result on our prototype Pensieve SSD shows that Pensieve can reduce the amount of program operations by 19%, while delivering competitive performance.",2018,Oliveira; Wong; Li,35,42,8,,10.1109/ICCD.2018.00016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615666,IEEE Conferences,IEEE
WERD: Using social text spelling variants for evaluating dialectal speech recognition,Automatic speech recognition;dialectal ASR;ASR evaluation;word error rate;multi-reference WER,"We study the problem of evaluating automatic speech recognition (ASR) systems that target dialectal speech input. A major challenge in this case is that the orthography of dialects is typically not standardized. From an ASR evaluation perspective, this means that there is no clear gold standard for the expected output, and several possible outputs could be considered correct according to different human annotators, which makes standard word error rate (WER) inadequate as an evaluation metric. Such a situation is typical for machine translation (MT), and thus we borrow ideas from an MT evaluation metric, namely TERp, an extension of translation error rate which is closely-related to WER. In particular, in the process of comparing a hypothesis to a reference, we make use of spelling variants for words and phrases, which we mine from Twitter in an unsupervised fashion. Our experiments with evaluating ASR output for Egyptian Arabic, and further manual analysis, show that the resulting WERd (i.e., WER for dialects) metric, a variant of TERp, is more adequate than WER for evaluating dialectal ASR.",2017,P. Bhagat; A. S. Varde; A. Feldman,141,148,8,1,10.1109/ASRU.2017.8268928,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268928,IEEE Conferences,IEEE
Designing a multilanguage blended learning system for Thai agricultural science students,application of machine translation;blended learning system;multilanguage blended learning system,"This study proposes the design of a new learning system based on Multilanguage and blended learning strategies. The multilanguage blended learning system (MBLS) is an integrated LMS technology with translation technology. The MBLS was designed for students who were restricted by an English language barrier in acquiring new knowledge. The purpose of MBLS was to assist students in improving students' learning through the use of multilanguage blended learning environment (MBLE). Freeware software which included Moodle 2.7, Google Chrome web browser, Google Dictionary Chrome 4.0.2 and Imtranslator, has been used for designing MBLS. It is expected that the MBLE may facilitate, engage, and motivate students in learning content from the English medium instruction. The MBLS can also be extended to deliver content in languages other than English.",2016,P. Kumar; K. Goel,131,138,8,1,10.1109/TALE.2016.7851783,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851783,IEEE Conferences,IEEE
TVDP: Translational Visual Data Platform for Smart Cities,"geo-tagging, visual data management, machine learning, smart city, data as infrastructure","This paper proposes a platform, dubbed ""Translational Visual Data Platform (TVDP)"", to collect, manage, analyze urban visual data which enables participating community members connected not only to enhance their individual operations but also to smartly incorporate visual data acquisition, access, analysis methods and results among them. Specifically, we focus on geo-tagged visual data since location information is essential in many smart city applications and provides a fundamental connection in managing and sharing data among collaborators. Furthermore, our study targets for an image-based machine learning platform to prepare users for the upcoming era of machine learning (ML) and artificial intelligence (AI) applications. TVDP will be used to pilot, test, and apply various visual data-intensive applications in a collaborative way. New data, methods, and extracted knowledge from one application can be effectively translated into other applications, ultimately making visual data and analysis as a smart city infrastructure. The goal is to make value creation through visual data and their analysis as broadly available as possible, thus to make social and economic problem solving more distributed and collaborative among users. This paper reports the design and implementation of TVDP in progress and partial experimental results to demonstrate its feasibility.",2019,R. G. Guendel; F. Fioranelli; A. Yarovoy,45,52,8,4,10.1109/ICDEW.2019.00-36,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750940,IEEE Conferences,IEEE
Automated Detection of Symptomatic Autonomic Dysreflexia Through Multimodal Sensing,Machine learning;physiological telemonitoring;spinal cord injuries;support vector machines;wearable computer,"Objective: Autonomic Dysreflexia (AD) is a potentially life-threatening syndrome which occurs in individuals with higher level spinal cord injuries (SCI). AD is caused by triggers which can lead to rapid escalation of pathophysiological responses and if the trigger is not removed, AD can be fatal. There is currently no objective, non-invasive and accurate monitoring system available to automatically detect the onset of AD symptoms in real time in a non-clinical setting. Technology or Method: We developed a user-independent method of symptomatic AD detection in real time with a wearable physiological telemetry system (PTS) and a machine learning model using data from eleven participants with SCI. Results: The PTS could detect onset of AD symptoms with an average accuracy of 94.10% and a false negative rate of 4.89%. Conclusions: The PTS can detect the onset of the symptoms AD with high sensitivity and specificity to assist people with SCIs in preventing the occurrence of AD. It would enable persons with high level SCIs to be more independent and pursue vocational activities while granting continuous medical oversight. Clinical Impact: The PTS could serve as a supplementary tool to current solutions to detect the onset of AD and prepare individuals who are newly injured to be better prepared for AD episodes. Moreover, it could be translated into a system to encourage individuals to practice better healthcare management to prevent future occurrences.",2020,R. M. Nayana; R. R. Rajeev; C. Naseer,1,8,8,1,10.1109/JTEHM.2019.2955947,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8963665,IEEE Journals,IEEE
Stochastic Finite Automata for the translation of DNA to protein,DNA;pattern;stochastic finite automata;machine learning;proteins;bigdata,"The use of Statistical Finite Automata (SFA) has been explored in the field of understanding the DNA sequences; many focus on local patterns, namely partial representations of DNA sequences. In this paper, we focus on global and complete representations to understand the patterns in whole DNA sequences. Obviously, DNA sequences are not random. Based on Kolmogorov complexity theory, there should be some simple Turing machines that write out such sequences; here simple means the complexity of the Turing machine is simpler than the data. The primary goal of this paper is to approximate such simple Turing machines by SFA. We use SFA, via ALERGIA algorithm (in the light granular computing), to capture and analyze the translation process (DNA to protein) based on amino acids' chemical property viz., polarity. This, in turn, enables the understanding of interspecies DNA comparisons and the creation of phylogeny - the `tree of life'.",2014,R. N. Devendrakumar; A. Praveena,1060,1067,8,2,10.1109/BigData.2014.7004340,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004340,IEEE Conferences,IEEE
New RNN Activation Technique for Deeper Networks: LSTCM Cells,Long short-term memory;language modeling;neural machine translation,"Long short-term memory (LSTM) has shown good performance when used with sequential data, but gradient vanishing or exploding problem can arise, especially when using deeper layers to solve complex problems. Thus, in this paper, we propose a new LSTM cell termed long short-time complex memory (LSTCM) that applies an activation function to the cell state instead of a hidden state for better convergence in deep layers. Moreover, we propose a sinusoidal function as an activation function for LSTM and the proposed LSTCM instead of a hyperbolic tangent activation function. The performance capabilities of the proposed LSTCM cell and the sinusoidal activation function are demonstrated through experiments on various natural language benchmark datasets, in this case the Penn Tree-bank, IWSLT 2015 English-Vietnamese, and WMT 2014 English-German datasets.",2020,R. Wang; H. Zhao; B. Lu; M. Utiyama; E. Sumita,214625,214632,8,,10.1109/ACCESS.2020.3040405,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269980,IEEE Journals,IEEE
Investigation of Anemia and the Dielectric Properties of Human Blood at Microwave Frequencies,Biological material;classification algorithms;dielectric measurements;open-ended coaxial probe;support vector machines;tissue properties,"Anemia is a condition that affects over 1.6 billion people worldwide untreated, the disease could lead to increased morbidity and mortality during pregnancy, affecting both the mother and the unborn child. This paper presents the measured dielectric properties of whole blood samples from 176 patients obtained from a hematology clinic; with 80 samples from male patients and 96 samples from female patients. Measurements were performed using a Keysight slim form probe and Keysight network analyzer to obtain the dielectric properties over a wide frequency range (500 MHz-8.5 GHz). A multiple linear regression analysis is performed to identify which components of the blood show the highest correlation with changes in the dielectric properties. Hemoglobin (Hgb) is shown to be the biggest predictor of changes in complex permittivity, demonstrating that permittivity measurements at a single frequency can potentially be used to detect anemia. A support vector machines algorithm is trained and tested to classify between blood samples from healthy patients and blood samples from patients with anemia. The classifier is optimized using a Bayesian-optimization approach during 10-fold cross-validation and then the average performance of the final trained classifier is evaluated through 10-fold testing on unseen data sets. Using a clinical definition of anemia defined as patients having a concentration of Hgb <; 12.0g/dL, the trained classifier has an average sensitivity of 96.89% and specificity of 94.56%. These results demonstrate the potential for a low-cost resonant microwave device to be used to accurately detect the onset of anemia.",2018,R. Zhao; H. Zhang; J. Lu; C. Li; H. Zhang,56885,56892,8,4,10.1109/ACCESS.2018.2873447,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478784,IEEE Journals,IEEE
Automated Machine Learning for Short-term Electric Load Forecasting,machine learning;automated machine learning;short-term load forecasting;energy management,"From detecting skin cancer to translating languages and to forecasting electricity consumption, machine learning is enabling advanced capabilities of computer systems across a broad range of important real-world applications. In this work, we present machine learning models for forecasting the consumption of electricity. Short-term electric load forecasting has been a fundamental concern in power operation systems for over a century. Energy load forecasting is of even greater importance, due to applications in the planning of demand side management, smart electric vehicles and other smart grid technologies. We use two state-of-the-art automated machine learning systems (auto-sklearn and TPOT), which automate model selection and hyperparameter optimization, to achieve maximum prediction accuracy, and compare their performance for the task of load prediction using two benchmark problems. These benchmarks are derived from real world load consumption tasks, namely household consumption from the UCI data repository and consumption data from an industrial office building. Our experimental results indicate great potential for improving the accuracy of energy consumption prediction by using automated machine learning approaches.",2019,Rajpirathap S; Sheeyam S; Umasuthan K; A. Chelvarajah,314,321,8,1,10.1109/SSCI44817.2019.9002839,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9002839,IEEE Conferences,IEEE
Robust Sparse Representation and Multiclass Support Matrix Machines for the Classification of Motor Imagery EEG Signals,Brain-computer interfaces;Electroencephalography (EEG);Principal component Analysis (PCA);Brain disorder,"Background: EEG signals are extremely complex in comparison to other biomedical signals, thus require an efficient feature selection as well as classification approach. Traditional feature extraction and classification methods require to reshape the data into vectors that results in losing the structural information exist in the original featured matrix. Aim: The aim of this work is to design an efficient approach for robust feature extraction and classification for the classification of EEG signals. Method: In order to extract robust feature matrix and reduce the dimensionality of from original epileptic EEG data, in this paper, we have applied robust joint sparse PCA (RJSPCA), Outliers Robust PCA (ORPCA) and compare their performance with different matrix base feature extraction methods, followed by classification through support matrix machine. The combination of joint sparse PCA with robust support matrix machine showed good generalization performance for classification of EEG data due to their convex optimization. Results: A comprehensive experimental study on the publicly available EEG datasets is carried out to validate the robustness of the proposed approach against outliers. Conclusion: The experiment results, supported by the theoretical analysis and statistical test, show the effectiveness of the proposed framework for solving classification of EEG signals.",2019,S. Ando; M. Suzuki; N. Itoh; G. Kurata; N. Minematsu,1,8,8,2,10.1109/JTEHM.2019.2942017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854827,IEEE Journals,IEEE
High Precision Digitization of Paper-Based ECG Records: A Step Toward Machine Learning,Electrocardiogram;digitization;Matlab tool;image processing,"Introduction: The electrocardiogram (ECG) plays an important role in the diagnosis of heart diseases. However, most patterns of diseases are based on old datasets and stepwise algorithms that provide limited accuracy. Improving diagnostic accuracy of the ECG can be done by applying machine learning algorithms. This requires taking existing scanned or printed ECGs of old cohorts and transforming the ECG signal to the raw digital (time (milliseconds), voltage (millivolts)) form. Objectives: We present a MATLAB-based tool and algorithm that converts a printed or scanned format of the ECG into a digitized ECG signal. Methods: 30 ECG scanned curves are utilized in our study. An image processing method is first implemented for detecting the ECG regions of interest and extracting the ECG signals. It is followed by serial steps that digitize and validate the results. Results: The validation demonstrates very high correlation values of several standard ECG parameters: PR interval 0.984 +/-0.021 (p-value <; 0.001), QRS interval 1+/- SD (p-value <; 0.001), QT interval 0.981 +/- 0.023 p-value <; 0.001, and RR interval 1 +/- 0.001 p-value <; 0.001. Conclusion: Digitized ECG signals from existing paper or scanned ECGs can be obtained with more than 95% of precision. This makes it possible to utilize historic ECG signals in machine learning algorithms to identify patterns of heart diseases and aid in the diagnostic and prognostic evaluation of patients with cardiovascular disease.",2019,S. Assem; S. Aida,1,8,8,1,10.1109/JTEHM.2019.2949784,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894038,IEEE Journals,IEEE
Punctuated transcription of multi-genre broadcasts using acoustic and lexical approaches,punctuation;speech recognition;neural machine translation;rich transcription,"In this paper we investigate the punctuated transcription of multi-genre broadcast media. We examine four systems, three of which are based on lexical features, the fourth of which uses acoustic features by integrating punctuation into the speech recognition acoustic models. We also explore the combination of these component systems using voting and log-linear interpolation. We performed experiments on the English language MGB Challenge data, which comprises about 1,600h of BBC television recordings. Our results indicate that a lexical system, based on a neural machine translation approach is significantly better than other systems achieving an F-Measure of 62.6% on reference text, with a relative degradation of 19% on ASR output. Our analysis of the results in terms of specific punctuation indicated that using longer context improves the prediction of question marks and acoustic information improves prediction of exclamation marks. Finally, we show that even though the systems are complementary, their straightforward combination does not yield better F-measures than a single system using neural machine translation.",2016,S. Berrichi; A. Mazroui,433,440,8,6,10.1109/SLT.2016.7846300,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846300,IEEE Conferences,IEEE
SSA: A More Humanized Automatic Evaluation Method for Open Dialogue Generation,generative dialogue;semantic coherence;syntactic validity;evaluation;neural networks,"Dialogue generation has been gaining ever-increasing attention, and various models have been proposed and adopted in many fields in recent years. How to evaluate their performance is critical. However, current evaluation metrics tend to be insufficient because of their simplicity and crudeness, resulting in weak correlation with human judgements. To solve this issue, we propose an automatic and comprehensive evaluation metric, which consists of three assessment criteria: Semantic Coherence, Syntactic Validity and Ability of Expression (SSA). The first two criteria are used to evaluate the generations from semantic and syntactic aspects respectively at the sentence level and the last one is to evaluate the overall performance at the model level. With two generative models, we conduct experiments on three datasets, including Twitter, Subtitle and Lenovo. Comparing with the previous metrics such as BLEU, METEOR and ROUGE, the correlation coefficient between SSA and human judgements is increased by 0.23-0.35, i.e. 324%-864% relative improvements. The experimental results demonstrate that SSA correlates more strongly with human judgements on the evaluation for open dialogue generation. Additionally, SSA is able to evaluate the semantic coherence and syntactic validity of generations exactly. More importantly, the evaluation models can be trained without human annotations. Thus, SSA is flexible and extensible to different datasets.",2019,S. Chaudhury; A. Rao; D. M. Sharma,1,8,8,,10.1109/IJCNN.2019.8851960,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851960,IEEE Conferences,IEEE
Can We Identify NAT Behavior by Analyzing Traffic Flows?,Network address translation classification;traffic flows;traffic analysis;machine learning,"It is shown in the literature that network address translation devices have become a convenient way to hide the source of malicious behaviors. In this research, we explore how far we can push a machine learning (ML) approach to identify such behaviors using only network flows. We evaluate our proposed approach on different traffic data sets against passive fingerprinting approaches and show that the performance of a machine learning approach is very promising even without using any payload (application layer) information.",2014,S. K. Dwivedi; P. P. Sukhadeve,132,139,8,11,10.1109/SPW.2014.28,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957296,IEEE Conferences,IEEE
A New Automatic Method for Control Chart Patterns Recognition Based on ConvNet and Harris Hawks Meta Heuristic Optimization Algorithm,Artificial intelligence;automation;neural network;optimization;pattern recognition,"The productions quality has become one of the essential issues in the modern manufacturing industry and several techniques have introduced for control and monitoring the production process. Control charts are the most practical and popular tools for continuously monitoring and, if required, make adjustments to the product or process. A new automatic method based on deep learning and optimization algorithms for nine control chart patterns (CCPs) recognition are proposed in this paper. This method has two principal parts: the classification part and the tuning part. In the last few years, a convolutional neural network (ConvNet) has led to an excellent performance on various tasks, like image processing, speech recognition, and signal processing. Therefore, in the classification part, ConvNet is used as the intelligent classifier for CCPs recognition. One significant difficulty of ConvNet is that it requires considerable proficiency to select suitable parameters like a number of kernels and their spatial sizes, learning rate, etc. The ConvNet parameters have domestic dependencies which make the tuning of these parameters a challenging task. According to these issues, in the tuning part of the proposed method, the Harris hawks optimization (HHO) algorithm is used for optimal tuning of ConvNet parameters. Contrasting the common CCPs recognition methods, the proposed method takes unprocessed data and passes to more than one hidden layer for extracting the optimal feature representation instead of relying on any feature engineering mechanisms. The quantitative and simulation results show the superiority of the proposed method over the previous techniques in terms of its performance.",2019,S. Khadivi; H. Ney,149398,149405,8,11,10.1109/ACCESS.2019.2945596,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859191,IEEE Journals,IEEE
Robust facial 2D motion model estimation for 3D head pose extraction and automatic camera mouse implementation,Camera mouse;3D head pose estimation;mouse pointer control;visual tracking module,"In this paper, we present a novel approach to 3D head pose estimation from monocular camera images for the control of mouse pointer movements on the screen and clicking events. This work is motivated by the goal of providing a non-contact instrument to control the mouse pointer on a PC system for handicapped people with severe disabilities using low-cost and widely available hardware. The required information is derived from video data captured using a monocular web camera mounted on the computer monitor. Our approach proceeds in six stages. First, the face area is extracted using Haar-like features and AdaBoost algorithm. Second, the locations of the point features are detected and tracked over video frames by LK algorithm. Third, the 2D transformation model between consecutive frames is estimated by matching features and robust RANSAC algorithm. Fourth, the estimated 2D transformation model is applied to four supposed points on the face area. Then, the 3D rotation matrix and translation vector between the web camera and 3D head pose are estimated using four points correspondences. Finally, the 3D rotation and translation matrix is applied for estimating the mouse pointer movements on the PC screen and clicking events. Experimental results showed the promise of the algorithm.",2010,S. M. Shovan; M. A. M. Hasan,817,824,8,2,10.1109/ISTEL.2010.5734135,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734135,IEEE Conferences,IEEE
Ensemble Machine Methods for DNA Binding,machine learning;ensembles;bioinformatics;transcription factor;DNA,"We introduce three ensemble machine learning methods for analysis of biological DNA binding by transcription factors (TFs). The goal is to identify both TF target genes and their binding motifs. Subspace-valued weak learners (formed from an ensemble of different motif finding algorithms) combine candidate motifs as probability weight matrices (PWM), which are then translated into subspaces of a DNA k-mer (string) feature space. Assessing and then integrating highly informative subspaces by machine methods gives more reliable target classification and motif prediction. We compare these target identification methods with probability weight matrix (PWM) rescanning and use of support vector machines on the full k-mer space of the yeast S. cerevisiae. This method, SVMotif-PWM, can significantly improve accuracy in computational identification of TF targets. The software is publicly available at http://cagt10.bu.edu/SVMotif .",2008,S. Pudaruth; U. Singh; H. Ramnial,709,716,8,1,10.1109/ICMLA.2008.114,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4725053,IEEE Conferences,IEEE
"Comparing ANN, SVM, and HMM based Machine Learning Methods for American Sign Language Recognition using Wearable Motion Sensors",machine learning;sign language recognition;human computer interaction;artificial neural networks;wearable technology,"Millions of people with speech and hearing impairments, worldwide, communicate through sign languages every day. In the same way that voice recognition provides a simple communication platform for most users, gesture recognition is a natural means of correspondence for the hearing-impaired. In this paper, we explore the problem of translating/converting sign language to speech, and propose an improved solution using different machine learning techniques. We seek to build a system that can be employed in the daily lives of people with hearing impairments, in order to enhance communication and collaboration between the hearing-impaired community and those untrained in American Sign Language (ASL). The system architecture is based on using wearable motion sensors and machine learning techniques. In this study, we propose a solution using Artificial Neural Networks (ANN) and Support Vector Machines (SVM), and compare their accuracy with the Hidden Markov Model (HMM) results from our previous work to recognize ASL words. Experimental results show that using ANN gives an overall higher accuracy in recognizing ASL words, compared to other machine learning techniques.",2019,S. Raju; V. Jagtap; P. Kulkarni; M. Ravikanth; M. Rafeeq,290,297,8,4,10.1109/CCWC.2019.8666491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666491,IEEE Conferences,IEEE
Evaluation of some English-Hindi MT systems,MT Evaluation;Automatic Evaluation;Human Evaluation,"MT evaluation is a very important activity in MT system development. Evaluation of MT systems can help MT developers in understanding the short-comings of their systems and clear focus on the problem areas, so that systems performance can increase. In this paper we have discussed evaluation of some English-Hindi MT engines. For this, we have applied human as well as automatic evaluations of these systems. Automatic evaluation metrics across linguistic levels have been used to perform this study.",2014,S. Vuotto; M. Narizzano; L. Pulina; A. Tacchella,1751,1758,8,3,10.1109/ICACCI.2014.6968570,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968570,IEEE Conferences,IEEE
WordPrep: Word-based Preposition Prediction Tool,Big Data and Big Knowledge;ESL Learners;Intelligent Tutoring Systems;Machine Learning;Natural Language Processing;Pedagogical Tools;Text Mining;Writing Aids,"As big data heads towards big knowledge, data management and machine learning techniques work together to address several interesting problems. In this paper, we address a problem in natural language processing that involves learning by mining from large text databases. More specifically, we deal with the problem of preposition prediction, especially for ESL (English as a second language) learners. Prepositions are function words that typically show a relationship between a noun or a pronoun and other elements of a sentence. They play a key role in determining the meaning of a sentence. Accurate prediction of correct prepositions in a sentence is a challenging job since preposition usage is one of the most subtle aspects of the English grammar, making it difficult for non-native speakers. This paper proposes an approach for preposition prediction called WordPrep based on which we build a tool. WordPrep relies on mining based on the words themselves rather than on their lexical or syntactic connotations. This addresses the challenges of prepositions appearing in idiomatic phrases or in different semantic contexts, due to which the actual words are better than their grammatical positions. Our proposed solution entails a direct data-driven approach to predict the missing preposition in a sentence by learning from matching tokens consisting of ngrams with words before and after the preposition. Using various searches and pattern-matching methods against a large number of database records from big text corpora, this approach predicts the missing preposition(s). We describe our pilot approach, tool implementation and experiments in this paper. This work is particularly helpful for pedagogical applications.",2019,T. Kamruzzaman,2169,2176,8,,10.1109/BigData47090.2019.9005608,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005608,IEEE Conferences,IEEE
Explainable data-driven modeling of patient satisfaction survey data,explainable machine learning;data mining;lazy lasso;patient satisfaction;healthcare management,"In the personalized patient-centered healthcare, self-reported patient satisfaction survey data plays an important role. Given the patient survey data, it is necessary to identify the drivers of patient satisfaction and explain them so that such patterns can be used in future as well as necessary corrective actions can be taken. In healthcare, both accuracy and interpretability are important criteria for choosing a reliable predictive model for analyzing patient data. Usually, complex models such as Random Forest, neural networks can achieve high prediction accuracy but lack necessary interpretation to their prediction results. In this paper, we address this problem by proposing a local explanation method to interpret complex model prediction results. First, we build a predictive model using Random Forest to fit the patient satisfaction data. Second, we utilize local explanation method to provide insights into the Random Forest prediction results so as to discover true reasons behind patient experiences and overall ratings. Specifically, our approach allows us to interpret patient's overall rating of a hospital at the individual level, and find out the set of the most influential factors for each patient. We focus on all unhappy patients to investigate the top reasons for patient dissatisfaction. Our approach and findings will help to establish guidelines for a quality healthcare.",2017,T. Mantoro; J. Asian; R. Octavian; M. A. Ayu,3869,3876,8,1,10.1109/BigData.2017.8258391,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258391,IEEE Conferences,IEEE
Finding Answers from the Word of God: Domain Adaptation for Neural Networks in Biblical Question Answering,Machine Learning;The Bible;Natural Language Processing;Question Answering,"Question answering (QA) has significantly benefitted from deep learning techniques in recent years. However, domain-specific QA remains a challenge due to the significant amount of data required to train a neural network. This paper studies the answer sentence selection task in the Bible domain and answer questions by selecting relevant verses from the Bible. For this purpose, we create a new dataset BibleQA based on bible trivia questions and propose three neural network models for our task. We pre-train our models on a large-scale QA dataset, SQuAD, and investigate the effect of transferring weights on model accuracy. Furthermore, we also measured the model accuracies with different answer context lengths and different Bible translations. We affirm that transfer learning has a noticeable improvement in the model accuracy. We achieved relatively good results with shorter context lengths, whereas longer context lengths decreased model accuracy. We also find that using a more modern Bible translation in the dataset has a positive effect on the task.",2018,T. Nomura; T. Akiba,1,8,8,4,10.1109/IJCNN.2018.8489756,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489756,IEEE Conferences,IEEE
Espresso: A Fast End-to-End Neural Speech Recognition Toolkit,automatic speech recognition;end-to-end;parallel decoding;language model fusion,"We present Espresso, an open-source, modular, extensible end-to-end neural automatic speech recognition (ASR) toolkit based on the deep learning library PyTorch and the popular neural machine translation toolkit FAIRSEQ. ESRESSO supports distributed training across GPUs and computing nodes, and features various decoding approaches commonly employed in ASR, including look-ahead word-based language model fusion, for which a fast, parallelized decoder is implemented. Espresso achieves state-of-the-art ASR performance on the WSJ, LibriSpeech, and Switchboard data sets among other end-to-end systems without data augmentation, and is 4-11x faster for decoding than similar systems (e.g. ESPNET).",2019,T. P. Nagarhalli; V. Vaze; N. K. Rana,136,143,8,5,10.1109/ASRU46091.2019.9003968,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003968,IEEE Conferences,IEEE
Automatic Network Protocol Automaton Extraction,protocol reverse engineering;automaton inference;regular expression;Protocol analysis,"Protocol reverse engineering, the process of (re)constructing the protocol context of communication sessions by an implementation, which involves translating a sequence of packets into protocol messages, grouping them into sessions, and modeling state transitions in the protocol state machine, is well-known to be invaluable for many network security applications, including intrusion prevention and detection, traffic normalization, and penetration testing, etc. However, current practice in deriving protocol specifications is either mostly manual or focusing on automatic reverse engineering the message format only and leaving the protocol state machine inverse undone. Although regular expressions offer superior expressive ability and flexibility, application protocols are described by regular expression manually based on sufficiently understanding protocol itself. At present there is not an effect method to realize classification, recognition and control automatically for the known applications and the unknown applications in future. In this paper a novel approach is presented to model network application specification. In this work, the whole automatic protocol reverse engineering is realized through accomplishing the protocol state machine, and then the FSMs are translated to corresponding regular expressions to enrich and update the pattern database. This approach uses grammatical inference and is motivated by the observation that an implementation of the protocol is inherently a state transition process, the state machine model the essence exactly. The important significance is to describe various state protocols with a common method through modeling the protocol state transition, including known and unknown ones. This approach had been implemented in the system and evaluated using real-world implementations of three different protocols: HTTP, SMTP, FTP, and compared the extracted protocol to the corresponding other newly system, such as 17-filter.",2009,T. Stefan-Adrian; M. Doru-Petru,336,343,8,8,10.1109/NSS.2009.71,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319072,IEEE Conferences,IEEE
Analysis of Punctuation Prediction Models for Automated Transcript Generation in MOOC Videos,Punctuation Prediction;Machine Translation;MOOC Videos;Deep Learning;Convolution Neural Networks;Long Short Term Memory,"In today's e-learning based educational scenarios, lot of efforts in terms of time and manpower are required by the MOOC instructors for the generation of transcripts. This research study is focused on the efficient and correct punctuation prediction in the process of automated generation of these transcripts. Various deep learning based and other commonly used punctuation prediction techniques and models existing in the literature have been identified and analyzed for the educational domain videos. The hybrid model of Convolution Neural Networks and Bidirectional Long Short Term Memory ensembled with the acoustic model outperformed other models. It yielded an accuracy of 93.56 percent, recall of 56.15 percent and precision of 63.69 percent. This study also proposed a generalized architecture for efficient punctuation prediction.",2018,T. Wiatowski; H. BÃ¶lcskei,19,26,8,,10.1109/MITE.2018.8747063,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747063,IEEE Conferences,IEEE
Naturalistic Programming: Model and Implementation,Automatic Source Code Generation;Controlled Natural English;Expressiveness;Naturalistic Programming,"Naturalistic programming is defined as a programming technique that uses abstractions whose expressiveness is close to natural languages. The objective is preserving as much as possible the needs of the client in their language, while the text of these needs is simultaneously the requirements specification and the program source code. Consequently, the goal of the naturalistic paradigm is reducing the gap between problem domain and solution domain. In the literature, two main approaches are reported, one focuses on transforming controlled natural languages into high level code, such as Java and Python; in the other approach the requirements description is at the same time the program source code. While the translators employed in the first approach do not offer a new paradigm, the few naturalistic languages reported have utility in specific domains. In the absence of a naturalistic framework, this article presents the minimum elements for defining a naturalistic model that allows the creation of general-purpose languages and at the same time, the SN language is introduced as a proof-of-concept, which is a prototype language for naturalistic programming.",2020,Taihao Li; Fuji Ren,1230,1237,8,,10.1109/TLA.2020.9099764,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099764,IEEE Journals,IEEE
Hand Gesture Controlled Drones: An Open Source Library,drone;machine vision;image processing;machine learning,"Drones are conventionally controlled using joysticks, remote controllers, mobile applications, and embedded computers. A few significant issues with these approaches are that drone control is limited by the range of electromagnetic radiation and susceptible to interference noise. In this study we propose the use of hand gestures as a method to control drones. We investigate the use of computer vision methods to develop an intuitive way of agent-less communication between a drone and its operator. Computer vision-based methods rely on the ability of a drone's camera to capture surrounding images and use pattern recognition to translate images to meaningful and/or actionable information. The proposed framework involves a few key parts toward an ultimate action to be taken. They are: image segregation from the video streams of front camera, creating a robust and reliable image recognition based on segregated images, and finally conversion of classified gestures into actionable drone movement, such as takeoff, landing, hovering and so forth. A set of five gestures are studied in this work. Haar feature-based AdaBoost classifier[1] is employed for gesture recognition. We also envisage safety of the operator and drone's action calculating the distance based on computer vision for this task. A series of experiments are conducted to measure gesture recognition accuracies considering the major scene variabilities, illumination, background, and distance. Classification accuracies show that well-lit, clear background, and within 3 ft gestures are recognized correctly over 90%. Limitations of current framework and feasible solutions for better gesture recognition are discussed, too. The software library we developed, and hand gesture datasets are open-sourced at project website.",2018,Tao Zhang; Yue-Jie Zhang,168,175,8,5,10.1109/ICDIS.2018.00035,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367759,IEEE Conferences,IEEE
Face Depth Estimation and 3D Reconstruction,Machine Learning;Generative Adversarial Network;Pix2Pix;3D representation,"In the world of fast growing technology people look for more realistic representation and hence 3D representation of 2D images acquires great importance. 3D models are used in various fields like face recognition and animation games. They are widely used in medical industry to create interactive representations of human anatomy. However, generation of 3D models from 2D images is still one of the major challenges faced by researchers. Many methods have been introduced and developed for generating 3D representation. Here in our work, we used a Generative Adversarial Network(GAN) based model for estimating the depth map of a given face image. Pix2pix GAN, a variant of conditional GAN is used in this method. It is capable of performing image-to-image translation using the unsupervised method of machine learning. We found that it is the most robust method.",2020,V. Hoang; M. Ngo; D. Dinh,125,132,8,,10.1109/ACCTHPA49271.2020.9213233,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213233,IEEE Conferences,IEEE
Automatic Sublingual Vein Feature Extraction System,tongue diagnosis;sublingual veins;tongue-back imagery;histogram equalization,"The quintessence of the diagnosis in traditional Chinese medicine is syndrome differentiation and treatment. Syndrome differentiation consists of four methods: observing, hearing as well as smelling, asking, and touching. The examination of the observing is the most important procedure in the method of ""tongue."" In recent years, numerous medical studies have identified the close relations between sublingual veins and human organs. Therefore, sublingual pathological symptoms, as well as demographical information of patients, imply pathological changes in the organs, and early diagnosis is beneficial for early treatment. However, the diagnosis of sublingual pathological symptoms is usually influenced by the doctor's subjective interpretation, experience, and environmental factors. The results can easily be limited by subjective factors such as knowledge, experience, mentality, diagnostic techniques, color perception and interpretation. Different doctors may make different judgments on the same tongue, presenting less than desirable repeatability. Therefore, assisting doctors' diagnoses with scientific methods and standardizing the differentiating process to obtain reliable diagnoses and enhance the clinical applicability of Chinese medicine is an important issue. In its wake, this study aims to construct an Automatic Sublingual Vein Feature Extraction System based on image processing technologies to allow objective and quantified computer readings. The extraction of sublingual vein features mainly captures the back of the tongue and extract the sublingual vein area for feature expression analysis. Firstly, the patient's back of the tongue is photographed and color-graded to compensate for color distortion, and then the tongue-back area is extracted. This study extracts tongue-back imagery by analyzing the RGB color expression of the back of the tongue, lips, teeth and skin, translating it into the HSI color space easily perceived by the human eye, along with skin area removal, rectangle detection, teeth area removal, black area removal and control point detection. The captured tongue-back image goes through histogram equalization and hue shift to enhance color contrast. Sublingual veins are extracted through analyzing RGB color component shift, hues, saturation and brightness. Then the sublingual vein color information and positioning are used to differentiate hues, lengths and branches. Thinning analysis is used to determine the presence of varicose veins. At the same time, the surrounding features of sublingual veins, such as columnar vein, bubbly vein, petechiae and bloodshot, are extracted. The information regarding features and lingual vein conditions are integrated and analyzed for doctors' clinical reference. This study utilizes 199 lingual images for statistic testing and three lingual diagnostic experts in Chinese medicine for lingual reading. The accuracy for the extractions are: tongue back 86%, sublingual vein 80%, varicose veins 90%, branches 87%, and the accuracy rates for columnar veins and bubbly veins are 87%, 88% and 73% respectively.",2014,W. Czaja; D. Dong; P. -E. Jabin; F. O. N. Njeunje,55,62,8,,10.1109/ICMB.2014.17,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6845825,IEEE Conferences,IEEE
Automatic Event Coding Framework for Spanish Political News Articles,Multilingual;Apache Spark;Universal Dependency;Automated Event Coder;NLP;BERT,"Today, Spanish speaking countries face widespread political crisis. These political conflicts are published in a large volume of Spanish news articles from Spanish agencies. Our goal is to create a fully functioning system that parses realtime Spanish texts and generates scalable event code. Rather than translating Spanish text into English text and using English event coders, we aim to create a tool that uses raw Spanish text and Spanish event coders for better flexibility, coverage, and cost.To accommodate the processing of a large number of Spanish articles, we adapt a distributed framework based on Apache Spark. We highlight how to extend the existing ontology to provide support for the automated coding process for Spanish texts. We also present experimental data to provide insight into the data collection process with filtering unrelated articles, scaling the framework, and gathering basic statistics on the dataset.",2020,W. T. Kerr; A. Y. Cho; A. Anderson; P. K. Douglas; E. P. Lau; E. S. Hwang; K. R. Raman; A. Trefler; M. S. Cohen; S. T. Nguyen; N. M. Reddy; D. H. Silverman,246,253,8,,10.1109/BigDataSecurity-HPSC-IDS49724.2020.00052,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123024,IEEE Conferences,IEEE
Empirical Comparison of Automatic Image Annotation Systems,image annotation;clustering;constrained clustering;content-based image retrieval,"The performance of content-based image retrieval systems has proved to be inherently constrained by the used low-level features, and cannot give satisfactory results when the user's high level concepts cannot be expressed by low level features. In an attempt to bridge this semantic gap, recent approaches started integrating both low level-visual features and high-level textual keywords. Unfortunately, manual image annotation is a tedious process and may not be possible for large image databases. To overcome this limitation, several approaches that can annotate images in a semi-supervised or unsupervised way have emerged. In this paper, we outline and compare four different algorithms. The first one is simple and assumes that image annotation can be viewed as the task of translating from a vocabulary of fixed image regions to a vocabulary of words. The second approach uses a set of annotated images as a training set and learns the joint distribution of regions and words. The third and fourth approaches are based on segmenting the images into homogeneous regions. Both of these approaches rely on a clustering algorithm to learn the association between visual features and keywords. The clustering task is not trivial as it involves clustering a very high-dimensional and sparse feature spaces. To address this, the third approach uses semi-supervised constrained clustering while the fourth approach relies on an algorithm that performs simultaneous clustering and feature discrimination. These four algorithms were implemented and tested on a data set that includes 6000 images using four-fold cross validation.",2008,W. Wang; W. Zheng; D. Liu; C. Zhang; Q. Zeng; Y. Deng; W. Yang; P. He; T. Xie,1,8,8,1,10.1109/IPTA.2008.4743754,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4743754,IEEE Conferences,IEEE
Detecting Suspected Pump Thrombosis in Left Ventricular Assist Devices via Acoustic Analysis,Left ventricular assist device;pump thrombosis;heart failure;machine learning,"Objective: Left ventricular assist devices (LVADs) fail in up to 10% of patients due to the development of pump thrombosis. Remote monitoring of patients with LVADs can enable early detection and, subsequently, treatment and prevention of pump thrombosis. We assessed whether acoustical signals measured on the chest of patients with LVADs, combined with machine learning algorithms, can be used for detecting pump thrombosis. Methods: 13 centrifugal pump (HVAD) recipients were enrolled in the study. When hospitalized for suspected pump thrombosis, clinical data and acoustical recordings were obtained at admission, prior to and after administration of thrombolytic therapy, and every 24 hours until laboratory and pump parameters normalized. First, we selected the most important features among our feature set using LDH-based correlation analysis. Then using these features, we trained a logistic regression model and determined our decision threshold to differentiate between thrombosis and non-thrombosis episodes. Results: Accuracy, sensitivity and precision were calculated to be 88.9%, 90.9% and 83.3%, respectively. When tested on the post-thrombolysis data, our algorithm suggested possible pump abnormalities that were not identified by the reference pump power or biomarker abnormalities. Significance: We showed that the acoustical signatures of LVADs can be an index of mechanical deterioration and, when combined with machine learning algorithms, provide clinical decision support regarding the presence of pump thrombosis.",2020,Y. Herdiyeni; S. Nurdiati; I. A. Daud,1899,1906,8,,10.1109/JBHI.2020.2966178,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957505,IEEE Journals,IEEE
Improved Deep Belief Network for Short-Term Load Forecasting Considering Demand-Side Management,Short-term load forecasting;deep belief network;restricted Boltzmann machine;deep learning;demand-side management,"Demand-side management (DSM) increases the complexity of forecasting environment, which makes traditional forecasting methods difficult to meet the firm's need for predictive accuracy. Since deep learning can comprehensively consider various factors to improve prediction results, this paper improves the deep belief network from three aspects of input data, model and performance, and uses it to solve the short-term load forecasting problem in DSM. In the data optimization stage, the Hankel matrix is constructed to increase the input weight of DSM data, and the gray relational analysis is used to select strongly correlated data from the data set. In the model optimization stage, the Gauss-Bernoulli restricted Boltzmann machine is used as the first restricted Boltzmann machine of the deep network to convert the continuity feature of input data into binomial distribution feature. In the performance optimization stage, a pre-training method combining error constraint and unsupervised learning is proposed to provide good initial parameters, and the global fine-tuning of network parameters is realized based on the genetic algorithm. Based on the actual data of Tianjin Power Grid in China, the experimental results show that the proposed method is superior to other methods.",2020,Y. Kawai; M. Seo; Y. Chen,1531,1538,8,8,10.1109/TPWRS.2019.2943972,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854896,IEEE Journals,IEEE
Exploiting external knowledge sources to improve kernel-based Word Sense Disambiguation,word sense disambiguation;kernel based method;support vector machine,"This paper proposes a novel approach to improve the kernel-based word sense disambiguation (WSD). We first explain why linear kernels are more suitable to WSD and many other natural language processing problems than translation-invariant kernels. Based on the linear kernel, two external knowledge sources are integrated. One comprises a set of linguistic rules to find the crucial features. For the other, a distributional similarity thesaurus is used to alleviate data sparseness by generalizing crucial features when they do not match the word-form exactly. The experiments show that we have outperformed the state-of-the-art system on the benchmark data from English lexical sample task of SemEval-2007 and the improvement is statistically significant.",2008,Y. Wang; Y. Xia; L. Zhao; J. Bian; T. Qin; E. Chen; T. Liu,1,8,8,,10.1109/NLPKE.2008.4906810,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906810,IEEE Conferences,IEEE
Data Mining model in the discovery of trends and patterns of intruder attacks on the data network as a public-sector innovation,CRISP-DM;data networks attacks;data mining;IDS/IPS;machine learning;public-sector innovation,"Innovation in the public-sector refers to the development of important improvements in the public administration and their corresponding services. One of such public services is the social security, of which central process has been the information security of their offered services. The aim of the present study has been the analysis of the trends and the discovery of behavioural patterns in the attacks to the data network of an institution of the public-sector. To fulfil such objective, a model has been implemented on algorithms and data mining techniques, based on the Cross Industry Standard Process for Data Mining methodology. The model uses a free and open source network Intrusion Detection and Prevention System (IDS/IPS) for the capture of the logs of the attacks to the data network of the organization. This has been followed by a quantitative assessment of various algorithms of intrusion detection leading to the selection of J48 and REPTree as Data Mining algorithms with a level of insolence in instances properly classified by the lowest absolute error. The data were processed and served as input for the construction of rules. The resulting rules of the decision tree have been based on the principle of calculating the information gain via entropy and minimizing the error that arises from the variance. These rules were the product of applying machine learning on the logs analysed and they were subsequently translated and reprogrammed to the IDS/IPS in order to assess the efficiency of the model. The results demonstrate a significant improvement of some 67% in detection of attacks in relation to the traditional IDS. Consequently, we extrapolated a wide difference in behaviour and trends with the use of a traditional system compared to that generated by Data Mining.",2017,Y. Yang; X. Li; T. Jiang; J. Kong; B. Ma; X. Zhou; L. Wang,55,62,8,3,10.1109/ICEDEG.2017.7962513,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962513,IEEE Conferences,IEEE
The classification of periodic light curves from non-survey optimized observational data through automated extraction of phase-based visual features,Data analysis;Machine Learning;Light Curve Classification;Variable Stars;Visual feature extraction,"We present Random Forest, Support Vector Machine and Feedforward Neural Network models to classify 2519 variable star light curves. These light curves are generated from a reduction of non-survey optimized observational images gathered by wide-field cameras mounted on the Liverpool Telescope. We extract 16 features found to be highly informative in previous studies and achieve an area under the curve of 0.8495 using a feedforward neural network with 50 hidden neurons trained with stratified 10-fold cross-validation with 3 repeats. We propose using an automated visual feature extraction technique by transforming bin-averaged phase-folded light curves into image based representations. This eliminates much of the noise and the missing phase data, due to sampling defects, should have a less destructive effect on these shape features as they still remain at least partially present. There is also no need for feature engineering as the learning algorithms can learn shape features directly from the light curves. We produced a set of scaled images based on a threshold of data points in each pixel. Training on the same feedforward network, we achieve an area under the curve of 0.6348. By introducing the Period and Amplitude as features into this dataset therefore giving meaning to the dimensions of the image we show this improves to 0.7952. Our current models lack translational-invariance and the method may be better suited to specific sub-classification problems common in the variable object hierarchical multi-class problem.",2017,Yan-xi Yang; Y. Gao; Yi Deng,3058,3065,8,,10.1109/IJCNN.2017.7966236,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966236,IEEE Conferences,IEEE
Scientific Discovery and Rigor with ML,Discovery;Artificial Intelligence (AI);Machine Learning (ML);Data Management;API;Platform;Cloud,"The evolution of Data Management Scenarios augmented by scientific discovery and rigor is apparent in the industry, judging by the sheer focus on it by analysts and others over the past couple of years. Machine Learning helps immensely playing its part in simplifying enterprise data landscapes, contributing to many aspects of Data Management. We see value in focusing on the Data Discovery and Data Quality aspects in this context, as enterprises these days have complex landscapes, with the average enterprise using more than 5 Cloud storages in addition to their on-prem data sources.A greater affinity for enterprise grade Machine Learning has created a significant pull for system design. This leads platforms towards capabilities like standard APIs for scaled-database queries and integration scenarios. This paper explores the integration of Machine Learning tools and customized libraries with any Cloud Platform for enhancing the stakeholders' experience with Analytics. As far as concepts are concerned, we propose a hypothesis for scaling an existent platform to a community-based approach, which helps enable sharing of experimental iterations, ideally translating into industry specific solutions that should stay extremely reusable. The intent is to offer a data model flexible enough to handle diverse data scenarios, evaluating confidence scores for each of these. It should enable reproducible shared experiments with consistent evaluated scores, thereby easing the integration process through automated guidance. This paper will touch upon the good practices and architectural recommendations that need to be considered for general Machine Learning applications.",2020,Ying Li,69,76,8,,10.1109/MPCIT51588.2020.9350455,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350455,IEEE Conferences,IEEE
Evolving complex yet interpretable representations: application to Alzheimerâ€™s diagnosis and prognosis,grammar evolution;feature representation;interpretability;Alzheimerâ€™s disease;machine learning,"With increasing accuracy and availability of more data, the potential of using machine learning (ML) methods in medical and clinical applications has gained considerable interest. However, the main hurdle in translational use of ML methods is the lack of explainability, especially when non-linear methods are used. Explainable (i.e. human-interpretable) methods can provide insights into disease mechanisms but can equally importantly promote clinician-patient trust, in turn helping wider social acceptance of ML methods. Here, we empirically test a method to engineer complex, yet interpretable, representations of base features via evolution of context-free grammar (CFG). We show that together with a simple ML algorithm evolved features provide higher accuracy on several benchmark datasets and then apply it to a real word problem of diagnosing Alzheimer's disease (AD) based on magnetic resonance imaging (MRI) data. We further demonstrate high performance on a hold-out dataset for the prognosis of AD.",2020,Z. Li; P. He; Y. Sun,1,8,8,,10.1109/CEC48606.2020.9185843,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185843,IEEE Conferences,IEEE
Hybrid method based on multi-feature descriptor for static sign language recognition,vision-Based approach;HOG feature extraction;edge orientation histogram EOH;multiclass support vector machine,"Sign Language Recognition is an essential research problem for enabling communication with deaf-dumb people. Sign language recognition system confronts many challenges such as complex background, illumination changes, translation, rotation, and scale problem, besides system requirements such as time of recognition, robustness, performance, and computational efficiency. This paper proposes hybridization between two strong descriptors including Histogram of Oriented Gradients (HOG) and Edge Oriented Histogram (EOH) to achieve better recognition rate with relatively low memory requirements. A new feature descriptor is used as a combined feature descriptor, which joins the advantages of each descriptor to achieve good performance. Multi-class support vector machine classifier is utilized to classify the hand gestures. Experimental results demonstrate that the proposed system gives recognition rate of 96.15 % for 1AASVM classifier and 99.23 % for 1A1SVM classifier under different hand poses and complex background with changes in lightning conditions.",2017,Z. Liu; Y. Jin,98,105,8,,10.1109/INTELCIS.2017.8260039,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260039,IEEE Conferences,IEEE
Research Report: ICARUS: Understanding De Facto Formats by Way of Feathers and Wax,parser;security;data;machine learning;format;language inference,"When a data format achieves a significant level of adoption, the presence of multiple format implementations expands the original specification in often-unforeseen ways. This results in an implicitly defined, de facto format, which can create vulnerabilities in programs handling the associated data files. In this paper we present our initial work on ICARUS: a toolchain for dealing with the problem of understanding and hardening de facto file formats. We show the results of our work in progress in the following areas: labeling and categorizing a corpora of data format samples to understand accepted variations of a format; the detection of sublanguages within the de facto format using both entropy- and taint-tracking-based methods, as a means of breaking down the larger problem of learning how the grammar has evolved; grammar inference via reinforcement learning, as a means of tying together the learned sublanguages; and the defining of both safe subsets of the de facto grammar, as well as translations from unsafe regions of the de facto grammar into safe regions. Real-world data formats evolve as they find use in real-world applications, and a comprehensive ICARUS toolchain for understanding and hardening the resulting de facto formats can identify and address security risks arising from this evolution.",2020,Z. Liu; Y. Jin; W. Chang,327,334,8,,10.1109/SPW50608.2020.00067,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283834,IEEE Conferences,IEEE
Detecting duplicates with shallow and parser-based methods,Duplicate detection;Plagiarism;Semantic networks;Support vector machine;Paraphrases;Entailments,"Identifying duplicate texts is important in many areas like plagiarism detection, information retrieval, text summarization, and question answering. Current approaches are mostly surface-oriented (or use only shallow syntactic representations) and see each text only as a token list. In this work however, we describe a deep, semantically oriented method based on semantic networks which are derived by a syntactico-semantic parser. Semantically identical or similar semantic networks for each sentence of a given base text are efficiently retrieved by using a specialized semantic network index. In order to detect many kinds of paraphrases the current base semantic network is varied by applying inferences: lexico-semantic relations, relation axioms, and meaning postulates. Some important phenomena occurring in difficult-to-detect duplicates are discussed. The deep approach profits from background knowledge, whose acquisition from corpora like Wikipedia is explained briefly. This deep duplicate recognizer is combined with two shallow duplicate recognizers in order to guarantee high recall for texts which are not fully parsable. The evaluation shows that the combined approach preserves recall and increases precision considerably, in comparison to traditional shallow methods. For the evaluation, a standard corpus of German plagiarisms was extended by four diverse components with an emphasis on duplicates (and not just plagiarisms), e.g., news feed articles from different web sources and two translations of the same short story.",2010,Z. Vulaj; M. BrajoviÄ‡; A. DraganiÄ‡; I. OroviÄ‡,1,8,8,,10.1109/NLPKE.2010.5587838,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587838,IEEE Conferences,IEEE
A Gamification Framework for Sensor Data Analytics,Internet of Things;Sensor Data;Gamification;Data Analytics;Machine Learning;Crowdsourcing,"The Internet of Things (IoT) enables connected objects to capture, communicate, and collect information over the network through a multitude of sensors, setting the foundation for applications such as smart grids, smart cars, and smart cities. In this context, large scale analytics is needed to extract knowledge and value from the data produced by these sensors. The ability to perform analytics on these data, however, is highly limited by the difficulties of collecting labels. Indeed, the machine learning techniques used to perform analytics rely upon data labels to learn and to validate results. Historically, crowdsourcing platforms have been used to gather labels, yet they cannot be directly used in the IoT because of poor human readability of sensor data. To overcome these limitations, this paper proposes a framework for sensor data analytics which leverages the power of crowdsourcing through gamification to acquire sensor data labels. The framework uses gamification as a socially engaging vehicle and as a way to motivate users to participate in various labelling tasks. To demonstrate the framework proposed, a case study is also presented. Evaluation results show the framework can successfully translate gamification events into sensor data labels.",2017,Z. Zhu; J. Ruan; K. Wang; J. Zhou; G. Ye; C. Wu,74,81,8,3,10.1109/IEEE.ICIOT.2017.18,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8039057,IEEE Conferences,IEEE
Efficiency of a machine translation system,Machine Translation;Corpus;Syntactic;Interlingua Machine Translation Lexical,"In the field of machine translation ample amount of work has been done to improve the essence of translation systems. It all started in 1949 when Warren Weaver proposed the first idea of using computer for translation. Since then several approaches have been followed out to ameliorate the quality of translation. But even after continuing development in this field, we haven't reached the level where we could get the exact translation of the source text. The aim of this paper is to brief about different approaches of machine translation and introduce a mechanism for the evaluation of the efficiency of translation systems based on the lexical, syntactical and semantics differences between source text and translated text. This mechanism provides a statistical analysis of translation systems, the results of this analysis can be used as a rating mechanism on the translation systems used worldwide. In this paper, we have emphasized on translation between English and Hindi.",2017,A. K. Saha; M. F. Mridha; M. R. Hussein; J. K. Das,140,148,9,,10.1109/ICECA.2017.8203660,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8203660,IEEE Conferences,IEEE
Revisiting Back-Translation for Low-Resource Machine Translation Between Chinese and Vietnamese,Back-translation;Chinese;low-resource languages;machine translation;Vietnamese,"Back-translation (BT) has been widely used and become one of standard techniques for data augmentation in Neural Machine Translation (NMT), BT has proven to be beneficial for improving the performance of translation effectively, especially for low-resource scenarios. While most previous works related to BT mainly focus on European languages with high relatedness, few of them study less-related languages in other areas around the world. In this paper, we choose the language pair with less relatedness in Asia: Chinese and Vietnamese, to investigate the impacts of BT on extremely low-resource machine translation between them. We first discuss the similarities and differences between the two languages, then evaluate and compare the effects of different sizes of back-translated data on NMT and Statistical Machine Translation (SMT) models for Chinese-Vietnamese and Vietnamese-Chinese, with both character-based and word-based settings, and conduct further analysis on the translation outputs from several aspects. Some conclusions from previous works are partially confirmed and we also draw some new findings and conclusions, which are beneficial to understand BT further and deeper for translation between less-related low-resource languages.",2020,A. Nugumanova; A. Novosselov; Y. Baiburin; A. Karimov,119931,119939,9,,10.1109/ACCESS.2020.3006129,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129718,IEEE Journals,IEEE
Machine Translation of Mathematical Text,Machine translation;natural language processing;multi-layer neural network;LaTeX,"We have implemented a machine translation system, the PolyMath Translator, for LaTeX documents containing mathematical text. The current implementation translates English LaTeX to French LaTeX, attaining a BLEU score of 53.6 on a held-out test corpus of mathematical sentences. It produces LaTeX documents that can be compiled to PDF without further editing. The system first converts the body of an input LaTeX document into English sentences containing math tokens, using the pandoc universal document converter to parse LaTeX input. We have trained a Transformer-based translator model, using OpenNMT, on a combined corpus containing a small proportion of domain-specific sentences. Our full system uses this Transformer model and also Google Translate with a custom glossary, the latter being used as a backup to better handle linguistic features that do not appear in our training dataset. Google Translate is used when the Transformer model does not have confidence in its translation, as determined by a high perplexity score. Ablation testing demonstrates that the tokenization of symbolic expressions is essential to the high quality of translations produced by our system. We have published our test corpus of mathematical text. The PolyMath Translator is available as a web service at http://www.polymathtrans.ai.",2021,B. Zhang; D. Xiong; J. Su,38078,38086,9,,10.1109/ACCESS.2021.3063715,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9369381,IEEE Journals,IEEE
A2R2: Robust Unsupervised Neural Machine Translation With Adversarial Attack and Regularization on Representations,Natural language processing;machine translation;unsupervised learning;adversarial attack,"Unsupervised neural machine translation (UNMT) has recently achieved significant progress without requirement on any parallel data. The models for UNMT are typically the sequence-to-sequence architecture with an encoder to map sentences in different languages to a shared latent space, and a decoder to generate their corresponding translation. Denoising autoencoding and back-translation are called in every iteration for the models to learn the relationship of sentence pairs in languages or between languages. However, sentences generated by the noise model of autoencoding or the reverse model of back-translation are normally different from those written by humans, which may cause inference bias. In this paper, we propose a regularization method for back-translation to explicitly draw representations of sentence pairs closer in the shared space. To enhance the robustness to sentences after autoencoding or back-translation, the adversarial attack on representations is applied. Experiments on unsupervised Englishâ†”French, Englishâ†”German and Englishâ†”Romanian benchmarks show that our approach outperforms the cross-lingual language model (XLM) baseline by 0.4~1.8 BLEU scores. Additionally, the boost on noisy test sets in most translation directions is over 5 BLEU scores.",2021,C. Mi; L. Xie; Y. Zhang,19990,19998,9,,10.1109/ACCESS.2021.3054935,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9336722,IEEE Journals,IEEE
Ancient Korean Neural Machine Translation,Ancient Korean translation;neural machine translation;transformer;subword tokenization;share vocabulary and entity restriction byte pair encoding,"Translation of the languages of ancient times can serve as a source for the content of various digital media and can be helpful in various fields such as natural phenomena, medicine, and science. Owing to these needs, there has been a global movement to translate ancient languages, but expert minds are required for this purpose. It is difficult to train language experts, and more importantly, manual translation is a slow process. Consequently, the recovery of ancient characters using machine translation has been recently investigated, but there is currently no literature on the machine translation of ancient Korean. This paper proposes the first ancient Korean neural machine translation model using a Transformer. This model can improve the efficiency of a translator by quickly providing a draft translation for a number of untranslated ancient documents. Furthermore, a new subword tokenization method called the Share Vocabulary and Entity Restriction Byte Pair Encoding is proposed based on the characteristics of ancient Korean sentences. This proposed method yields an increase in the performance of the original conventional subword tokenization methods such as byte pair encoding by 5.25 BLEU points. In addition, various decoding strategies such as n-gram blocking and ensemble models further improve the performance by 2.89 BLEU points. The model has been made publicly available as a software application.",2020,D. Banik; P. Bhattacharyya; A. Ekbal,116617,116625,9,,10.1109/ACCESS.2020.3004879,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9125904,IEEE Journals,IEEE
Integrating pronunciation into Chinese-Vietnamese statistical machine translation,pronunciation integration;low-resource languages;Chinese-Vietnamese machine translation;Sino-Vietnamese words,"Statistical machine translation for low-resource language suffers from the lack of abundant training corpora. Several methods, such as the use of a pivot language, have been proposed as a bridge to translate from one language to another. However, errors will accumulate during the extensive translation pipelines. In this paper, we propose an approach to low-resource language translation by exploiting the pronunciation correlations between languages. We find that the pronunciation features can improve both Chinese-Vietnamese and Vietnamese-Chinese translation qualities. Experimental results show that our proposed model yields effective improvements, and the translation performance (bilingual evaluation understudy score) is improved by a maximum value of 1.03.",2018,D. Jones; E. Gibson; W. Shen; N. Granoien; M. Herzog; D. Reynolds; C. Weinstein,715,723,9,,10.26599/TST.2018.9010006,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8484935,TUP Journals,TUP
Listwise Ranking Functions for Statistical Machine Translation,Statistical machine translation;listwise ranking function;discriminative reranking;Discriminative reranking;listwise ranking function;statistical machine translation,"Decision rules play an important role in the tuning and decoding steps of statistical machine translation. The traditional decision rule selects the candidate with the greatest potential from a candidate space by examining each candidate individually. However, viewing each candidate as independent imposes a serious limitation on the translation task. We instead view the problem from a ranking perspective that naturally allows the consideration of an entire list of candidates as a whole through the adoption of a listwise ranking function. Our shift from a pointwise to a listwise perspective proves to be a simple yet powerful extension to current modeling that allows arbitrary pairwise functions to be incorporated as features, whose weights can be estimated jointly with traditional ones. We further demonstrate that our formulation encompasses the minimum Bayes risk (MBR) approach, another decision rule that considers restricted listwise information, as a special case. Experiments show that our approach consistently outperforms the baseline and MBR methods across the considered test sets.",2016,D. Rativa; B. J. T. Fernandes; A. Roque,1464,1472,9,3,10.1109/TASLP.2016.2560527,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7462217,IEEE Journals,IEEE
Developing a system for machine translation from Hindi language to English language,GB theory;Hindi to English translation system;Indian language;exampled-based approach;government-and-binding theory;machine translation system;phrase structure;ruled-based approach,"Many research organizations in India and abroad have started developing translation systems for the Indian languages recently using conventional approaches like ruled-based or exampled-based or hybrid. Very few have tried to identify universality of government and binding (GB) theory, which emphasizes common phrase structure for all the languages. In this paper, a machine translation system based on ruled-based theory is proposed. The system takes Hindi as source language and English as target language.",2013,E. Kozerenko; Y. Sinyaghina; N. Somin; S. Pozdeeva,79,87,9,9,10.1109/ICCCT.2013.6749607,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6749607,IEEE Conferences,IEEE
Machine translation â€” A journey,Machine Translation;Generation;Indian language;Foreign Language;Devnagri;algorithm;technique,"Translation of natural language has always attracted attention of scholars world-wide, be it manual or machine based. Since, the last six decades machine translation has been witnessed. It is attempted in various Indian and Foreign languages. Machine Translation has also been attempted with different techniques. The success ratio of translation has always been an encouraging factor, which kept attracting talents and organizations. Therefore, we have seen progress of machine translation by leaps and bounds.",2014,F. Azadi; S. Khadivi,187,195,9,,10.1109/SAI.2014.6918189,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918189,IEEE Conferences,IEEE
Statistical Machine Translation: Little Changes Big Impacts,statistical machine translation;superficial changes;Brazilian Portuguese;English,"In this paper we describe some experiments carried out to test the impact of automatic casing and punctuation changes when training and testing statistical translation models. The experiments described here concern the translation from/to English and Brazilian Portuguese texts but since the superficial changes investigated are language independent, we believe that the conclusions can be applied to many other pairs of languages. These experiments were designed aiming at setting a baseline scenario for future training and testing of more complex statistical translation models such as the factored ones. From the experiments presented here it is possible to see that case and punctuation changes have a significant impact on automatic translation results.",2009,F. Bouzit; M. T. Laskri,63,71,9,,10.1109/STIL.2009.24,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5532439,IEEE Conferences,IEEE
Design and implementation of an â€œWeb APIâ€? for the automatic translation Colombia's language pairs: Spanish-Wayuunaiki case,API;Apertium;automatic translation;Wayuunaiki,"This paper presents the design and implementation of an Application Programming Interface (API) that allows exposing the service of automatic translation between two languages (Spanish and Wayuunaiki case) using a evolving development model based on prototypes and through solutions based on open source technologies. This innovative development uses the Information Technology and Communication (ICT) to focus on Aboriginal languages translation enhancing the integration of technology with communities and allowing inclusion of languages and cultures conserving in the ICT ecosystem in Colombia. During the development of this document It will describe how various open source (Python 2.7, Apertium, SO Ubuntu Linux 12.04 LTS 64 Bits Server Edition, Apache Web Server con mod_wsgi, PostgreSQL 9.1,Gunicorn, Django 1.4) tools were integrated to achieve the goal of creating an API with a reproducible architecture in various environments, which complies with current trends and technical requirements for web implementation, such as usability, scalability, simple and clear code, and others. Finally we developed a web application that allows knowing and validating the functionality of the API implemented.",2013,F. C. Flores; S. M. Peres; F. J. Von Zuben,1,9,9,1,10.1109/ColComCon.2013.6564817,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6564817,IEEE Conferences,IEEE
A Context-Aware Recurrent Encoder for Neural Machine Translation,Context-aware encoder;neural machine translation (NMT);natural language processing;recurrent encoder,"Neural machine translation (NMT) heavily relies on its encoder to capture the underlying meaning of a source sentence so as to generate a faithful translation. However, most NMT encoders are built upon either unidirectional or bidirectional recurrent neural networks, which either do not deal with future context or simply concatenate the history and future context to form context-dependent word representations, implicitly assuming the independence of the two types of contextual information. In this paper, we propose a novel context-aware recurrent encoder (CAEncoder), as an alternative to the widely-used bidirectional encoder, such that the future and history contexts can be fully incorporated into the learned source representations. Our CAEncoder involves a two-level hierarchy: The bottom level summarizes the history information, whereas the upper level assembles the summarized history and future context into source representations. Additionally, CAEncoder is as efficient as the bidirectional RNN encoder in terms of both training and decoding. Experiments on both Chinese-English and English-German translation tasks show that CAEncoder achieves significant improvements over the bidirectional RNN encoder on a widely-used NMT system.",2017,F. Delmastro; F. D. Martino; C. Dolciotti,2424,2432,9,9,10.1109/TASLP.2017.2751420,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031316,IEEE Journals,IEEE
A technical reading in statistical and neural machines translation (SMT & NMT),Neural Networks;Reccurent Neural Networks;Natural Language Processing;Machine learning;Neural Language Model;Phrase-based SMT,"Automatic translation of natural languages has been an active body of research in the last decades, especially when it comes to statistical translation which uses machine learning algorithms for translation tasks. Machine translation being a key application in the field of natural language processing, it leads to develop many approaches namely, statistical machine translation and recently neural machine translation. In this paper, we present a survey of the state of the art, where we describe the context of the current research studies by reviewing both the statistical machine translation and neural machine translation, and an overview of the main strengths and limitations of the two approaches.",2017,F. MÃ¼ller; D. Schug; P. Hallen; J. Grahe; V. Schulz,157,165,9,,10.1109/ICITECH.2017.8079994,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079994,IEEE Conferences,IEEE
Architecture of English to Sanskrit machine translation,machine translation;database design;structure;english;sanskrit,"Machine Translation has been a widely addressed topic. It is critically analyzed from various angles, like-languages attempted for translation, techniques evolved, models designed etc. Apart from this, the results obtained as well as the percentage of accuracy are also highly focused. In this paper, we have discussed the structure of the Sanskrit language followed by the similarities between Sanskrit grammar and Context Free Grammar along with the grammatical differences between Sanskrit and English Language. The formation of noun words in Sanskrit language is also discussed briefly with the help of derivation tree. We have also focused on database design and model developed for translation.",2015,G. Mahmut; M. Nijat; R. Memet; A. Hamdulla,616,624,9,2,10.1109/IntelliSys.2015.7361204,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361204,IEEE Conferences,IEEE
A Controlled Experiment on the Effects of Machine Translation in Multilingual Requirements Meetings,machine translation;language barrier;requirements engineering;empirical study,"Requirements engineering is a communication-intensive activity and thus it suffers much from language difficulties in global software projects. Remote requirements meetings can benefit from machine translation as this technology is today available in the form of cross-language chat services. In this paper, we present the design of a controlled experiment to investigate the effects of automatic machine translation services in requirements meetings. Experiment participants, using either Italian or Portuguese as native language, are asked to interact with a communication tool from a distance in order to prioritize and estimate requirements. First results show that real-time machine translation is not disruptive of the conversation flow and is accepted with favor by participants. However, concrete effects are expected to emerge when language barriers are critical.",2011,G. Manias; A. Mavrogiorgou; A. Kiourtis; D. Kyriazis,94,102,9,8,10.1109/ICGSE.2011.14,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063154,IEEE Conferences,IEEE
Attention based English-Bodo Neural Machine Translation System for Tourism Domain,Neural Machine Translation;Natural Language Processing;Bodo Language;Low Resource Indian Language;Low Resource Indian Languages,"Bodo language is a relatively low resource language. Other than the text-book, novels and some print publication of newspaper, there appears to be very few resources available in the public domain. As the technology becomes affordable there is a growing number of active Bodo internet users. It requires a technology that can bring information in their own language. Machine translation appears to be a promising solution for that purpose. In this work we build an English-Bodo Neural Machine Translation by adopting a two layered bidirectional Long Short Term Memory (LSTM) cells that can capture the long term dependencies. As very few work has been done on English-Bodo NMT, we make our baseline model which produced a BLEU Score of 11.8 . We then gradually overcome the baseline model by introducing several attention mechanism. We achieved a BLEU Score of 16.71 using the approach presented in Bahdanu. Furthermore we got a better BLEU score of 17.9 when we introduced beam search with a beam width of 5. We found that the model performs very well despite the few dataset available.",2019,G. Tambouratzis,335,343,9,,10.1109/ICCMC.2019.8819699,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8819699,IEEE Conferences,IEEE
A survey of voice translation methodologies â€” Acoustic dialect decoder,Voice Translator;Speech Recognition;Machine Translation;Speech Synthesis;Deep learning;RNN;LSTM;HTK;HTS;HMMs,"Language Translation has always been about inputting source as text/audio and waiting for system to give translated output in desired form. In this paper, we present the Acoustic Dialect Decoder (ADD) - a voice to voice earpiece translation device. We introduce and survey the recent advances made in the field of Speech Engineering, to employ in the ADD, particularly focusing on the three major processing steps of Recognition, Translation and Synthesis. We tackle the problem of machine understanding of natural language by designing a recognition unit for source audio to text, a translation unit for source language text to target language text, and a synthesis unit for target language text to target language speech. Speech from the surroundings will be recorded by the recognition unit present on the ear-piece and translation will start as soon as one sentence is successfully read. This way, we hope to give translated output as and when input is being read. The recognition unit will use Hidden Markov Models (HMMs) Based Tool-Kit (HTK), RNNs with LSTM cells, and the synthesis unit, HMM based speech synthesis system HTS. This system will initially be built as an English to Tamil translation device.",2016,H. Zhang; J. Li; Y. Ji; H. Yue,1,9,9,,10.1109/ICICES.2016.7518940,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518940,IEEE Conferences,IEEE
Comparative study on corpora for speech translation,Corpus;machine translation;speech translation;spoken dialog,"This paper investigates issues in preparing corpora for developing speech-to-speech translation (S2ST). It is impractical to create a broad-coverage parallel corpus only from dialog speech. An alternative approach is to have bilingual experts write conversational-style texts in the target domain, with translations. There is, however, a risk of losing fidelity to the actual utterances. This paper focuses on balancing a tradeoff between these two kinds of corpora through the analysis of two newly developed corpora in the travel domain: a bilingual parallel corpus with 420 K utterances and a collection of in-domain dialogs using actual S2ST systems. We found that the first corpus is effective for covering utterances in the second corpus if complimented with a small number of utterances taken from monolingual dialogs. We also found that characteristics of in-domain utterances become closer to those of the first corpus when more restrictive conditions and instructions to speakers are given. These results suggest the possibility of a bootstrap-style of development of corpora and S2ST systems, where an initial S2ST system is developed with parallel texts, and is then gradually improved with in-domain utterances collected by the system as restrictions are relaxed",2006,K. M. M. Adlaon; N. Marcos,1674,1682,9,21,10.1109/TASL.2006.878262,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1677987,IEEE Journals,IEEE
Computational modelling of personal pronouns for English to YorÃ¹bÃ  machine translation system,YorÃºbÃ¡;personal-pronoun;bÃ¬nrin;kÃ¹nrin;unkÃ n;rule-based,"Translating third person singular pronouns from English to YorÃºbÃ¡ is yet to receive research attention. The issue can be understood if the translation is speech to speech. In the literature, the authors translate sentence without considering the gender of the author or doer as it is in the English (source language) sentence. This does pose a problem to the reader of English to YorÃºbÃ¡ translated sentences. We envisaged that there is need to represent she/he/it differently unlike the way we are translating it now. Presently, she/he/it are translated as Ã“. We proposed ways of representing the three third person singular pronouns; bÃ¬nrin, kÃºnrin and unkÃ n. Feminine (She) is bÃ¬nrin, masculine (he) is kÃºnrin and non-human (it) is unkÃ n. We developed English to YorÃºbÃ¡ machine translation (IFEMT1) system that can translate simple English sentence text to YorÃºbÃ¡ sentence text using the existing and proposed third person singular pronouns translation processes. We used rule based approach and python programming language to implement the IFEMT1 system. The system graphical user interface (GUI) can display the English sentences (to be translated), translated YorÃºbÃ¡ sentences for the existing and our proposed translations.",2015,Keh-Yih Su,733,741,9,1,10.1109/IntelliSys.2015.7361222,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361222,IEEE Conferences,IEEE
Towards Contradiction Detection in German: a Translation-Driven Approach,machine learning;natural language processing;natural language inference;contradiction detection,"With the recent advancements in Machine Learning based Natural Language Processing (NLP), language dependency has always been a limiting factor for a majority of NLP applications. Typically, models are trained for the English language due to the availability of very large labeled and unlabeled datasets, which also allow to fine tune models for that language. Contradiction Detection is one such problem that has found many practical applications in NLP and up to this point has only been studied in the context of English language. The scope of this paper is to examine a set of baseline methods for the Contradiction Detection task on German text. For this purpose, the well-known Stanford Natural Language Inference (SNLI) data set (110,000 sentence pairs) is machine-translated from English to German. We train and evaluate four classifiers on both the original and the translated data, using state-of-the-art textual data representations. Our main contribution is the first large-scale assessment for this problem in German, and a validation of machine translation as a data generation method. We also present a novel approach to learn sentence embeddings by exploiting the hidden states of an encoder-decoder Sequence-To-Sequence RNN trained for autoencoding or translation.",2019,M. K. Ishak; M. Dyson,2497,2505,9,1,10.1109/SSCI44817.2019.9003090,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003090,IEEE Conferences,IEEE
Height and Weight Estimation From Anthropometric Measurements Using Machine Learning Regressions,Machine learning;statistical learning;health information management,"Height and weight are measurements explored to tracking nutritional diseases, energy expenditure, clinical conditions, drug dosages, and infusion rates. Many patients are not ambulant or may be unable to communicate, and a sequence of these factors may not allow accurate estimation or measurements; in those cases, it can be estimated approximately by anthropometric means. Different groups have proposed different linear or non-linear equations which coefficients are obtained by using single or multiple linear regressions. In this paper, we present a complete study of the application of different learning models to estimate height and weight from anthropometric measurements: support vector regression, Gaussian process, and artificial neural networks. The predicted values are significantly more accurate than that obtained with conventional linear regressions. In all the cases, the predictions are non-sensitive to ethnicity, and to gender, if more than two anthropometric parameters are analyzed. The learning model analysis creates new opportunities for anthropometric applications in industry, textile technology, security, and health care.",2018,M. S. Hassani; J. R. Green,1,9,9,1,10.1109/JTEHM.2018.2797983,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327832,IEEE Journals,IEEE
Early Detection of Alzheimer's Disease with Blood Plasma Proteins Using Support Vector Machines,Alzheimer's disease;blood biomarker;dementia;machine learning;support vector machine,"The successful development of amyloid-based biomarkers and tests for Alzheimer's disease (AD) represents an important milestone in AD diagnosis. However, two major limitations remain. Amyloid-based diagnostic biomarkers and tests provide limited information about the disease process and they are unable to identify individuals with the disease before significant amyloid-beta accumulation in the brain develops. The objective in this study is to develop a method to identify potential blood-based non-amyloid biomarkers for early AD detection. The use of blood is attractive because it is accessible and relatively inexpensive. Our method is mainly based on machine learning (ML) techniques (support vector machines in particular) because of their ability to create multivariable models by learning patterns from complex data. Using novel feature selection and evaluation modalities, we identified 5 novel panels of non-amyloid proteins with the potential to serve as biomarkers of early AD. In particular, we found that the combination of A2M, ApoE, BNP, Eot3, RAGE and SGOT may be a key biomarker profile of early disease. Disease detection models based on the identified panels achieved sensitivity (SN) > 80%, specificity (SP) > 70%, and area under receiver operating curve (AUC) of at least 0.80 at prodromal stage (with higher performance at later stages) of the disease. Existing ML models performed poorly in comparison at this stage of the disease, suggesting that the underlying protein panels may not be suitable for early disease detection. Our results demonstrate the feasibility of early detection of AD using non-amyloid based biomarkers.",2021,M. Tomalin; M. J. F. Gales; X. A. Liu; K. C. Sim; R. Sinha; L. Wang; P. C. Woodland; K. Yu,218,226,9,1,10.1109/JBHI.2020.2984355,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9078785,IEEE Journals,IEEE
Understanding Subtitles by Character-Level Sequence-to-Sequence Learning,Character-level;neural machine translation;recurrent neural network (RNN);sequence learning,"This paper presents a character-level seque-nce-to-sequence learning method, RNNembed. This method allows the system to read raw characters, instead of words generated by preprocessing steps, into a pure single neural network model under an end-to-end framework. Specifically, we embed a recurrent neural network into an encoder-decoder framework and generate character-level sequence representation as input. The dimension of input feature space can be significantly reduced as well as avoiding the need to handle unknown or rare words in sequences. In the language model, we improve the basic structure of a gated recurrent unit by adding an output gate, which is used for filtering out unimportant information involved in the attention scheme of the alignment model. Our proposed method was examined in a large-scale dataset on an English-to-Chinese translation task. Experimental results demonstrate that the proposed approach achieves a translation performance comparable, or close, to conventional word-based and phrase-based systems.",2017,O. Castro-Lopez; I. F. Vega-Lopez,616,624,9,70,10.1109/TII.2016.2601521,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547277,IEEE Journals,IEEE
Machine Learning for Efficient Integration of Record Systems for Missing US Service Members,"machine-learning, process automation, record linkage, data integration","More than 16 million Americans served in World War II. Of these service members, over 400,000 were killed in action during the war. Today, more than 72,000 service members remain unaccounted for from World War II. The United States continues to diligently locate, recover, and identify missing personnel from World War II and other past conflicts to provide the fullest possible accounting. This work importantly provides closure and resolution to numerous US families. To fulfill this mission, massive amounts of information must be integrated from historical records, genealogy records, anthropological data, archeological data, odontology data, and DNA. These disparate data sources are produced and maintained by multiple agencies, with different data governance rules and different internal structuring of service member information. Previously, a manual approach had been undertaken to Extract, Transform, Load (ETL) records from these different data sources, which creates the potential for introduced human error. In addition, a large number of person-hours were required to synthesize this data on a biweekly basis. To address this issue, we implemented (i) a regex decision tree to translate genealogical relationships into DNA type availability and (ii) a machine learning approach for record-linkage between disparate data sources. This application is currently in production and greatly reduces person-hours needed and has a very low error rate for record translation and integration.",2019,O. Temam,561,569,9,,10.1109/DSAA.2019.00071,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964203,IEEE Conferences,IEEE
Comparison of the Evaluation Metrics for Neural Grammatical Error Correction With Overcorrection,Grammar error correction;overcorrection;neural machine translation;copy mechanism;metric,"Grammar error correction (GEC) refers to the proper correction of grammatical errors in a given sentence. Important factors to consider in GEC are not only the grammatical correction of the sentence, but also the recognition of a correct sentence in which no changes are required. However, GEC approaches in which deep learning recently started being used consider only the former aspect, which leads to overcorrection, whereby changes are made to a correct sentence unnecessarily. Because this bias is also reflected in performance metrics, conventional performance metrics consider only part of the important factors in GEC. This study proposes a new metric to consider both important aspects in GEC and to provide a new viewpoint for the GEC task. To the best of the authors knowledge, this study is the first to deal with comprehensively considering the correction performance and overcorrection problem in GEC. The experimental results demonstrate that the model performance ranking was reversed when evaluating the performance with the proposed metric compared to the General Language Understanding Evaluation benchmark [21], which only considers the correction performance. This indicates that the high performance of the correction does not result in less problems with the overcorrection and that the overcorrection problem should also be considered when evaluating the model performance. Moreover, we found that the copy mechanism [14] helps to alleviate the problem of overcorrection.",2020,T. Wu; J. Luo; W. Dong; L. Gao; X. Hu; Z. Wu; Y. Sun; J. Liu,106264,106272,9,,10.1109/ACCESS.2020.2998149,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102992,IEEE Journals,IEEE
Accurate Heuristic Terrain Prediction in Powered Lower-Limb Prostheses Using Onboard Sensors,Intent recognition;inertial measurement;machine learning;wearable robotics,"Objective: This study describes the development and offline validation of a heuristic algorithm for accurate prediction of ground terrain in a lower limb prosthesis. This method is based on inference of the ground terrain geometry using estimation of prosthetic limb kinematics during gait with a single integrated inertial measurement unit. Methods: We asked five subjects with below-knee amputations to traverse level ground, stairs, and ramps using a high-range-of-motion powered prosthesis while internal sensor data were remotely logged. We used these data to develop three terrain prediction algorithms. The first two employed state-of-the-art machine learning approaches, while the third was a directly tuned heuristic using thresholds on estimated prosthetic ankle joint translations and ground slope. We compared the performance of these algorithms using resubstitution error for the machine learning algorithms and overall error for the heuristic algorithm. Results: Our optimal machine learning algorithm attained a resubstitution error of 3.4% using 45 features, while our heuristic method attained an overall prediction error of 2.8% using only 5 features derived from estimation of ground slope and horizontal and vertical ankle joint displacement. Compared with pattern recognition, the heuristic performed better on each individual subject, and across both level and non-level strides. Conclusion and significance: These results demonstrate a method for heuristic prediction of ground terrain in a powered prosthesis. The method is more accurate, more interpretable, and less computationally expensive than machine learning methods considered state-of-the-art for intent recognition, and relies only on integrated prosthesis sensors. Finally, the method provides intuitively tunable thresholds to improve performance for specific walking conditions.",2021,V. K. Chippa; D. Mohapatra; A. Raghunathan; K. Roy; S. T. Chakradhar,384,392,9,1,10.1109/TBME.2020.2994152,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091330,IEEE Journals,IEEE
FRIP: a region-based image retrieval tool using automatic image segmentation and stepwise Boolean AND matching,Bayes' theorem;Boolean AND matching;content-based image retrieval (CBIR);finding region in the pictures (FRIP),"We present our region-based image retrieval tool, finding region in the picture (FRIP), that is able to accommodate, to the extent possible, region scaling, rotation, and translation. Our goal is to develop an effective retrieval system to overcome a few limitations associated with existing systems. To do this, we propose adaptive circular filters used for semantic image segmentation, which are based on both Bayes' theorem and texture distribution of image. In addition, to decrease the computational complexity without losing the accuracy of the search results, we extract optimal feature vectors from segmented regions and apply them to our stepwise Boolean AND matching scheme. The experimental results using real world images show that our system can indeed improve retrieval performance compared to other global property-based or region-of-interest-based image retrieval methods.",2005,W. W. GuimarÃ£es; C. L. N. Pinto; C. N. Nobre; L. E. ZÃ¡rate,105,113,9,60,10.1109/TMM.2004.840603,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1386246,IEEE Journals,IEEE
Audio Example Recognition and Retrieval Based on Geometric Incremental Learning Support Vector Machine System,Content audio;wavelet transform;audio feature;audio processing,"With the fast development of computer and information technology, multimedia data has become the most important form of information media. Auditory information plays an important role in information location, this comes from the fact that it can be difficult to find useful information. Thus audio classification becomes more important in audio analysis as it prepares for content-based audio retrieval. There is quite a bit of research on the topic of audio classification methods, audio feature analysis, and extraction based on audio classification. Many works of literature extract features of audio signals based on time or Fourier transform frequency domain. The emergence of the wavelet theory provides a time-frequency analysis tool for signal analysis. Wavelet transformation is a local transformation of the signal in time and frequency which can effectively extract information from the signal, and perform multi-scale refinement analysis on functions or signals through operations such as stretching and translation instead of the traditional Fourier transformation. In the time-frequency analysis of the signal, the wavelet analysis captures the local time and frequency characters of the signal which can improve the ability of signal analysis. It can also change certain locals of the signal without affecting other aspects of it. In this paper, the frequency domain features are combined with the wavelet domain features. At the same time that the MFCC features are extracted, the discrete wavelet transform is used to extract the features of the wavelet domain. Then the statistical features are extracted for each audio example, and the SVM model is used to realize the different forms of audio classification identification.",2020,X. Wang; Z. Tu; M. Zhang,78630,78638,9,1,10.1109/ACCESS.2020.2988686,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072167,IEEE Journals,IEEE
EEG-Based Adaptive Driver-Vehicle Interface Using Variational Autoencoder and PI-TSVM,Brain-controlled vehicle;EEG;semi-supervised learning;variational autoencoder;transductive support vector machine,"Event-related potential (ERP)-based driver-vehicle interfaces (DVIs) have been developed to provide a communication channel for people with disabilities to drive a vehicle. However, they require a tedious and time-consuming training procedure to build the decoding model, which can translate EEG signals into commands. In this paper, to address this problem, we propose an adaptive DVI by using a new semi-supervised algorithm. The decoding model of the proposed DVI is first built with a small labeled training set, and then gradually improved by updating the proposed semi-supervised decoding model with new collected unlabeled EEG signals. In our semi-supervised algorithm, independent component analysis (ICA) and Kalman smoother are first used to improve the signal-to-noise ratio (SNR). After that, variational autoencoder is applied to provide a robust feature representation of EEG signals. Finally, a prior information-based transductive support vector machine (PI-TSVM) classifier is developed to translate these features into commands. Experimental results show that the proposed DVI can significantly reduce the training effort. After a short updating, its performance can be close to that of the supervised DVI requiring a lengthy training procedure. This work is vital for advancing the application of these DVIs.",2019,Y. Liang,2025,2033,9,3,10.1109/TNSRE.2019.2940046,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827606,IEEE Journals,IEEE
Prospective Fall-Risk Prediction Models for Older Adults Based on Wearable Sensors,Accelerometer;pressure-sensing insole;fall risk;older adults;artificial intelligence;machine learning;classifiers,"Wearable sensors can provide quantitative, gait-based assessments that can translate to point-of-care environments. This investigation generated elderly fall-risk predictive models based on wearable-sensor-derived gait data and prospective fall occurrence, and identified the optimal sensor type, location, and combination for single and dual-task walking. 75 individuals who reported six month prospective fall occurrence (75.2 Â± 6.6 years; 47 non-fallers and 28 fallers) walked 7.62 m under single-task and dual-task conditions while wearing pressure-sensing insoles and tri-axial accelerometers at the head, pelvis, and left and right shanks. Fall-risk classification models were assessed for all sensor combinations and three model types: neural network, naÃ¯ve Bayesian, and support vector machine. The best performing model used a neural network, dual-task gait data, and input parameters from head, pelvis, and left shank accelerometers (accuracy = 57%, sensitivity = 43%, and specificity = 65%). The best single-sensor model used a neural network, dual-task gait data, and pelvis accelerometer parameters (accuracy = 54%, sensitivity = 35%, and specificity = 67%). Single-task and dual-task gait assessments provided similar fall-risk model performance. Fall-risk predictive models developed for point-of-care environments should use multi-sensor dual-task gait assessment with the pelvis location considered if assessment is limited to a single sensor.",2017,Y. Qin,1812,1820,9,9,10.1109/TNSRE.2017.2687100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886263,IEEE Journals,IEEE
Know your customer: Detection of Customer Experience (CX) in Social Platforms using Text Categorization,Customer Experience;Text categorization;Social Media;Machine Learning;Data Science,"Customers nowadays are one online post away from their stores, specially when it comes to post-shopping experiences. This translates to large amounts of text messages to evaluate and process for big brands that aim to maintain a good quality of service as well as a digital channel of communication for their customers. Automating the understanding of this text data poses questions such as how large the corpus should be and which are the best algorithms to discriminate whether a social media post is related or not to customer experience (CX). In order to help answering these questions, first, we get hold of posts from three different platforms: Foursquare (77K) , Twitter (153K) and Facebook (2.2M). Such posts are directed to brands ranked in the ForeSee CX Index and the Forrester CX Index rankings. Second, we build a binary classifier using different algorithms to identify customer experience posts on a social platform. The accuracy of the best performing setting is 86.4% for Facebook and 91.2% for Twitter. Third, we explore the effect of increasing the number of training samples, and how a plateau is reached after 5K posts. Finally, we conduct experiments using different combinations of n-grams as features for the text mining process. As a result we observe that uni-grams and bi-grams are the best combination when we need to choose features for a classifier discriminating customer experience social media posts on Twitter and a combination of up to four-grams on Facebook.",2018,Y. Shido; Y. Kobayashi; A. Yamamoto; A. Miyamoto; T. Matsumura,4086,4094,9,,10.1109/BigData.2018.8622556,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622556,IEEE Conferences,IEEE
Assessment of Shift-Invariant CNN Gaze Mappings for PS-OG Eye Movement Sensors,"eye tracking, virtual reality, photo sensor oculography, machine learning","Photosensor oculography (PS-OG) eye movement sensors offer desirable performance characteristics for integration within wireless head mounted devices (HMDs), including low power consumption and high sampling rates. To address the known performance degradation of these sensors due to HMD shifts, various machine learning techniques have been proposed for mapping sensor outputs to gaze location. This paper advances the understanding of a recently introduced convolutional neural network designed to provide shift invariant gaze mapping within a specified range of sensor translations. Performance is assessed for shift training examples which better reflect the distribution of values that would be generated through manual repositioning of the HMD during a dedicated collection of training data. The network is shown to exhibit comparable accuracy for this realistic shift distribution versus a previously considered rectangular grid, thereby enhancing the feasibility of in-field set-up. In addition, this work further demonstrates the practical viability of the proposed initialization process by demonstrating robust mapping performance versus training data scale. The ability to maintain reasonable accuracy for shifts extending beyond those introduced during training is also demonstrated.",2019,Y. Xu; J. Liu; M. Tang; Y. Wen,3651,3659,9,1,10.1109/ICCVW.2019.00450,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022315,IEEE Conferences,IEEE
Survey of Sentiment Analysis Using Deep Learning Techniques,Sentiment Analysis;Natural Language Processing;Machine Learning;Deep Learning;Convolution Neural Network;Recurrent Neural Network;Long Short Term Memory,"This paper presents a detailed review of deep learning techniques used in Sentiment Analysis. Sentiment analysis is one of the most researched areas in natural language processing. Natural language processing has a wide range of applications like voice recognition, machine translation, product review, aspect oriented product analysis, sentiment analysis and text classification like email categorization and spam filtering. The conventional methods used for sentiment analysis is lexicon based processing. However, with the advancements in the field of artificial intelligence, the machine learning algorithms started to play a major role in sentiment analysis applications. Currently deep learning technique is the latest hotspot being used for predicting the sentiments. Several research works have been carried out in the Natural Language Processing (NLP) using the deep learning methods. The most popular deep learning methods employed includes Convolution Neural Network (CNN) and Recurrent Neural Network (RNN) particularly the Long Short Term Memory (LSTM). These techniques are used in combination or as stand-alone based on the domain area of application. The focus of this survey is on the various flavors of the deep learning methods used in different applications of sentiment analysis at sentence level and aspect/target level. Furthermore, the advantages and drawbacks of the methods are discussed along with their performance parameters.",2019,Z. Wang; G. Xie; J. Du; Y. Zhang,1,9,9,1,10.1109/ICIICT1.2019.8741438,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741438,IEEE Conferences,IEEE
aCortex: An Energy-Efficient Multipurpose Mixed-Signal Inference Accelerator,Artificial neural networks;floating-gate memory;machine learning;mixed-signal circuits;neuromorphic inference accelerator;nonvolatile memory (NVM),"We introduce â€œaCortex,â€? an extremely energy-efficient, fast, compact, and versatile neuromorphic processor architecture suitable for the acceleration of a wide range of neural network inference models. The most important feature of our processor is a configurable mixed-signal computing array of vector-by-matrix multiplier (VMM) blocks utilizing embedded nonvolatile memory arrays for storing weight matrices. Analog peripheral circuitry for data conversion and high-voltage programming are shared among a large array of VMM blocks to facilitate compact and energy-efficient analog-domain VMM operation of different types of neural network layers. Other unique features of aCortex include configurable chain of buffers and data buses, simple and efficient instruction set architecture and its corresponding multiagent controller, programmable quantization range, and a customized refresh-free embedded dynamic random access memory. The energy-optimal aCortex with 4-bit analog computing precision was designed in a 55-nm process with embedded NOR flash memory. Its physical performance was evaluated using experimental data from testing individual circuit elements and physical layout of key components for several common benchmarks, namely, Inception-v1 and ResNet-152, two state-of-the-art deep feedforward networks for image classification, and GNTM, Google's deep recurrent network for language translation. The system-level simulation results for these benchmarks show the energy efficiency of 97, 106, and 336 TOp/J, respectively, combined with up to 15 TOp/s computing throughput and 0.27-MB/mm2 storage efficiency. Such estimated performance results compare favorably with those of previously reported mixed-signal accelerators based on much less mature aggressively scaled resistive switching memories.",2020,Z. Zhao; C. Luo; A. Solomon; F. Basti; C. Caicedo; M. C. Gursoy; Q. Qiu,98,106,9,,10.1109/JXCDC.2020.2999581,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107115,IEEE Journals,IEEE
Latent Attribute Based Hierarchical Decoder for Neural Machine Translation,Latent attribute;limited vocabulary;hierarchical decoder;neural machine translation (NMT),"Neural machine translation (NMT) has achieved state-of-the-art performance in many translation tasks. However, because the computational cost increases with the size of the search space for predicting the target words, the translation quality of NMT is constrained by the limited vocabulary. To alleviate this problem, we propose a novel dynamic hierarchical decoder for NMT to utilize all of the target words in the training and decoding process. In the proposed model, a target word is represented by two latent attribute vectors rather than a word vector. The model is trained to dynamically put together those words that share similar linguistic attributes. The prediction of a target word is, therefore, turned into the prediction of attribute vectors, where the $\mathrm{softmax}$ functions are performed at the attribute level. This greatly reduces the model size and the decoding time. Our experimental results demonstrate that the proposed model significantly outperforms the NMT baselines in both Chinese-English and English-German translation tasks.",2019,A. Ohri; T. Schmah,2103,2112,10,,10.1109/TASLP.2019.2941587,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839081,IEEE Journals,IEEE
Translation between English and Mauritian Creole: A statistical machine translation approach,Statistical machine translation;Natural language processing;Mauritian Creole;Artificial Intelligence;Technology-enhanced learning;Machine learning,"Translation between one language and another is extensively carried out by students, tourists and business persons. The importance of translation cannot be underestimated, especially with the number of translation devices in use by travellers. Google Translate has set up a multilingual translation system and it is regularly used by people all over the world. In Mauritius, translation of the Mauritian Creole language is not available from Google Translate as the available size of the parallel corpora is quite small. The objective of this study is, therefore, to develop a web-based system for the translation between English language and the Mauritian Creole language for learning the two languages. This project on machine translation for the Mauritian Creole language is a starting point that will benefit the Mauritian population at large as well as the Tourism and Business sectors. Statistical Machine Translation, which is the state of-the-art technique, has been adopted for translation between English and Mauritian Creole language. In this paper, the translation between English and Mauritian Creole language is explored.",2014,A. Ramos-Soto; A. J. BugarÃ­n; S. Barro; J. Taboada,1,10,10,,10.1109/ISTAFRICA.2014.6880635,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6880635,IEEE Conferences,IEEE
Neural Machine Translation With Explicit Phrase Alignment,Alignment;machine translation;natural language processing;neural-networks,"While neural machine translation has achieved state-of-the-art translation performance, it is unable to capture the alignment between the input and output during the translation process. The lack of alignment in neural machine translation models leads to three problems: it is hard to (1) interpret the translation process, (2) impose lexical constraints, and (3) impose structural constraints. These problems not only increase the difficulty of designing new architectures for neural machine translation, but also limit its applications in practice. To alleviate these problems, we propose to introduce explicit phrase alignment into the translation process of arbitrary neural machine translation models. The key idea is to build a search space similar to that of phrase-based statistical machine translation for neural machine translation where phrase alignment is readily available. We design a new decoding algorithm that can easily impose lexical and structural constraints. Experiments show that our approach makes the translation process of neural machine translation more interpretable without sacrificing translation quality. In addition, our approach achieves significant improvements in lexically and structurally constrained translation tasks.",2021,B. Cosenza; J. J. Durillo; S. Ermon; B. Juurlink,1001,1010,10,,10.1109/TASLP.2021.3057831,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351682,IEEE Journals,IEEE
Using Translation Paraphrases from Trilingual Corpora to Improve Phrase-Based Statistical Machine Translation: A Preliminary Report,Statistical Machine Translation;Paraphrases;interlingua,"Statistical methods have proven to be very effective when addressing linguistic problems, specially when dealing with machine translation. Nevertheless, statistical machine translation effectiveness is limited to situations where large amounts of training data are available. Therefore, the broader the coverage of a SMT system is, the better the chances to get a reasonable output are. In this paper we propose a method to improve quality of translations of a phrase-based machine translation system by extending phrase-tables with the use of translation paraphrases learned from a third language. Our experiments were done translating from Spanish to English pivoting through French.",2007,B. Reyes Ayala; J. Chen,163,172,10,,10.1109/MICAI.2007.34,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4659306,IEEE Conferences,IEEE
STD: An Automatic Evaluation Metric for Machine Translation Based on Word Embeddings,Machine translation evaluation;metric;semantic;word embeddings;earth mover's distance;n-gram;word order,"Lexical-based metrics such as BLEU, NIST, and WER have been widely used in machine translation (MT) evaluation. However, these metrics badly represent semantic relationships and impose strict identity matching, leading to moderate correlation with human judgments. In this paper, we propose a novel MT automatic evaluation metric Semantic Travel Distance (STD) based on word embeddings. STD incorporates both semantic and lexical features (word embeddings and n-gram and word order) into one metric. It measures the semantic distance between the hypothesis and reference by calculating the minimum cumulative cost that the embedded n-grams of the hypothesis need to â€œtravelâ€? to reach the embedded n-grams of the reference. Experiment results show that STD has a better and more robust performance than a range of state-of-the-art metrics for both the segment-level and system-level evaluation.",2019,Bin Dong; Qingwei Zhao; Jianping Zhang; Yonghong Yan,1497,1506,10,1,10.1109/TASLP.2019.2922845,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736840,IEEE Journals,IEEE
The RACAI speech translation system challenges of morphologically rich languages,automatic speech recognition;machine translation;speech synthesis;speech to speech translation,"Recent advances in Multilingual Machine Translation and in Speech Processing, coupled with the unprecedented computing power increase of mobile devices, served by faster communication means, made possible the implementation of operational Speech to Speech (S2S) translation systems on smart phones and tablets. Through S2S, a text spoken in one language is automatically recognized, translated and synthesized in another language. This article presents an overview of the first version of our Android-based Romanian-English bi-directional speech translation system and covers the methods and technologies used for implementing it. To the best of our knowledge, this is the first bidirectional S2S for Romanian-English implemented on mobile devices.",2013,C. Lu; X. Li; H. Pan,1,10,10,1,10.1109/SpeD.2013.6682657,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682657,IEEE Conferences,IEEE
An Evaluation of Neural Machine Translation and Pre-trained Word Embeddings in Multilingual Neural Sentiment Analysis,neural sentiment analysis;neural machine translation;deep learning;word embeddings (key words),"One of the main elements in several application domains, such as policy making, addresses the scope of public opinion analysis. The latter is recently realized through sentiment analysis and Natural Language Processing, for identifying and extracting subjective information from raw texts. An additional challenge refers to the exploitation and correlation of data from different languages, in order to analyse sentiments by considering all available information in a holistic way. This paper investigates the impact of Neural Machine Translation in sentiment analysis, based on the translation of text for which neural sentiment analysis in English has been already applied and is applied again on the translated German and Greek texts. The latter is performed through the same Neural Network models that were used in the original language, in order to analyse the differences between the performed neural sentiment analysis on the source and the target languages. The outcomes of the proposed approach have a twofold interpretation. While, it is concluded that modern Neural Machine Translation tools are mature enough to provide high accuracy translations and have minor impact on multilingual sentiment analysis, on the other hand it is shown that additional research should be performed on the multilingualism that pre-trained Word Embeddings can provide.",2020,Ching Chuen Teck; Li Xiang; Zhou Junhong; Li Xiaoli; Cao Hong; D. Woon,274,283,10,,10.1109/PIC50277.2020.9350849,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350849,IEEE Conferences,IEEE
A Hierarchy-to-Sequence Attentional Neural Machine Translation Model,Hierarchy-to-sequence;neural machine translation;natural language processing,"Although sequence-to-sequence attentional neural machine translation (NMT) has achieved great progress recently, it is confronted with two challenges: learning optimal model parameters for long parallel sentences and well exploiting different scopes of contexts. In this paper, partially inspired by the idea of segmenting a long sentence into short clauses, each of which can be easily translated by NMT, we propose a hierarchy-to-sequence attentional NMT model to handle these two challenges. Our encoder takes the segmented clause sequence as input and explores a hierarchical neural network structure to model words, clauses, and sentences at different levels, particularly with two layers of recurrent neural networks modeling semantic compositionality at the word and clause level. Correspondingly, the decoder sequentially translates segmented clauses and simultaneously applies two types of attention models to capture contexts of interclause and intraclause for translation prediction. In this way, we can not only improve parameter learning, but also well explore different scopes of contexts for translation. Experimental results on Chinese-English and English-German translation demonstrate the superiorities of the proposed model over the conventional NMT model.",2018,D. E. Nirmala; B. S. Paul; V. Vaidehi,623,632,10,17,10.1109/TASLP.2018.2789721,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8246560,IEEE Journals,IEEE
Improving Adversarial Neural Machine Translation for Morphologically Rich Language,Neural machine translation (NMT);morp-hologically rich language;adversarial training;morphological word embedding;multiple references,"Generative adversarial networks (GAN) have great successes on natural language processing (NLP) and neural machine translation (NMT). However, the existing discriminator in GAN for NMT only combines two words as one query to train the translation models, which restrict the discriminator to be more meaningful and fail to apply rich monolingual information. Recent studies only consider one single reference translation during model training, this limit the GAN model to learn sufficient information about the representation of source sentence. These situations are even worse when languages are morphologically rich. In this article, an extended version of GAN model for neural machine translation is proposed to optimize the performance of morphologically rich language translation. In particular, we use the morphological word embedding instead of word embedding as input in GAN model to enrich the representation of words and overcome the data sparsity problem during model training. Moreover, multiple references are integrated into discriminator to make the model consider more context information and adapt to the diversity of different languages. Experimental results on Germanâ†”English, Frenchâ†”English, Czechâ†”English, Finnishâ†”English, Turkishâ†”English, Chineseâ†”English, Finnishâ†”Turkish and Turkishâ†”Czech translation tasks demonstrate that our method achieves significant improvements over baseline systems.",2020,D. Gu; Y. Li; F. Jiang; Z. Wen; S. Liu; W. Shi; G. Lu; C. Zhou,417,426,10,,10.1109/TETCI.2019.2960546,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099374,IEEE Journals,IEEE
Neural Machine Translation with Deep Attention,Deep attention network;neural machine translation (NMT);attention-based sequence-to-sequence learning;natural language processing,"Deepening neural models has been proven very successful in improving the model's capacity when solving complex learning tasks, such as the machine translation task. Previous efforts on deep neural machine translation mainly focus on the encoder and the decoder, while little on the attention mechanism. However, the attention mechanism is of vital importance to induce the translation correspondence between different languages where shallow neural networks are relatively insufficient, especially when the encoder and decoder are deep. In this paper, we propose a deep attention model (DeepAtt). Based on the low-level attention information, DeepAtt is capable of automatically determining what should be passed or suppressed from the corresponding encoder layer so as to make the distributed representation appropriate for high-level attention and translation. We conduct experiments on NIST Chinese-English, WMT English-German, and WMT English-French translation tasks, where, with five attention layers, DeepAtt yields very competitive performance against the state-of-the-art results. We empirically find that with an adequate increase of attention layers, DeepAtt tends to produce more accurate attention weights. An in-depth analysis on the translation of important context words further reveals that DeepAtt significantly improves the faithfulness of system translations.",2020,D. I. FernÃ¡ndez; O. Q. Gamboa; J. M. Atencia; O. E. Bedoya,154,163,10,6,10.1109/TPAMI.2018.2876404,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493282,IEEE Journals,IEEE
Dependency-to-Dependency Neural Machine Translation,Syntax;neural machine translation;dependence parsing,"Recent research has proven that syntactic knowledge is effective to improve the performance of neural machine translation (NMT). Most previous work focuses on leveraging either source or target syntax in the recurrent neural network (RNN) based encoder-decoder model. In this paper, we simultaneously use both source and target dependency tree to improve the NMT model. First, we propose a simple but effective syntax-aware encoder to incorporate source dependency tree into NMT. The new encoder enriches each source state with dependence relations from the tree. Then, we propose a novel sequence-to-dependence framework. In this framework, the target translation and its corresponding dependence tree are jointly constructed and modeled. During decoding, the tree structure is used as context to facilitate word generations. Finally, we extend the sequence-to-dependence framework with the syntax-aware encoder to build a dependence-NMT model and apply the dependence-based framework to the Transformer. Experimental results on several translation tasks show that both source and target dependence structures can improve the translation quality and their effects can be accumulated.",2018,D. Lancheros-Cuesta; C. S. Schlenker; L. F. Morales,2132,2141,10,2,10.1109/TASLP.2018.2855968,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410795,IEEE Journals,IEEE
Training Google Neural Machine Translation on an Intel CPU Cluster,machine translation;recurrent neural networks;TensorFlow;LIBXSMM;Intel architecture,"Google's neural machine translation (GNMT) is state-of-the-art recurrent neural network (RNN/LSTM) based language translation application. It is computationally more demanding than well-studied convolutional neural networks (CNNs). Also, in contrast to CNNs, RNNs heavily mix compute and memory bound layers which requires careful tuning on a latency machine to optimally use fast on-die memories for best single processor performance. Additionally, due to massive compute demand, it is essential to distribute the entire workload among several processors and even compute nodes. To the best of our knowledge, this is the first work which attempts to scale this application on an Intel CPU cluster. Our CPU-based GNMT optimization, the first of its kind, achieves this by the following steps: (i) we choose a monolithic long short-term memory (LSTM) cell implementation from LIBXSMM library (specifically tuned for CPUs) and integrate it into TensorFlow, (ii) we modify GNMT code to use fused time step LSTM op for the encoding stage, (iii) we combine Horovod and Intel MLSL scaling libraries for improved performance on multiple nodes, and (iv) we extend the bucketing logic for grouping similar length sentences together to multiple nodes for achieving load balance across multiple ranks. In summary, we demonstrate that due to these changes we are able to outperform Google's stock CPU-based GNMT implementation by ~2x on single node and potentially enable more than 25x speedup using 16 node CPU cluster.",2019,E. Matusov; G. Leusch; R. E. Banchs; N. Bertoldi; D. Dechelotte; M. Federico; M. Kolss; Y. -S. Lee; J. B. Marino; M. Paulik; S. Roukos; H. Schwenk; H. Ney,1,10,10,1,10.1109/CLUSTER.2019.8891019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891019,IEEE Conferences,IEEE
Future-Aware Knowledge Distillation for Neural Machine Translation,Future context;knowledge distillation;natural language processing;neural machine translation,"Although future context is widely regarded useful for word prediction in machine translation, it is quite difficult in practice to incorporate it into neural machine translation. In this paper, we propose a future-aware knowledge distillation framework (FKD) to address this issue. In the FKD framework, we learn to distill future knowledge from a backward neural language model (teacher) to future-aware vectors (student) during the training phase. The future-aware vector for each word position is computed in a bridge network and optimized towards the corresponding hidden state in the backward neural language model via a knowledge distillation mechanism. We further propose an algorithm to jointly train the neural machine translation model, neural language model and knowledge distillation module end-to-end. The learned future-aware vectors are incorporated into the attention layer of the decoder to provide full-range context information during the decoding phase. Experiments on the NIST Chinese-English and WMT English-German translation tasks show that the proposed method significantly improves translation quality and word alignment.",2019,E. Takoulidou; V. Sosoni; K. Kermanidis; M. van Zaanen,2278,2287,10,4,10.1109/TASLP.2019.2946480,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863411,IEEE Journals,IEEE
Assessing the impact of real-time machine translation on requirements meetings: A replicated experiment,Controlled experiment;global software engineering;machine translation;requirements meetings,"Opportunities for global software development are limited in those countries with a lack of English-speaking professionals. Machine translation technology is today available in the form of cross-language web services and can be embedded into multiuser and multilingual chats without disrupting the conversation flow. However, we still lack a thorough understanding of how real-time machine translation may affect communication in global software teams. In this paper, we present the replication of a controlled experiment that assesses the effect of real-time machine translation on multilingual teams while engaged in distributed requirements meetings. In particular, in this replication we specifically evaluate whether non- English speaking groups benefit from communicating in their own native languages when their English is not fluid enough for a fast-paced conversation.",2012,G. Lancioni; R. Villano; F. R. Romani,251,260,10,3,10.1145/2372251.2372299,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6475426,IEEE Conferences,IEEE
Exploiting Morphology and Local Word Reordering in English-to-Turkish Phrase-Based Statistical Machine Translation,Complex morphology;English;statistical machine translation (SMT);Turkish;word reordering,"In this paper, we present the results of our work on the development of a phrase-based statistical machine translation prototype from English to Turkish-an agglutinative language with very productive inflectional and derivational morphology. We experiment with different morpheme-level representations for English-Turkish parallel texts. Additionally, to help with word alignment, we experiment with local word reordering on the English side, to bring the word order of specific English prepositional phrases and auxiliary verb complexes, in line with the morpheme order of the corresponding case-marked nouns and complex verbs, on the Turkish side. To alleviate the dearth of the parallel data available, we also augment the training data with sentences just with content word roots obtained from the original training data to bias root word alignment, and with highly reliable phrase-pairs from an earlier corpus alignment. We use a morpheme-based language model in decoding and a word-based language model in re-ranking the n-best lists generated by the decoder. Lastly, we present a scheme for repairing the decoder output by correcting words which have incorrect morphological structure or which are out-of-vocabulary with respect to the training data and language model, to further improve the translations. We improve from 15.53 BLEU points for our word-based baseline model to 25.17 BLEU points for an improvement of 9.64 points or about 62% relative.",2010,G. Sidhu,1313,1322,10,10,10.1109/TASL.2009.2033321,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5272404,IEEE Journals,IEEE
Hierarchical Transfer Learning Architecture for Low-Resource Neural Machine Translation,Hierarchical transfer learning;low-resource problem;neural machine translation,"Neural Machine Translation(NMT) has achieved notable results in high-resource languages, but still works poorly on low-resource languages. As times goes on, It is widely recognized that transfer learning methods are effective for low-resource language problems. However, existing transfer learning methods are typically based on the parent-child architecture, which does not adequately take advantages of helpful languages. In this paper, inspired by human transitive inference and learning ability, we handle this issue by proposing a new hierarchical transfer learning architecture for low-resource languages. In the architecture, the NMT model is trained in the unrelated high-resource language pair, the similar intermediate language pair and the low-resource language pair in turn. Correspondingly, the parameters are transferred and fine-tuned layer by layer for initialization. In this way, our hierarchical transfer learning architecture simultaneously combines the data volume advantages of high-resource languages and the syntactic similarity advantages of cognate languages. Specially, we utilize Byte Pair Encoding(BPE) and character-level embedding for data pre-processing, which effectively solve the problem of out of vocabulary(OOV). Experimental results on Uygur-Chinese and Turkish-English translation demonstrate the superiorities of the proposed architecture over the NMT model with parent-child architecture.",2019,G. Tsang; S. -M. Zhou; X. Xie,154157,154166,10,2,10.1109/ACCESS.2019.2936002,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805098,IEEE Journals,IEEE
Towards the implementation of an Attention-based Neural Machine Translation with artificial pronunciation for Nahuatl as a mobile application,Nahuatl;NMT;mobile;translation;attention;machine learning;CoreML;neural network;Mel spectrogram,"There are great translation systems online. However, even though this technology is available for the majority of languages, it is not the case of Nahuatl [1]. For this reason, this paper outlines a master's degree thesis proposal which is aimed to use a Neural Network for Translation with an attention mechanism and Long Short-Term Memory (LSTM) like the one used by Google [2]. In addition, it seeks to implement an artificial Text To Speech (TTS) system trained with a Neural Network with a given dataset of Mel spectrograms in [3] from a person speaking in Nahuatl and it attempts to achieve a natural voice output as a spectrogram, then process it and obtain the sound desired. Finally, once trained, these models can be prepared for being used within mobile devices, and even taking advantage of the neural engine some of them are equipped with. In this way, this technology can reach more people and help to preserve and even spread the language. The early results showed how the limited resources of this language could cause a strong bias in the outputs and also how there could be some loss of information given the morphemes Nahuatl has, given its polysynthetic nature. This also highlights the way it can be tokenized, playing an important role in how the results turn out obtaining a BLEU score of 0.34 at best. Finally, this application and research can be an interesting framework of how a polysynthetic language can be manipulated to be used for fusional languages like Spanish or English. This research work was carried out at the â€œTecnolÃ³gico Nacional de MÃ©xicoâ€? (TecNM), campus of the â€œInstituto TecnolÃ³gico de Apizacoâ€? (ITA).",2020,Guo-Feng Pan; Ping He; Ya-Tong Zhou; Jian-Hua Li,235,244,10,,10.1109/CONISOFT50191.2020.00041,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307780,IEEE Conferences,IEEE
Unsupervised Multi-Modal Neural Machine Translation,Vision + Language,"Unsupervised neural machine translation (UNMT) has recently achieved remarkable results \cite{lample2018phrase} with only large monolingual corpora in each language. However, the uncertainty of associating target with source sentences makes UNMT theoretically an ill-posed problem. This work investigates the possibility of utilizing images for disambiguation to improve the performance of UNMT. Our assumption is intuitively based on the invariant property of image, i.e., the description of the same visual content by different languages should be approximately similar. We propose an unsupervised multi-modal machine translation (UMNMT) framework based on the language translation cycle consistency loss conditional on the image, targeting to learn the bidirectional multi-modal translation simultaneously. Through an alternate training between multi-modal and uni-modal, our inference model can translate with or without the image. On the widely used Multi30K dataset, the experimental results of our approach are significantly better than those of the text-only UNMT on the 2016 test dataset.",2019,K. Brink; L. J. G. Bun; J. van Katwijk; R. F. Lutje Spelberg; W. J. Toetenel,10474,10483,10,,10.1109/CVPR.2019.01073,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954072,IEEE Conferences,IEEE
Image Classification in Arabic: Exploring Direct English to Arabic Translations,Image classification;image processing;information retrieval;machine translation;natural language processing,"Image classification is an ongoing research challenge. Most of the current research focuses on image classification in English with very little research in Arabic. Expanding image classification to Arabic has several applications and benefits. This paper investigates the accuracy of direct translations of English labels that are available in ImageNet, a database of images labeled in English that is commonly used in computer vision research, to Arabic. A dataset comprised of 2,887 labeled images was constructed by randomly selecting images from ImageNet. All of the labels were translated to Arabic using an online translation service. The accuracy of each translation was evaluated by a human judge. Results indicated that 65.6% of the generated Arabic labels were accurate with the highest results achieved when the labels consisted of only one word. This study makes three important contributions to the image classification literature: (1) it determines a baseline level of accuracy for image classification in Arabic algorithms; (2) it provides 1,910,935 images classified with accurate Arabic labels (based on accurately labeling 1,895 images that consist of 1,643 unique synsets); and (3) it measures the accuracy of translations of image labels in ImageNet to Arabic.",2019,Li Zhao; F. Li,122730,122739,10,1,10.1109/ACCESS.2019.2926924,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8755849,IEEE Journals,IEEE
The Conceptual Design of a Novel Workstation for Seizure Prediction Using Machine Learning With Potential eHealth Applications,EEG analysis;EEG machine learning computer;seizure prediction;seizure prediction workstation,"Recent attempts to predict refractory epileptic seizures using machine learning algorithms to process electroencephalograms (EEGs) have shown great promise. However, research in this area requires a specialized workstation. Commercial solutions are unsustainably expensive, can be unavailable in most countries, and are not designed specifically for seizure prediction research. On the other hand, building the optimal workstation is a complex task, and system instability can arise from the least obvious sources imaginable. Therefore, the absence of a template for a dedicated seizure prediction workstation in today's literature is a formidable obstacle to seizure prediction research. To increase the number of researchers working on this problem, a template for a dedicated seizure prediction workstation needs to become available. This paper proposes a novel dedicated system capable of machine learning-based seizure prediction and training for under U.S. $1000, which is significantly less expensive (U.S. $700 or more) than comparable commercial solutions. This powerful workstation will be capable of training sophisticated machine learning algorithms that can be deployed to lightweight wearable devices, which enables the creation of wearable EEG-based seizure early warning systems.",2019,M. S. Fujimoto; P. M. Bodily; C. A. Lyman; A. J. Jacobsen; Q. Snell; M. J. Clement,1,10,10,2,10.1109/JTEHM.2019.2910063,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715377,IEEE Journals,IEEE
An IoT-Enabled Stroke Rehabilitation System Based on Smart Wearable Armband and Machine Learning,sEMG control;stroke rehabilitation;IoT-enabled wearable device;machine learning,"Surface electromyography signal plays an important role in hand function recovery training. In this paper, an IoT-enabled stroke rehabilitation system was introduced which was based on a smart wearable armband (SWA), machine learning (ML) algorithms, and a 3-D printed dexterous robot hand. User comfort is one of the key issues which should be addressed for wearable devices. The SWA was developed by integrating a low-power and tiny-sized IoT sensing device with textile electrodes, which can measure, pre-process, and wirelessly transmit bio-potential signals. By evenly distributing surface electrodes over user's forearm, drawbacks of classification accuracy poor performance can be mitigated. A new method was put forward to find the optimal feature set. ML algorithms were leveraged to analyze and discriminate features of different hand movements, and their performances were appraised by classification complexity estimating algorithms and principal components analysis. According to the verification results, all nine gestures can be successfully identified with an average accuracy up to 96.20%. In addition, a 3-D printed five-finger robot hand was implemented for hand rehabilitation training purpose. Correspondingly, user's hand movement intentions were extracted and converted into a series of commands which were used to drive motors assembled inside the dexterous robot hand. As a result, the dexterous robot hand can mimic the user's gesture in a real-time manner, which shows the proposed system can be used as a training tool to facilitate rehabilitation process for the patients after stroke.",2018,M. S. Hossain; H. Mahmood,1,10,10,27,10.1109/JTEHM.2018.2822681,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356006,IEEE Journals,IEEE
A 12-Lead ECG-Based System With Physiological Parameters and Machine Learning to Identify Right Ventricular Hypertrophy in Young Adults,Electrocardiographic system;right ventricular hypertrophy;support vector machine;physiological parameters;young adults,"Objective: The presence of right ventricular hypertrophy (RVH) accounts for approximately 5-10% in young adults. The sensitivity estimated by commonly used 12-lead electrocardiographic (ECG) criteria for identifying the presence of RVH is under 20% in the general population. The aim of this study is to develop a 12-lead ECG system with the related information of age, body height and body weight via machine learning to increase the sensitivity and the precision for detecting RVH. Method: In a sample of 1,701 males, aged 17-45 years, support vector machine is used for the training of 31 parameters including age, body height and body weight in addition to 28 ECG data such as axes, intervals and wave voltages as the inputs to link the output RVH. The RVH is defined on the echocardiographic finding for young males as right ventricular anterior wall thickness > 5.5 mm. Results: On the system goal for increasing sensitivity, the specificity is controlled around 70-75% and all data tested in the proposed method show competent sensitivity up to 70.3%. The values of area under curve of receiver operating characteristic curve and precision-recall curve using the proposed method are 0.780 and 0.285, respectively, which are better than 0.518 and 0.112 using the Sokolow-Lyon voltage criterion, respectively, for detecting unspecific RVH. Conclusion: We present a method using simple physiological parameters with ECG data to effectively identify more than 70% of the RVH among young adults. Clinical Impact: This system provides a fast, precise and feasible diagnosis tool to screen RVH.",2020,M. S. Rahman; Muhammad Firoz Mridha; Sangita Rani Poddar; Mohammad Nurul Huda,1,10,10,3,10.1109/JTEHM.2020.2996370,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097893,IEEE Journals,IEEE
A hybrid part-of-speech tagger for Marathi sentences,POS Ambiguity;Machine Translation;Marathi Grammar rules;Part-of-Speech (POS);Root/Stem of a Word;Stemming;Tagger;YASS,"With thousands of languages in the world, and the increasing speed and quantity of information being distributed across the world, automatic translation between languages by computers, Machine Translation, has become an increasingly important area of research. For a machine to translate text in one natural language to target text in another language, it requires an understanding of the language, its grammar (syntax), its meaning (semantics) and the ability to use this knowledge for making inferences. Words have definite meaning(s) making them deterministic and finite. Words are not ambiguous in their meaning. Context dependency arises when a word is used with a group of words (bag-of-words) in a specific way that causes its meaning to be dependent on the group of words. In this paper, we present a hybrid, multi-pass Part-Of-Speech (POS) tagger developed for Marathi sentences which builds feature vector for each word in a sentence by referring to the previous and next word preceding and succeeding the current word that is being tagged. The analysis of the Marathi input sentence is done first by tokenizing each word in the sentence and finding the stem for each token. Every token is analyzed for its POS tag, the tense, mood and aspect. This process is POS tagging. Ambiguities may arise in the process of tagging.",2018,M. YÄ±ldÎ¹rÄ±m; F. Y. Okay; S. Ã–zdemir,1,10,10,,10.1109/ICCICT.2018.8325898,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325898,IEEE Conferences,IEEE
Empirical Use of Information Retrieval to Build Synthetic Data for SMT Domain Adaptation,Domain adaptation;information retrieval;monolingual corpus;statistical machine translation,"In this paper, we present information retrieval as a powerful tool for addressing an imperative problem in the field of statistical machine translation, i.e., improving translation quality when not enough parallel corpora are available. We devise a framework, which uses information retrieval to create a synthetic corpus from the easily available monolingual corpora. We propose an improved unsupervised training approach with a data selection mechanism, which selects only the most appropriate sentences, thus reducing the amount of data, which is less related to the domain in the additional bitext. We also introduce a new method to choose sentences based on their relative similarity/difference from the query sentence. Using the synthetic corpus created by our method, we are able to improve state-of-the-art statistical machine translation systems.",2016,M. Yang; H. Jiang; Z. Tiejun; S. Li; D. Liu,745,754,10,3,10.1109/TASLP.2016.2517318,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378935,IEEE Journals,IEEE
The NESPOLE! System for multilingual speech communication over the Internet,Distributed processing;machine translation;multimodal interfaces;speech communication,"The NESPOLE! System is a speech communication system designed to support multilingual interaction between common users and providers of e-commerce services over the Internet. The core of the system is a distributed interlingua-based speech-to-speech translation system, which is supported by multimodal capabilities that allow the two parties participating in the communication to share Web pages and graphical content which can be annotated using gestures. We describe the unique features and considerations behind the design and implementation of this system, and evaluate these within the context of a constructed full prototype of the system that was developed for the domain of travel planning",2006,P. Guo; H. Huang; P. Jian; Y. Guo,1664,1673,10,7,10.1109/TSA.2005.858520,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1677986,IEEE Journals,IEEE
Heart Sound Signal Classification Algorithm: A Combination of Wavelet Scattering Transform and Twin Support Vector Machine,Wavelet scattering transform;multidimensional scaling (MDS);twin support vector machine (TWSVM);signal classification,"By classifying the heart sound signals, it can provide very favorable clinical information to the diagnosis of cardiovascular diseases. According to the characteristics of heart sound signals which are complex and difficult to classify and recognize, a new method of feature extraction and classification about heart sound signal is proposed by a combination of wavelet scattering transform and twin support vector machine in this paper. The method is as follows: The heart sound signal data set is firstly divided into two parts, one as a training set and the other as a testing set. Then the wavelet scattering transform is applied to the heart sound signals in the training set and the testing set. The scattering transform is a new time-frequency analysis method. It overcomes the shortcomings of the traditional wavelet transform which has the time-shift changes. It has the advantages of translation invariance and elastic deformation stability. Thus obtain the scattering feature matrix of the heart sound signal. Due to the large dimension of scattering feature matrix, this paper uses multidimensional scaling (MDS) method to reduce the dimension. This method is compared with the classical dimension reduction method-principal component analysis (PCA). Finally, the dimensionality-reduced feature matrix is input into the twin support vector machine (TWSVM) for training. After training the classifier to get the optimal parameters, the dimensionality-reduced scattering feature matrix of the testing signal is input into the classifier for testing. Experimental results show that the classification accuracy of the proposed method can reach 98% or more, and the running time is greatly reduced compared with support vector machine (SVM).",2019,Peng Meng; Liusheng Hang; Wei Yang; Zhili Chen,179339,179348,10,8,10.1109/ACCESS.2019.2959081,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931765,IEEE Journals,IEEE
Automatic Recognition of Activities of Daily Living Utilizing Insole-Based and Wrist-Worn Wearable Sensors,Activities of daily living;activity recognition;insole sensors;machine learning;shoe sensors;wearable sensors,"Automatic recognition of activities of daily living (ADL) is an important component in understanding of energy balance, quality of life, and other areas of health and well-being. In our previous work, we had proposed an insole-based activity monitor-SmartStep, designed to be socially acceptable and comfortable. The goals of the current study were: first, validation of SmartStep in recognition of a broad set of ADL; second, comparison of the SmartStep to a wrist sensor and testing these in combination; third, evaluation of SmartStep's accuracy in measuring wear noncompliance and a novel activity class (driving); fourth, performing the validation in free living against a well-studied criterion measure (ActivPAL, PAL Technologies); and fifth, quantitative evaluation of the perceived comfort of SmartStep. The activity classification models were developed from a laboratory study consisting of 13 different activities under controlled conditions. Leave-one-out cross validation showed 89% accuracy for the combined SmartStep and wrist sensor, 81% for the SmartStep alone, and 69% for the wrist sensor alone. When household activities were grouped together as one class, SmartStep performed equally well compared to the combination of SmartStep and wrist-worn sensor (90% versus 94%), whereas the accuracy of the wrist sensor increased marginally (73% from 69%). SmartStep achieved 92% accuracy in recognition of nonwear and 82% in recognition of driving. Participants then were studied for a day under free-living conditions. The overall agreement with ActivPAL was 82.5% (compared to 97% for the laboratory study). The SmartStep scored the best on the perceived comfort reported at the end of the study. These results suggest that insole-based activity sensors may present a compelling alternative or companion to commonly used wrist devices",2018,R. Pais; L. Gomes; J. P. Barros,979,988,10,14,10.1109/JBHI.2017.2734803,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7999178,IEEE Journals,IEEE
Toward New Retail: A Benchmark Dataset for Smart Unmanned Vending Machines,Unmanned retail;vending machine;object detection;benchmark dataset,"Deep learning is a popular direction in computer vision and digital image processing. It is widely utilized in many fields, such as robot navigation, intelligent video surveillance, industrial inspection, and aerospace. With the extensive use of deep learning techniques, classification and object detection algorithms have been rapidly developed. In recent years, with the introduction of the concept of â€œunmanned retail,â€? object detection, and image classification play a central role in unmanned retail applications. However, open-source datasets of traditional classification and object detection have not yet been optimized for application scenarios of unmanned retail. Currently, classification and object detection datasets do not exist that focus on unmanned retail solely. Therefore, in order to promote unmanned retail applications by using deep learning-based classification and object detection, in this article we collected more than 30 000 images of unmanned retail containers using a refrigerator affixed with different cameras under both static and dynamic recognition environments. These images were categorized into ten kinds of beverages. After manual labeling, images in our constructed dataset contained 155 153 instances, each of which was annotated with a bounding box. We performed extensive experiments on this dataset using ten state-of-the-art deep learning-based models. Experimental results indicate great potential of using these deep learning-based models for real-world smart unmanned vending machines.",2020,R. Singh; M. Paste; N. Shinde; H. Patel; N. Mishra,7722,7731,10,9,10.1109/TII.2019.2954956,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908822,IEEE Journals,IEEE
Predicting Opioid Overdose Readmission and Opioid Use Disorder with Machine Learning,opioid use disorder;opioid dependence;patient readmission;machine learning;electronic health records,"Opioid use disorder (OUD) is a medical condition associated with problematic patterns of opioid use that cause interpersonal and social impairment. This research demonstrates how supervised machine learning can be used to predict patients at risk of hospital readmission following opioid overdose, and to predict patients at risk of developing OUD. Two labeled datasets were built from deidentified hospital data provided by a Level I Trauma Center Hospital. Several machine learning models were constructed (logistic regression, random forest, support vector machine, AdaBoost, XGBoost) and validated with 10 iterations of 10-fold cross validation. The XGBoost classifier can sufficiently predict patients at risk for OUD (AUC = 0.78, precision = 0.71, recall = 0.53). This work can assist providers in determining appropriate preventive care and resources for at-risk patients.",2020,R. Stolyarov; M. Carney; H. Herr,4892,4901,10,,10.1109/BigData50022.2020.9378496,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378496,IEEE Conferences,IEEE
Automated Lung Segmentation and Image Quality Assessment for Clinical 3-D/4-D-Computed Tomography,Biomedical image processing;Image analysis;Classification algorithms;Morphological operations;Machine learning algorithms;Data visualization;Computed tomography;Biomedical image processing;image analysis;classification algorithms;morphological operations;machine learning algorithms;data visualization;computed tomography,"4-D-computed tomography (4DCT) provides not only a new dimension of patient-specific information for radiation therapy planning and treatment, but also a challenging scale of data volume to process and analyze. Manual analysis using existing 3-D tools is unable to keep up with vastly increased 4-D data volume, automated processing and analysis are thus needed to process 4DCT data effectively and efficiently. In this paper, we applied ideas and algorithms from image/signal processing, computer vision, and machine learning to 4DCT lung data so that lungs can be reliably segmented in a fully automated manner, lung features can be visualized and measured on the fly via user interactions, and data quality classifications can be computed in a robust manner. Comparisons of our results with an established treatment planning system and calculation by experts demonstrated negligible discrepancies (within Â±2%) for volume assessment but one to two orders of magnitude performance enhancement. An empirical Fourier-analysis-based quality measure-delivered performances closely emulating human experts. Three machine learners are inspected to justify the viability of machine learning techniques used to robustly identify data quality of 4DCT images in the scalable manner. The resultant system provides a toolkit that speeds up 4-D tasks in the clinic and facilitates clinical research to improve current clinical practice.",2014,R. Zhang; Y. Jin,1,10,10,7,10.1109/JTEHM.2014.2381213,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6994263,IEEE Journals,IEEE
Human Visual System-Based Fundus Image Quality Assessment of Portable Fundus Camera Photographs,Human visual system;machine learning;portable fundus photography;quality assessment,"Telemedicine and the medical â€œbig dataâ€? era in ophthalmology highlight the use of non-mydriatic ocular fundus photography, which has given rise to indispensable applications of portable fundus cameras. However, in the case of portable fundus photography, non-mydriatic image quality is more vulnerable to distortions, such as uneven illumination, color distortion, blur, and low contrast. Such distortions are called generic quality distortions. This paper proposes an algorithm capable of selecting images of fair generic quality that would be especially useful to assist inexperienced individuals in collecting meaningful and interpretable data with consistency. The algorithm is based on three characteristics of the human visual system-multi-channel sensation, just noticeable blur, and the contrast sensitivity function to detect illumination and color distortion, blur, and low contrast distortion, respectively. A total of 536 retinal images, 280 from proprietary databases and 256 from public databases, were graded independently by one senior and two junior ophthalmologists, such that three partial measures of quality and generic overall quality were classified into two categories. Binary classification was implemented by the support vector machine and the decision tree, and receiver operating characteristic (ROC) curves were obtained and plotted to analyze the performance of the proposed algorithm. The experimental results revealed that the generic overall quality classification achieved a sensitivity of 87.45% at a specificity of 91.66%, with an area under the ROC curve of 0.9452, indicating the value of applying the algorithm, which is based on the human vision system, to assess the image quality of non-mydriatic photography, especially for low-cost ophthalmological telemedicine applications.",2016,R. Zhou; S. Kaneko; F. Tanaka; M. Kayamori; M. Shimizu,1046,1055,10,37,10.1109/TMI.2015.2506902,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349228,IEEE Journals,IEEE
A Knowledge-Based Approach to Automatic Detection of Equipment Alarm Sounds in a Neonatal Intensive Care Unit Environment,Acoustic event detection;alarm detection;neonatal intensive care unit;sinusoid detection;non-negative matrix factorization;neural networks,"A large number of alarm sounds triggered by biomedical equipment occur frequently in the noisy environment of a neonatal intensive care unit (NICU) and play a key role in providing healthcare. In this paper, our work on the development of an automatic system for detection of acoustic alarms in that difficult environment is presented. Such automatic detection system is needed for the investigation of how a preterm infant reacts to auditory stimuli of the NICU environment and for an improved real-time patient monitoring. The approach presented in this paper consists of using the available knowledge about each alarm class in the design of the detection system. The information about the frequency structure is used in the feature extraction stage, and the time structure knowledge is incorporated at the post-processing stage. Several alternative methods are compared for feature extraction, modeling, and post-processing. The detection performance is evaluated with real data recorded in the NICU of the hospital, and by using both frame-level and period-level metrics. The experimental results show that the inclusion of both spectral and temporal information allows to improve the baseline detection performance by more than 60%.",2018,S. A. E. El-Din; M. A. A. El-Ghany,1,10,10,,10.1109/JTEHM.2017.2781224,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8234562,IEEE Journals,IEEE
Weather impact on airport arrival meter fix throughput,Air Traffic Control;Airport Meter Fix;Weather;Machine Learning Model,"Time-based flow management provides arrival aircraft schedules based on arrival airport conditions, airport capacity, required spacing, and weather conditions. In order to meet a scheduled time at which aircraft can cross an airport arrival meter fix prior to entering the airport terminal airspace, air traffic controllers impose regulations on air traffic. Severe weather may create an airport arrival bottleneck if one or more of airport arrival meter fixes are partially or completely blocked by the weather and the arrival demand has not been reduced accordingly. Under these conditions, aircraft are frequently put in holding patterns until they can be rerouted. A model that predicts the weather-impacted meter fix throughput may help air traffic controllers direct arrival flows into the airport more efficiently, minimizing arrival meter fix congestion. This paper presents an analysis of air traffic flows across arrival meter fixes at Newark Liberty International Airport (EWR). Several scenarios of weather-impacted EWR arrival fix flows are described. Furthermore, multiple linear regression and regression tree ensemble learning approaches for translating sector Weather Impacted Traffic Indexes (WITI) to EWR arrival meter fix throughput are examined. These weather translation models are developed and validated using EWR arrival flight and weather data for the period of April-September in 2014. This study also compares the performance of the regression tree ensemble with traditional multiple linear regression models for estimating the weather-impacted throughput at each of the EWR arrival meter fixes. For all meter fixes investigated, the results from the regression tree ensemble weather translation models show a stronger correlation between model outputs and observed meter fix throughput than that produced by multiple linear regression method.",2017,S. Kobashi; B. Hossain; M. Nii; S. Kambara; T. Morooka; M. Okuno; S. Yoshiya,1,10,10,,10.1109/DASC.2017.8102133,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8102133,IEEE Conferences,IEEE
Predictive Monitoring of Critical Cardiorespiratory Alarms in Neonates Under Intensive Care,Alarm fatigue;medical devices;machine learning;NICU;patient monitoring;predictive monitoring;real-time monitoring,"We aimed at reducing alarm fatigue in neonatal intensive care units by developing a model using machine learning for the early prediction of critical cardiorespiratory alarms. During this study in over 34,000 patient monitoring hours in 55 infants 278,000 advisory (yellow) and 70,000 critical (red) alarms occurred. Vital signs including the heart rate, breathing rate, and oxygen saturation were obtained at a sampling frequency of 1 Hz while heart rate variability was calculated by processing the ECG - both were used for feature development and for predicting alarms. Yellow alarms that were followed by at least one red alarm within a short post-alarm window constituted the case-cohort while the remaining yellow alarms constituted the control cohort. For analysis, the case and control cohorts, stratified by proportion, were split into training (80%) and test sets (20%). Classifiers based on decision trees were used to predict, at the moment the yellow alarm occurred, whether a red alarm(s) would shortly follow. The best performing classifier used data from the 2-min window before the occurrence of the yellow alarm and could predict 26% of the red alarms in advance (18.4s, median), at the expense of 7% additional red alarms. These results indicate that based on predictive monitoring of critical alarms, nurses can be provided a longer window of opportunity for preemptive clinical action. Further, such as algorithm can be safely implemented as alarms that are not algorithmically predicted can still be generated upon the usual breach of the threshold, as in current clinical practice.",2019,S. Maldonado-Bascon; S. Lafuente-Arroyo; P. Gil-Jimenez; H. Gomez-Moreno; F. Lopez-Ferreras,1,10,10,,10.1109/JTEHM.2019.2953520,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910552,IEEE Journals,IEEE
Use of Accelerometry for Long Term Monitoring of Stroke Patients,Accelerometers or wearable sensors;machine learning algorithms;neurology,"Stroke patients are monitored hourly by physicians and nurses in an attempt to better understand their physical state. To quantify the patients' level of mobility, hourly movement (i.e. motor) assessment scores are performed, which can be taxing and time-consuming for nurses and physicians. In this paper, we attempt to find a correlation between patient motor scores and continuous accelerometer data recorded in subjects who are unilaterally impaired due to stroke. The accelerometers were placed on both upper and lower extremities of four severely unilaterally impaired patients and their movements were recorded continuously for 7 to 14 days. Features that incorporate movement smoothness, strength, and characteristic movement patterns were extracted from the accelerometers using time-frequency analysis. Support vector classifiers were trained with the extracted features to test the ability of the long term accelerometer recordings in predicting dependent and antigravity sides, and significantly above baseline performance was obtained in most instances (P <; 0.05). Finally, a leave-one-subject-out approach was carried out to assess the generalizability of the proposed methodology, and above baseline performance was obtained in two out of the three tested subjects. The methodology presented in this paper provides a simple, yet effective approach to perform long term motor assessment in neurocritical care patients.",2019,S. Mall; U. C. Jaiswal,1,10,10,,10.1109/JTEHM.2019.2897306,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633876,IEEE Journals,IEEE
From Group-Level Statistics to Single-Subject Prediction: Machine Learning Detection of Concussion in Retired Athletes,Event-related potentials;brain injury;electroencephalography;EEG;concussions;machine learning;explainable models,"There has been increased effort to understand the neurophysiological effects of concussion aimed to move diagnosis and identification beyond current subjective behavioral assessments that suffer from poor sensitivity. Recent evidence suggests that event-related potentials (ERPs) measured with electroencephalography (EEG) are persistent neurophysiological markers of past concussions. However, as such evidence is limited to group-level analyzes, the extent to which they enable concussion detection at the individual-level is unclear. One promising avenue of research is the use of machine learning to create quantitative predictive models that can detect prior concussions in individuals. In this paper, we translate the recent group-level findings from ERP studies of concussed individuals into a machine learning framework for performing single-subject prediction of past concussion. We found that a combination of statistics of single-subject ERPs and wavelet features yielded a classification accuracy of 81% with a sensitivity of 82% and a specificity of 80%, improving on current practice. Notably, the model was able to detect concussion effects in individuals who sustained their last injury as much as 30 years earlier. However, failure to detect past concussions in a subset of individuals suggests that the clear effects found in group-level analyses may not provide us with a full picture of the neurophysiological effects of concussion.",2019,S. Pandit; S. K. Bhattacharya; C. Mandal; A. Patra,1492,1501,10,,10.1109/TNSRE.2019.2922553,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735773,IEEE Journals,IEEE
A Unified Analytical Framework for Trustable Machine Learning and Automation Running with Blockchain,machine learning;trust;automation;blockchain,"Traditional machine learning algorithms use data from databases that are mutable, and therefore the data cannot be fully trusted. Also, the machine learning process is difficult to automate. This paper proposes building a trustable machine learning system by using blockchain technology, which can store data in a permanent and immutable way. In addition, smart contracts are used to automate the machine learning process. This paper makes three contributions. First, it establishes a link between machine learning technology and blockchain technology. Previously, machine learning and blockchain have been considered two independent technologies without an obvious link. Second, it proposes a unified analytical framework for trustable machine learning by using blockchain technology. This unified framework solves both the trustability and automation issues in machine learning. Third, it enables a computer to translate core machine learning implementation from a single thread on a single machine to multiple threads on multiple machines running with blockchain by using a unified approach. The paper uses association rule mining as an example to demonstrate how trustable machine learning can be implemented with blockchain, and it shows how this approach can be used to analyze opioid prescriptions to help combat the opioid crisis.",2018,S. Patel; R. S. McGinnis; I. Silva; S. DiCristofaro; N. Mahadevan; E. Jortberg; J. Franco; A. Martin; J. Lust; M. Raj; B. McGrane; P. DePetrillo; A. J. Aranyosi; M. Ceruolo; J. Pindado; R. Ghaffari,4974,4983,10,3,10.1109/BigData.2018.8622262,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622262,IEEE Conferences,IEEE
A Machine Learning Approach for Efficient Parallel Simulation of Beam Dynamics on GPUs,Machine Learning;Irregular application;GPUs;Parallel Simulation,"Parallel computing architectures like GPUs have traditionally been used to accelerate applications with dense and highly-structured workloads; however, many important applications in science and engineering are irregular and dynamic in nature, making their effective parallel implementation a daunting task. Numerical simulation of charged particle beam dynamics is one such application where the distribution of work and data in the accurate computation of collective effects at each time step is irregular and exhibits control-flow and memory access patterns that are not readily amenable to GPU's architecture. Algorithms with these properties tend to present both significant branch and memory divergence on GPUs which leads to severe performance bottlenecks.We present a novel cache-aware algorithm that uses machine learning to address this problem. The algorithm presented here uses supervised learning to adaptively model and track irregular access patterns in the computation of collective effects at each time step of the simulation to anticipate the future control-flow and data access patterns. Access pattern forecast are then used to formulate runtime decisions that minimize branch and memory divergence on GPUs, thereby improving the performance of collective effects computation at a future time step based on the observations from earlier time steps. Experimental results on NVIDIA Tesla K40 GPU shows that our approach is effective in maximizing data reuse, ensuring workload balance among parallel threads, and in minimizing both branch and memory divergence. Further, the parallel implementation delivers up to 485 Gflops of double precision performance, which translates to a speedup of up to 2.5X compared to the fastest known GPU implementation.",2017,S. Punjabi; H. Arsikere; S. Garimella,462,471,10,,10.1109/ICPP.2017.55,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8025320,IEEE Conferences,IEEE
Automatic image hanging protocol for chest radiographs in PACS,Bayesian learning framework;chest radiography;hanging protocol;picture archive and communication system (PACS),"Chest radiography is one of the most widely used techniques in diagnostic imaging. It comprises at least one-third of all diagnostic radiographic procedures in hospitals. However, in the picture archive and communication system, images are often stored with the projection and orientation unknown or mislabeled, which causes inefficiency for radiologists' interpretation. To address this problem, an automatic hanging protocol for chest radiographs is presented. The method targets the most effective region in a chest radiograph, and extracts a set of size-, rotation-, and translation-invariant features from it. Then, a well-trained classifier is used to recognize the projection. The orientation of the radiograph is later identified by locating the neck, heart, and abdomen positions in the radiographs. Initial experiments are performed on the radiographs collected from daily routine chest exams in hospitals and show promising results. Using the presented protocol, 98.2% of all cases could be hung correctly on projection view (without protocol, 62%), and 96.1% had correct orientation (without protocol, 75%). A workflow study on the protocol also demonstrates a significant improvement in efficiency for image display",2006,S. Wei; S. Ji; M. Lu,302,311,10,13,10.1109/TITB.2005.859872,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1613956,IEEE Journals,IEEE
Towards Machine-Learning Assisted Asset Generation for Games: A Study on Pixel Art Sprite Sheets,"Deep Learning, Generative Adversarial Networks, Asset Generation;Procedural Content Generation;Qualitative and Quantitative Analyses, Character Designers Evaluation","Game development is simultaneously a technical and an artistic challenge. The past two decades have brought many improvements to general-purpose game engines, reducing the new games development effort considerably. However, the amount of artistic work per title has continuously grown ever since, as a result of increased audience's expectations. The cost of asset-making is further increased based on the aesthetics chosen by the design team and the availability of professionals capable of understanding the nuances of the specific visual language chosen. In this paper, we dig into the topic of deep-learning assets generation to reduce the costs of the asset making pipeline, a major concern for game development teams. More specifically, we tackle the challenge of generating pixel art sprites from line art sketches using state-of-the-art image translation techniques. We set this work within the pipeline of Trajes Fatais: Suits of Fate, a 2D pixel-art fighting game inspired by the late nineties classics of the fighting genre. The results show that our deep-learning assets generation technique is able to generate sprites that look similar to those created by the artists' team. Moreover, by means of qualitative and quantitative analyses, as well as character designers evaluation, we demonstrate the similarity of the generated results to the ground truth.",2019,T. Fukushima; T. Yoshino,182,191,10,,10.1109/SBGames.2019.00032,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924853,IEEE Conferences,IEEE
Machine Learning-Based Traffic Management Model for UAS Instantaneous Density Prediction in an Urban Area,instantaneous density prediction;UAS;spatial-temporal model;continuous prediction framework,"The number of daily sUAS operations in uncontrolled low altitude airspace is expected to reach into the millions in a few years. Therefore, UAS density prediction has become an emerging and challenging problem. In this paper, a machine learning-based UAS instantaneous density prediction model is presented. The model takes two types of data as input: 1) the historical density generated from the historical data, and 2) the future sUAS mission information. The architecture of our model contains four components: Historical Density Formulation module, UAS Mission Translation module, Mission Feature Extraction module, and Density Map Projection module. The training and testing data are generated by a python based simulator which is inspired by the multi-agent air traffic resource usage simulator (MATRUS) framework. The quality of prediction is measured by the correlation score and the Area Under the Receiver Operating Characteristics (AUROC) between the predicted value and simulated value. The experiment results demonstrate outstanding performance of the machine learning-based UAS density predictor. Compared to the baseline models, for simplified traffic scenario where no-fly zones and safe distance among sUASs are not considered, our model improves the prediction accuracy by up to 15.2% and its correlation score reaches 0.947. In a more realistic scenario, where the no-fly zone avoidance and the safe distance among sUASs are maintained using A* routing algorithm, our model can still achieve 0.822 correlation score. Meanwhile, the AUROC can reach 0.951 for the hot spot prediction. Finally, we extend our UAS instantaneous density prediction model to a continuous prediction framework. By applying the continuous prediction framework, the UAS density prediction time horizon can be significantly increased from 60 simulation cycles to 360 simulation cycles (1 hour), with highest 0.892 correlation score on average. This feature grants us a chance to apply our density prediction model in real-word scenarios.",2020,T. Jitsuhiro; S. Nakamura,1,10,10,,10.1109/DASC50938.2020.9256471,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256471,IEEE Conferences,IEEE
An Automatic Bad Band Pre-Removal Method for Hyperspectral Imagery,Bad band removal;band selection;hyperspectral;matched filter;target detection,"For most hyperspectral remote sensing applications, removing bad bands, such as low signal-to-noise ratio bands, is a required preprocessing step. Currently, the commonly used methods are by visual inspection and the sensor setting. The former is very time-consuming, and the latter is easy to either delete bands with tolerable quality or overlook some noisy bands. In this article, an inherent connection between bad band removal and target detection has been found. As we know, the result of target detection is the linear combination of all bands, and the weight coefficient of each band, i.e., the component of the filter vector, can be considered as the contribution of each band for the detection of targets of interest. Based on this fact, we develop an automatic bad band pre-removal method by using the matched filter (MF) weights of multiple targets within a scene, named the normalized MF weight method (NMFW). Experiments with three well-known hyperspectral data sets show that NMFW cannot only identify most reference bad bands but also extract other corrupted bands that are not labeled as reference bands.",2019,T. KomÃ¡rek; M. Grill; T. PevnÃ½,4985,4994,10,1,10.1109/JSTARS.2019.2944930,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882494,IEEE Journals,IEEE
Automatic Identification of Breast Ultrasound Image Based on Supervised Block-Based Region Segmentation Algorithm and Features Combination Migration Deep Learning Model,Breast tumor;Elastography;Ultrasound images;Convolutional neural network;identification,"Breast cancer is a high-incidence type of cancer for women. Early diagnosis plays a crucial role in the successful treatment of the disease and the effective reduction of deaths. In this paper, deep learning technology combined with ultrasound imaging diagnosis was used to identify and determine whether the tumors were benign or malignant. First, the tumor regions were segmented from the breast ultrasound (BUS) images using the supervised block-based region segmentation algorithm. Then, a VGG-19 network pretrained on the ImageNet dataset was applied to the segmented BUS images to predict whether the breast tumor was benign or malignant. The benchmark data for bio-validation were obtained from 141 patients with 199 breast tumors, including 69 cases of malignancy and 130 cases of benign tumors. The experiment showed that the accuracy of the supervised block-based region segmentation algorithm was almost the same as that of manual segmentation; therefore, it can replace manual work. The diagnostic effect of the combination feature model established based on the depth feature of the B-mode ultrasonic imaging and strain elastography was better than that of the model established based on these two images alone. The correct recognition rate was 92.95%, and the AUC was 0.98 for the combination feature model.",2020,T. Koutsandreas; A. Bajram; C. Mastrokalou; E. Pilalis; A. Chatziioannou; I. Maglogiannis,984,993,10,,10.1109/JBHI.2019.2960821,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936948,IEEE Journals,IEEE
Fault-Attention Generative Probabilistic Adversarial Autoencoder for Machine Anomaly Detection,"Anomaly detection;artificial neural networks;condition monitoring;one-class classification, predictive maintenance","Anomaly detection is one of the most fundamental and indispensable components in predictive maintenance. In this article, anomaly detection is modeled as a one-class classification problem. Based on the scenario that the training data only include healthy state data, a fault-attention generative probabilistic adversarial autoencoder (FGPAA) is proposed to automatically find low-dimensional manifold embedded in high-dimensional space of the signal. Benefited from the characteristics of autoencoder, the signal information loss in feature extraction is reduced. Then, the fault-attention abnormal state indictor can be constructed with the distribution probability of low-dimensional feature and reconstruction error. Effectiveness of the model is verified with fault classification datasets and run-to-failure experimental datasets. The results show that FGPAA outperforms both GPAA and other traditional methods and can be processed in real time. It not only can obtain high accuracy for both classification data and run-to-failure data, but also achieve a certain trend index for run-to-failure data.",2020,T. N. Tan,7479,7488,10,5,10.1109/TII.2020.2976752,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9016153,IEEE Journals,IEEE
Subject Recognition Based on Ground Reaction Force Measurements of Gait Signals,Feature selection;ground reaction forces (GRFs) of gait;human gait analysis;kernel-based support vector machine (SVM) classification;subject recognition;wavelet packet (WP) decomposition;Feature selection;ground reaction forces (GRFs) of gait;human gait analysis;kernel-based support vector machine (SVM) classification;subject recognition;wavelet packet (WP) decomposition,"An effective subject recognition approach is designed in this paper, using ground reaction force (GRF) measurements of human gait. The method is a three-stage procedure: 1) The original GRF data are translated through wavelet packet (WP) transform in the time-frequency domain. Using a fuzzy-set-based criterion, we determine an optimal WP decomposition, involving feature subspaces with distinguishing gait characteristics. 2) A feature extraction scheme is employed next for wavelet feature ranking, according to discrimination power. 3) The classification task is accomplished by means of a kernel-based support vector machine. The design parameters of the classifier are tuned through a genetic algorithm to improve recognition rates. The method is evaluated on a database comprising GRF records obtained from 40 subjects. To account for the natural variability of human gait, the experimental setup is designed, allowing different walking speeds and loading conditions. Simulation results demonstrate that high recognition rates can be achieved with moderate number of features and for different training/testing settings. Finally, the performance of our approach is favorably compared with the one obtained using other traditional classification algorithms.",2008,Tianyong Hao; Yingying Qu; Fang Xia,1476,1485,10,52,10.1109/TSMCB.2008.927722,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637291,IEEE Journals,IEEE
The Classification of Enzymes by Deep Learning,Commission;enzyme classification;machine learning;bioinformatics,"Enzymes, as a group of crucial biocatalysts produced by living cells, enable the chemical reactions in organisms to be more efficient. According to the properties of the reactions catalyzed by enzymes, the Enzyme Commission (EC) number system divided enzymes into 6 primary main classes in 1961: oxidoreductases (EC1), transferases (EC2), hydrolases (EC3), lyases (EC4), isomerases (EC5), and ligases (EC6). These six categories did not change for many years until a new class, the translocases (EC7), was added in August 2018. Different enzymes have different properties of catalytic reaction, and the prediction of enzyme classes is a very important research topic, allowing us to further study the structure and function of enzyme molecules when we know the category of enzyme. Because the number of enzymes whose function remains unknown is enormous, it is time-consuming to use biological experiments to determine enzyme characteristics. Thus, devising various computational models to predict enzyme classes has become a feasible scheme. In hope of giving researchers more inspiration and ideas for predicting the EC number of enzymes by machine learning, we summarize a variety of research methods used in the prediction of enzyme families in this research.",2020,V. Gokhale; J. Jin; A. Dundar; B. Martini; E. Culurciello,89802,89811,10,,10.1109/ACCESS.2020.2992468,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086514,IEEE Journals,IEEE
Detecting Learner Engagement in MOOCs using Automatic Facial Expression Recognition,MOOCs;engagement;facial expressions;e-learning,"Drop out rates in Massive Open Online Courses (MOOCs) are very high. Although there are many external factors, such as users not having enough time or not intending to complete the course, there are some aspects that instructors can control to optimally engage their students. To do this, they need to know how students engage throughout their video lecture. This paper explores the use of webcams to record students' facial expressions whilst they watched educational video material to analyse their Learner Engagement levels. Convolutional neural networks (CNNs) were trained to detect facial action units, which were mapped onto two psychological measurements, valence (emotional state) and arousal (attentiveness), using support vector regressions. These valence and arousal values were combined in a novel manner resulting in Learner Engagement levels. Moreover, a new approach was used to combine CNNs with geometric feature-based techniques to improve the performance of the models. Two experiments were conducted and found that 9 out of 10 CNN models achieved 95% accuracy on average across the majority of the subjects, whilst the Learner Engagement detector was able to identify facial expressions that translated to Learner Engagement levels successfully. These results suggest that there is promise in this approach, in that feedback on students' Learner Engagement can be provided back to the instructor. Additional research should be undertaken to further prove these results and overcome some limitations that were faced.",2020,W. Ying,447,456,10,,10.1109/EDUCON45650.2020.9125149,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9125149,IEEE Conferences,IEEE
WITM: Intelligent Traffic Monitoring Using Fine-Grained Wireless Signal,Intelligent traffic monitoring;WiFi;CSI;machine learning,"With the rapid development of the traffic volume, intelligent traffic monitoring technologies have attracted more and more attention, which can support a broad range of applications, including traffic congestion mitigation, traffic violation management, and automated driving assistance. Therefore, it is important to realize convenient, effective, and intelligent traffic monitoring at low cost. In this paper, we develop a comprehensive traffic monitoring system named WiFi-based intelligent traffic monitoring (WITM), which achieves vehicle detection, vehicle type classification, and vehicle speed estimation by measuring the changes of wireless channel state information. The system shows the advantages of convenient deployment, low cost and easy to expand. The proposed detection processes include three key components, a traffic detection method with moving variance, a convolutional neural network-based learning engine to classify the vehicle types, and a combination method of gradient-based and curve fitting to estimate the vehicle speed. By using the fine-grained wireless signal information, WITM achieves vehicle detection with the accuracy of 93.12% and differentiates vehicle types with an accuracy of 87.27%. In addition, the average error of the vehicle speed estimation is less than 5 km/h.",2020,Y. Gu; Z. Ge; C. P. Bonnington; J. Zhou,206,215,10,1,10.1109/TETCI.2019.2926505,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887224,IEEE Journals,IEEE
VINet: A Visually Interpretable Image Diagnosis Network,Machine learning;neural network;image classification;medical diagnostic imaging,"Recently, due to the black box characteristics of deep learning techniques, the deep network-based computer-aided diagnosis (CADx) systems have encountered many difficulties in practical applications. The crux of the problem is that these models should be explainable the model should give doctors rationales that can explain the diagnosis. In this paper, we propose a visually interpretable network (VINet) which can generate diagnostic visual interpretations while making accurate diagnoses. VINet is an end-to-end model consisting of an importance estimation network and a classification network. The former produces a diagnostic visual interpretation for each case, and the classifier diagnoses the case. In the classifier, by exploring the information in the diagnostic visual interpretation, the irrelevant information in the feature maps is eliminated by our proposed feature destruction process. This allows the classification network to concentrate on the important features and use them as the primary references for classification. Through a joint optimization of higher classification accuracy and eliminating as many irrelevant features as possible, a precise, fine-grained diagnostic visual interpretation, along with an accurate diagnosis, can be produced by our proposed network simultaneously. Based on a computed tomography image dataset (LUNA16) on pulmonary nodule, extensive experiments have been conducted, demonstrating that the proposed VINet can produce state-of-the-art diagnostic visual interpretations compared with all baseline methods.",2020,Y. Jin; W. Xiong,1720,1729,10,,10.1109/TMM.2020.2971170,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8979157,IEEE Journals,IEEE
Assessment of Speech Intelligibility in Parkinsonâ€™s Disease Using a Speech-To-Text System,Parkinsonâ€™s disease;speech analysis;automatic speech recognition;human voice;speech to text,"Patients with Parkinson's disease (PD) may have difficulties in speaking because of reduced coordination of the muscles that control breathing, phonation, articulation, and prosody. Symptoms that may occur are weakening of the volume of the voice, voice monotony, changes in the quality of the voice, the speed of speech, uncontrolled repetition of words, and difficult speech intelligibility. To date, evaluation of the speech intelligibility is performed based on the unified PD rating scale. Specifically, section 3.1 (eloquence) of the cited scale provides the specialist with some tips to evaluate the patient's speech ability. With the aim of evaluating the speech intelligibility by measuring the variation in parameters in an objective manner, we show that a speech-to-text (STT) system could help specialists to obtain an accurate and objective measure of speech, phrase, and word intelligibility in PD. STT systems are based on methodologies and technologies that enable the recognition and translation of spoken language into text by computers and computerized devices. We decided to base our study on Google STT conversion. We expand Voxtester, a software system for digital assessment of voice and speech changes in PD, in order to perform this study. No previous studies have been presented to address the mentioned challenges based on STT. The experiments here presented are related with detection/classification between pathological speech from patients with PD and regular speech from healthy control group. The results are very interesting and are an important step toward assessing the intelligibility of the speech of PD patients.",2017,Y. Liu; C. Yan,22199,22208,10,4,10.1109/ACCESS.2017.2762475,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070308,IEEE Journals,IEEE
Systematic Testing of Database Engines Using a Relational Constraint Solver,SQL;Alloy;Database;Automatic testing;DBMS;Constraint Solver,"We describe an automated approach for systematic black-box testing of database management systems (DBMS) using a relational constraint solver. We reduce the problem of automated database testing into generating three artifacts: (1) SQL queries for testing, (2) meaningful input data to populate test databases, and (3) expected results of executing the queries on the generated data. We leverage our previous work on ADUSA and the Automated SQL Query Generator to form high-quality test suites for testing DBMS engines. This paper presents a detailed description of our framework for Automated SQL Query Generation using the Alloy tool-set, and experimental results of testing database engines using our framework. We show how the main SQL grammar constraints can be solved by translating them to Alloy constraints to generate semantically and syntactically correct SQL queries. We also present experimental results of combining ADUSA and the Automated SQL Query Generator, and applying our framework to test the Oracle 11g database. Our framework generated 5 new queries, which reveal erroneous behavior of Oracle 11g.",2011,Y. Liu; F. Ren,50,59,10,10,10.1109/ICST.2011.21,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5770594,IEEE Conferences,IEEE
Autotuning Stencil Computations with Structural Ordinal Regression Learning,automatic tuning;structural SVMs;stencil computations,"Stencil computations expose a large and complex space of equivalent implementations. These computations often rely on autotuning techniques, based on iterative compilation or machine learning (ML), to achieve high performance. Iterative compilation autotuning is a challenging and time-consuming task that may be unaffordable in many scenarios. Meanwhile, traditional ML autotuning approaches exploiting classification algorithms (such as neural networks and support vector machines) face difficulties in capturing all features of large search spaces. This paper proposes a new way of automatically tuning stencil computations based on structural learning. By organizing the training data in a set of partially-sorted samples (i.e., rankings), the problem is formulated as a ranking prediction model, which translates to an ordinal regression problem. Our approach can be coupled with an iterative compilation method or used as a standalone autotuner. We demonstrate its potential by comparing it with state-of-the-art iterative compilation methods on a set of nine stencil codes and by analyzing the quality of the obtained ranking in terms of Kendall rank correlation coefficients.",2017,Y. Meng; W. Speier; C. Shufelt; S. Joung; J. E Van Eyk; C. N. Bairey Merz; M. Lopez; B. Spiegel; C. W. Arnold,287,296,10,1,10.1109/IPDPS.2017.102,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967118,IEEE Conferences,IEEE
A Real-Time ATC Safety Monitoring Framework Using a Deep Learning Approach,Automatic speech recognition;pilot-controller voice communications;controlling intent inference;slot filling;control safety monitoring,"A deep learning-based safety monitoring framework for air traffic control (ATC) systems is proposed in this paper to reduce human errors and relieve the controllers' workload by regulating the controlling procedure, eliminating communication misunderstanding, monitoring flight conformance, and detecting potential conflicts. The framework comprises automatic speech recognition (ASR), controlling intent inference (CII), and control safety monitoring (CSM) subsystems. The pipeline of the proposed framework can be described as follows: the ASR subsystem translates the pilot-controller voice communications (PCVCs) into texts, which are then converted to the predefined data structure by the CII subsystem. Three types of air traffic safety measures, including repetition check, flight conformance verification, and potential conflict detection, are finally validated by the CSM subsystem. An improved end-to-end ASR model with convolutional, bidirectional long short-term memory (BLSTM) and fully connected (FC) layers is trained using the connectionist temporal classification loss function. The BLSTM and FC combined CII model is designed to infer the controlling intent and slot filling. A language model is also trained in this subsystem to improve the overall performance of the framework. After converting the PCVCs to ATC data, the CSM subsystem checks the given safety monitoring tasks and sends warnings to the current system. The experimental results show that the proposed ASR model obtains a better performance than that of other approaches, and the tasks in the CII subsystem are fulfilled with a high classification precision. The CSM subsystem is also tested to confirm its safety monitoring function by playing back the data and several simulated instructions. To the best of our knowledge, this is pioneering work in the safety monitoring of flight control by recognizing the PCVCs with deep learning-based methods.",2020,Y. Nagashima; K. Araki; K. Tochinai,4572,4581,10,,10.1109/TITS.2019.2940992,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846596,IEEE Journals,IEEE
What do Support Analysts Know About Their Customers? On the Study and Prediction of Support Ticket Escalations in Large Software Organizations,Customer relationship management;machine learning;escalation prediction;customer support ticket,"Understanding and keeping the customer happy is a central tenet of requirements engineering. Strategies to gather, analyze, and negotiate requirements are complemented by efforts to manage customer input after products have been deployed. For the latter, support tickets are key in allowing customers to submit their issues, bug reports, and feature requests. Whenever insufficient attention is given to support issues, however, their escalation to management is time-consuming and expensive, especially for large organizations managing hundreds of customers and thousands of support tickets. Our work provides a step towards simplifying the job of support analysts and managers, particularly in predicting the risk of escalating support tickets. In a field study at our large industrial partner, IBM, we used a design science methodology to characterize the support process and data available to IBM analysts in managing escalations. Through iterative cycles of design and evaluation, we translated our understanding of support analysts' expert knowledge of their customers into features of a support ticket model to be implemented into a Machine Learning model to predict support ticket escalations. We trained and evaluated our Machine Learning model on over 2.5 million support tickets and 10,000 escalations, obtaining a recall of 79.9% and an 80.8% reduction in the workload for support analysts looking to identify support tickets at risk of escalation. Further on-site evaluations, through a prototype tool we developed to implement our Machine Learning techniques in practice, showed more efficient weekly support-ticket-management meetings. The features we developed in the Support Ticket Model are designed to serve as a starting place for organizations interested in implementing our model to predict support ticket escalations, and for future researchers to build on to advance research in escalation prediction.",2017,Y. Qin,362,371,10,8,10.1109/RE.2017.61,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049142,IEEE Conferences,IEEE
Short-Term Photovoltaic Power Forecasting Using an LSTM Neural Network and Synthetic Weather Forecast,PV power forecasting;machine learning;LSTM;neural network;deep learning;synthetic weather forecast,"In this paper, a forecasting algorithm is proposed to predict photovoltaic (PV) power generation using a long short term memory (LSTM) neural network (NN). A synthetic weather forecast is created for the targeted PV plant location by integrating the statistical knowledge of historical solar irradiance data with the publicly available type of sky forecast of the host city. To achieve this, a K-means algorithm is used to classify the historical irradiance data into dynamic type of sky groups that vary from hour to hour in the same season. In other words, the types of sky are defined for each hour uniquely using different levels of irradiance based on the hour of the day and the season. This can mitigate the performance limitations of using fixed type of sky categories by translating them into dynamic and numerical irradiance forecast using historical irradiance data. The proposed synthetic weather forecast is proved to embed the statistical features of the historical weather data, which results in a significant improvement in the forecasting accuracy. The performance of the proposed model is investigated using different intraday horizon lengths in different seasons. It is shown that using the synthetic irradiance forecast can achieve up to 33% improvement in accuracy in comparison to that when an hourly categorical type of sky forecast is used, and up to 44.6% in comparison to that when a daily type of sky forecast is used. This highlights the significance of utilizing the proposed synthetic forecast, and promote a more efficient utilization of the publicly available type of sky forecast to achieve a more reliable PV generation prediction. Moreover, the superiority of the LSTM NN with the proposed features is verified by investigating other machine learning engines, namely the recurrent neural network (RNN), the generalized regression neural network (GRNN) and the extreme learning machine (ELM).",2020,Y. -Z. Low; L. -K. Soon; S. Sapai,172524,172533,10,1,10.1109/ACCESS.2020.3024901,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200614,IEEE Journals,IEEE
Feedback Matching Framework for Semantic Interoperability of Product Data,Concept matching;product lifecycle management (PLM);ranking support vector machine (SVM);semantic interoperability,"There is a need to promote drastically increased levels of interoperability of product data across a broad spectrum of stakeholders, while ensuring that the semantics of product knowledge are preserved, and when necessary, translated. In order to achieve this, multiple methods have been proposed to determine semantic maps across concepts from different representations. Previous research has focused on developing different individual matching methods, i.e., ones that compute mapping based on a single matching measure. These efforts assume that some weighted combination can be used to obtain the overall maps. We analyze the problem of combination of multiple individual methods to determine requirements specific to product development and propose a solution approach called FEedback Matching Framework with Implicit Training (FEMFIT). FEMFIT provides the ability to combine the different matching approaches using ranking Support Vector Machine (ranking SVM). The method accounts for nonlinear relations between the individual matchers. It overcomes the need to explicitly train the algorithm before it is used, and further reduces the decision-making load on the domain expert by implicitly capturing the expert's decisions without requiring him to input real numbers on similarity. We apply FEMFIT to a subset of product constraints across a commercial system and the ISO standard. We observe that FEMIT demonstrates better accuracy (average correctness of the results) and stability (deviation from the average) in comparison with other existing combination methods commonly assumed to be valid in this domain.",2012,Z. Gu; H. Hou; N. Wu; S. Sun,436,445,10,1,10.1109/TASE.2011.2171950,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6074968,IEEE Journals,IEEE
A Heterogeneous Sensing Suite for Multisymptom Quantification of Parkinsonâ€™s Disease,Parkinsonâ€™s disease symptoms;wearable sensor system;machine learning;MMG;telemedicine;muscle stiffness,"Parkinson's disease (PD) is the second most common neurodegenerative disease affecting millions worldwide. Bespoke subject-specific treatment (medication or deep brain stimulation (DBS)) is critical for management, yet depends on precise assessment cardinal PD symptoms - bradykinesia, rigidity and tremor. Clinician diagnosis is the basis of treatment, yet it allows only a cross-sectional assessment of symptoms which can vary on an hourly basis and is liable to inter- and intra-rater subjectivity across human examiners. Automated symptomatic assessment has attracted significant interest to optimise treatment regimens between clinician visits, however, no wearable has the capacity to simultaneously assess all three cardinal symptoms. Challenges in the measurement of rigidity, mapping muscle activity out-of-clinic and sensor fusion have inhibited translation. In this study, we address all through a novel wearable sensor system and machine learning algorithms. The sensor system is composed of a force-sensor, three inertial measurement units (IMUs) and four custom mechanomyography (MMG) sensors. The system was tested in its capacity to predict Unified Parkinson's Disease Rating Scale (UPDRS) scores based on quantitative assessment of bradykinesia, rigidity and tremor in PD patients. 23 PD patients were tested with the sensor system in parallel with exams conducted by treating clinicians and 10 healthy subjects were recruited as a comparison control group. Results prove the system accurately predicts UPDRS scores for all symptoms (85.4% match on average with physician assessment) and discriminates between healthy subjects and PD patients (96.6% on average). MMG features can also be used for remote monitoring of severity and fluctuations in PD symptoms out-of-clinic. This closed-loop feedback system enables individually tailored and regularly updated treatment, facilitating better outcomes for a very large patient population.",2020,Z. Kang; S. Zlatanova,1397,1406,10,1,10.1109/TNSRE.2020.2978197,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064818,IEEE Journals,IEEE
Nondestructive Detection of Targeted Microbubbles Using Dual-Mode Data and Deep Learning for Real-Time Ultrasound Molecular Imaging,Image enhancement/restoration (noise and artifact reduction);machine learning;molecular and cellular imaging;neural network;ultrasound,"Ultrasound molecular imaging (UMI) is enabled by targeted microbubbles (MBs), which are highly reflective ultrasound contrast agents that bind to specific biomarkers. Distinguishing between adherent MBs and background signals can be challenging in vivo. The preferred preclinical technique is differential targeted enhancement (DTE), wherein a strong acoustic pulse is used to destroy MBs to verify their locations. However, DTE intrinsically cannot be used for real-time imaging and may cause undesirable bioeffects. In this work, we propose a simple 4-layer convolutional neural network to nondestructively detect adherent MB signatures. We investigated several types of input data to the network: â€œanatomy-modeâ€? (fundamental frequency), â€œcontrast-modeâ€? (pulse-inversion harmonic frequency), or both, i.e., â€œdual-modeâ€?, using IQ channel signals, the channel sum, or the channel sum magnitude. Training and evaluation were performed on in vivo mouse tumor data and microvessel phantoms. The dual-mode channel signals yielded optimal performance, achieving a soft Dice coefficient of 0.45 and AUC of 0.91 in two test images. In a volumetric acquisition, the network best detected a breast cancer tumor, resulting in a generalized contrast-to-noise ratio (GCNR) of 0.93 and Kolmogorov-Smirnov statistic (KSS) of 0.86, outperforming both regular contrast mode imaging (GCNR = 0.76, KSS = 0.53) and DTE imaging (GCNR = 0.81, KSS = 0.62). Further development of the methodology is necessary to distinguish free from adherent MBs. These results demonstrate that neural networks can be trained to detect targeted MBs with DTE-like quality using nondestructive dual-mode data, and can be used to facilitate the safe and real-time translation of UMI to clinical applications.",2020,Z. Li; N. T. Hung; H. Ikeda; D. Huang,3079,3088,10,2,10.1109/TMI.2020.2986762,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062573,IEEE Journals,IEEE
FairSight: Visual Analytics for Fairness in Decision Making,Fairness in Machine Learning;Visual Analytic,"Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions - understanding, measuring, diagnosing and mitigating biases - that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes.",2020,Z. Wang; J. Poon; S. Poon,1086,1095,10,3,10.1109/TVCG.2019.2934262,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805420,IEEE Journals,IEEE
Real-Time Radiofrequency Ablation Lesion Depth Estimation Using Multi-frequency Impedance With a Deep Neural Network and Tree-Based Ensembles,Radiofrequency ablation;tumor;cancer;control;monitoring;machine learning;ensemble;lesion;depth;deep network;random forest;adaptive boosting,"Objective: Design and optimization of statistical models for use in methods for estimating radiofrequency ablation (RFA) lesion depths in soft real-time performance. Methods: Using tissue multi-frequency complex electrical impedance data collected from a low-cost embedded system, a deep neural network (NN) and tree-based ensembles (TEs) were trained for estimating the RFA lesion depth via regression. Results: Addition of frequency sweep data, previous depth data, and previous RF power state data boosted accuracy of the statistical models. The root mean square errors were 2 mm for NN and 0.5 mm for TEs for previous statistical models and the root mean square errors were 0.4 mm for NN and 0.04 mm for TEs for the statistical models presented in this paper. Simulation ablation performance showed a mean difference against physical measurements of 0.5 Â± 0.2 mm for the NN-based depth estimation method and 0.7 Â± 0.4 mm for the TE-based depth estimation method. Conclusion: The results show that multi-frequency data significantly improves the depth estimation performance of the statistical models. Significance: The RFA lesion depth estimation methods presented in this work achieve millimeter-resolution accuracy with soft realtime performance on an ARMv7-based embedded system for potential translation to clinical RFA technologies.",2020,Zhan Yong; Zhou Yan-Hong; Lu Zheng-Ding,1890,1899,10,,10.1109/TBME.2019.2950342,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886409,IEEE Journals,IEEE
A Hierarchical Clustering Approach to Fuzzy Semantic Representation of Rare Words in Neural Machine Translation,Fuzzy semantic representation (FSR);hierarchical clustering;neural network;neural machine translation (NMT),"Rare words are usually replaced with a single <;unk> token in the current encoder-decoder style of neural machine translation, challenging the translation modeling by an obscured context. In this article, we propose to build a fuzzy semantic representation (FSR) method for rare words through a hierarchical clustering method to group rare words together, and integrate it into the encoder-decoder framework. This hierarchical structure can compensate for the semantic information in both source and target sides, and providing fuzzy context information to capture the semantic of rare words. The introduced FSR can also alleviate the data sparseness, which is the bottleneck in dealing with rare words in neural machine translation. In particular, our method is easily extended to the transformer-based neural machine translation model and learns the FSRs of all in-vocabulary words to enhance the sentence representations in addition to rare words. Our experiments on Chinese-to-English translation tasks confirm a significant improvement in the translation quality brought by the proposed method.",2020,A. Emami; K. Papineni; J. Sorensen,992,1002,11,1,10.1109/TFUZZ.2020.2969399,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970343,IEEE Journals,IEEE
Improving Structural Statistical Machine Translation for Sign Language With Small Corpus Using Thematic Role Templates as Translation Memory,Sign language;small corpus;structural statistical machine translation (SSMT);thematic relation,"This paper presents a structural statistical machine translation (SSMT) model to deal with the data sparseness problem that occurs as a result of the necessarily small corpus to translate Chinese into Taiwanese Sign Language (TSL). A parallel bilingual corpus was developed, and linguistic information from the Sinica Treebank is adopted for Chinese sentence analysis. The synchronous context free grammar (SCFG) was adopted to convert a Chinese structure to the corresponding TSL structure and then extract a translation memory which comprises the thematic relations between the grammar rules of both structures. In structural translation, the statistical MT (SMT) approach was used to align the thematic roles in the grammar rules and the translation memory provides the reference templates for TSL structure translation. Finally, the agreement information for TSL verbs was labeled for enriching the expressiveness of the translated TSL sequence. Several experiments were conducted to evaluate the translation performance and the communication effectiveness for the deaf. The evaluation results demonstrate that the proposed approach outperforms a baseline statistical MT system using the same small corpus, especially for the translation of long sentences.",2009,C. Duan; K. Chen; R. Wang; M. Utiyama; E. Sumita; C. Zhu; T. Zhao,1305,1315,11,13,10.1109/TASL.2009.2016234,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5165114,IEEE Journals,IEEE
Topic-Based Coherence Modeling for Statistical Machine Translation,Text coherence;text analysis;coherence chain;topic modeling;statistical machine translation (SMT);natural language processing,"Coherence that ties sentences of a text into a meaningfully connected structure is of great importance to text generation and translation. In this paper, we propose topic-based coherence models to produce coherence for document translation, in terms of the continuity of sentence topics in a text. We automatically extract a coherence chain for each source text to be translated. Based on the extracted source coherence chain, we adopt a maximum entropy classifier to predict the target coherence chain that defines a linear topic structure for the target document. We build two topic-based coherence models on the predicted target coherence chain: 1) a word level coherence model that helps the decoder select coherent word translations and 2) a phrase level coherence model that guides the decoder to select coherent phrase translations. We integrate the two models into a state-of-the-art phrase-based machine translation system. Experiments on large-scale training data show that our coherence models achieve substantial improvements over both the baseline and models that are built on either document topics or sentence topics obtained under the assumption of direct topic correspondence between the source and target side. Additionally, further evaluations on translation outputs suggest that target translations generated by our coherence models are more coherent and similar to reference translations than those generated by the baseline.",2015,C. Yang,483,493,11,11,10.1109/TASLP.2015.2395254,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050388,IEEE Journals,IEEE
Exploring Diverse Features for Statistical Machine Translation Model Pruning,Classification;statistical machine translation (SMT);syntactic constraints;translation model pruning,"In phrase-based and hierarchical phrase-based statistical machine translation systems, translation performance depends heavily on the size and quality of the translation table. To meet the requirements of making a real-time response, some research has been performed to filter the translation table. However, most existing methods are always based on one or two constraints that act as hard rules, such as not allowing phrase-pairs with low translation probabilities. These approaches sometimes make constraints rigid because they consider only a single factor instead of composite factors. Based on the considerations above, in this paper, we propose a machine learning-based framework that integrates multiple features for translation model pruning. Experimental results show that our framework is effective by pruning 80% of the phrase-pairs and 70% of the hierarchical rules, while retaining the quality of the translation models when using the BLEU evaluation metric. Our study further shows that our method can select the most useful phrase-pairs and rules, including those that are low in frequency but still very useful.",2015,Chun-Xiang Zhang; Sheng Li; Tie-Jun Zhao; Hai-Long Cao,1847,1857,11,3,10.1109/TASLP.2015.2456413,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7156075,IEEE Journals,IEEE
Minimum Bayes-Risk Phrase Table Pruning for Pivot-Based Machine Translation in Internet of Things,Internet of Things;smart services;minimum Bayes risk;pivot-based SMT;phrase table pruning;statistical machine translation,"Machine translation, which will be used widely in human-computer interaction services to Internet of Things (IoT), is a key technology in artificial intelligence field. This paper presents a minimum Bayes-risk (MBR) phrase table pruning method for pivot-based statistical machine translation (SMT). The SMT system requires a great amount of bilingual data to build a high-performance translation model. For some language pairs, such as Chinese-English, massive bilingual data are available on the web. However, for most language pairs, large-scale bilingual data are hard to obtain. Pivot-based SMT is proposed to solve the data scarcity problem: it introduces a pivot language to bridge the source language and the target language. Therefore, a source-target translation model based on well-trained source-pivot and pivot-target translation models can be derived with the pivot-based approach. However, due to the ambiguities of the pivot language, source and target phrases with different meanings may be wrongly matched. Consequently, the derived source-target phrase table may contain incorrect phrase pairs. To alleviate this problem, we apply the MBR method to prune the phrase table. The MBR pruning method removes the phrase pairs with the lowest risk from the phrase table. Experimental results on Europarl data show that the proposed method can both reduce the size of phrase tables and improve the performance of translations. This study also gives a useful reference to many IoT research field and smart web services.",2018,D. Falavigna; M. Gerosa; R. Gretter; D. Giuliani,55754,55764,11,,10.1109/ACCESS.2018.2872773,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476551,IEEE Journals,IEEE
Neural Machine Translation With GRU-Gated Attention Model,Gated recurrent unit (GRU);gated attention model (GAtt);neural machine translation (NMT),"Neural machine translation (NMT) heavily relies on context vectors generated by an attention network to predict target words. In practice, we observe that the context vectors for different target words are quite similar to one another and translations with such nondiscriminatory context vectors tend to be degenerative. We ascribe this similarity to the invariant source representations that lack dynamics across decoding steps. In this article, we propose a novel gated recurrent unit (GRU)-gated attention model (GAtt) for NMT. By updating the source representations with the previous decoder state via a GRU, GAtt enables translation-sensitive source representations that then contribute to discriminative context vectors. We further propose a variant of GAtt by swapping the input order of the source representations and the previous decoder state to the GRU. Experiments on the NIST Chinese-English, WMT14 English-German, and WMT17 English-German translation tasks show that the two GAtt models achieve significant improvements over the vanilla attention-based NMT. Further analyses on the attention weights and context vectors demonstrate the effectiveness of GAtt in enhancing the discriminating capacity of representations and handling the challenging issue of overtranslation.",2020,D. Li,4688,4698,11,1,10.1109/TNNLS.2019.2957276,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948335,IEEE Journals,IEEE
Neural Machine Translation With Noisy Lexical Constraints,Neural machine translation;lexical constraints,"In neural machine translation, lexically constrained decoding generates translation outputs strictly including the constraints predefined by users, and it is beneficial to improve translation quality at the cost of more decoding overheads if the constraints are perfect. Unfortunately, those constraints may contain mistakes in real-world situations and incorrect constraints will undermine lexically constrained decoding. In this article, we propose a novel framework that is capable of improving the translation quality even if the constraints are noisy. The key to our framework is to treat the lexical constraints as external memories. More concretely, it encodes the constraints by a memory encoder and then leverages the memories by a memory integrator. Experiments demonstrate that our framework can not only deliver substantial BLEU gains in handling noisy constraints, but also achieve speedup in decoding. These results motivate us to apply our models to a new scenario where the constraints are generated without the help of users. Experiments show that our models can indeed improve the translation quality with the automatically generated constraints.",2020,E. Varsha; P. C. Rafeeque,1864,1874,11,,10.1109/TASLP.2020.2999724,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108255,IEEE Journals,IEEE
Translation Quality Estimation Using Only Bilingual Corpora,Conditional random fields;feed-forward neural networks;machine translation;maximum marginal likelihood estimation;recurrent neural networks;translation quality estimation,"In computer-aided translation scenarios, quality estimation of machine translation hypotheses plays a critical role. Existing methods for word-level translation quality estimation (TQE) rely on the availability of manually annotated TQE training data obtained via direct annotation or postediting. However, due to the cost of human labor, such data are either limited in size or is only available for few tasks in practice. To avoid the reliance on such annotated TQE data, this paper proposes an approach to train word-level TQE models using bilingual corpora, which are typically used in machine translation training and is relatively easier to access. We formalize the training of our proposed method under the framework of maximum marginal likelihood estimation. To avoid degenerated solutions, we propose a novel regularized training objective whose optimization is achieved by an efficient approximation. Extensive experiments on both written and spoken language datasets empirically show that our approach yields comparable performance to the standard training on annotated data.",2017,G. Jose; N. S. Raj,1762,1772,11,1,10.1109/TASLP.2017.2716195,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7949019,IEEE Journals,IEEE
Meaningful Variable Names for Decompiled Code: A Machine Translation Approach,Decompilation;Understandability;Statistical Machine Translation;Renaming Identifiers,"When code is compiled, information is lost, including some of the structure of the original source code as well as local identifier names. Existing decompilers can reconstruct much of the original source code, but typically use meaningless placeholder variables for identifier names. Using variable names which are more natural in the given context can make the code much easier to interpret, despite the fact that variable names have no effect on the execution of the program. In theory, it is impossible to recover the original identifier names since that information has been lost. However, most code is natural: it is highly repetitive and predictable based on the context. In this paper we propose a technique that assigns variables meaningful names by taking advantage of this naturalness property. We consider decompiler output to be a noisy distortion of the original source code, where the original source code is transformed into the decompiler output. Using this noisy channel model, we apply standard statistical machine translation approaches to choose natural identifiers, combining a translation model trained on a parallel corpus with a language model trained on unmodified C code. We generate a large parallel corpus from 1.2 TB of C source code obtained from GitHub. Under the most conservative assumptions, our technique is still able to recover the original variable names up to 16.2% of the time, which represents a lower bound for performance.",2018,G. TirkeÅŸ; C. Ã‡. Ekin; G. engul; A. Bostan; M. Karakaya,2000,2010,11,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8973072,IEEE Conferences,IEEE
Multi-Information Spatialâ€“Temporal LSTM Fusion Continuous Sign Language Neural Machine Translation,Continuous SLR;attention;ST-LSTM;neural machine translation;CNN,"There are two basic problems in sign language recognition (SLR): (a) isolated word SLR and (b) continuous SLR. Most of the existing continuous SLR methods are extensions of the isolated word SLR methods. These methods use the isolated word SLR results as the basic module and obtain the sentence recognition results through sentence segmentation and word alignment. However, sentence segmentation and word alignment are often not accurate, resulting in a low sentence recognition accuracy. At the same time, continuous SLR usually requires strict sample labels, leading to the difficult task of manual labeling and limited training data availability. To address these challenges, this paper proposes a bidirectional spatial-temporal LSTM fusion attention network (Bi-ST-LSTM-A) for continuous SLR. This approach avoids problems such as sentence segmentation, word alignment, and tedious manual labeling. Our contributions are summarized as follows: (1) we proposed a sign language video feature representation method using a convolutional neural network (CNN) and spatial-temporal LSTM (ST-LSTM) information fusion technology; and (2) we constructed a uniform neural machine translation framework that can be used for complex continuous SLR and gesture recognition of nonspecific people in nonspecific environments. Experiments were carried out on some large continuous sign language datasets. The sign language recognition accuracy reached 81.22% on the 500 CSL dataset, 76.12% on the RWTH-PHOENIX-Weather dataset and 75.32% on the RWTH-PHOENIX-Weather-2014T dataset, thereby illustrating the effectiveness of the proposed framework.",2020,H. d. M. Caseli; I. A. Nunes,216718,216728,11,1,10.1109/ACCESS.2020.3039539,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265176,IEEE Journals,IEEE
AlignVis: Semi-automatic Alignment and Visualization of Parallel Translations,Information Visualization;Parallel Translations;Alignment,"Digital humanities and translation scholars utilize off-the-shelf tools to align multiple related translations. These tools generally rely solely on domain expert knowledge and do not exploit the recent advancements in computational linguistics and text mining. This paper presents AlignVis, a visual tool that provides a semi-automatic alignment framework to align multiple translations. It presents the results of using text similarity measurements and enables the user to create, verify, and edit alignments using a novel visual interface. The design consists of three main components: the alignment editor canvas, the post-edit area, and the user options panel. AlignVis exploits both close and distant reading and is designed to help digital humanities and translation scholars enhance the process of text alignment for multiple translations. The design of AlignVis is driven by iterative discussions with the domain expert which resulted in five benefits: presenting an overview of the aligned translations, support for multiple alignments, enhancement and acceleration of the alignment process, alignment refinement, and testing different similarity measurements. We evaluate AlignVis with domain expert feedback and a comparison with a standard alignment tool and computational and visual alignment tools.",2020,J. Nair,98,108,11,,10.1109/IV51561.2020.00026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373142,IEEE Conferences,IEEE
Computer-assisted translation using speech recognition,Computer-assisted translation (CAT);speech recognition;statistical machine translation,"Current machine translation systems are far from being perfect. However, such systems can be used in computer-assisted translation to increase the productivity of the (human) translation process. The idea is to use a text-to-text translation system to produce portions of target language text that can be accepted or amended by a human translator using text or speech. These user-validated portions are then used by the text-to-text translation system to produce further, hopefully improved suggestions. There are different alternatives of using speech in a computer-assisted translation system: From pure dictated translation to simple determination of acceptable partial translations by reading parts of the suggestions made by the system. In all the cases, information from the text to be translated can be used to constrain the speech decoding search space. While pure dictation seems to be among the most attractive settings, unfortunately perfect speech decoding does not seem possible with the current speech processing technology and human error-correcting would still be required. Therefore, approaches that allow for higher speech recognition accuracy by using increasingly constrained models in the speech recognition process are explored here. All these approaches are presented under the statistical framework. Empirical results support the potential usefulness of using speech within the computer-assisted translation paradigm.",2006,J. R. Medina; J. Kalita,941,951,11,14,10.1109/TSA.2005.857788,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1621206,IEEE Journals,IEEE
Automatic Inference of Java-to-Swift Translation Rules for Porting Mobile Applications,source to source translation;iterative rule inference;minimalist domain knowledge,"A native cross-platform mobile app has multiple platform-specific implementations. Typically, an app is developed for one platform and then ported to the remaining ones. Translating an app from one language (e.g., Java) to another (e.g., Swift) by hand is tedious and error-prone, while automated translators either require manually defined translation rules or focus on translating APIs. To automate the translation of native cross-platform apps, we present j2SINFERER, a novel approach that iteratively infers syntactic transformation rules and API mappings from Java to Swift. Given a software corpus in both languages, j2SINFERER first identifies the syntactically equivalent code based on braces and string similarity. For each pair of similar code segments, j2SINFERER then creates syntax trees of both languages, leveraging the minimalist domain knowledge of language correspondence (e.g., operators and markers) to iteratively align syntax tree nodes, and to infer both syntax and API mapping rules. j2SINFERER represents inferred rules as string templates, stored in a database, to translate code from Java to Swift. We evaluated j2SINFERER with four applications, using one part of the data to infer translation rules, and the other part to apply the rules. With 76% in-project accuracy and 65% cross-project accuracy, j2SINFERER outperforms in accuracy j2swift, a state-of-the-art Java-to-Swift conversion tool. As native cross-platform mobile apps grow in popularity, j2SINFERER can shorten their time to market by automating the tedious and error prone task of source-to-source translation.",2018,J. Sun; S. Sun; Y. Chen; L. J. Jiang,180,190,11,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543453,IEEE Conferences,IEEE
Machine translation survey for Punjabi and Urdu languages,Shamukhi;Gurmukhi;MTS;Rule-based,"Computer technology plays a major role in human's life, so the automatic translation perspectives are important for making communication possible among each other. Translation from one regional language to another national or international language is important to understand the information and technology expressed in that language. This led to the inception of machine translation from regional language to national or international language. Machine translation is a field of Natural Language Processing (NLP) and Artificial Intelligence (AI), where it deals with translation from one language to another language. The statistical machine translation approach is popular in automatic translation research area with good accuracy. This paper gives a review of the work done in Punjabi and Urdu languages. To the best of our knowledge, no work is available on Punjabi to Urdu MTS methodology, but Urdu to Punjabi MTS is already developed [Umrinder Pal Singh et. al, 2016]. Punjabi is a regional language as well as official language of Indian state, Punjab. All state government related work within Punjab is done in Punjabi language only, written in two scripts i.e. Gurmukhi and Shahmukhi. Urdu is an international language, where most of the Muslim states/countries use Urdu language only. This paper also surveys the various Indian Machine Translation systems and existing methods for evaluating the translated output of various MTS.",2017,K. A. Patel; J. S. Pareek,1,11,11,1,10.1109/ICACCAF.2017.8344667,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344667,IEEE Conferences,IEEE
Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation,Algorithms;Education;Statistical Approach,"Pseudo-code written in natural language can aid the comprehension of source code in unfamiliar programming languages. However, the great majority of source code has no corresponding pseudo-code, because pseudo-code is redundant and laborious to create. If pseudo-code could be generated automatically and instantly from given source code, we could allow for on-demand production of pseudo-code without human effort. In this paper, we propose a method to automatically generate pseudo-code from source code, specifically adopting the statistical machine translation (SMT) framework. SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort. In experiments, we generated English or Japanese pseudo-code from Python statements using SMT, and find that the generated pseudo-code is largely accurate, and aids code understanding.",2015,M. Nimaiti; Y. Izumi,574,584,11,53,10.1109/ASE.2015.36,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372045,IEEE Conferences,IEEE
Adequacyâ€“Fluency Metrics: Evaluating MT in the Continuous Space Model Framework,Machine translation;natural language processing;system evaluation,"This work extends and evaluates a two-dimensional automatic evaluation metric for machine translation, which is designed to operate at the sentence level. The metric is based on the concepts of adequacy and fluency, aiming at decoupling both semantic and syntactic components of the translation process to provide a more balanced view on translation quality. These two elements are independently evaluated by using continuous space and n-gram language modeling frameworks, respectively. Two different implementations are evaluated: a monolingual version that fully operates on the target language side, and a cross-language version that has the main advantage of not requiring reference translations. Both implementations are evaluated by comparing their performance with state-of-the-art automatic metrics over a dataset involving five different European languages.",2015,M. Trudel; C. A. Furia; M. Nordio,472,482,11,14,10.1109/TASLP.2015.2405751,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045551,IEEE Journals,IEEE
Improved Machine Reading Comprehension Using Data Validation for Weakly Labeled Data,Computational and artificial intelligence;data validation;natural language processing;neural networks;machine reading comprehension;weak label,"Machine reading comprehension (MRC) is a natural language processing task wherein a given question is answered according to a holistic understanding of a given context. Recently, many researchers have shown interest in MRC, for which a considerable number of datasets are being released. Datasets for MRC, which are composed of the context-query-answer triple, are designed to answer a given query by referencing and understanding a readily-available, relevant context text. The TriviaQA dataset is a weakly labeled dataset, because it contains irrelevant context that forms no basis for answering the query. The existing syntactic data cleaning method struggles to deal with the contextual noise this irrelevancy creates. Therefore, a semantic data cleaning method using reasoning processes is necessary. To address this, we propose a new MRC model in which the TriviaQA dataset is validated and trained using a high-quality dataset. The data validation method in our MRC model improves the quality of the training dataset, and the answer extraction model learns with the validated training data, because of our validation method. Our proposed method showed a 4.33% improvement in performance for the TriviaQA Wiki, compared to the existing baseline model. Accordingly, our proposed method can address the limitation of irrelevant context in MRC better than the human supervision.",2020,N. A. Golilarz; A. Addeh; H. Gao; L. Ali; A. M. Roshandeh; H. Mudassir Munir; R. U. Khan,5667,5677,11,1,10.1109/ACCESS.2019.2963569,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948019,IEEE Journals,IEEE
"Do Contexts Help in Phrase-Based, Statistical Source Code Migration?",Statistical Machine Translation;Code Migration;Language Migration;Semantic Features;Context Integration,"Prior research showed that to migrate Java code to C# by directly applying phrase-based statistical machine translation (SMT) on the lexemes of source code produces much semantically incorrect code. In this work, we conduct empirical studies on several open-source projects to investigate the use of well-defined semantics in programming languages to guide the translation process in SMT. We have investigated five types of features forming the contexts involving the (semantic) relations among code tokens including occurrence association among code tokens, data and control dependencies among program entities, visibility constraints of entities, and the consistency in declarations and accesses of variables, fields and methods. We use the Direct Maximum Entropy (DME) approach for feature integration. Our empirical results show that as individual features added to the baseline SMT model, token association and data dependencies contribute much with highest relative improvement in semantic correctness of up to 18.3% and 18.5%, respectively. The integration of three feature types (token association, data dependencies, and visibility) into the baseline model has highest relative improvement with up to 26.4% improvement in semantic correctness. Generally, 43.5-80.7% of the total translated methods are semantically correct. Our results show a good direction of using SMT with semantic features at different levels of abstraction to improve its accuracy.",2016,N. Tran; H. Tran; S. Nguyen; H. Nguyen; T. Nguyen,155,165,11,6,10.1109/ICSME.2016.89,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816463,IEEE Conferences,IEEE
Question Answering Systems With Deep Learning-Based Symbolic Processing,Deep learning;knowledge base;prolog;question answering system;neural machine translation;symbolic processing;Word2Vec,"The authors propose methods to learn symbolic processing with deep learning and to build question answering systems by means of learned models. Symbolic processing, performed by the Prolog processing systems which execute unification, resolution, and list operations, is learned by a combination of deep learning models, Neural Machine Translation (NMT) and Word2Vec training. To our knowledge, the implementation of a Prolog-like processing system using deep learning is a new experiment that has not been conducted in the past. The results of their experiments revealed that the proposed methods are superior to the conventional methods because symbolic processing (1) has rich representations, (2) can interpret inputs even if they include unknown symbols, and (3) can be learned with a small amount of training data. In particular (2), handling of unknown data, which is a major task in artificial intelligence research, is solved using Word2Vec. Furthermore, question answering systems can be built from knowledge bases written in Prolog with learned symbolic processing, which, with conventional methods, is extremely difficult to accomplish. Their proposed systems can not only answer questions through powerful inferences by utilizing facts that harbor unknown data but also have the potential to build knowledge bases from a large amount of data, including unknown data, on the Web. The proposed systems are a completely new trial, there is no state-of-the-art methods in the sense of â€œnewestâ€?. Therefore, to evaluate their efficiency, they are compared with the most traditional and robust system i.e., the Prolog system. This is new research that encompasses the subjects of conventional artificial intelligence and neural network, and their systems have higher potential to build applications such as FAQ chatbots, decision support systems and energy-efficient estimation using a large amount of information on the Web. Mining hidden information through these applications will provide great value.",2019,P. Kulkarni; P. Bhalerao; K. Nayek; R. V. Deolekar,152368,152378,11,1,10.1109/ACCESS.2019.2948081,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873551,IEEE Journals,IEEE
Statistical Learning of API Fully Qualified Names in Code Snippets of Online Forums,Type Resolution;Type Inference;Type Annotations;Partial Program Analysis;Statistical Machine Translation;Naturalness;Big Code,"Software developers often make use of the online forums such as StackOverflow to learn how to use software libraries and their APIs. However, the code snippets in such a forum often contain undeclared, ambiguous, or largely unqualified external references. Such declaration ambiguity and external reference ambiguity present challenges for developers in learning to correctly use the APIs. In this paper, we propose StatType, a statistical approach to resolve the fully qualified names (FQNs) for the API elements in such code snippets. Unlike existing approaches that are based on heuristics, StatType has two well-integrated factors. We first learn from a large training code corpus the FQNs that often co-occur. Then, to derive the FQN for an API name in a code snippet, we use that knowledge and leverage the context consisting of neighboring API names. To realize those factors, we treat the problem as statistical machine translation from source code with partially qualified names to source code with FQNs of the APIs. Our empirical evaluation on real-world code and StackOverflow posts shows that StatType achieves very high accuracy with 97.6% precision and 96.7% recall, which is 16.5% relatively higher than the state-of-the-art approach.",2018,P. Lambert; J. Gimenez; M. R. Costa-jussa; E. Amigo; R. E. Banchs; L. Marquez; J. A. R. Fonollosa,632,642,11,9,10.1145/3180155.3180230,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453132,IEEE Conferences,IEEE
HyCLASSS: A Hybrid Classifier for Automatic Sleep Stage Scoring,Automatic sleep stage scoring;EEG;hybrid classifier;PSG;sleep stage transition,"Automatic identification of sleep stage is an important step in a sleep study. In this paper, we propose a hybrid automatic sleep stage scoring approach, named HyCLASSS, based on single channel electroencephalogram (EEG). HyCLASSS, for the first time, leverages both signal and stage transition features of human sleep for automatic identification of sleep stages. HyCLASSS consists of two parts: A random forest classifier and correction rules. Random forest classifier is trained using 30 EEG signal features, including temporal, frequency, and nonlinear features. The correction rules are constructed based on stage transition feature, importing the continuity property of sleep, and characteristic of sleep stage transition. Compared with the gold standard of manual scoring using Rechtschaffen and Kales criterion, the overall accuracy and kappa coefficient applied on 198 subjects has reached 85.95% and 0.8046 in our experiment, respectively. The performance of HyCLASS compared favorably to previous work, and it could be integrated with sleep evaluation or sleep diagnosis system in the future.",2018,R. Gulde; M. Tuscher; A. Csiszar; O. Riedel; A. Verl,375,385,11,11,10.1109/JBHI.2017.2668993,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858702,IEEE Journals,IEEE
Generating Commit Messages from Diffs using Pointer-Generator Network,automatic commit message generation;sequence-to-sequence model;pointer-generator network;code change pattern recognition,"The commit messages in source code repositories are valuable but not easy to be generated manually in time for tracking issues, reporting bugs, and understanding codes. Recently published works indicated that the deep neural machine translation approaches have drawn considerable attentions on automatic generation of commit messages. However, they could not deal with out-of-vocabulary (OOV) words, which are essential context-specific identifiers such as class names and method names in code diffs. In this paper, we propose PtrGNCMsg, a novel approach which is based on an improved sequence-to-sequence model with the pointer-generator network to translate code diffs into commit messages. By searching the smallest identifier set with the highest probability, PtrGNCMsg outperforms recent approaches based on neural machine translation, and first enables the prediction of OOV words. The experimental results based on the corpus of diffs and manual commit messages from the top 2,000 Java projects in GitHub show that PtrGNCMsg outperforms the state-of-the-art approach with improved BLEU by 1.02, ROUGE-1 by 4.00 and ROUGE-L by 3.78, respectively.",2019,R. Haque; S. K. Naskar; A. Way; M. R. Costa-jussa; R. E. Banchs,299,309,11,1,10.1109/MSR.2019.00056,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816770,IEEE Conferences,IEEE
Sub-Microwatt Analog VLSI Trainable Pattern Classifier,Micropower techniques;machine learning;biometrics;MOS translinear principle;flash analog memory;smart sensors;vector ADC,"The design and implementation of an analog system-on-chip template-based pattern classifier for biometric signature verification at sub-microwatt power is presented. A programmable array of floating-gate subthreshold MOS translinear circuits matches input features with stored templates and combines the scores into category outputs. Subtractive normalization of the outputs by current-mode feedback produces confidence scores which are integrated for category selection. The classifier implements a support vector machine to select programming values from training samples. A two-step calibration procedure during programming alleviates offset and gain errors in the analog array. A 24-class, 14-input, 720-template classifier trained for speaker identification and fabricated on a 3 mmtimes3 mm chip in 0.5 mum CMOS delivers real-time recognition accuracy on par with floating-point emulation in software. At 40 classifications per second and 840 nW power, the processor attains a computational efficiency of 1.3times1012 multiply-accumulates per second per Watt of power",2007,S. Jiang; A. Armaly; C. McMillan,1169,1179,11,80,10.1109/JSSC.2007.894803,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4160061,IEEE Journals,IEEE
TRACE: A Topological Graph Representation for Automatic Sulcal Curve Extraction,Cortical surface;line simplification;shortest path;sulcal curve;topological graph;valley detection,"A proper geometric representation of the cortical regions is a fundamental task for cortical shape analysis and landmark extraction. However, a significant challenge has arisen due to the highly variable, convoluted cortical folding patterns. In this paper, we propose a novel topological graph representation for automatic sulcal curve extraction (TRACE). In practice, the reconstructed surface suffers from noise influences introduced during image acquisition/surface reconstruction. In the presence of noise on the surface, TRACE determines stable sulcal fundic regions by employing the line simplification method that prevents the sulcal folding pattern from being significantly smoothed out. The sulcal curves are then traced over the connected graph in the determined regions by the Dijkstra's shortest path algorithm. For validation, we used the state-of-the-art surface reconstruction pipelines on a reproducibility data set. The experimental results showed higher reproducibility and robustness to noise in TRACE than the existing method (Li et al. 2010) with over 20% relative improvement in error for both surface reconstruction pipelines. In addition, the extracted sulcal curves by TRACE were well-aligned with manually delineated primary sulcal curves. We also provided a choice of parameters to control quality of the extracted sulcal curves and showed the influences of the parameter selection on the resulting curves.",2018,S. K. T.; C. S. Kumar; K. I. Ramachandran,1653,1663,11,2,10.1109/TMI.2017.2787589,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240660,IEEE Journals,IEEE
Locally Linear Embedding and fMRI Feature Selection in Psychiatric Classification,Nonlinear;dimensionality reduction;image processing;machine learning;kernel methods;optimization;least squares;neurophysiology;evidence-based medicine;(computer-assisted) diagnosis;fMRI;method of image charges;integration;oscillations;theorema egregium,"Background: Functional magnetic resonance imaging (fMRI) provides non-invasive measures of neuronal activity using an endogenous Blood Oxygenation-Level Dependent (BOLD) contrast. This article introduces a nonlinear dimensionality reduction (Locally Linear Embedding) to extract informative measures of the underlying neuronal activity from BOLD time-series. The method is validated using the Leave-One-Out-Cross-Validation (LOOCV) accuracy of classifying psychiatric diagnoses using resting-state and task-related fMRI. Methods: Locally Linear Embedding of BOLD time-series (into each voxel's respective tensor) was used to optimise feature selection. This uses GauÃŸ' Principle of Least Constraint to conserve quantities over both space and time. This conservation was assessed using LOOCV to greedily select time points in an incremental fashion on training data that was categorised in terms of psychiatric diagnoses. Findings: The embedded fMRI gave highly diagnostic performances (> 80%) on eleven publicly-available datasets containing healthy controls and patients with either Schizophrenia, Attention-Deficit Hyperactivity Disorder (ADHD), or Autism Spectrum Disorder (ASD). Furthermore, unlike the original fMRI data before or after using Principal Component Analysis (PCA) for artefact reduction, the embedded fMRI furnished significantly better than chance classification (defined as the majority class proportion) on ten of eleven datasets. Interpretation: Locally Linear Embedding appears to be a useful feature extraction procedure that retains important information about patterns of brain activity distinguishing among psychiatric cohorts.",2019,S. Mall; U. C. Jaiswal,1,11,11,,10.1109/JTEHM.2019.2936348,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807145,IEEE Journals,IEEE
An Open-Source Feature Extraction Tool for the Analysis of Peripheral Physiological Data,Affective computing;biosignal processing;blood pressure (BP);dimensionality reduction;electrocardiogram (ECG);electrodermal activity (EDA);electromyography (EMG);feature extraction;health informatics;impedance cardiography (ICG);machine learning;pattern recognition;quality checking,"Electrocardiogram, electrodermal activity, electromyogram, continuous blood pressure, and impedance cardiography are among the most commonly used peripheral physiological signals (biosignals) in psychological studies and healthcare applications, including health tracking, sleep quality assessment, disease early-detection/diagnosis, and understanding human emotional and affective phenomena. This paper presents the development of a biosignal-specific processing toolbox (Bio-SP tool) for preprocessing and feature extraction of these physiological signals according to the state-of-the-art studies reported in the scientific literature and feedback received from the field experts. Our open-source Bio-SP tool is intended to assist researchers in affective computing, digital and mobile health, and telemedicine to extract relevant physiological patterns (i.e., features) from these biosignals semi-automatically and reliably. In this paper, we describe the successful algorithms used for signal-specific quality checking, artifact/noise filtering, and segmentation along with introducing features shown to be highly relevant to category discrimination in several healthcare applications (e.g., discriminating patterns associated with disease versus non-disease). Further, the Bio-SP tool is a publicly-available software written in MATLAB with a user-friendly graphical user interface (GUI), enabling future crowd-sourced modification to these tools. The GUI is compatible with MathWorks Classification Learner app for inference model development, such as model training, cross-validation scheme farming, and classification result computation.",2018,S. Maskey; A. Sethy,1,11,11,2,10.1109/JTEHM.2018.2878000,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8510820,IEEE Journals,IEEE
Multiple Linear Discriminant Models for Extracting Salient Characteristic Patterns in Capsule Endoscopy Images for Multi-Disease Detection,Capsule endoscopy;linear discriminant analysis;gastrointestinal disease detection;probability density function model;support vector machine,"Background: Computer-aided disease detection schemes from wireless capsule endoscopy (WCE) videos have received great attention by the researchers for reducing physicians' burden due to the time-consuming and risky manual review process. While single disease classification schemes are greatly dealt by the researchers in the past, developing a unified scheme which is capable of detecting multiple gastrointestinal (GI) diseases is very challenging due to the highly irregular behavior of diseased images in terms of color patterns. Method: In this paper, a computer-aided method is developed to detect multiple GI diseases from WCE videos utilizing linear discriminant analysis (LDA) based region of interest (ROI) separation scheme followed by a probabilistic model fitting approach. Commonly in training phase, as pixel-labeled images are available in small number, only the image-level annotations are used for detecting diseases in WCE images, whereas pixel-level knowledge, although a major source for learning the disease characteristics, is left unused. In view of learning the characteristic disease patterns from pixel-labeled images, a set of LDA models are trained which are later used to extract the salient ROI from WCE images both in training and testing stages. The intensity patterns of ROI are then modeled by a suitable probability distribution and the fitted parameters of the distribution are utilized as features in a supervised cascaded classification scheme. Results: For the purpose of validation of the proposed multi-disease detection scheme, a set of pixel-labeled images of bleeding, ulcer and tumor are used to extract the LDA models and then, a large WCE dataset is used for training and testing. A high level of accuracy is achieved even with a small number of pixel-labeled images. Conclusion: Therefore, the proposed scheme is expected to help physicians in reviewing a large number of WCE images to diagnose different GI diseases.",2020,S. Maskey; B. Zhou,1,11,11,,10.1109/JTEHM.2020.2964666,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8962125,IEEE Journals,IEEE
The Identification of Alzheimerâ€™s Disease Using Functional Connectivity Between Activity Voxels in Resting-State fMRI Data,Activity voxels;fMRI;functional connectivity;independent component analysis;support vector machine,"Background: Alzheimer's disease (AD) is a common neurodegenerative disease occurring in the elderly population. The effective and accurate classification of AD symptoms by using functional magnetic resonance imaging (fMRI) has a great significance for the clinical diagnosis and prediction of AD patients. Methods: Therefore, this paper proposes a new method for identifying AD patients from healthy subjects by using functional connectivities (FCs) between the activity voxels in the brain based on fMRI data analysis. Firstly, independent component analysis is used to detect the activity voxels in the fMRI signals of AD patients and healthy subjects; Secondly, the FCs between the common activity voxels of the two groups are calculated, and then the FCs with significant differences are further identified by statistical analysis between them; Finally, the classification of AD patients from healthy subjects is realized by using FCs with significant differences as the feature samples in support vector machine. Results: The results show that the proposed identification method can obtain higher classification accuracy, and the FCs between activity voxels within prefrontal lobe as well as those between prefrontal and parietal lobes play an important role in the prediction of AD patients. Furthermore, we also find that more brain regions and much more voxels in some regions are activity in AD group compared with health control group. Conclusion: It has a great potential value for the AD pathogenesis mechanism study.",2020,S. Mathur; V. P. Saxena,1,11,11,,10.1109/JTEHM.2020.2985022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9056851,IEEE Journals,IEEE
From Optimization-Based Machine Learning to Interpretable Security Rules for Operation,Machine learning;optimal classification trees;power systems operation;security rules;dynamic stability,"Various supervised machine learning approaches have been used in the past to assess the power system security (also known as reliability). This is typically done by training a classifier on a large number of operating points whose postfault status (stable or unstable) has been determined via time-domain simulations. The output of this training process can be expressed as a security rule that is used online to classify an operating point. A critical, and little-studied aspect of these approaches is the interpretability of the rules produced. The lack of interpretability is a well-known issue of some machine learning approaches, especially when dealing with difficult classification problems. In the case of the security assessment of the power system, which is a complex mission-critical task, interpretability is a key requirement for the adoption and deployment by operators of these approaches. In this paper, for the first time, we explore the tradeoff between predictive accuracy and interpretability in the context of power system security assessment. We begin by demonstrating how decision trees (DTs) can be used to learn data-driven security rules and use the tree depth as a measure for interpretability. We leverage disjunctive programming to formulate novel training methods, capable of learning high-quality DTs while still maintaining interpretability. In particular, we propose two new approaches: 1) optimal classification trees is proposed for training DTs of low-depth and 2) greedy optimization-based tree is proposed for training DTs of intermediate depth, where the increased computational burden is managed by exploiting the nested tree structure. We also demonstrate that the ability to generate high-quality interpretable rules can actually translate to impressive benefits in terms of training requirements. Through case studies on the IEEE 68-bus system, we demonstrate that the proposed methods can produce DTs of higher quality compared to the state-of-the-art approach classification and regression tree approach, also if the DT was trained on a significant smaller database, resulting in computational savings of 80%. Given that generating a large training database is a practical bottleneck in these data-driven approaches, this is a significant breakthrough for real-world application.",2019,S. McDougall; P. Annapureddy; P. Madiraju; N. Fumo; S. Hargarten,3826,3836,11,7,10.1109/TPWRS.2019.2911598,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692582,IEEE Journals,IEEE
Alignment-Supervised Bidimensional Attention-Based Recursive Autoencoders for Bilingual Phrase Representation,Alignment supervision;attention network;bilingual phrase representation;machine translation;recursive autoencoder (RAE),"Exploiting semantic interactions between the source and target linguistic items at different levels of granularity is crucial for generating compact vector representations for bilingual phrases. To achieve this, we propose alignment-supervised bidimensional attention-based recursive autoencoders (ABattRAE) in this paper. ABattRAE first individually employs two recursive autoencoders to recover hierarchical tree structures of bilingual phrase, and treats the subphrase covered by each node on the tree as a linguistic item. Unlike previous methods, ABattRAE introduces a bidimensional attention network to measure the semantic matching degree between linguistic items of different languages, which enables our model to integrate information from all nodes by dynamically assigning varying weights to their corresponding embeddings. To ensure the accuracy of the generated attention weights in the attention network, ABattRAE incorporates word alignments as supervision signals to guide the learning procedure. Using the general stochastic gradient descent algorithm, we train our model in an end-to-end fashion, where the semantic similarity of translation equivalents is maximized while the semantic similarity of nontranslation pairs is minimized. Finally, we incorporate a semantic feature based on the learned bilingual phrase representations into a machine translation system for better translation selection. Experimental results on NIST Chinese-English and WMT English-German test sets show that our model achieves substantial improvements of up to 2.86 and 1.09 BLEU points over the baseline, respectively. Extensive in-depth analyses demonstrate the superiority of our model in learning bilingual phrase embeddings.",2020,Sanghwa Yuh; Jungyun Seo,503,513,11,2,10.1109/TCYB.2018.2868982,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472901,IEEE Journals,IEEE
Detecting Clinically Meaningful Shape Clusters in Medical Image Data: Metrics Analysis for Hierarchical Clustering Applied to Healthy and Pathological Aortic Arches,Aortic arch;automatic segmentation;cardiovascular magnetic resonance imaging;clinical decision support;congenital heart disease;hierarchical clustering;statistical shape analysis,"Objective: Today's growing medical image databases call for novel processing tools to structure the bulk of data and extract clinically relevant information. Unsupervised hierarchical clustering may reveal clusters within anatomical shape data of patient populations as required for modern precision medicine strategies. Few studies have applied hierarchical clustering techniques to three-dimensional patient shape data and results depend heavily on the chosen clustering distance metrics and linkage functions. In this study, we sought to assess clustering classification performance of various distance/linkage combinations and of different types of input data to obtain clinically meaningful shape clusters. Methods: We present a processing pipeline combining automatic segmentation, statistical shape modeling, and agglomerative hierarchical clustering to automatically subdivide a set of 60 aortic arch anatomical models into healthy controls, two groups affected by congenital heart disease, and their respective subgroups as defined by clinical diagnosis. Results were compared with traditional morphometrics and principal component analysis of shape features. Results: Our pipeline achieved automatic division of input shape data according to primary clinical diagnosis with high F-score (0.902 Â± 0.042) and Matthews correlation coefficient (0.851 Â± 0.064) using the correlation/weighted distance/linkage combination. Meaningful subgroups within the three patient groups were obtained and benchmark scores for automatic segmentation and classification performance are reported. Conclusion: Clustering results vary depending on the distance/linkage combination used to divide the data. Yet, clinically relevant shape clusters and subgroups could be found with high specificity and low misclassification rates. Significance: Detecting disease-specific clusters within medical image data could improve image-based risk assessment, treatment planning, and medical device development in complex disease.",2017,T. K. Rao; M. Rajyalakshmi; T. V. Prasad,2373,2383,11,7,10.1109/TBME.2017.2655364,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7857751,IEEE Journals,IEEE
Multi-Step Ahead Predictions for Critical Levels in Physiological Time Series,Predictive modeling;physiological time series;multi-step ahead prediction;prediction performance metrics;support vector machines;Predictive modeling;physiological time series;multi-step ahead prediction;prediction performance metrics;support vector machines,"Standard modeling and evaluation methods have been classically used in analyzing engineering dynamical systems where the fundamental problem is to minimize the (mean) error between the real and predicted systems. Although these methods have been applied to multi-step ahead predictions of physiological signals, it is often more important to predict clinically relevant events than just to match these signals. Adverse clinical events, which occur after a physiological signal breaches a clinically defined critical threshold, are a popular class of such events. This paper presents a framework for multi-step ahead predictions of critical levels of abnormality in physiological signals. First, a performance metric is presented for evaluating multi-step ahead predictions. Then, this metric is used to identify personalized models optimized with respect to predictions of critical levels of abnormality. To address the paucity of adverse events, weighted support vector machines and cost-sensitive learning are used to optimize the proposed framework with respect to statistical metrics that can take into account the relative rarity of such events.",2016,T. Kano; S. Sakti; S. Nakamura,1704,1714,11,23,10.1109/TCYB.2016.2561974,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7478676,IEEE Journals,IEEE
A Minimum Spanning Forest-Based Method for Noninvasive Cancer Detection With Hyperspectral Imaging,Hyperspectral imaging;image classification;mutual information;minimum spanning forest;noninvasive cancer detection;support vector machine;Hyperspectral imaging;image classification;minimum spanning forest;mutual information;noninvasive cancer detection;support vector machine,Goal: The purpose of this paper is to develop a classification method that combines both spectral and spatial information for distinguishing cancer from healthy tissue on hyperspectral images in an animal model. Methods: An automated algorithm based on a minimum spanning forest (MSF) and optimal band selection has been proposed to classify healthy and cancerous tissue on hyperspectral images. A support vector machine classifier is trained to create a pixel-wise classification probability map of cancerous and healthy tissue. This map is then used to identify markers that are used to compute mutual information for a range of bands in the hyperspectral image and thus select the optimal bands. An MSF is finally grown to segment the image using spatial and spectral information. Conclusion: The MSF based method with automatically selected bands proved to be accurate in determining the tumor boundary on hyperspectral images. Significance: Hyperspectral imaging combined with the proposed classification technique has the potential to provide a noninvasive tool for cancer detection.,2016,T. Kimura; J. Matsuoka; Y. Nishikawa; Y. Lepage,653,663,11,39,10.1109/TBME.2015.2468578,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202847,IEEE Journals,IEEE
Automatic Markerless Registration and Tracking of the Bone for Computer-Assisted Orthopaedic Surgery,Computer-assisted orthopaedic surgery;deep learning;depth imaging;markerless registration,"To achieve a simple and less invasive registration procedure in computer-assisted orthopaedic surgery, we propose an automatic, markerless registration and tracking method based on depth imaging and deep learning. A depth camera is used to continuously capture RGB and depth images of the exposed bone during surgery, and deep neural networks are trained to first localise the surgical target using the RGB image, then segment the target area of the corresponding depth image, from which the surface geometry of the target bone can be extracted. The extracted surface is then compared to a pre-operative model of the same bone for registration. This process can be performed dynamically during the procedure at a rate of 5-6 Hz, without any need for surgeon intervention or invasive optical markers. Ex vivo registration experiments were performed on a cadaveric knee, and accuracy measurements against an optically tracked ground truth resulted in a mean translational error of 2.74 mm and a mean rotational error of 6.66Â°. Our results are the first to describe a promising new way to achieve automatic markerless registration and tracking in computer-assisted orthopaedic surgery, demonstrating that truly seamless registration and tracking of the limb is within reach. Our method reduces invasiveness by removing the need for percutaneous markers. The surgeon is also exempted from inserting markers and collecting registration points manually, which contributes to a more efficient surgical workflow and shorter procedure time in the operating room.",2020,W. Chen; J. Kazama; M. Zhang; Y. Tsuruoka; Y. Zhang; Y. Wang; K. Torisawa; H. Li,42010,42020,11,2,10.1109/ACCESS.2020.2977072,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018195,IEEE Journals,IEEE
Automatic Registration of Terrestrial and Airborne Point Clouds Using Building Outline Features,Airborne laser scanning;building outline;global optimization method;registration;terrestrial laser scanning,"Terrestrial laser scanner (TLS) and airborne laser scanner (ALS) can effectively capture point clouds from side or top view, respectively. Registering point clouds captured by ALS and TLS provides an integrated data source for three-dimensional (3-D) reconstruction. However, registration is difficult between TLS and ALS data because of the differences in scanning perspectives, scanning area, and spatial resolutions. A new method that can achieve automatic horizontal registration with ALS and TLS data based on building contour features is proposed in this study. The key steps include horizontal and vertical registrations based on 2-D building outlines and ground planes in ALS and TLS data, respectively. First, the 2-D building outlines are extracted from both ALS and TLS data. Second, the horizontal registration is accomplished by using the four-point congruent sets method for initial registration and the global optimization method for refined registration. Finally, the ground surface in the same region of ALS and TLS data are fitted for vertical registration, and the average elevation difference between the corresponding ground planes is calculated as the translation parameter value in the vertical direction. The results indicate that the proposed method can successfully match ALS and TLS data with an accuracy of 0.2-m both in the horizontal and vertical directions.",2018,W. Kim; J. Chai,628,638,11,4,10.1109/JSTARS.2017.2788054,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255608,IEEE Journals,IEEE
Context-Based Filtering of Noisy Labels for Automatic Basemap Updating From UAV Data,Basemap updating;image classification;informal settlements;label noise;random forests;unmanned aerial vehicles (UAVs);urban planning,"Unmanned aerial vehicles (UAVs) have the potential to obtain high-resolution aerial imagery at frequent intervals, making them a valuable tool for urban planners who require up-to-date basemaps. Supervised classification methods can be exploited to translate the UAV data into such basemaps. However, these methods require labeled training samples, the collection of which may be complex and time consuming. Existing spatial datasets can be exploited to provide the training labels, but these often contain errors due to differences in the date or resolution of the dataset from which these outdated labels were obtained. In this paper, we propose an approach for updating basemaps using global and local contextual cues to automatically remove unreliable samples from the training set, and thereby, improve the classification accuracy. Using UAV datasets over Kigali, Rwanda, and Dar es Salaam, Tanzania, we demonstrate how the amount of mislabeled training samples can be reduced by 44.1% and 35.5%, respectively, leading to a classification accuracy of 92.1% in Kigali and 91.3% in Dar es Salaam. To achieve the same accuracy in Dar es Salaam, between 50000 and 60000 manually labeled image segments would be needed. This demonstrates that the proposed approach of using outdated spatial data to provide labels and iteratively removing unreliable samples is a viable method for obtaining high classification accuracies while reducing the costly step of acquiring labeled training samples.",2018,Wen Wang; A. Stolcke; Jing Zheng,2731,2741,11,,10.1109/JSTARS.2017.2762905,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103751,IEEE Journals,IEEE
Bidirectional Attention-Recognition Model for Fine-Grained Object Classification,Fine-grained object classification;interpretable machine learning;visual attention;pattern recognition;data augmentation,"Fine-grained object classification (FGOC) is a challenging research topic in multimedia computing with machine learning, which faces two pivotal conundrums: focusing attention on the discriminate part regions, and then processing recognition with the part-based features. Existing approaches generally adopt a unidirectional two-step structure, that first locate the discriminate parts and then recognize the part-based features. However, they neglect the truth that part localization and feature recognition can be reinforced in a bidirectional process. In this paper, we propose a novel bidirectional attention-recognition model (BARM) to actualize the bidirectional reinforcement for FGOC. The proposed BARM consists of one attention agent for discriminate part regions proposing and one recognition agent for feature extraction and recognition. Meanwhile, a feedback flow is creatively established to optimize the attention agent directly by recognition agent. Therefore, in BARM the attention agent and the recognition agent can reinforce each other in a bidirectional way and the overall framework can be trained end-to-end without neither object nor parts annotations. Moreover, a novel Multiple Random Erasing data augmentation is proposed, and it exhibits impressive pertinency and superiority for FGOC. Conducted on several extensive FGOC benchmarks, BARM outperforms the present state-of-the-art methods in classification accuracy. Furthermore, BARM exhibits a clear interpretability and keeps consistent with the human perception in visualization experiments.",2020,Y. Gao; A. Rehman; Z. Wang,1785,1795,11,2,10.1109/TMM.2019.2954747,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907499,IEEE Journals,IEEE
Robust Reading Comprehension With Linguistic Constraints via Posterior Regularization,Machine reading comprehension;robust;adversarial examples;linguistic constraints;posterior regularization,"In spite of the great advancements of machine reading comprehension (RC), existing RC models are still vulnerable and not robust to different types of adversarial examples. Neural models over-confidently predict wrong answers to semantic different adversarial examples, while over-sensitively predict wrong answers to semantic equivalent adversarial examples. Existing methods which improve the robustness of such neural models merely mitigate one of the two issues but ignore the other. In this article, we address the over-confidence issue and the over-sensitivity issue existing in current RC models simultaneously with the help of external linguistic knowledge. We first incorporate external knowledge to impose different linguistic constraints (entity constraint, lexical constraint, and predicate constraint), and then regularize RC models through posterior regularization. Linguistic constraints induce more reasonable predictions for both semantic different and semantic equivalent adversarial examples, and posterior regularization provides an effective mechanism to incorporate these constraints. Our method can be applied to any existing neural RC models including state-of-the-art BERT models. Extensive experiments show that our method remarkably improves the robustness of base RC models, and is better to cope with these two issues simultaneously.",2020,Y. Jin; Z. Liu,2500,2510,11,1,10.1109/TASLP.2020.3016132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165888,IEEE Journals,IEEE
Seq2seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models,Explainable AI;Visual Debugging;Visual Analytics;Machine Learning;Deep Learning;NLP,"Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and â€œwhat ifâ€?-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.",2019,Y. Li; S. Zhang; J. Zhang; Y. Yin; W. Xiao; Z. Zhang,353,363,11,24,10.1109/TVCG.2018.2865044,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8494828,IEEE Journals,IEEE
A Perspective on Deep Imaging,Tomographic imaging;medical imaging;data acquisition;image reconstruction;image analysis;big data;machine learning;deep learning,"The combination of tomographic imaging and deep learning, or machine learning in general, promises to empower not only image analysis but also image reconstruction. The latter aspect is considered in this perspective article with an emphasis on medical imaging to develop a new generation of image reconstruction theories and techniques. This direction might lead to intelligent utilization of domain knowledge from big data, innovative approaches for image reconstruction, and superior performance in clinical and preclinical applications. To realize the full impact of machine learning for tomographic imaging, major theoretical, technical and translational efforts are immediately needed.",2016,Y. Yang; S. Kang; J. Seo,8914,8924,11,198,10.1109/ACCESS.2016.2624938,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7733110,IEEE Journals,IEEE
"Enabling Low-Power, Multi-Modal Neural Interfaces Through a Common, Low-Bandwidth Feature Space",Brain-machine interface (BMI);implantable;low power;multi-modal;neural interface,"Brain-Machine Interfaces (BMIs) have shown great potential for generating prosthetic control signals. Translating BMIs into the clinic requires fully implantable, wireless systems; however, current solutions have high power requirements which limit their usability. Lowering this power consumption typically limits the system to a single neural modality, or signal type, and thus to a relatively small clinical market. Here, we address both of these issues by investigating the use of signal power in a single narrow frequency band as a decoding feature for extracting information from electrocorticographic (ECoG), electromyographic (EMG), and intracortical neural data. We have designed and tested the Multi-modal Implantable Neural Interface (MINI), a wireless recording system which extracts and transmits signal power in a single, configurable frequency band. In prerecorded datasets, we used the MINI to explore low frequency signal features and any resulting tradeoff between power savings and decoding performance losses. When processing intracortical data, the MINI achieved a power consumption 89.7% less than a more typical system designed to extract action potential waveforms. When processing ECoG and EMG data, the MINI achieved similar power reductions of 62.7% and 78.8%. At the same time, using the single signal feature extracted by the MINI, we were able to decode all three modalities with less than a 9% drop in accuracy relative to using high-bandwidth, modality-specific signal features. We believe this system architecture can be used to produce a viable, cost-effective, clinical BMI.",2016,Yu Zhou; Chengqing Zong; Bo Xu,521,531,11,19,10.1109/TNSRE.2015.2501752,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332964,IEEE Journals,IEEE
Gradient Tree Boosting-Based Positioning Method for Monolithic Scintillator Crystals in Positron Emission Tomography,Field-programmable gate array (FPGA);gradient tree boosting;machine learning;monolithic scintillator;positron emission tomography (PET),"Monolithic crystals are considered as an alternative for complex segmented scintillator arrays in positron emission tomography systems. Monoliths provide high sensitivity, good timing, and energy resolution while being cheaper than highly segmented arrays. Furthermore, monoliths enable intrinsic depth of interaction capabilities and good spatial resolutions (SRs) mostly based on statistical calibrations. To widely translate monoliths into clinical applications, a time-efficient calibration method and a positioning algorithm implementable in system architecture such as field-programmable gate arrays (FPGAs) are required. We present a novel positioning algorithm based on gradient tree boosting (GTB) and a fast fan beam calibration requiring less than 1 h per detector block. GTB is a supervised machine learning technique building a set of sequential binary decisions (decision trees). The algorithm handles different sets of input features, their combinations and partially missing data. GTB models are strongly adaptable influencing both the positioning performance and the memory requirement of trained positioning models. For an FPGA-implementation, the memory requirement is the limiting aspect. We demonstrate a general optimization and propose two different optimization scenarios: one without compromising on positioning performance and one optimizing the positioning performance for a given memory restriction. For a 12 mm high LYSO-block, we achieve an SR better than 1.4 mm FWHM.",2018,Z. Chen; X. Yang; C. Zhang; S. Jiang,411,421,11,9,10.1109/TRPMS.2018.2837738,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360486,IEEE Journals,IEEE
Modeling Future Cost for Neural Machine Translation,Future cost;future cost representation;neural machine translation;transformer,"Existing neural machine translation (NMT) systems utilize sequence-to-sequence neural networks to generate target translation word by word, and then make the generated word at each time-step and the counterpart in the references as consistent as possible. However, the trained translation model tends to focus on ensuring the accuracy of the generated target word at the current time-step and does not consider its future cost which means the expected cost of generating the subsequent target translation (i.e., the next target word). To respond to this issue, in this article, we propose a simple and effective method to model the future cost of each target word for NMT systems. In detail, a future cost representation is learned based on the current generated target word and its contextual information to compute an additional loss to guide the training of the NMT model. Furthermore, the learned future cost representation at the current time-step is used to help the generation of the next target word in the decoding. Experimental results on three widely-used translation datasets, including the WMT14 English-to-German, WMT14 English-to-French, and WMT17 Chinese-to-English, show that the proposed approach achieves significant improvements over strong Transformer-based NMT baseline.",2021,A. Akl; B. Taati; A. Mihailidis,770,781,12,,10.1109/TASLP.2020.3042006,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9330773,IEEE Journals,IEEE
Automatic Testing and Improvement of Machine Translation,machine translation;testing and repair;translation consistency,"This paper presents TransRepair, a fully automatic approach for testing and repairing the consistency of machine translation systems. TransRepair combines mutation with metamorphic testing to detect inconsistency bugs (without access to human oracles). It then adopts probability-reference or cross-reference to post-process the translations, in a grey-box or black-box manner, to repair the inconsistencies. Our evaluation on two state-of-the-art translators, Google Translate and Transformer, indicates that TransRepair has a high precision (99%) on generating input pairs with consistent translations. With these tests, using automatic consistency metrics and manual assessment, we find that Google Translate and Transformer have approximately 36% and 40% inconsistency bugs. Black-box repair fixes 28% and 19% bugs on average for Google Translate and Transformer. Grey-box repair fixes 30% bugs on average for Transformer. Manual inspection indicates that the translations repaired by our approach improve consistency in 87% of cases (degrading it in 2%), and that our repairs have better translation acceptability in 27% of the cases (worse in 8%).",2020,A. Anguita; A. Beghelli; W. Creixell,974,985,12,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284046,IEEE Conferences,IEEE
Towards More Diverse Input Representation for Neural Machine Translation,Neural machine translation;source features;diverse input representation,"Source input information plays a very important role in the Transformer-based translation system. In practice, word embedding and positional embedding of each word are added as the input representation. Then self-attention networks are used to encode the global dependencies in the input representation to generate a source representation. However, this processing on the source representation only adopts a single source feature and excludes richer and more diverse features such as recurrence features, local features, and syntactic features, which results in tedious representation and thereby hinders the further translation performance improvement. In this paper, we introduce a simple and efficient method to encode more diverse source features into the input representation simultaneously, and thereby learning an effective source representation by self-attention networks. In particular, the proposed grouped strategy is only applied to the input representation layer, to keep the diversity of translation information and the efficiency of the self-attention networks at the same time. Experimental results show that our approach improves the translation performance over the state-of-the-art baselines of Transformer in regard to WMT14 English-to-German and NIST Chinese-to-English machine translation tasks.",2020,A. Bodile; M. Kshirsagar,1586,1597,12,,10.1109/TASLP.2020.2996077,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097389,IEEE Journals,IEEE
Incorporating Statistical Machine Translation Word Knowledge Into Neural Machine Translation,Neural machine translation;statistical machine translation;hybrid translation;translation combination,"Neural machine translation (NMT) has gained more and more attention in recent years, mainly due to its simplicity yet state-of-the-art performance. However, previous research has shown that NMT suffers from several limitations: source coverage guidance, translation of rare words, and the limited vocabulary, while statistical machine translation (SMT) has complementary properties that correspond well to these limitations. It is straightforward to improve the translation performance by combining the advantages of two kinds of models. This paper proposes a general framework for incorporating the SMT word knowledge into NMT to alleviate above word-level limitations. In our framework, the NMT decoder makes more accurate word prediction by referring to the SMT word recommendations in both training and testing phases. Specifically, the SMT model offers informative word recommendations based on the NMT decoding information. Then, we use the SMT word predictions as prior knowledge to adjust the NMT word generation probability, which unitizes a neural network based classifier to digest the discrete word knowledge. In this paper, we use two model variants to implement the framework, one with a gating mechanism and the other with a direct competition mechanism. Experimental results on Chinese-to-English and English-to-German translation tasks show that the proposed framework can take advantage of the SMT word knowledge and consistently achieve significant improvements over NMT and SMT baseline systems.",2018,A. C. M. Fong; M. Usman,2255,2266,12,6,10.1109/TASLP.2018.2860287,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421063,IEEE Journals,IEEE
A Maximum-Entropy Segmentation Model for Statistical Machine Translation,Bracketing transduction grammar (BTG)-based phrasal machine translation;hierarchical segmentation;maximum entropy;phrasal segmentation;statistical machine translation (SMT),Segmentation is of great importance to statistical machine translation. It splits a source sentence into sequences of translatable segments. We propose a maximum-entropy segmentation model to capture desirable phrasal and hierarchical segmentations for statistical machine translation. We present an approach to automatically learning the beginning and ending boundaries of cohesive segments from word-aligned bilingual data without using any additional resources. The learned boundaries are then used to define cohesive segments in both phrasal and hierarchical segmentations. We integrate the segmentation model into phrasal statistical machine translation (SMT) and conduct experiments on the newswire and broadcast news domain to investigate the effectiveness of the proposed segmentation model on a large-scale training data. Our experimental results show that the maximum-entropy segmentation model significantly improves translation quality in terms of BLEU. We further validate that 1) the proposed segmentation model significantly outperforms syntactic constraints which are used in previous work to constrain segmentations; and 2) it is necessary to capture hierarchical segmentations besides phrasal segmentations.,2011,A. Emami; S. F. Chen,2494,2505,12,3,10.1109/TASL.2011.2144971,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753927,IEEE Journals,IEEE
On the Evaluation of Adaptive Machine Translation for Human Post-Editing,Computer-assisted translation;domain adaptation;human in the loop evaluation;machine translation;online adaptation;post-editing,"We investigate adaptive machine translation (MT) as a way to reduce human workload and enhance user experience when professional translators operate in real-life conditions. A crucial aspect in our analysis is how to ensure a reliable assessment of MT technologies aimed to support human post-editing. We pay particular attention to two evaluation aspects: i) the design of a sound experimental protocol to reduce the risk of collecting biased measurements, and ii) the use of robust statistical testing methods (linear mixed-effects models) to reduce the risk of under/over-estimating the observed variations. Our adaptive MT technology is integrated in a web-based full-fledged computer-assisted translation (CAT) tool. We report on a post-editing field test that involved 16 professional translators working on two translation directions (English-Italian and English-French), with texts coming from two linguistic domains (legal, information technology). Our contrastive experiments compare user post-editing effort with static vs. adaptive MT in an end-to-end scenario where the system is evaluated as a whole. Our results evidence that adaptive MT leads to an overall reduction in post-editing effort (HTER) up to 10.6% (p <; 0.05). A follow-up manual evaluation of the MT outputs and their corresponding post-edits confirms that the gain in HTER corresponds to higher quality of the adaptive MT system and does not come at the expense of the final human translation quality. Indeed, adaptive MT shows to return better suggestions than static MT (p <; 0.01), and the resulting post-edits do not significantly differ in the two conditions.",2016,C. Wang; S. Wang; M. Bao; Arong,388,399,12,6,10.1109/TASLP.2015.2509241,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358024,IEEE Journals,IEEE
Multi-Source Neural Machine Translation With Missing Data,Neural machine translation (NMT);multi-linguality;data augmentation,"Machine translation is rife with ambiguities in word ordering and word choice, and even with the advent of machine-learning methods that learn to resolve this ambiguity based on statistics from large corpora, mistakes are frequent. Multi-source translation is an approach that attempts to resolve these ambiguities by exploiting multiple inputs (e.g. sentences in three different languages) to increase translation accuracy. These methods are trained on multilingual corpora, which include the multiple source languages and the target language, and then at test time uses information from both source languages while generating the target. While there are many of these multilingual corpora, such as multilingual translations of TED talks or European parliament proceedings, in practice, many multilingual corpora are not complete due to the difficulty to provide translations in all of the relevant languages. Existing studies on multi-source translation did not explicitly handle such situations, and thus are only applicable to complete corpora that have all of the languages of interest, severely limiting their practical applicability. In this article, we examine approaches for multi-source neural machine translation (NMT) that can learn from and translate such incomplete corpora. Specifically, we propose methods to deal with incomplete corpora at both training time and test time. For training time, we examine two methods: (1) a simple method that simply replaces missing source translations with a special NULL symbol, and (2) a data augmentation approach that fills in incomplete parts with source translations created from multi-source NMT. For test-time, we examine methods that use multi-source translation even when only a single source is provided by first translating into an additional auxiliary language using standard NMT, then using multi-source translation on the original source and this generated auxiliary language sentence. Extensive experiments demonstrate that the proposed training-time and test-time methods both significantly improve translation performance.",2020,C. Wei-Gang; C. Huang; W. Hwang,569,580,12,,10.1109/TASLP.2019.2959224,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930957,IEEE Journals,IEEE
Bilingual Continuous-Space Language Model Growing for Statistical Machine Translation,Continuous-space language model;language model growing (LMG);neural network language model;statistical machine translation (SMT),"Larger n-gram language models (LMs) perform better in statistical machine translation (SMT). However, the existing approaches have two main drawbacks for constructing larger LMs: 1) it is not convenient to obtain larger corpora in the same domain as the bilingual parallel corpora in SMT; 2) most of the previous studies focus on monolingual information from the target corpora only, and redundant n-grams have not been fully utilized in SMT. Nowadays, continuous-space language model (CSLM), especially neural network language model (NNLM), has been shown great improvement in the estimation accuracies of the probabilities for predicting the target words. However, most of these CSLM and NNLM approaches still consider monolingual information only or require additional corpus. In this paper, we propose a novel neural network based bilingual LM growing method. Compared to the existing approaches, the proposed method enables us to use bilingual parallel corpus for LM growing in SMT. The results show that our new method outperforms the existing approaches on both SMT performance and computational efficiency significantly.",2015,C. Xue,1209,1220,12,19,10.1109/TASLP.2015.2425220,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090970,IEEE Journals,IEEE
Optimizing Instance Selection for Statistical Machine Translation with Feature Decay Algorithms,Domain adaptation;information retrieval;instance selection;machine translation;transductive learning,"We introduce FDA5 for efficient parameterization, optimization, and implementation of feature decay algorithms (FDA), a class of instance selection algorithms that use feature decay. FDA increase the diversity of the selected training set by devaluing features (i.e., n-grams) that have already been included. FDA5 decides which instances to select based on three functions used for initializing and decaying feature values and scaling sentence scores controlled with five parameters. We present optimization techniques that allow FDA5 to adapt these functions to in-domain and out-of-domain translation tasks for different language pairs. In a transductive learning setting, selection of training instances relevant to the test set can improve the final translation quality. In machine translation experiments performed on the 2 million sentence English-German section of the Europarl corpus, we show that a subset of the training set selected by FDA5 can gain up to 3.22 BLEU points compared to a randomly selected subset of the same size, can gain up to 0.41 BLEU points compared to using all of the available training data using only 15% of it, and can reach within 0.5 BLEU points to the full training set result by using only 2.7% of the full training data. FDA5 peaks at around 8M words or 15% of the full training set. In an active learning setting, FDA5 minimizes the human effort by identifying the most informative sentences for translation and FDA gains up to 0.45 BLEU points using 3/5 of the available training data compared to using all of it and 1.12 BLEU points compared to random training set. In translation tasks involving English and Turkish, a morphologically rich language, FDA5 can gain up to 11.52 BLEU points compared to a randomly selected subset of the same size, can achieve the same BLEU score using as little as 4% of the data compared to random instance selection, and can exceed the full dataset result by 0.78 BLEU points. FDA5 is able to reduce the time to build a statistical machine translation system to about half with 1M words using only 3% of the space for the phrase table and 8% of the overall space when compared with a baseline system using all of the training data available yet still obtain only 0.58 BLEU points difference with the baseline system in out-of-domain translation.",2015,D. Ionescu,339,350,12,8,10.1109/TASLP.2014.2381882,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987314,IEEE Journals,IEEE
Effect of Word Sense Disambiguation on Neural Machine Translation: A Case Study in Korean,Lexical semantic network;neural machine translation;word sense disambiguation,"With the advent of robust deep learning, neural machine translation (NMT) has achieved great progress and recently become the dominant paradigm in machine translation (MT). However, it is still confronted with the challenge of word ambiguities that force NMT to choose among several translation candidates that represent different senses of an input word. This research presents a case study using Korean word sense disambiguation (WSD) to improve NMT performance. First, we constructed a Korean lexical semantic network (LSN) as a large-scale lexical semantic knowledge base. Then, based on the Korean LSN, we built a Korean WSD preprocessor that can annotate the correct sense of Korean words in the training corpus. Finally, we conducted a series of translation experiments using Korean-English, Korean-French, Korean-Spanish, and Korean-Japanese language pairs. The experimental results show that our Korean WSD system can significantly improve the translation quality of NMT in terms of the BLEU, TER, and DLRATIO metrics. On average, it improved the precision by 2.94 BLEU points and improved translation error prevention by 4.04 TER points and 4.51 DLRATIO points for all the language pairs.",2018,D. Kostadinov; S. Bogdanova,38512,38523,12,4,10.1109/ACCESS.2018.2851281,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399736,IEEE Journals,IEEE
Searching Better Architectures for Neural Machine Translation,Neural architecture search (NAS);neural machine translation,"Neural architecture search (NAS) has played important roles in the evolution of neural architectures. However, no much attention has been paid to improve neural machine translation (NMT) through NAS approaches. In this work, we propose a gradient-based NAS algorithm for NMT, which automatically discovers architectures with better performances. Compared with previous NAS work, we jointly search the network operations (e.g., LSTM, CNN, self-attention etc) as well as dropout rates to ensure better results. We show that with reasonable resources it is possible to discover novel neural network architectures for NMT, which achieve consistently better performances than Transformer [1], the state-of-the-art NMT model, across different tasks. On WMT'14 English-to-German translation, IWSLT'14 German-to-English translation and WMT'18 Finnish-to-English translation tasks, our discovered architectures could obtain 30.1, 36.1 and 26.4 BLEU scores, which are great improvement over Transformer baselines. We also empirically verify that the discovered model on one task can be transferred to other tasks.",2020,D. Liu; N. Ma; F. Yang; X. Yang,1574,1585,12,2,10.1109/TASLP.2020.2995270,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095246,IEEE Journals,IEEE
Multimodal Neural Machine Translation With Weakly Labeled Images,Humanâ€“computer interaction;multi-layer neural network;natural language processing;image classification;multimodal neural machine translation;weak label,"Machine translation refers to a fully automated process that translates a user's input text into a target language. To improve the accuracy of machine translation, studies usually exploit not only the input text itself but also various background knowledge related to the text, such as visual information or prior knowledge. Herein, in this paper, we propose a multimodal neural machine translation system that uses both texts and their related images to translate Korean image captions into English. The data in the experiment is a set of unlabeled images only containing bilingual captions. To train the system with a supervised learning approach, we propose a weak-labeling method that selects a keyword from an image caption using feature selection methods. The keywords are used to roughly determine an image label. We also introduce an improved feature selection method using sentence clustering to select keywords that reflect the characteristics of the image captions more accurately. We found that our multimodal system achieves an improved performance compared to a text-only neural machine translation system (baseline). Furthermore, the additional images have positive impacts on addressing the issue of under-translation, where some words in a source sentence are falsely translated or not translated at all.",2019,D. M. Salih; S. B. M. Noor; M. H. Marhaban; R. M. K. R. Ahmad,54042,54053,12,3,10.1109/ACCESS.2019.2911656,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692345,IEEE Journals,IEEE
Neural-Machine-Translation-Based Commit Message Generation: How Far Are We?,Commit message generation;Nearest neighbor algorithm;Neural machine translation,"Commit messages can be regarded as the documentation of software changes. These messages describe the content and purposes of changes, hence are useful for program comprehension and software maintenance. However, due to the lack of time and direct motivation, commit messages sometimes are neglected by developers. To address this problem, Jiang et al. proposed an approach (we refer to it as NMT), which leverages a neural machine translation algorithm to automatically generate short commit messages from code. The reported performance of their approach is promising, however, they did not explore why their approach performs well. Thus, in this paper, we first perform an in-depth analysis of their experimental results. We find that (1) Most of the test diffs from which NMT can generate high-quality messages are similar to one or more training diffs at the token level. (2) About 16% of the commit messages in Jiang et al.'s dataset are noisy due to being automatically generated or due to them describing repetitive trivial changes. (3) The performance of NMT declines by a large amount after removing such noisy commit messages. In addition, NMT is complicated and time-consuming. Inspired by our first finding, we proposed a simpler and faster approach, named NNGen (Nearest Neighbor Generator), to generate concise commit messages using the nearest neighbor algorithm. Our experimental results show that NNGen is over 2,600 times faster than NMT, and outperforms NMT in terms of BLEU (an accuracy measure that is widely used to evaluate machine translation systems) by 21%. Finally, we also discuss some observations for the road ahead for automated commit message generation to inspire other researchers.",2018,E. Matusov; H. Ney,373,384,12,9,10.1145/3238147.3238190,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000000,IEEE Conferences,IEEE
Efficient Methods for Mapping Neural Machine Translator on FPGAs,Hardware-efficient inference;neural machine translation;FPGA;high level synthesis,"Neural machine translation (NMT) is one of the most critical applications in natural language processing (NLP) with the main idea of converting text in one language to another using deep neural networks. In recent year, we have seen continuous development of NMT by integrating more emerging technologies, such as bidirectional gated recurrent units (GRU), attention mechanisms, and beam-search algorithms, for improved translation quality. However, with the increasing problem size, the real-life NMT models have become much more complicated and difficult to implement on hardware for acceleration opportunities. In this article, we aim to exploit the capability of FPGAs to deliver highly efficient implementations for real-life NMT applications. We map the inference of a large-scale NMT model with total computation of 172 GFLOP to a highly optimized high-level synthesis (HLS) IP and integrate the IP into Xilinx VCU118 FPGA platform. The model has widely used key features for NMTs, including the bidirectional GRU layer, attention mechanism, and beam search. We quantize the model to mixed-precision representation in which parameters and portions of calculations are in 16-bit half precision, and others remain as 32-bit floating-point. Compared to the float NMT implementation on FPGA, we achieve 13.1Ã— speedup with an end-to-end performance of 22.0 GFLOPS without any accuracy degradation. Based on our knowledge, this is the first work that successfully implements a real-life end-to-end NMT model to an FPGA on board.",2021,E. Saquete; P. Martinez-Barco; R. Munoz,1866,1877,12,,10.1109/TPDS.2020.3047371,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309170,IEEE Journals,IEEE
Improving Statistical Machine Translation Using Bayesian Word Alignment and Gibbs Sampling,Bayesian methods;Gibbs sampling;statistical machine translation (SMT);word alignment,"We present a Bayesian approach to word alignment inference in IBM Models 1 and 2. In the original approach, word translation probabilities (i.e., model parameters) are estimated using the expectation-maximization (EM) algorithm. In the proposed approach, they are random variables with a prior and are integrated out during inference. We use Gibbs sampling to infer the word alignment posteriors. The inferred word alignments are compared against EM and variational Bayes (VB) inference in terms of their end-to-end translation performance on several language pairs and types of corpora up to 15 million sentence pairs. We show that Bayesian inference outperforms both EM and VB in the majority of test cases. Further analysis reveals that the proposed method effectively addresses the high-fertility rare word problem in EM and unaligned rare word problem in VB, achieves higher agreement and vocabulary coverage rates than both, and leads to smaller phrase tables.",2013,G. Shuo; Z. Yi-sheng,1090,1101,12,4,10.1109/TASL.2013.2244087,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425427,IEEE Journals,IEEE
Attention With Sparsity Regularization for Neural Machine Translation and Summarization,Sequence to sequence learning;attention mechanism;sparsity regularization;machine translation;summarization,"The attention mechanism has become the de facto standard component in neural sequence to sequence tasks, such as machine translation and abstractive summarization. It dynamically determines which parts in the input sentence should be focused on when generating each word in the output sequence. Ideally, only few relevant input words should be attended to at each decoding time step and the attention weight distribution should be sparse and sharp. However, previous methods have no good mechanism to control this attention weight distribution. In this paper, we propose a sparse attention model in which a sparsity regularization term is designed to augment the objective function. We explore two kinds of regularizations: $L_{\infty }$-norm regularization and minimum entropy regularization, both of which aim to sharpen the attention weight distribution. Extensive experiments on both neural machine translation and abstractive summarization demonstrate that our proposed sparse attention model can substantially outperform the strong baselines. And the detailed analyses reveal that the final attention distribution indeed becomes sparse and sharp.",2019,Gong Zhengxian; Zhou Guodong,507,518,12,3,10.1109/TASLP.2018.2883740,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550728,IEEE Journals,IEEE
On Learning Meaningful Code Changes Via Neural Machine Translation,Neural-Machine Translation;Empirical Study,"Recent years have seen the rise of Deep Learning (DL) techniques applied to source code. Researchers have exploited DL to automate several development and maintenance tasks, such as writing commit messages, generating comments and detecting vulnerabilities among others. One of the long lasting dreams of applying DL to source code is the possibility to automate non-trivial coding activities. While some steps in this direction have been taken (e.g., learning how to fix bugs), there is still a glaring lack of empirical evidence on the types of code changes that can be learned and automatically applied by DL. Our goal is to make this first important step by quantitatively and qualitatively investigating the ability of a Neural Machine Translation (NMT) model to learn how to automatically apply code changes implemented by developers during pull requests. We train and experiment with the NMT model on a set of 236k pairs of code components before and after the implementation of the changes provided in the pull requests. We show that, when applied in a narrow enough context (i.e., small/medium-sized pairs of methods before/after the pull request changes), NMT can automatically replicate the changes implemented by developers during pull requests in up to 36% of the cases. Moreover, our qualitative analysis shows that the model is capable of learning and replicating a wide variety of meaningful code changes, especially refactorings and bug-fixing activities. Our results pave the way for novel research in the area of DL on code, such as the automatic learning and applications of refactoring.",2019,H. Bais; M. Machkour; L. Koutti,25,36,12,9,10.1109/ICSE.2019.00021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811910,IEEE Conferences,IEEE
From UI Design Image to GUI Skeleton: A Neural Machine Translator to Bootstrap Mobile GUI Implementation,User interface;reverse engineering;deep learning,"A GUI skeleton is the starting point for implementing a UI design image. To obtain a GUI skeleton from a UI design image, developers have to visually understand UI elements and their spatial layout in the image, and then translate this understanding into proper GUI components and their compositions. Automating this visual understanding and translation would be beneficial for bootstraping mobile GUI implementation, but it is a challenging task due to the diversity of UI designs and the complexity of GUI skeletons to generate. Existing tools are rigid as they depend on heuristically-designed visual understanding and GUI generation rules. In this paper, we present a neural machine translator that combines recent advances in computer vision and machine translation for translating a UI design image into a GUI skeleton. Our translator learns to extract visual features in UI images, encode these features' spatial layouts, and generate GUI skeletons in a unified neural network framework, without requiring manual rule development. For training our translator, we develop an automated GUI exploration method to automatically collect large-scale UI data from real-world applications. We carry out extensive experiments to evaluate the accuracy, generality and usefulness of our approach.",2018,J. Kang; K. Wu; K. Chi; X. Wang,665,676,12,19,10.1145/3180155.3180240,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453135,IEEE Conferences,IEEE
Syntax-Based Translation With Bilingually Lexicalized Synchronous Tree Substitution Grammars,Bilingually lexicalized synchronous tree substitution grammars;discriminative model;generative model;syntax-based statistical machine translation,"Syntax-based models can significantly improve the translation performance due to their grammatical modeling on one or both language side(s). However, the translation rules such as the non-lexical rule â€œ VPâ†’(x0x1,VP:x1PP:x0)â€? in string-to-tree models do not consider any lexicalized information on the source or target side. The rule is so generalized that any subtree rooted at VP can substitute for the nonterminal VP:x1. Because rules containing nonterminals are frequently used when generating the target-side tree structures, there is a risk that rules of this type will potentially be severely misused in decoding due to a lack of lexicalization guidance. In this article, inspired by lexicalized PCFG, which is widely used in monolingual parsing, we propose to upgrade the STSG (synchronous tree substitution grammars)-based syntax translation model with bilingually lexicalized STSG. Using the string-to-tree translation model as a case study, we present generative and discriminative models to integrate lexicalized STSG into the translation model. Both small- and large-scale experiments on Chinese-to-English translation demonstrate that the proposed lexicalized STSG can provide superior rule selection in decoding and substantially improve the translation quality.",2013,J. Liu,1586,1597,12,3,10.1109/TASL.2013.2255283,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6490019,IEEE Journals,IEEE
Preordering Encoding on Transformer for Translation,Neural machine translation;preordering;word-order;transformer,"The difference in word orders between source and target languages is a serious hurdle for machine translation. Preordering methods, which reorder the words in a source sentence before translation to obtain a similar word ordering with a target language, significantly improve the quality in statistical machine translation. While the information on the preordering position improved the translation quality in recurrent neural network-based models, questions such as how to use preordering information and whether it is helpful for the Transformer model remain unaddressed. In this article, we successfully employed preordering techniques in the Transformer-based neural machine translation. Specifically, we proposed a novel preordering encoding that exploits the reordering information of the source and target sentences as positional encoding in the Transformer model. Experimental results on ASPEC Japanese-English and WMT 2015 English-German, English-Czech, and English-Russian translation tasks confirmed that the proposed method significantly improved the translation quality evaluated by the BLEU scores of the Transformer model by 1.34 points in the Japanese-to-English task, 2.19 points in the English-to-German task, 0.15 points in the Czech-to-English task, and 1.48 points in the English-to-Russian task.",2021,Jing Liu; Dongmei Zhang; Yaohong Jin,644,655,12,,10.1109/TASLP.2020.3042001,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290425,IEEE Journals,IEEE
Patching as Translation: the Data and the Metaphor,neural machine translation;big code;sequence-to-sequence model;automated program repair,"Machine Learning models from other fields, like Computational Linguistics, have been transplanted to Software Engineering tasks, often quite successfully. Yet a transplanted model's initial success at a given task does not necessarily mean it is well-suited for the task. In this work, we examine a common example of this phenomenon: the conceit that software patching is like language translation. We demonstrate empirically that there are subtle, but critical distinctions between sequence-to-sequence models and translation model: while program repair benefits greatly from the former, general modeling architecture, it actually suffers from design decisions built into the latter, both in terms of translation accuracy and diversity. Given these findings, we demonstrate how a more principled approach to model design, based on our empirical findings and general knowledge of software development, can lead to better solutions. Our findings also lend strong support to the recent trend towards synthesizing edits of code conditional on the buggy context, to repair bugs. We implement such models ourselves as â€œproof-of-conceptâ€? tools and empirically confirm that they behave in a fundamentally different, more effective way than the studied translation-based architectures. Overall, our results demonstrate the merit of studying the intricacies of machine learned models in software engineering: not only can this help elucidate potential issues that may be overshadowed by increases in accuracy; it can also help innovate on these models to raise the state-of-the-art further. We will publicly release our replication data and materials at https://github.com/ARiSE-Lab/Patch-as-translation.",2020,K. Ayadi; Y. O. M. Elhadj; A. Ferchichi,275,286,12,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286060,IEEE Conferences,IEEE
Lattice-Based ASR-MT Interface for Speech Translation,Machine translation (MT);natural languages;SLP-SSMT;speech processing,"The usual approach to improve the interface between automatic speech recognition (ASR) and machine translation (MT) is to use ASR word lattices for translation. In comparison with the previous research along this line, this paper presents an efficient algorithm for lattice-based search in MT. This algorithm utilizes confusion network information to enable phrase-level reordering, and is also able to process general lattices. The proposed search is not constrained to be monotonic; thus, it is able to perform the same type of reordering given lattice input as any statistical phrase-based search algorithm with a single sentence input. Using the concept described in this paper, we are able to significantly improve speech translation results on several small and large vocabulary tasks. The improvements of the MT quality as measured by BLEU are as high as 5% relative. We also show that the proposed lattice-based translation can outperform state-of-the-art translation of confusion networks and has advantages in terms of translation speed. Furthermore, we propose and evaluate a novel approach that shares the benefits of lattice-based translation with those translation systems which are not designed to process word lattices.",2011,K. M. Chaman Kumar; S. Aswale; P. Shetgaonkar; V. Pawar; D. Kale; S. Kamat,721,732,12,5,10.1109/TASL.2010.2060483,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5518378,IEEE Journals,IEEE
Neural Network-Based Tree Translation for Knowledge Base Construction,Knowledge base construction;machine translation;named entity disambiguation;natural language processing;representation learning;word sense disambiguation;neural networks,"Knowledge bases (KB), such as Probase and ConceptNet, play an important role in many natural language processing tasks. Compared with resource-poor languages such as Chinese, the scale and quality of English knowledge bases are obviously superior. To expand Chinese KBs by using English KB resources, translating English KBs into Chinese is an effective way. In this direction, two major challenges are how to model more structure semantics to improve translation quality and how to avoid labor-intensive feature engineering. We address these challenges by presenting a neural network approach, which learns tree representation by different structure features. We also build a new dataset for English-Chinese KB translation from Probase and ConceptNet, and compare our proposed approach with several baselines on it. Experimental results show that the proposed method improves the translation accuracy compared with baseline methods. Meanwhile, we translate Probase and ConceptNet into Zh-Probase and Zh-ConceptNet by our proposed model, and release them to the public, in hope of speeding up the research in Chinese natural language processing tasks.",2021,K. Natarajan; T. D. Nguyen; M. Mete,38706,38717,12,,10.1109/ACCESS.2021.3063234,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367191,IEEE Journals,IEEE
Statistical Translation of English Texts to API Code Templates,"Text to Code Translation, API Usage Synthesis, Graph based Statistical Machine Translation","We develop T2API, a context-sensitive, graph-based statistical translation approach that takes as input an English description of a programming task and synthesizes the corresponding API code template for the task. We train T2API to statistically learn the alignments between English and API elements and determine the relevant API elements. The training is done on StackOverflow, a bilingual corpus on which developers discuss programming problems in two types of language: English and programming language. T2API considers both the context of the words in the input query and the context of API elements that often go together in the corpus. The derived API elements with their relevance scores are assembled into an API usage by GraSyn, a novel graph-based API synthesis algorithm that generates a graph representing an API usage from a large code corpus. Importantly, it is capable of generating new API usages from previously seen sub-usages. We curate a test benchmark of 250 real-world StackOverflow posts. Across the benchmark, T2API's synthesized snippets have the correct API elements with a median top-1 precision and recall of 67% and 100%, respectively. Four professional developers and five graduate students judged that 77% of our top synthesized API code templates are useful to solve the problem presented in the StackOverflow posts.",2018,K. Takabuchi; N. Iwahashi; T. Kunishima,194,205,12,4,10.1109/ICSME.2018.00029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530029,IEEE Conferences,IEEE
Does BLEU Score Work for Code Migration?,Code Migration;Statistical Machine Translation;BLEU score,"Statistical machine translation (SMT) is a fast-growing sub-field of computational linguistics. Until now, the most popular automatic metric to measure the quality of SMT is BiLingual Evaluation Understudy (BLEU) score. Lately, SMT along with the BLEU metric has been applied to a Software Engineering task named code migration. (In) Validating the use of BLEU score could advance the research and development of SMT-based code migration tools. Unfortunately, there is no study to approve or disapprove the use of BLEU score for source code. In this paper, we conducted an empirical study on BLEU score to (in) validate its suitability for the code migration task due to its inability to reflect the semantics of source code. In our work, we use human judgment as the ground truth to measure the semantic correctness of the migrated code. Our empirical study demonstrates that BLEU does not reflect translation quality due to its weak correlation with the semantic correctness of translated code. We provided counter-examples to show that BLEU is ineffective in comparing the translation quality between SMT-based models. Due to BLEU's ineffectiveness for code migration task, we propose an alternative metric RUBY, which considers lexical, syntactical, and semantic representations of source code. We verified that RUBY achieves a higher correlation coefficient with the semantic correctness of migrated code, 0.775 in comparison with 0.583 of BLEU score. We also confirmed the effectiveness of RUBY in reflecting the changes in translation quality of SMT-based translation models. With its advantages, RUBY can be used to evaluate SMT-based code migration models.",2019,M. Namazi Zavareh; S. Khadivi,165,176,12,1,10.1109/ICPC.2019.00034,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8813269,IEEE Conferences,IEEE
Divide-and-Conquer Approach for Multi-phase Statistical Migration for Source Code (T),Language Migration;Statistical Machine Translation;Syntax-directed Translation,"Prior research shows that directly applying phrase-based SMT on lexical tokens to migrate Java to C# produces much semantically incorrect code. A key limitation is the use of sequences in phrase-based SMT to model and translate source code with well-formed structures. We propose mppSMT, a divide-and-conquer technique to address that with novel training and migration algorithms using phrase-based SMT in three phases. First, mppSMT treats a program as a sequence of syntactic units and maps/translates such sequences in two languages to one another. Second, with a syntax-directed fashion, it deals with the tokens within syntactic units by encoding them with semantic symbols to represent their data and token types. This encoding via semantic symbols helps better migration of API usages. Third, the lexical tokens corresponding to each sememe are mapped or migrated. The resulting sequences of tokens are merged together to form the final migrated code. Such divide-and-conquer and syntax-direction strategies enable phrase-based SMT to adapt well to syntactical structures in source code, thus, improving migration accuracy. Our empirical evaluation on several real-world systems shows that 84.8 -- 97.9% and 70 -- 83% of the migrated methods are syntactically and semantically correct, respectively. 26.3 -- 51.2% of total migrated methods are exactly matched to the human-written C# code in the oracle. Compared to Java2CSharp, a rule-based migration tool, it achieves higher semantic accuracy from 6.6 -- 57.7% relatively. Importantly, it does not require manual labeling for training data or manual definition of rules.",2015,M. Singh; R. Kumar; I. Chana,585,596,12,23,10.1109/ASE.2015.74,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372046,IEEE Conferences,IEEE
Towards Better Word Alignment in Transformer,Neural network;neural machine translation;Transformer;word alignment;language model pre-training;alignment concentration,"While neural models based on the Transformer architecture achieve the State-of-the-Art translation performance, it is well known that the learned target-to-source attentions do not correlate well with word alignment. There is an increasing interest in inducing accurate word alignment in Transformer, due to its important role in practical applications such as dictionary-guided translation and interactive translation. In this article, we extend and improve the recent work on unsupervised learning of word alignment in Transformer on two dimensions: a) parameter initialization from a pre-trained cross-lingual language model to leverage large amounts of monolingual data for learning robust contextualized word representations, and b) regularization of the training objective to directly model characteristics of word alignments which results in favorable word alignments receiving more concentrated probabilities. Experiments on benchmark data sets of three language pairs show that the proposed methods can significantly reduce alignment error rate (AER) by at least 3.7 to 7.7 points on each language pair over two recent works on improving the Transformer's word alignment. Moreover, our methods can achieve better alignment results than GIZA++ on certain test sets.",2020,M. Xiao; S. Yu; Y. Wang,1801,1812,12,,10.1109/TASLP.2020.2998278,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103090,IEEE Journals,IEEE
Towards automatic translation of social network policies into controlled natural language,Data policies;Data Management;Data Storage and Sharing;Ontologies;Natural Language Processing,"On social networks, the storage, usage, and sharing of users data is usually regulated by privacy policies: natural language terms, in which specific actions are authorised, obliged, or denied, under some contextual conditions. Although guaranteeing degrees of readability and clarity, policies in natural language are not machine readable, thus preventing automatic controls on how the data are actually going to be used and processed by the entities that operate on them. In this paper, we propose an ontology-based approach for automatic translation of privacy statements, from natural language to a controlled natural one, to facilitate machine-readable processing. We provide a prototype implementation of the software-based translation tool, showing its effectiveness on a set of Facebook data policies.",2018,O. Letychevskyi; T. Polhul,1,12,12,,10.1109/RCIS.2018.8406683,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406683,IEEE Conferences,IEEE
A 1 TOPS/W Analog Deep Machine-Learning Engine With Floating-Gate Storage in 0.13 Âµm CMOS,Analog signal processing;current mode arithmetic;deep machine learning;floating gate;neuromorphic engineering;translinear circuits,"An analog implementation of a deep machine-learning system for efficient feature extraction is presented in this work. It features online unsupervised trainability and non-volatile floating-gate analog storage. It utilizes a massively parallel reconfigurable current-mode analog architecture to realize efficient computation, and leverages algorithm-level feedback to provide robustness to circuit imperfections in analog signal processing. A 3-layer, 7-node analog deep machine-learning engine was fabricated in a 0.13 Î¼m standard CMOS process, occupying 0.36 mm 2 active area. At a processing speed of 8300 input vectors per second, it consumes 11.4 Î¼W from the 3 V supply, achieving 1Ã—10 12 operation per second per Watt of peak energy efficiency. Measurement demonstrates real-time cluster analysis, and feature extraction for pattern recognition with 8-fold dimension reduction with an accuracy comparable to the floating-point software simulation baseline.",2015,O. Van Acker; O. Lachish; G. Burnett,270,281,12,60,10.1109/JSSC.2014.2356197,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6919341,IEEE Journals,IEEE
On Learning Meaningful Assert Statements for Unit Test Cases,Testing;Unit Tests;Deep Learning;Neural Machine Translation,"Software testing is an essential part of the software lifecycle and requires a substantial amount of time and effort. It has been estimated that software developers spend close to 50% of their time on testing the code they write. For these reasons, a long standing goal within the research community is to (partially) automate software testing. While several techniques and tools have been proposed to automatically generate test methods, recent work has criticized the quality and usefulness of the assert statements they generate. Therefore, we employ a Neural Machine Translation (NMT) based approach called Atlas (AuTomatic Learning of Assert Statements) to automatically generate meaningful assert statements for test methods. Given a test method and a focal method (i.e., the main method under test), Atlas can predict a meaningful assert statement to assess the correctness of the focal method. We applied Atlas to thousands of test methods from GitHub projects and it was able to predict the exact assert statement manually written by developers in 31% of the cases when only considering the top-1 predicted assert. When considering the top-5 predicted assert statements, Atlas is able to predict exact matches in 50% of the cases. These promising results hint to the potential usefulness of our approach as (i) a complement to automatic test case generation techniques, and (ii) a code completion support for developers, who can benefit from the recommended assert statements while writing test code.",2020,P. He; C. Meister; Z. Su,1398,1409,12,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283916,IEEE Conferences,IEEE
A Neural Model for Generating Natural Language Summaries of Program Subroutines,automatic documentation generation;source code summarization;code comment generation,"Source code summarization -- creating natural language descriptions of source code behavior -- is a rapidly-growing research topic with applications to automatic documentation generation, program comprehension, and software maintenance. Traditional techniques relied on heuristics and templates built manually by human experts. Recently, data-driven approaches based on neural machine translation have largely overtaken template-based systems. But nearly all of these techniques rely almost entirely on programs having good internal documentation; without clear identifier names, the models fail to create good summaries. In this paper, we present a neural model that combines words from code with code structure from an AST. Unlike previous approaches, our model processes each data source as a separate input, which allows the model to learn code structure independent of the text in code. This process helps our approach provide coherent summaries in many cases even when zero internal documentation is provided. We evaluate our technique with a dataset we created from 2.1m Java methods. We find improvement over two baseline techniques from SE literature and one from NLP literature.",2019,R. Upadhyay; P. K. Kankar; P. K. Padhy; V. K. Gupta,795,806,12,9,10.1109/ICSE.2019.00087,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811932,IEEE Conferences,IEEE
Using Smartphone Sensors for Improving Energy Expenditure Estimation,Accelerometer;Barometer;Energy Expenditure;Machine Learning;Accelerometer;barometer;energy expenditure;machine learning,"Energy expenditure (EE) estimation is an important factor in tracking personal activity and preventing chronic diseases, such as obesity and diabetes. Accurate and real-time EE estimation utilizing small wearable sensors is a difficult task, primarily because the most existing schemes work offline or use heuristics. In this paper, we focus on accurate EE estimation for tracking ambulatory activities (walking, standing, climbing upstairs, or downstairs) of a typical smartphone user. We used built-in smartphone sensors (accelerometer and barometer sensor), sampled at low frequency, to accurately estimate EE. Using a barometer sensor, in addition to an accelerometer sensor, greatly increases the accuracy of EE estimation. Using bagged regression trees, a machine learning technique, we developed a generic regression model for EE estimation that yields upto 96% correlation with actual EE. We compare our results against the state-of-the-art calorimetry equations and consumer electronics devices (Fitbit and Nike+ FuelBand). The newly developed EE estimation algorithm demonstrated superior accuracy compared with currently available methods. The results were calibrated against COSMED K4b2 calorimeter readings.",2015,R. Zhang; B. Zhou,1,12,12,10,10.1109/JTEHM.2015.2480082,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272038,IEEE Journals,IEEE
CHOBS: Color Histogram of Block Statistics for Automatic Bleeding Detection in Wireless Capsule Endoscopy Video,Bleeding detection;bleeding zone;color histogram;feature extraction;wireless capsule endoscopy,"Wireless capsule endoscopy (WCE) is the most advanced technology to visualize whole gastrointestinal (GI) tract in a non-invasive way. But the major disadvantage here, it takes long reviewing time, which is very laborious as continuous manual intervention is necessary. In order to reduce the burden of the clinician, in this paper, an automatic bleeding detection method for WCE video is proposed based on the color histogram of block statistics, namely CHOBS. A single pixel in WCE image may be distorted due to the capsule motion in the GI tract. Instead of considering individual pixel values, a block surrounding to that individual pixel is chosen for extracting local statistical features. By combining local block features of three different color planes of RGB color space, an index value is defined. A color histogram, which is extracted from those index values, provides distinguishable color texture feature. A feature reduction technique utilizing color histogram pattern and principal component analysis is proposed, which can drastically reduce the feature dimension. For bleeding zone detection, blocks are classified using extracted local features that do not incorporate any computational burden for feature extraction. From extensive experimentation on several WCE videos and 2300 images, which are collected from a publicly available database, a very satisfactory bleeding frame and zone detection performance is achieved in comparison to that obtained by some of the existing methods. In the case of bleeding frame detection, the accuracy, sensitivity, and specificity obtained from proposed method are 97.85%, 99.47%, and 99.15%, respectively, and in the case of bleeding zone detection, 95.75% of precision is achieved. The proposed method offers not only low feature dimension but also highly satisfactory bleeding detection performance, which even can effectively detect bleeding frame and zone in a continuous WCE video data.",2018,S. A. Hossain; L. A. Biswas; M. I. Hossain,1,12,12,5,10.1109/JTEHM.2017.2756034,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268657,IEEE Journals,IEEE
Automatic Quantitative Analysis of Human Respired Carbon Dioxide Waveform for Asthma and Non-Asthma Classification Using Support Vector Machine,Area;quantitative;feature;classifier;asthma,"Currently, carbon dioxide (CO2) waveforms measured by capnography are used to estimate respiratory rate and end-tidal CO2 (EtCO2) in the clinic. However, the shape of the CO2 signal carries significant diagnostic information about the asthmatic condition. Previous studies have shown a strong correlation between various features that quantitatively characterize the shape of CO2 signal and are used to discriminate asthma from non-asthma using pulmonary function tests, but no reliable progress was made, and no translation into clinical practice has been achieved. Therefore, this paper reports a relatively simple signal processing algorithm for automatic differentiation of asthma and non-asthma. CO2 signals were recorded from 30 non-asthmatic and 43 asthmatic patients. Each breath cycle was decomposed into subcycles, and features were computationally extracted. Thereafter, feature selection was performed using the area (Az) under the receiver operating characteristics curve analysis. A classification was performed via a leave-oneout cross-validation procedure by employing a support vector machine. Our results show maximum screening capabilities for upward expiration (AR1), downward inspiration (AR2), and the sum of AR1 and AR2, with an Az of 0.892, 0.803, and 0.793, respectively. The proposed method obtained an average accuracy of 94.52%, sensitivity of 97.67%, and specificity of 90% for discrimination of asthma and non-asthma. The proposed method allows for automatic classification of asthma and non-asthma condition by analyzing the shape of the CO2 waveform. The developed method may possibly be incorporated in real-time for assessment and management of the asthmatic conditions.",2018,S. Alansary; M. Nagi; N. Adly,55245,55256,12,2,10.1109/ACCESS.2018.2871091,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468979,IEEE Journals,IEEE
Bitext Dependency Parsing With Auto-Generated Bilingual Treebank,Dependency parsing;natural language processing;statistical machine translation;unannotated data,"This paper proposes a method to improve the accuracy of bilingual texts (bitexts) dependency parsing by using an auto-generated bilingual treebank created with the help of statistical machine translation (SMT) systems. Previous bitext parsing methods use human-annotated bilingual treebanks that are costly and troublesome to obtain. In the proposed method, we use an auto-generated bilingual treebank to train the parsing models. First, an SMT system is used to translate a monolingual treebank into the target language; then, a monolingual parser for the target language is used to parse the translated sentences. Since the auto-translated sentences and auto-parsed trees in the auto-generated bilingual treebank are far from perfect, the bilingual constraints are not sufficiently reliable. To overcome this problem, we propose a method to verify the reliability of the constraints using a large amount of target monolingual and bilingual unannotated data. Finally, we design a set of effective bilingual features for parsing models on the basis of the verified constraints. We conduct the experiments using a standard test data. The experimental results show that our bitext parser significantly outperforms monolingual parsers. Moreover, our method is still able to provide improvement when we use a larger monolingual treebank containing over 50 000 sentences. We also test the proposed method with different SMT systems and the results show that our method is very robust to the noise. In particular, the proposed method can be used in a purely monolingual setting with the help of SMT. That is, it does not need the human translation of the test set as previous methods do.",2012,S. Anand; J. Sutanto; M. S. Baker; M. Okandan; J. Muthuswamy,1461,1472,12,1,10.1109/TASL.2011.2180898,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111269,IEEE Journals,IEEE
Massive Exploration of Pseudo Data for Grammatical Error Correction,Natural language processing;language generation;grammars and other rewriting systems;machine translation,"Collecting a large amount of training data for grammatical error correction (GEC) models has been an ongoing challenge in the field of GEC. Recently, it has become common to use data demanding deep neural models such as an encoder-decoder for GEC; thus, tackling the problem of data collection has become increasingly important. The incorporation of pseudo data in the training of GEC models is one of the main approaches for mitigating the problem of data scarcity. However, a consensus is lacking on experimental configurations, namely, (i) the methods for generating pseudo data, (ii) the seed corpora used as the source of the pseudo data, and (iii) the means of optimizing the model. In this study, these configurations are thoroughly explored through massive amount of experiments, with the aim of providing an improved understanding of pseudo data. Our main experimental finding is that pretraining a model with pseudo data generated by back-translation-based method is the most effective approach. Our findings are supported by the achievement of state-of-the-art performance on multiple benchmark test sets (the CoNLL-2014 test set and the official test set of the BEA-2019 shared task) without requiring any modifications to the model architecture. We also perform an in-depth analysis of our model with respect to the grammatical error type and proficiency level of the text. Finally, we suggest future directions for further improving model performance.",2020,S. K. Pulipaka; C. K. Kasaraneni; V. N. Sandeep Vemulapalli; S. S. Mourya Kosaraju,2134,2145,12,,10.1109/TASLP.2020.3007753,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134890,IEEE Journals,IEEE
In-Bed Pose Estimation: Deep Learning With Shallow Dataset,Convolutional neural network (CNN);convolutional pose machine (CPM);histogram of oriented gradient (HOG);in-bed pose estimation;infrared selective (IRS),"This paper presents a robust human posture and body parts detection method under a specific application scenario known as in-bed pose estimation. Although the human pose estimation for various computer vision (CV) applications has been studied extensively in the last few decades, the in-bed pose estimation using camera-based vision methods has been ignored by the CV community because it is assumed to be identical to the general purpose pose estimation problems. However, the in-bed pose estimation has its own specialized aspects and comes with specific challenges, including the notable differences in lighting conditions throughout the day and having pose distribution different from the common human surveillance viewpoint. In this paper, we demonstrate that these challenges significantly reduce the effectiveness of the existing general purpose pose estimation models. In order to address the lighting variation challenge, the infrared selective (IRS) image acquisition technique is proposed to provide uniform quality data under various lighting conditions. In addition, to deal with the unconventional pose perspective, a 2- end histogram of oriented gradient (HOG) rectification method is presented. The deep learning framework proves to be the most effective model in human pose estimation; however, the lack of large public dataset for in-bed poses prevents us from using a large network from scratch. In this paper, we explored the idea of employing a pre-trained convolutional neural network (CNN) model trained on large public datasets of general human poses and fine-tuning the model using our own shallow (limited in size and different in perspective and color) in-bed IRS dataset. We developed an IRS imaging system and collected IRS image data from several realistic life-size mannequins in a simulated hospital room environment. A pre-trained CNN called convolutional pose machine (CPM) was fine-tuned for in-bed pose estimation by re-training its specific intermediate layers. Using the HOG rectification method, the pose estimation performance of CPM improved significantly by 26.4% in the probability of correct key-point (PCK) criteria at PCK0.1 compared to the model without such rectification. Even testing with only well aligned in-bed pose images, our fine-tuned model still surpassed the traditionally tuned CNN by another 16.6% increase in pose estimation accuracy.",2019,S. Ma; Y. Han,1,12,12,5,10.1109/JTEHM.2019.2892970,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611350,IEEE Journals,IEEE
Histogram-Based Features Selection and Volume of Interest Ranking for Brain PET Image Classification,Machine learning;computer-aided diagnosis;first order statistics;feature selection;positron emission tomography;classification;Alzheimerâ€™s disease,"Positron emission tomography (PET) is a molecular medical imaging modality which is commonly used for neurodegenerative diseases diagnosis. Computer-aided diagnosis, based on medical image analysis, could help quantitative evaluation of brain diseases such as Alzheimer's disease (AD). A novel method of ranking the effectiveness of brain volume of interest (VOI) to separate healthy control from AD brains PET images is presented in this paper. Brain images are first mapped into anatomical VOIs using an atlas. Histogram-based features are then extracted and used to select and rank VOIs according to the area under curve (AUC) parameter, which produces a hierarchy of the ability of VOIs to separate between groups of subjects. The top-ranked VOIs are then input into a support vector machine classifier. The developed method is evaluated on a local database image and compared to the known selection feature methods. Results show that using AUC outperforms classification results in the case of a two group separation.",2018,S. Mall; U. C. Jaiswal,1,12,12,7,10.1109/JTEHM.2018.2796600,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318637,IEEE Journals,IEEE
Automatic Extraction of Cause-Effect-Relations from Requirements Artifacts,causality extraction;natural language processing;pattern matching;requirements artifacts,"Background: The detection and extraction of causality from natural language sentences have shown great potential in various fields of application. The field of requirements engineering is eligible for multiple reasons: (1) requirements artifacts are primarily written in natural language, (2) causal sentences convey essential context about the subject of requirements, and (3) extracted and formalized causality relations are usable for a (semi-)automatic translation into further artifacts, such as test cases. Objective: We aim at understanding the value of interactive causality extraction based on syntactic criteria for the context of requirements engineering. Method: We developed a prototype of a system for automatic causality extraction and evaluate it by applying it to a set of publicly available requirements artifacts, determining whether the automatic extraction reduces the manual effort of requirements formalization. Result: During the evaluation we analyzed 4457 natural language sentences from 18 requirements documents, 558 of which were causal (12.52%). The best evaluation of a requirements document provided an automatic extraction of 48.57% cause-effect graphs on average, which demonstrates the feasibility of the approach. Limitation: The feasibility of the approach has been proven in theory but lacks exploration of being scaled up for practical use. Evaluating the applicability of the automatic causality extraction for a requirements engineer is left for future research. Conclusion: A syntactic approach for causality extraction is viable for the context of requirements engineering and can aid a pipeline towards an automatic generation of further artifacts from requirements artifacts.",2020,S. Yamane; T. Takano,561,572,12,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286079,IEEE Conferences,IEEE
Autonomous Unobtrusive Detection of Mild Cognitive Impairment in Older Adults,Mild Cognitive Impairment;Walking Speed;Home Activity;Unobtrusive Sensing Technologies;Older Population;Signal Processing;Smart Systems;Machine Learning;Home activity;machine learning;mild cognitive impairment (MCI);older population;signal processing;smart systems;unobtrusive sensing technologies;walking speed,"The current diagnosis process of dementia is resulting in a high percentage of cases with delayed detection. To address this problem, in this paper, we explore the feasibility of autonomously detecting mild cognitive impairment (MCI) in the older adult population. We implement a signal processing approach equipped with a machine learning paradigm to process and analyze real-world data acquired using home-based unobtrusive sensing technologies. Using the sensor and clinical data pertaining to 97 subjects, acquired over an average period of three years, a number of measures associated with the subjects' walking speed and general activity in the home were calculated. Different time spans of these measures were used to generate feature vectors to train and test two machine learning algorithms namely support vector machines and random forests. We were able to autonomously detect MCI in older adults with an area under the ROC curve of 0.97 and an area under the precision-recall curve of 0.93 using a time window of 24 weeks. This study is of great significance since it can potentially assist in the early detection of cognitive impairment in older adults.",2015,T. Kano; S. Sakti; S. Nakamura,1383,1394,12,54,10.1109/TBME.2015.2389149,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7005481,IEEE Journals,IEEE
Automatic Deep Extraction of Robust Dynamic Features for Industrial Big Data Modeling and Soft Sensor Application,"Attention denoising;dynamic vector, ensemble trees;feature extractor;soft sensor","Dynamic is one of the main bottlenecks in the industrial soft sensor application, due to the difficulties in representing and extracting dynamic data features. Meanwhile, an end-to-end deep network owns the ability to characterize sequence data information, but its fitting ability requires improvements in practical applications. In this article, an ensemble tree model with transferable and robust dynamic features extracted by a newly developed automatic dynamic feature extractor is proposed. First, the dynamic feature extractor with an encoding-decoding structure can provide effective dynamic features, which is equivalent to crossing and nonlinear mapping of sequences under the supervision of a decoder. Meanwhile, a new â€œregularizationâ€? method by smoothing dynamic features based on attention weights is proposed to denoise and alleviate the overfitting of the regressor after adding new features. Then, the extracted dynamic features can be transferred to the regressor with strong generalization ability, which takes into account the feature extraction of the deep network and the generalization of strong models. Finally, application results on a debutanizer distillation process show that the incorporation of robust dynamic features can significantly improve the soft sensing performance, compared to traditional methods. Moreover, the proposed model is further implemented through a cloud computing platform for industrial big data analytics.",2020,T. Kopinski; A. Gepperth; U. Handmann,4456,4467,12,3,10.1109/TII.2019.2945411,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859224,IEEE Journals,IEEE
To Be or Not to Be: Predicting Soluble SecAs as Membrane Proteins,Embedded membrane segment;position specific scoring matrix;SecA protein;support vector machine;transmembrane segment,"SecA is an important component of protein translocation in bacteria, and exists in soluble and membrane-integrated forms. Most membrane prediction programs predict SecA as being a soluble protein, with the exception of TMpred and TopPred. However, the membrane associated predicted segments by TMpred and TopPred are inconsistent across bacterial species in spite of high sequence homology. In this paper we describe a new method for membrane protein prediction, PSSM_SVM, which provides consistent results for integral membrane domains of SecAs across bacterial species. This PSSM encoding scheme demonstrates the highest accuracy in terms of Q2 among the common prediction methods, and produces consistent results on blind test data. None of the previously described methods showed this kind of consistency when tested against the same blind test set. This scheme predicts traditional transmembrane segments and most of the soluble proteins accurately. The PSSM scheme applied to the membrane-associated protein SecA shows characteristic features. In the set of 223 known SecA sequences, the PSSM_SVM prediction scheme predicts eight to nine residue embedded membrane segments. This predicted region is part of a 12 residue helix from known X-ray crystal structures of SecAs. This information could be important for determining the structure of SecA proteins in the membrane which have different conformational properties from other transmembrane proteins, as well as other soluble proteins that may similarly integrate into lipid bi-layers.",2007,V. Jayan; V. K. Bhadran,168,179,12,13,10.1109/TNB.2007.897486,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4220632,IEEE Journals,IEEE
Improving Computer-Aided Detection Using Convolutional Neural Networks and Random View Aggregation,Computer aided diagnosis;computed tomography;medical diagnostic imaging;machine learning;object detection;artificial neural networks;multi-layer neural network;deep learning,"Automated computer-aided detection (CADe) has been an important tool in clinical practice and research. State-of-the-art methods often show high sensitivities at the cost of high false-positives (FP) per patient rates. We design a two-tiered coarse-to-fine cascade framework that first operates a candidate generation system at sensitivities ~ 100% of but at high FP levels. By leveraging existing CADe systems, coordinates of regions or volumes of interest (ROI or VOI) are generated and function as input for a second tier, which is our focus in this study. In this second stage, we generate 2D (two-dimensional) or 2.5D views via sampling through scale transformations, random translations and rotations. These random views are used to train deep convolutional neural network (ConvNet) classifiers. In testing, the ConvNets assign class (e.g., lesion, pathology) probabilities for a new set of random views that are then averaged to compute a final per-candidate classification probability. This second tier behaves as a highly selective process to reject difficult false positives while preserving high sensitivities. The methods are evaluated on three data sets: 59 patients for sclerotic metastasis detection, 176 patients for lymph node detection, and 1,186 patients for colonic polyp detection. Experimental results show the ability of ConvNets to generalize well to different medical imaging CADe applications and scale elegantly to various data sets. Our proposed methods improve performance markedly in all cases. Sensitivities improved from 57% to 70%, 43% to 77%, and 58% to 75% at 3 FPs per patient for sclerotic metastases, lymph nodes and colonic polyps, respectively.",2016,V. S. Kornilov; V. M. Glushan; A. Y. Lozovoy,1170,1181,12,268,10.1109/TMI.2015.2482920,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279156,IEEE Journals,IEEE
Classification of Atrial Fibrillation and Acute Decompensated Heart Failure Using Smartphone Mechanocardiography: A Multilabel Learning Approach,Acute decompensated heart failure;atrial fibrillation;gyrocardiography;machine learning;seismocardiography;smartphone mechanocardiography,"Timely diagnosis of cardiovascular diseases (CVD) is crucial to prevent morbidity and mortality. Atrial fibrillation (AFib) and heart failure (HF) are two prevalent cardiac disorders that are associated with a high risk of morbidity and mortality, especially if they are concurrently present. Current approaches fail to screen many at-risk individuals who would benefit from preventive treatment; while others receive unnecessary interventions. An effective approach to the detection of CVDs is mechanocardiography (MCG) by which translational and rotational precordial chest movements are monitored. In this study, we collected MCG data from a study sample of 300 hospitalized cardiac patients using multidimensional built-in inertial sensors of a smartphone. Our main objective was to detect concurrent AFib and acute decompensated HF (ADHF) using smartphone MCG (or sMCG). To this end, we adopted a supervised machine learning classification using multi-label and hierarchical classification. Logistic regression, random forest, and extreme gradient boosting were used as candidate classifiers. The results of the analysis showed the area under the receiver operating characteristic curve values of 0.98 and 0.85 for AFib and ADHF, respectively. The highest percentages of positive and negative predictive values for AFib were 91.9 and 100; while for ADHF, they were 56.9 and 88.4 for the multi-label classification and 69.9 and 68.8 for the hierarchical classification, respectively. We conclude that using a single sMCG measurement, AFib can be detected accurately whereas ADHF can be detected with moderate certainty.",2020,V. Topac; V. Stoicu-Tivadar,7957,7968,12,,10.1109/JSEN.2020.2981334,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039560,IEEE Journals,IEEE
Toward Automatic Building Footprint Delineation From Aerial Images Using CNN and Regularization,Building extraction;fully convolutional network (FCN);polygon regularization;segmentation,"This study proposes an automatic building footprint extraction framework that consists of a convolutional neural network (CNN)-based segmentation and an empirical polygon regularization that transforms segmentation maps into structured individual building polygons. The framework attempts to replace part of the manual delineation of building footprints that are involved in surveying and mapping field with algorithms. First, we develop a scale robust fully convolutional network (FCN) by introducing multiple scale aggregation of feature pyramids from convolutional layers. Two postprocessing strategies are introduced to refine the segmentation maps from the FCN. The refined segmentation maps are vectorized and polygonized. Then, we propose a polygon regularization algorithm consisting of a coarse and fine adjustment, to translate the initial polygons into structured footprints. Experiments on a large open building data set including 181 000 buildings showed that our algorithm reached a high automation level where at least 50% of individual buildings in the test area could be delineated to replace manual work. Experiments on different data sets demonstrated that our FCN-based segmentation method outperformed several most recent segmentation methods, and our polygon regularization algorithm is robust in challenging situations with different building styles, image resolutions, and even low-quality segmentation.",2020,W. T. Zaw; Y. K. Thu; S. S. Moe; N. N. Oo; T. Supnithi,2178,2189,12,3,10.1109/TGRS.2019.2954461,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933116,IEEE Journals,IEEE
A Multi-Dimension End-to-End CNN Model for Rotating Devices Fault Diagnosis on High-Speed Train Bogie,Multi-sensor data;Automatic fault diagnosis;Bogie;End-to-End model;CNN,"With the improvement of sensor techniques, and the urgent requirement of automatic fault diagnosis technologies, the intelligent perception system on high speed train is more popular than ever before. It records the devices' state information through a sensor network, and services for further analysis. However, Traditional machine learning algorithms are usually constrained by massive multi-sensor data and knowledge-based feature extraction in fault diagnosis. Therefore, this paper extended fault diagnosis methodology into tensor space to deal with multi-sensor monitoring data and take full use of available information. Moreover, the convolutional neural network (CNN) is used for automatic feature learning and classification without human intervention. The effectiveness and efficiency are validated by dataset of rolling element bearings obtained in lab and real-use case. Three features can be highlighted. First of all, the proposed model showed a good adaptability and high efficiency under various working condition by taking full use of the multi-sensor data. It has powerful ability in accuracy and convergence speed. Secondly, it is not as sensitive to data quantity as other deep learning algorithms do. Such superior characteristic made the model more suitable for practical application, because of the insufficient failure data. At last, it is an intelligent End-to-End model, performing automatic fault diagnosis without manual intervention and suitable for real-use case.",2020,Wu Ning; Wugun Chen; Xinggan Zhang,2513,2524,12,2,10.1109/TVT.2019.2955221,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910402,IEEE Journals,IEEE
Flickr Image Community Analytics by Deep Noise-Refined Matrix Factorization,Machine learning;deep model;noise-refined;matrix factorization;community,"Accurately categorizing Flickr images into multiple pre-defined communities (e.g., â€œarchitectureâ€? and â€œpeacefulâ€?) is an indispensable technique in multimedia analysis, graphic design, fashion recommendation, etc. In practice, these communities are constructed and updated manually, which is subjective and intolerably time consuming. To alleviate these shortcomings, a noise-refined deep matrix factorization (MF) framework is proposed to intelligently discover communities from million-scale Flickr users, wherein the semantic tag correlations and community correlations are simultaneously encoded. More specifically, it is believable that Flickr communities are high-level clues on the basis of human visual semantic perception. Thereby, a MF algorithm is employed to approximate the community label matrix by the product of pairwise factor matrices, which represent the latent representations of user-provided tags and the corresponding basis matrix respectively. Subsequently, an end-to-end deep model is formulated to hierarchically derive the latent deep representation from raw image pixels to semantic tags. To robustly handle contaminated image semantic tags and community labels, an l1 norm constraint is encoded to enhance the MF. Meanwhile, to optimally exploit the rich context information of Flickr images, the intrinsic structure between image semantic tags and between communities are collaboratively captured. Finally, the upgraded MF and the deep model are seamlessly combined into a unified framework, which is solved by an iterative algorithm. Experiments on 2 M Flickr images have demonstrated the superiority of our approach. Besides, the discovered Flickr communities can improve photo retargeting and visual aesthetics assessment significantly.",2020,Y. G. Thimmaraja; H. S. Jayanna,1273,1284,12,,10.1109/TMM.2019.2938664,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821403,IEEE Journals,IEEE
Data-Driven Multiobjective Optimization for Burden Surface in Blast Furnace With Feedback Compensation,Blast furnace (BF);burden surface;feedback compensation;kernel extreme learning machine (KELM);multiobjective optimization problem,"In this paper, an intelligent data-driven optimization scheme is proposed for finding the proper burden surface distribution, which exerts large influences on keeping blast furnace running smoothly in an energy-efficient state. In the proposed scheme, production indicators prediction models are first developed using a kernel extreme learning machine algorithm. To heel, burden surface decision is presented as a multiobjective optimization problem for the first time and solved by a modified two-stage intelligent optimization strategy to generate the initial setting values of burden surface. Furthermore, considering the existence of the approximation error of the created prediction models, feedback compensation is implemented to enhance the reliability of the results, in which an improved association rule mining method is developed to find the corrected values to compensate the initial setting values. Finally, we apply the proposed optimization scheme to determine the setting values of burden surface using actual data, and experimental results illustrate its effectiveness and feasibility.",2020,Y. Isono; Y. Ichifuji; H. Sato; S. Tanimoto; A. Kanai; T. Kobayashi; N. Sonehara,2233,2244,12,8,10.1109/TII.2019.2908989,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680649,IEEE Journals,IEEE
Neuromuscular Password-Based User Authentication,Biometrics;high-density surface electromyogram (sEMG);machine learning;neuromuscular password;user authentication,"In this article, we propose a novel neuromuscular password-based user authentication method. The method consists of two parts: surface electromyogram (sEMG) based finger muscle isometric contraction password (FMICP) and neuromuscular biometrics. FMICP can be entered through isometric contraction of different finger muscles in a prescribed order without actual finger movement, which makes it difficult for observers to obtain the password. In our study, the isometric contraction patterns of different finger muscles were recognized through high-density sEMG signals acquired from the right dorsal hand. Moreover, both time-frequency-space domain features at macroscopic level (interference-pattern EMG) and motor neuron firing rate features at microscopic level (via decomposition) were extracted to represent neuromuscular biometrics, serving as a second defense. The FMICP and macro-micro neuromuscular biometrics together form a neuromuscular password. The proposed neuromuscular password achieved an equal error rate (EER) of 0.0128 when impostors entered a wrong FMICP. Even when impostors entered the correct FMICP, the neuromuscular biometrics, as the second defense, inhibited impostors with an EER of 0.1496. To the best of our knowledge, this is the first study to use individually unique neuromuscular information during unobservable muscle isometric contractions for user authentication, with training and testing data acquired on different days.",2021,Y. Jin,2641,2652,12,,10.1109/TII.2020.3001612,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115220,IEEE Journals,IEEE
Speech Technology for Unwritten Languages,Speech processing;automatic speech recognition;unsupervised learning;speech synthesis;image retrieval,"Speech technology plays an important role in our everyday life. Among others, speech is used for human-computer interaction, for instance for information retrieval and on-line shopping. In the case of an unwritten language, however, speech technology is unfortunately difficult to create, because it cannot be created by the standard combination of pre-trained speech-to-text and text-to-speech subsystems. The research presented in this article takes the first steps towards speech technology for unwritten languages. Specifically, the aim of this work was 1) to learn speech-to-meaning representations without using text as an intermediate representation, and 2) to test the sufficiency of the learned representations to regenerate speech or translated text, or to retrieve images that depict the meaning of an utterance in an unwritten language. The results suggest that building systems that go directly from speech-to-meaning and from meaning-to-speech, bypassing the need for text, is possible.",2020,Y. Liu; D. Zhang; L. Du; Z. Gu; J. Qiu; Q. Tan,964,975,12,3,10.1109/TASLP.2020.2973896,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998182,IEEE Journals,IEEE
A Novel Positive Transfer Learning Approach for Telemonitoring of Parkinsonâ€™s Disease,Machine learning;negative transfer;telemonitoring;transfer learning (TL),"Telemonitoring is the use of electronic devices to remotely monitor patients. Taking the Parkinson's disease (PD) as an example, the use of at-home testing device (AHTD) enables remote, internet-based measurement of PD vocal symptoms. Translating AHTD measurement into a unified PD rating scale (UPDRS) through predictive analytics enables cost-effective, convenient, and close tracking of PD progression. Building a predictive model between AHTD measurement and UPDRS is not straightforward because PD patients are highly heterogeneous, which requires patient-specific models. Learning a patient-specific model faces the challenge of limited data. Transfer learning (TL) tackles this challenge by leveraging other patients' information to make up the data shortage when modeling a target patient. Among different TL methods, the category of parameter transfer methods is more appropriate for the telemonitoring application because it transfers patient-specific model parameters but not patients' data. However, existing parameter transfer methods fall short because not every other patient's information is helpful and blind transfer causes the problem of negative transfer. To tackle this limitation, we propose a positive TL (PTL) method. We provide an in-depth theoretical study on the risk and condition for negative transfer to happen, which further drive the development of novel PTL algorithms that are robust to negative transfer. We apply PTL to predict UPDRS of 42 PD patients using their AHTD vocal measurement. PTL achieves significantly better accuracy compared with single learning and one-model-fits-all approaches.",2019,Y. Siegert; X. Jiang; V. Krieg; S. BartholomÃ¤us,180,191,12,2,10.1109/TASE.2018.2874233,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520887,IEEE Journals,IEEE
Learning life cycle to speed up autonomic optical transmission and networking adoption,Autonomic optical transmission and networking;Machine learning;Training function placement,"Autonomic optical transmission and networking requires machine learning (ML) models to be trained with large datasets. However, the availability of enough real data to produce accurate ML models is rarely ensured since new optical equipment and techniques are continuously being deployed in the network. One option is to generate data from simulations and lab experiments, but such data could not cover the whole features space and would translate into inaccuracies in the ML models. In this paper, we propose an ML-based algorithm life cycle to facilitate ML deployment in real operator networks. The dataset for ML training can be initially populated based on the results from simulations and lab experiments. Once ML models are generated, ML retraining can be performed after inaccuracies are detected to improve their precision. Illustrative numerical results show the benefits of the proposed learning cycle for general use cases. In addition, two specific use cases are proposed and demonstrated that implement different learning strategies: (i) a two-phase strategy performing out-of-field training using data from simulations and lab experiments with generic equipment, followed by an in-field adaptation to support heterogeneous equipment (the accuracy of this strategy is shown for a use case of failure detection and identification), and (ii) in-field retraining, where ML models are retrained after detecting model inaccuracies. Different approaches are analyzed and evaluated for a use case of autonomic transmission, where results show the significant benefits of collective learning.",2019,Y. Wu,226,237,12,7,10.1364/JOCN.11.000226,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717575,IEEE Journals,IEEE
seIMC: A GSW-Based Secure and Efficient Integer Matrix Computation Scheme With Implementation,Homomorphic encryption;matrix computation;machine learning;GSW encryption scheme;big data;privacy protection,"As atomic operations, secure matrix-based computations using homomorphic encryption (HE) have attracted much attention in cloud-based machine learning. However, most existing secure matrix computation solutions that focus on HE schemes suffer efficiency loss as the size of the matrix, which greatly limits their applications in the big data environment. To address these issues, this paper proposes seIMC, an integer matrix computation scheme based on the Gentry-Sahai-Waters (GSW) scheme, to cope with privacy protection and secure computation of large-scale data. In detail, we translate the GSW scheme to encrypt an integer matrix modulo $q$ (i.e., a large positive integer), and homomorphically compute matrix addition and multiplication, which is a natural extension of HAO scheme. Besides, the correctness and security analysis of seIMC are shown, and complexity analysis is also given in this study. Furthermore, the proposed schemes are implemented, including public-key encryption and private-key encryption schemes. Compared with existing secure matrix computation schemes, the proposed scheme performs better in execution time. Finally, seIMC is applied to solve the problem of the number of ways in which any two participants make friends through $k$ steps in an encrypted social network. Experiments show that when the cloud server processes an integer matrix of 1000 people with a security level of 90, namely, 1 million data volumes, it only takes approximately 1.9 minutes for each homomorphic matrix multiplication. Hence, the practicality of the proposed seIMC in privacy protection under a big data environment is highly proven.",2020,Y. Zhang; T. Zhang,98383,98394,12,,10.1109/ACCESS.2020.2996000,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097235,IEEE Journals,IEEE
Learning Discriminative Spatiospectral Features of ERPs for Accurate Brainâ€“Computer Interfaces,Brain-computer interfaces;ERPs;P300;EEG;signal processing;machine learning,"Constructing accurate predictive models is at the heart of brain-computer interfaces (BCIs) because these models can ultimately translate brain activities into communication and control commands. The majority of the previous work in BCI use spatial, temporal, or spatiotemporal features of event-related potentials (ERPs). In this study, we examined the discriminatory effect of their spatiospectral features to capture the most relevant set of neural activities from electroencephalographic recordings that represent users' mental intent. In this regard, we model ERP waveforms using a sum of sinusoids with unknown amplitudes, frequencies, and phases. The effect of this signal modeling step is to represent high-dimensional ERP waveforms in a substantially lower dimensionality space, which includes their dominant power spectral contents. We found that the most discriminative frequencies for accurate decoding of visual attention modulated ERPs lie in a spectral range less than 6.4 Hz. This was empirically verified by treating dominant frequency contents of ERP waveforms as feature vectors in the state-of-the-art machine learning techniques used herein. The constructed predictive models achieved remarkable performance, which for some subjects was as high as 94% as measured by the area under curve. Using these spectral contents, we further studied the discriminatory effect of each channel and proposed an efficient strategy to choose subject-specific subsets of channels that generally led to classifiers with comparable performance.",2019,Yuejie Zhang; Tao Zhang,2009,2020,12,3,10.1109/JBHI.2018.2883458,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613780,IEEE Journals,IEEE
From Minimum Enclosing Ball to Fast Fuzzy Inference System Training on Large Datasets,Core vector machine (CVM);fuzzy inference systems (FISs);Gaussian mixture model (GMM);minimum enclosing ball (MEB),"While fuzzy inference systems (FISs) have been extensively studied in the past decades, the minimum enclosing ball (MEB) problem was recently introduced to develop fast and scalable methods in pattern classification and machine learning. In this paper, the relationship between these two apparently different data modeling techniques is explored. First, based on the reduced-set density estimator, a bridge between the MEB problem and the FIS is established. Then, an important finding that the Mamdani-Larsen FIS (ML-FIS) can be translated into a special kernelized MEB problem, i.e., a center-constrained MEB problem under some conditions, is revealed. Thus, fast kernelized MEB approximation algorithms can be adopted to construct ML-FIS in an efficient manner. Here, we propose the use of a core vector machine (CVM), which is a fast kernelized MEB approximation algorithm for support vector machine (SVM) training, to accomplish this task. The proposed fast ML-FIS training algorithm has the following merits: (1) the number of fuzzy rules can be automatically determined by the CVM training and (2) fast ML-FIS training on large datasets can be achieved as the upper bound on the time complexity of learning the parameters in ML-FIS is linear with the dataset size N and the upper bound on the corresponding space complexity is theoretically independent of N. Our experiments on simulated and real datasets confirm these advantages of the proposed training method, and demonstrate its superior robustness as well. This paper not only represents a very first study of the relationship between MEB and FIS, but it also points out the mutual transformation between kernel methods and FISs under the framework of the Gaussian mixture model and MEB.",2009,Z. BilanovÃ¡; J. PerhÃ¡Ä?,173,184,12,33,10.1109/TFUZZ.2008.2006620,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637848,IEEE Journals,IEEE
SVM-Based System for Prediction of Epileptic Seizures From iEEG Signal,Data-analytic modeling;epilepsy;feature representation;intracranial electroencephalogram (iEEG);postprocessing;seizure prediction;subject-specific modeling;support vector machine (SVM);unbalanced classification,"Objective: This paper describes a data-analytic modeling approach for the prediction of epileptic seizures from intracranial electroencephalogram (iEEG) recording of brain activity. Even though it is widely accepted that statistical characteristics of iEEG signal change prior to seizures, robust seizure prediction remains a challenging problem due to subject-specific nature of data-analytic modeling. Methods: Our work emphasizes the understanding of clinical considerations important for iEEG-based seizure prediction, and proper translation of these clinical considerations into data-analytic modeling assumptions. Several design choices during preprocessing and postprocessing are considered and investigated for their effect on seizure prediction accuracy. Results: Our empirical results show that the proposed support vector machine-based seizure prediction system can achieve robust prediction of preictal and interictal iEEG segments from dogs with epilepsy. The sensitivity is about 90-100%, and the false-positive rate is about 0-0.3 times per day. The results also suggest that good prediction is subject specific (dog or human), in agreement with earlier studies. Conclusion : Good prediction performance is possible only if the training data contain sufficiently many seizure episodes, i.e., at least 5-7 seizures. Significance: The proposed system uses subject-specific modeling and unbalanced training data. This system also utilizes three different time scales during training and testing stages.",2017,Z. Xu; C. Kit; J. J. Webster,1011,1022,12,37,10.1109/TBME.2016.2586475,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7501827,IEEE Journals,IEEE
Multiagent Deep-Reinforcement-Learning-Based Virtual Resource Allocation Through Network Function Virtualization in Internet of Things,Deep reinforcement learning (DRL);Internet of Things (IoT);machine learning (ML);network virtualization;optimization;Q-learning (QL);resource allocation,"Resource allocation is a significant task in the emerging area of Internet of Things (IoT). IoT devices are usually low-cost devices with limited computational power and capabilities for long term communication. In this article, the network function virtualization (NFV) technique is used to access resources of the network and a reinforcement learning (RL) algorithm is used to solve the problem of resource allocation in IoT networks. The traffic of the IoT network uses the substrate network which is available through NFV for its data transmission. The data transmission needs of the IoT network are translated to virtual requests and service function chain (SFC) are mapped to the substrate network to serve the requests. The problem of SFC placement while meeting the system constraints of the IoT network is a nonconvex problem. In the proposed deep RL (DRL)-based resource allocation, the virtual layer acts as a common repository of the network resources. The optimization problem of SFC placement under the system constraints of IoT networks can be formulated as a Markovian decision process (MDP). The MDP problem is solved through a multiagent DRL algorithm where each agent serves an SFC. Two Q-networks are considered, where one Q-network solves the SFC placement problem while the other updates weights of the Q-network through keeping track of long-term policy changes. The virtual agents serving SFCs interact with the environment, receive reward collectively and update the policy by using the learned experiences. We show that the proposed scheme can solve the optimization problem of SFC placement through adequate reward design, state, and action space formulation. Simulation results demonstrate that the multiagent DRL scheme outperforms the reference schemes in terms of utility gained as measured through different network parameters.",2021,Z. Yang; L. Chen; M. L. Nguyen,3410,3421,12,,10.1109/JIOT.2020.3022572,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187862,IEEE Journals,IEEE
Musical instrument recognition by pairwise classification strategies,Feature selection;Gaussian mixture model (GMM);genetic algorithms;inertia ratio maximization with feature space projection (IRMFSP);musical instrument recognition;pairwise classification;support vector machine (SVM),"Musical instrument recognition is an important aspect of music information retrieval. In this paper, statistical pattern recognition techniques are utilized to tackle the problem in the context of solo musical phrases. Ten instrument classes from different instrument families are considered. A large sound database is collected from excerpts of musical phrases acquired from commercial recordings translating different instrument instances, performers, and recording conditions. More than 150 signal processing features are studied including new descriptors. Two feature selection techniques, inertia ratio maximization with feature space projection and genetic algorithms are considered in a class pairwise manner whereby the most relevant features are fetched for each instrument pair. For the classification task, experimental results are provided using Gaussian mixture models (GMMs) and support vector machines (SVMs). It is shown that higher recognition rates can be reached with pairwise optimized subsets of features in association with SVM classification using a radial basis function kernel",2006,Z. Yang; M. Li; Z. Zhu; L. Chen; L. Wei; S. Wang,1401,1412,12,59,10.1109/TSA.2005.860842,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1643665,IEEE Journals,IEEE
Newton-ADMM: A Distributed GPU-Accelerated Optimizer for Multiclass Classification Problems,Second-Order Method;Newton;ADMM;Convex optimization;Machine Learning;Classification,"First-order optimization techniques, such as stochastic gradient descent (SGD) and its variants, are widely used in machine learning applications due to their simplicity and low per-iteration costs. However, they often require larger numbers of iterations, with associated communication costs in distributed environments. In contrast, Newton-type methods, while having higher per-iteration computation costs, typically require a significantly smaller number of iterations, which directly translates to reduced communication costs. We present a novel distributed optimizer for classification problems, which integrates a GPU-accelerated Newton-type solver with the global consensus formulation of Alternating Direction of Method Multipliers (ADMM). By leveraging the communication efficiency of ADMM, a highly efficient GPUaccelerated inexact-Newton solver, and an effective spectral penalty parameter selection strategy, we show that our proposed method (i) yields better generalization performance on several classification problems; (ii) significantly outperforms state-of-the-art methods in distributed time to solution; and (iii) offers better scaling on large distributed platforms.",2020,Z. Yang; W. Chen; F. Wang; B. Xu,1,12,12,,10.1109/SC41405.2020.00061,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355255,IEEE Conferences,IEEE
Unsupervised Neural Machine Translation With Cross-Lingual Language Representation Agreement,Unsupervised neural machine translation;un-supervised bilingual word embedding;cross-lingual language model,"Unsupervised cross-lingual language representation initialization methods such as unsupervised bilingual word embedding (UBWE) pre-training and cross-lingual masked language model (CMLM) pre-training, together with mechanisms such as denoising and back-translation, have advanced unsupervised neural machine translation (UNMT), which has achieved impressive results on several language pairs, particularly French-English and German-English. Typically, UBWE focuses on initializing the word embedding layer in the encoder and decoder of UNMT, whereas the CMLM focuses on initializing the entire encoder and decoder of UNMT. However, UBWE/CMLM training and UNMT training are independent, which makes it difficult to assess how the quality of UBWE/CMLM affects the performance of UNMT during UNMT training. In this paper, we first empirically explore relationships between UNMT and UBWE/CMLM. The empirical results demonstrate that the performance of UBWE and CMLM has a significant influence on the performance of UNMT. Motivated by this, we propose a novel UNMT structure with cross-lingual language representation agreement to capture the interaction between UBWE/CMLM and UNMT during UNMT training. Experimental results on several language pairs demonstrate that the proposed UNMT models improve significantly over the corresponding state-of-the-art UNMT baselines.",2020,A. C. Fang; H. Bunt; J. Cao; X. Liu,1170,1182,13,,10.1109/TASLP.2020.2982282,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043536,IEEE Journals,IEEE
Integration of Statistical Models for Dictation of Document Translations in a Machine-Aided Human Translation Task,Machine-aided human translation (MAHT);machine translation;named entity recognition;speech recognition,"This paper presents a model for machine-aided human translation (MAHT) that integrates source language text and target language acoustic information to produce the text translation of source language document. It is evaluated on a scenario where a human translator dictates a first draft target language translation of a source language document. Information obtained from the source language document, including translation probabilities derived from statistical machine translation (SMT) and named entity tags derived from named entity recognition (NER), is incorporated with acoustic phonetic information obtained from an automatic speech recognition (ASR) system. One advantage of the system combination used here is that words that are not included in the ASR vocabulary can be correctly decoded by the combined system. The MAHT model and system implementation is presented. It is shown that a relative decrease in word error rate of 29% can be obtained by this combined system relative to the baseline ASR performance on a French to English document translation task in the Hansard domain. In addition, it is shown that transcriptions obtained by using the combined system show a relative increase in NIST score of 34% compared to transcriptions obtained from the baseline ASR system.",2010,A. J. Agrawal; M. B. Chandak,2015,2027,13,13,10.1109/TASL.2010.2040793,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393062,IEEE Journals,IEEE
Structure-Invariant Testing for Machine Translation,Metamorphic testing;Machine translation;Structural invariance,"In recent years, machine translation software has increasingly been integrated into our daily lives. People routinely use machine translation for various applications, such as describing symptoms to a foreign doctor and reading political news in a foreign language. However, the complexity and intractability of neural machine translation (NMT) models that power modern machine translation make the robustness of these systems difficult to even assess, much less guarantee. Machine translation systems can return inferior results that lead to misunderstanding, medical misdiagnoses, threats to personal safety, or political conflicts. Despite its apparent importance, validating the robustness of machine translation systems is very difficult and has, therefore, been much under-explored. To tackle this challenge, we introduce structure-invariant testing (SIT), a novel metamorphic testing approach for validating machine translation software. Our key insight is that the translation results of â€œsimilarâ€? source sentences should typically exhibit similar sentence structures. Specifically, SIT (1) generates similar source sentences by substituting one word in a given sentence with semantically similar, syntactically equivalent words; (2) represents sentence structure by syntax parse trees (obtained via constituency or dependency parsing); (3) reports sentence pairs whose structures differ quantitatively by more than some threshold. To evaluate SIT, we use it to test Google Translate and Bing Microsoft Translator with 200 source sentences as input, which led to 64 and 70 buggy issues with 69.5% and 70% top-1 accuracy, respectively. The translation errors are diverse, including under-translation, over-translation, incorrect modification, word/phrase mistranslation, and unclear logic.",2020,C. Adak,961,973,13,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284002,IEEE Conferences,IEEE
Phonology-Augmented Statistical Framework for Machine Transliteration Using Limited Linguistic Resources,Transliteration;machine translation;cross-lingual information retrieval;named entity recognition,"Transliteration converts words in a source language (e.g., English) into words in a target language (e.g., Vietnamese). This conversion considers the phonological structure of the target language, as the transliterated output needs to be pronounceable in the target language. For example, a word in Vietnamese that begins with a consonant cluster is phonologically invalid and thus would be an incorrect output of a transliteration system. Most statistical transliteration approaches, albeit being widely adopted, do not explicitly model the target language's phonology, which often results in invalid outputs. The problem is compounded by the limited linguistic resources available when converting foreign words to transliterated words in the target language. In this paper, we present a phonology-augmented statistical framework suitable for transliteration, especially when only limited linguistic resources are available. We propose the concept of pseudo-syllables as structures representing how segments of a foreign word are organized according to the syllables of the target language's phonology. We performed transliteration experiments on Vietnamese and Cantonese. We show that the proposed framework outperforms the statistical baseline by up to 44.68% relative, when there are limited training examples (587 entries).",2019,C. Prasad; J. S. Kallimani,199,211,13,,10.1109/TASLP.2018.2875269,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488567,IEEE Journals,IEEE
Semi-Supervised Neural Machine Translation via Marginal Distribution Estimation,Neural machine translation;semi-supervised learning;natural language processing,"Neural machine translation (NMT) heavily relies on parallel bilingual corpora for training. Since large-scale, high-quality parallel corpora are usually costly to collect, it is appealing to exploit monolingual corpora to improve NMT. Inspired by the law of total probability, which connects the probability of a given target-side monolingual sentence to the conditional probability of translating from a source sentence to the target one, we propose to explicitly exploit this connection and help the training procedure of NMT models using monolingual data. The key technical challenge of this approach is that there are exponentially many source sentences for a target monolingual sentence while computing the sum of the conditional probability given each possible source sentence. We address this challenge by leveraging the reverse translation model (target-to-source translation model) to sample several mostly likely source-side sentences and avoid enumerating all possible candidate source sentences. Then we propose two different methods to leverage the law of total probability, including marginal distribution regularization and likelihood maximization of monolingual corpora. Experiment results on English-French and German-English tasks demonstrate that our methods achieve significant improvement over several strong baselines.",2019,Ding Liu; Yu Zhou; Chengqing Zong; Fuji Ren,1564,1576,13,1,10.1109/TASLP.2019.2921423,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732422,IEEE Journals,IEEE
A Novel Sentence-Level Agreement Architecture for Neural Machine Translation,Neural machine translation (NMT);sentence-level agreement,"In neural machine translation (NMT), there is a natural correspondence between source and target sentences. The traditional NMT method does not explicitly model the translation agreement on sentence-level. In this article, we propose a comprehensive and novel sentence-level agreement architecture to alleviate this problem. It directly minimizes the difference between the representations of the source-side and target-side sentence on sentence-level. First, we compare a variety of sentence representation strategies and propose a â€œGated Sumâ€? sentence representation to achieve better sentence semantic information. Then, rather than a single-layer sentence-level agreement architecture, we further propose a multi-layer sentence agreement architecture to make the source and target semantic spaces closer layer by layer. The proposed agreement module can be integrated into NMT as an additional training objective function, and can also be used to enhance the representation of the source-side sentences. Experiments on the NIST Chinese-to-English and the WMT English-to-German translation tasks show that the proposed agreement architecture achieves significant improvements over state-of-the-art baselines, demonstrating the effectiveness and necessity of exploiting sentence-level agreement for NMT.",2020,E. Dikici; M. SaraÃ§lar,2585,2597,13,,10.1109/TASLP.2020.3021347,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185042,IEEE Journals,IEEE
Improving Automatic Speech Recognition and Speech Translation via Word Embedding Prediction,Speech recognition;speech translation,"In this article, we target speech translation (ST). We propose lightweight approaches that generally improve either ASR or end-to-end ST models. We leverage continuous representations of words, known as word embeddings, to improve ASR in cascaded systems as well as end-to-end ST models. The benefit of using word embedding is that word embedding can be obtained easily by training on pure textual data, which alleviates data scarcity issue. Also, word embedding provides additional contextual information to speech models. We motivate to distill the knowledge from word embedding into speech models. In ASR, we use word embeddings as a regularizer to reduce the WER, and further propose a novel decoding method to fuse the semantic relations among words for further improvement. In the end-to-end ST model, we propose leveraging word embeddings as an intermediate representation to enhance translation performance. Our analysis shows that it is possible to map speech signals to semantic space, which motivates future work on applying the proposed methods in spoken language processing tasks.",2021,L. Ji; L. Wang; X. Geng,93,105,13,,10.1109/TASLP.2020.3037543,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257188,IEEE Journals,IEEE
Entity Highlight Generation as Statistical and Neural Machine Translation,Entity highlight generation;Seq2Seq model;attention mechanism;copy mechanism;coverage mechanism,"Entity highlight refers to a short, concise, and characteristic description for an entity, which can be applied to various applications. In this article, we study the problem of automatically generating entity highlights from the descriptive sentences of entities. Specifically, we develop two computational approaches, one is inspired by the statistical machine translation (SMT) and another is a sequence-to-sequence learning (Seq2Seq) approach, which has been successfully applied in neural machine translation and neural summarization. In the Seq2Seq approach, we use attention mechanism, copy mechanism, and coverage mechanism. To generate entity-specific highlights, we also incorporate entity name into the Seq2Seq model to guide the decoding process. We automatically collect large-scale instances as training data without any manual annotation, and ask annotators to create a test set. We compare with several strong baseline methods, and evaluate the approaches with both automatic evaluation and manual evaluation. Experimental results show that the entity enhanced Seq2Seq model with attention, copy, and coverage mechanisms significantly outperforms all other approaches in terms of multiple evaluation metrics.1",2018,M. Alharbi; T. Cheesman; R. S. Laramee,1860,1872,13,,10.1109/TASLP.2018.2845111,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374886,IEEE Journals,IEEE
Comparison and Combination of Lightly Supervised Approaches for Language Portability of a Spoken Language Understanding System,Language portability;spoken dialogue systems;spoken language understanding;statistical machine translation,"Portability of a spoken dialogue system (SDS) to a new domain or a new language is a hot topic as it may imply gains in time and cost for building new SDSs. In particular in this paper we investigate several fast and efficient approaches for language portability of the spoken language understanding (SLU) module of a dialogue system. We show that the use of statistical machine translation (SMT) can reduce the time and the cost of porting a system from a source to a target language. For conceptual decoding, a state-of-the-art module based on conditional random fields (CRF) is used and a new approach based on phrase-based statistical machine translation (PB-SMT) is also evaluated. The experimental results show the efficiency of the proposed methods for a fast and low cost SLU language portability. In addition, we propose two methods to increase SLU robustness to translation errors. Overall, it is shown that the combination of all these approaches can further reduce the concept error rate. While most of the experiments in this paper deal with portability from French to Italian (given the availability of the Media French corpus and its subset manually translated into Italian), a validation of our methodology is eventually proposed in Arabic.",2013,M. Tsujikawa; K. Okabe; K. Hanazawa; Y. Kajikawa,636,648,13,9,10.1109/TASL.2012.2229983,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6362182,IEEE Journals,IEEE
Automating App Review Response Generation,App reviews;response generation;neural machine translation,"Previous studies showed that replying to a user review usually has a positive effect on the rating that is given by the user to the app. For example, Hassan et al. found that responding to a review increases the chances of a user updating their given rating by up to six times compared to not responding. To alleviate the labor burden in replying to the bulk of user reviews, developers usually adopt a template-based strategy where the templates can express appreciation for using the app or mention the company email address for users to follow up. However, reading a large number of user reviews every day is not an easy task for developers. Thus, there is a need for more automation to help developers respond to user reviews. Addressing the aforementioned need, in this work we propose a novel approach RRGen that automatically generates review responses by learning knowledge relations between reviews and their responses. RRGen explicitly incorporates review attributes, such as user rating and review length, and learns the relations between reviews and corresponding responses in a supervised way from the available training data. Experiments on 58 apps and 309,246 review-response pairs highlight that RRGen outperforms the baselines by at least 67.4% in terms of BLEU-4 (an accuracy measure that is widely used to evaluate dialogue response generation systems). Qualitative analysis also confirms the effectiveness of RRGen in generating relevant and accurate responses.",2019,P. T. Krishnan; P. Balasubramanian,163,175,13,1,10.1109/ASE.2019.00025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952476,IEEE Conferences,IEEE
Machine Learning Techniques for Ophthalmic Data Processing: A Review,Ophthalmic diagnostics;deep learning;diabetic retinopathy;age-related macular degeneration;glaucoma,"Machine learning and especially deep learning techniques are dominating medical image and data analysis. This article reviews machine learning approaches proposed for diagnosing ophthalmic diseases during the last four years. Three diseases are addressed in this survey, namely diabetic retinopathy, age-related macular degeneration, and glaucoma. The review covers over 60 publications and 25 public datasets and challenges related to the detection, grading, and lesion segmentation of the three considered diseases. Each section provides a summary of the public datasets and challenges related to each pathology and the current methods that have been applied to the problem. Furthermore, the recent machine learning approaches used for retinal vessels segmentation, and methods of retinal layers and fluid segmentation are reviewed. Two main imaging modalities are considered in this survey, namely color fundus imaging, and optical coherence tomography. Machine learning approaches that use eye measurements and visual field data for glaucoma detection are also included in the survey. Finally, the authors provide their views, expectations and the limitations of the future of these techniques in the clinical practice.",2020,R. A. Dam; A. Guessoum,3338,3350,13,2,10.1109/JBHI.2020.3012134,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151176,IEEE Journals,IEEE
Automatic Lung Segmentation With Juxta-Pleural Nodule Identification Using Active Contour Model and Bayesian Approach,Active contour;lung segmentation;chest CT images;computer aided diagnosis;juxta-pleural nodule,"Objective: chest computed tomography (CT) images and their quantitative analyses have become increasingly important for a variety of purposes, including lung parenchyma density analysis, airway analysis, diaphragm mechanics analysis, and nodule detection for cancer screening. Lung segmentation is an important prerequisite step for automatic image analysis. We propose a novel lung segmentation method to minimize the juxta-pleural nodule issue, a notorious challenge in the applications. Method: we initially used the Chan-Vese (CV) model for active lung contours and adopted a Bayesian approach based on the CV model results, which predicts the lung image based on the segmented lung contour in the previous frame image or neighboring upper frame image. Among the resultant juxta-pleural nodule candidates, false positives were eliminated through concave points detection and circle/ellipse Hough transform. Finally, the lung contour was modified by adding the final nodule candidates to the area of the CV model results. Results: to evaluate the proposed method, we collected chest CT digital imaging and communications in medicine images of 84 anonymous subjects, including 42 subjects with juxta-pleural nodules. There were 16873 images in total. Among the images, 314 included juxta-pleural nodules. Our method exhibited a disc similarity coefficient of 0.9809, modified hausdorff distance of 0.4806, sensitivity of 0.9785, specificity of 0.9981, accuracy of 0.9964, and juxta-pleural nodule detection rate of 96%. It outperformed existing methods, such as the CV model used alone, the normalized CV model, and the snake algorithm. Clinical impact: the high accuracy with the juxta-pleural nodule detection in the lung segmentation can be beneficial for any computer aided diagnosis system that uses lung segmentation as an initial step.",2018,S. Abdulatif; K. Armanious; K. Guirguis; J. T. Sajeev; B. Yang,1,13,13,8,10.1109/JTEHM.2018.2837901,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361032,IEEE Journals,IEEE
Modeling Large Sparse Data for Feature Selection: Hospital Admission Predictions of the Dementia Patients Using Primary Care Electronic Health Records,Deep learning;dementia;electronic health records;feature selection;hospitalization;machine learning;risk factors;weight regularization,"A growing elderly population suffering from incurable, chronic conditions such as dementia present a continual strain on medical services due to mental impairment paired with high comorbidity resulting in increased hospitalization risk. The identification of at risk individuals allows for preventative measures to alleviate said strain. Electronic health records provide opportunity for big data analysis to address such applications. Such data however, provides a challenging problem space for traditional statistics and machine learning due to high dimensionality and sparse data elements. This article proposes a novel machine learning methodology: entropy regularization with ensemble deep neural networks (ECNN), which simultaneously provides high predictive performance of hospitalization of patients with dementia whilst enabling an interpretable heuristic analysis of the model architecture, able to identify individual features of importance within a large feature domain space. Experimental results on health records containing 54,647 features were able to identify 10 event indicators within a patient timeline: a collection of diagnostic events, medication prescriptions and procedural events, the highest ranked being essential hypertension. The resulting subset was still able to provide a highly competitive hospitalization prediction (Accuracy: 0.759) as compared to the full feature domain (Accuracy: 0.755) or traditional feature selection techniques (Accuracy: 0.737), a significant reduction in feature size. The discovery and heuristic evidence of correlation provide evidence for further clinical study of said medical events as potential novel indicators. There also remains great potential for adaption of ECNN within other medical big data domains as a data mining tool for novel risk factor identification.",2021,S. Mall; U. C. Jaiswal,1,13,13,,10.1109/JTEHM.2020.3040236,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268962,IEEE Journals,IEEE
Reliable Fault Diagnosis of Multiple Induction Motor Defects Using a 2-D Representation of Shannon Wavelets,Fault classification;global neighborhood structure (GNS) maps;induction machine;multi-class support vector machines (MCSVMs);wavelet transform,"This paper proposes an approach for a 2-D representation of Shannon wavelets for highly reliable fault diagnosis of multiple induction motor defects. Since the wavelet transform is efficient for analyzing non-stationary and non-deterministic vibration signals, this paper utilizes wavelet coefficients deduced from the Shannon mother wavelet function with varying dilation and translation parameters to create 2-D gray-level images. Using the resulting images and their associated texture characteristics, this paper extracts features by generating global neighborhood structure maps, which are used to extract global image features. The texture features are then used as inputs in one-against-all multi-class support vector machines to identify faults in the induction machine. To evaluate the performance of the proposed approach, it is compared with five conventional state-of-the-art algorithms in terms of classification accuracy. In addition, this paper explores the robustness of the proposed approach in noisy environments by adding white Gaussian noise to the acquired vibration signals. The experimental results indicate that the proposed approach outperforms conventional algorithms in terms of the classification accuracy. Moreover, the proposed approach achieves higher classification accuracy, even in noisy environments.",2014,S. Tyagi; D. Chopra; I. Mathur; N. Joshi,1,13,13,26,10.1109/TMAG.2014.2316474,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786484,IEEE Journals,IEEE
"Automatic Prosodic Event Detection Using Acoustic, Lexical, and Syntactic Evidence",Accent;prominence;prosodic phrase boundary;prosody recognition;prosodyâ€“syntax interface;spoken language processing;stress;Accent;prominence;prosodic phrase boundary;prosody recognition;prosody-syntax interface;spoken language processing;stress,"With the advent of prosody annotation standards such as tones and break indices (ToBI), speech technologists and linguists alike have been interested in automatically detecting prosodic events in speech. This is because the prosodic tier provides an additional layer of information over the short-term segment-level features and lexical representation of an utterance. As the prosody of an utterance is closely tied to its syntactic and semantic content in addition to its lexical content, knowledge of the prosodic events within and across utterances can assist spoken language applications such as automatic speech recognition and translation. On the other hand, corpora annotated with prosodic events are useful for building natural-sounding speech synthesizers. In this paper, we build an automatic detector and classifier for prosodic events in American English, based on their acoustic, lexical, and syntactic correlates. Following previous work in this area, we focus on accent (prominence, or ldquostressrdquo) and prosodic phrase boundary detection at the syllable level. Our experiments achieved a performance rate of 86.75% agreement on the accent detection task, and 91.61% agreement on the phrase boundary detection task on the Boston University Radio News Corpus.",2008,S. Yashothara; R. T. Uthayasanker; S. Jayasena,216,228,13,54,10.1109/TASL.2007.907570,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4358088,IEEE Journals,IEEE
Transformation Invariant On-Line Target Recognition,Active on-line learning;automatic target recognition;dual heuristic dynamic programming;face authentication;heuristic dynamic programming;image transformation invariance;reinforcement learning,"Transformation invariant automatic target recognition (ATR) has been an active research area due to its widespread applications in defense, robotics, medical imaging and geographic scene analysis. The primary goal for this paper is to obtain an on-line ATR system for targets in presence of image transformations, such as rotation, translation, scale and occlusion as well as resolution changes. We investigate biologically inspired adaptive critic design (ACD) neural network (NN) models for on-line learning of such transformations. We further exploit reinforcement learning (RL) in ACD framework to obtain transformation invariant ATR. We exploit two ACD designs, such as heuristic dynamic programming (HDP) and dual heuristic dynamic programming (DHP) to obtain transformation invariant ATR. We obtain extensive statistical evaluations of proposed on-line ATR networks using both simulated image transformations and real benchmark facial image database, UMIST, with pose variations. Our simulations show promising results for learning transformations in simulated images and authenticating out-of plane rotated face images. Comparing the two on-line ATR designs, HDP outperforms DHP in learning capability and robustness and is more tolerant to noise. The computational time involved in HDP is also less than that of DHP. On the other hand, DHP achieves a 100% success rate more frequently than HDP for individual targets, and the residual critic error in DHP is generally smaller than that of HDP. Mathematical analyses of both our RL-based on-line ATR designs are also obtained to provide a sufficient condition for asymptotic convergence in a statistical average sense.",2011,T. Okita; A. Way,906,918,13,7,10.1109/TNN.2011.2132737,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5766756,IEEE Journals,IEEE
WoMan: Logic-Based Workflow Learning and Management,[D.1.6] Logic programming;[I.2.6.g] machine learning;[M.7.0.a] business process modeling;[D.1.6] Logic programming;[I.2.6.g] machine learning;[M.7.0.a] business process modeling,"Workflow management is fundamental to efficiently, effectively, and economically carry out complex working and domestic activities. Manual engineering of workflow models is a complex, costly, and error-prone task. The WoMan framework for workflow management is based on first-order logic. Its core is an automatic procedure that learns and refines workflow models from observed cases of process execution. Its innovative peculiarities include incrementality (allowing quick learning even in the presence of noise and changed behavior), strict adherence to the observed practices, ability to learn complex conditions for the workflow components, and improved expressive power compared to the state of the art. This paper presents the entire algorithmic apparatus of WoMan, including translation and learning from a standard log format for case representation, import/export of workflow models from/into standard formalisms (Petri nets), and exploitation of the learned models for process simulation and monitoring. Qualitative and quantitative experimental evaluation shows the power and efficiency of WoMan, both in controlled and in real-world domains.",2014,V. Cappellini; L. Mattii; A. Mecocci,744,756,13,28,10.1109/TSMC.2013.2273310,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578158,IEEE Journals,IEEE
Image Operator Learning and Applications,Image Operator Learning;Machine Learning;Image Processing,"High-level understanding of image contents has been receiving much attention in the last decade. Low level processing figures as a building block in this framework and it also continues to play an important role in several specific tasks such as in image filtering and colorization, medical imaging, and document image processing. The design of image operators for these tasks is usually done manually by exploiting characteristics specific to the domain of application. An alternative design approach is to use machine learning techniques to estimate the transformations. Given pairs of images consisting of atypical input and respective desired output, the goal is to estimate an operator that transforms the inputs into the desired outputs. In this tutorial we present a rigorous mathematical formulation to the framework of learning locally defined and translation invariant transformations, practical procedures and strategies to address typical machine learning related issues, application examples, and current challenges. We also include information about the code used to generate the application examples.",2016,V. K. Menon; Rajendran S; Soman K P,38,50,13,1,10.1109/SIBGRAPI-T.2016.013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7812925,IEEE Conferences,IEEE
Support Vector Shape: A Classifier-Based Shape Representation,Shape matching;2D and 3D representation;support vector machines,"We introduce a novel implicit representation for 2D and 3D shapes based on Support Vector Machine (SVM) theory. Each shape is represented by an analytic decision function obtained by training SVM, with a Radial Basis Function (RBF) kernel so that the interior shape points are given higher values. This empowers support vector shape (SVS) with multifold advantages. First, the representation uses a sparse subset of feature points determined by the support vectors, which significantly improves the discriminative power against noise, fragmentation, and other artifacts that often come with the data. Second, the use of the RBF kernel provides scale, rotation, and translation invariant features, and allows any shape to be represented accurately regardless of its complexity. Finally, the decision function can be used to select reliable feature points. These features are described using gradients computed from highly consistent decision functions instead from conventional edges. Our experiments demonstrate promising results.",2013,V. T. Hung; G. Fafiotte,970,982,13,27,10.1109/TPAMI.2012.186,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6291722,IEEE Journals,IEEE
Interpretation of Spatial Language in a Map Navigation Task,Humanâ€“machine interaction;natural language processing;navigational instructions;spatial language understanding,"We have developed components of an automated system that understands and follows navigational instructions. The system has prior knowledge of the geometry and landmarks of specific maps. This knowledge is exploited to infer complex paths through maps based on natural language descriptions. The approach is based on an analysis of verbal commands in terms of elementary semantic units that are composed to generate a probability distribution over possible spatial paths in a map. An integration mechanism based on dynamic programming guides this language-to-path translation process, ensuring that resulting paths satisfy continuity and smoothness criteria. In the current implementation, parsing of text into semantic units is performed manually. Composition and interpretation of semantic units into spatial paths is performed automatically. In the evaluations, we show that the system accurately predicts the speakers' intended meanings for a range of instructions. This paper provides building blocks for a complete system that, when combined with robust parsing technologies, could lead to a fully automatic spatial language interpretation system",2007,V. V. Nguyen; T. P. Nguyen; A. Shimazu; M. L. Nguyen,667,679,13,20,10.1109/TSMCB.2006.889809,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4200804,IEEE Journals,IEEE
K-Complex Detection Using a Hybrid-Synergic Machine Learning Method,EEG;K-complex;multi-instance learning (MIL);sleep disorder,"Sleep stage identification is the first step in modern sleep disorder diagnostics process. K-complex is an indicator for the sleep stage 2. However, due to the ambiguity of the translation of the medical standards into a computer-based procedure, reliability of automated K-complex detection from the EEG wave is still far from expectation. More specifically, there are some significant barriers to the research of automatic K-complex detection. First, there is no adequate description of K-complex that makes it difficult to develop automatic detection algorithm. Second, human experts only provided the label for whether a whole EEG segment contains K-complex or not, rather than individual labels for each subsegment. These barriers render most pattern recognition algorithms inapplicable in detecting K-complex. In this paper, we attempt to address these two challenges, by designing a new feature extraction method that can transform visual features of the EEG wave with any length into mathematical representation and proposing a hybrid-synergic machine learning method to build a K-complex classifier. The tenfold cross-validation results indicate that both the accuracy and the precision of this proposed model are at least as good as a human expert in K-complex detection.",2012,X. Sun,1478,1490,13,16,10.1109/TSMCC.2012.2191775,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190762,IEEE Journals,IEEE
Atlas-Based Multiorgan Segmentation for Dynamic Abdominal PET,Image segmentation;machine learning;maximum a posteriori estimation;positron emission tomography,"Region of interest (ROI) delineation is required to extract tissue time-activity curves (TACs) in dynamic PET studies, to analyze functional changes or estimate physiological parameters. In this paper, we present an automatic framework for atlas-based multiorgan segmentation in abdominal dynamic PET images with three different methods (4D-pair, 4D-PCA, and 3-D), incorporating probabilistic atlas information into the segmentation as a spatial prior using maximum a posteriori (MAP) estimation. Due to different tracer kinetics in each organ, PET images from different time periods post injection (p.i.) have great intensity differences. Thus, when dynamic images are available, to use this temporal information, two strategies can be employed. First, tissue activities from two frames with highly different activity distributions were selected, namely, an early 8-10 min p.i. and a late 55-60 min p.i. frame, and modeled as a bivariate Gaussian distribution. Theoretically, this method can be applied if more than one frame of data is available. Second, principal component analysis (PCA) was applied to the full series of dynamic images to extract two images corresponding to the first two components. When dynamic image series are not available, the segmentation framework can be scaled down to 3-D, by building a univariate Gaussian distribution based on one 3-D image. The final segmentation results for all three methods were determined by optimizing the MAP-based energy function with two hyperparameters (Î»l, Î·) by multilabel graph cuts. We performed hyperparameter optimization and evaluated the proposed segmentation methods of 4D-pair and 4D-PCA by leave-one-out cross-validation using 30 sets of 4-D abdominal 18F-FP-(+)-DTBZ PET images. To evaluate segmentation results, the pancreas and spleen TACs were extracted, and the percentage error between the area under curve (AUC) of the TACs extracted by manual and automated segmentations was determined. The 4D-pair method with the hyperparameter combination of (Î»_l = 0.1, Î· = 1) yielded the best performance. TAC AUC %error results with PCA-based methods showed slightly higher %error than 4D-pair. The 3-D method showed much larger %error than the other two methods. The 4D-pair results agreed well with the manual segmentation, with mean pancreas and spleen TAC AUC %errors of 0.3Â±3.3% and -0.4Â±8.1%, respectively. In addition, the distribution volume (VT) values of pancreas and spleen were determined by kinetic modeling using TACs from either manual or automated segmentations. There were no significant differences between manual- and auto-VT values (p values of 0.14 and 0.74 for pancreas and spleen, respectively). Thus, the proposed automated segmentation method can provide robust and reliable ROIs of the pancreas and spleen for kinetic modeling.",2020,Y. Guo; L. Du; D. Wei; C. Li,50,62,13,,10.1109/TRPMS.2019.2926889,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8755506,IEEE Journals,IEEE
EEG Classification by Factoring in Sensor Spatial Configuration,Machine learning;EEG;CNN;spatio-temporal features;emotion recognition;SAD,"Electroencephalography (EEG) serves as an effective diagnostic tool for mental disorders and neurological abnormalities. Enhanced analysis and classification of EEG signals can help improve performance in classifying the disorders and abnormalities. A new approach is examined here for enhancing EEG classification performance using a novel model of data representation that leverages knowledge of spatial layout of EEG sensors. An investigation of the performance of the proposed data representation model provides evidence of consistently higher classification accuracy of the proposed model compared with a model that ignores the sensor layout. The performance is assessed for models that represent the information content of the EEG signals in two different ways: a one-dimensional concatenation of the channels of the frequency bands and a proposed image-like two-dimensional representation of the EEG channel locations. The models are used in conjunction with different machine learning techniques. Performance of these models is examined on two tasks: social anxiety disorder classification, and emotion recognition using a dataset, DEAP, for emotion analysis using physiological signals. We hypothesize that the proposed two-dimensional model will significantly outperform the one-dimensional model and this is validated in our results as this model consistently yields 5-8% higher accuracy in all machine learning algorithms investigated. Among the algorithms investigated, Convolutional Neural Networks provide the best performance, far exceeding that of Support Vector Machine and k-Nearest Neighbors algorithms.",2021,Y. Heo; S. Kang; D. Yoo,19053,19065,13,,10.1109/ACCESS.2021.3054670,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9336002,IEEE Journals,IEEE
Accelerating Federated Learning via Momentum Gradient Descent,Accelerating convergence;distributed machine learning;federated learning;momentum gradient descent,"Federated learning (FL) provides a communication-efficient approach to solve machine learning problems concerning distributed data, without sending raw data to a central server. However, existing works on FL only utilize first-order gradient descent (GD) and do not consider the preceding iterations to gradient update which can potentially accelerate convergence. In this article, we consider momentum term which relates to the last iteration. The proposed momentum federated learning (MFL) uses momentum gradient descent (MGD) in the local update step of FL system. We establish global convergence properties of MFL and derive an upper bound on MFL convergence rate. Comparing the upper bounds on MFL and FL convergence rates, we provide conditions in which MFL accelerates the convergence. For different machine learning models, the convergence performance of MFL is evaluated based on experiments with MNIST and CIFAR-10 datasets. Simulation results confirm that MFL is globally convergent and further reveal significant convergence improvement over FL.",2020,Y. Jian; S. Peng; L. Zhenpeng; Z. Yu; Z. Chenggui; Y. Zizhong,1754,1766,13,12,10.1109/TPDS.2020.2975189,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003425,IEEE Journals,IEEE
Novel Similarity-Invariant Line Descriptor and Matching Algorithm for Global Motion Estimation,Automatic quality control;global motion estimation;line descriptor;map registration,"We present a new and fast line descriptor and matching algorithm to geometrically register video frames that are deformed by a similarity transformation and contain line segments but with very low texture details, such as navigation maps. Line segments are extracted from the frames, and each line is described with a novel line descriptor that does not depend on pixel intensities. The described lines are then matched together and the matches are input to an outlier removal algorithm in order to estimate the parameters of the transformation describing the global motion between the frames. We propose a method for fast parameter estimation of the transformation using line segments instead of points. Additionally, we apply this algorithm in the testing and error detection context of navigation systems, in which we show how to detect map jump artifacts that could occur during the development of these systems, leading to a jerky and unsmooth motion between the frames. The proposed descriptor and its matching algorithm are shown to be fast enough for online use and very robust against a wide range of translation, rotation, and scale changes. Furthermore, the error detection algorithm allows to detect almost all map jump artifacts while maintaining a very low number of false alarms.",2014,Y. Oda; H. Fudaba; G. Neubig; H. Hata; S. Sakti; T. Toda; S. Nakamura,1323,1335,13,5,10.1109/TCSVT.2014.2302874,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6725640,IEEE Journals,IEEE
Robust Sound Event Classification Using Deep Neural Networks,Auditory event detection;machine hearing,"The automatic recognition of sound events by computers is an important aspect of emerging applications such as automated surveillance, machine hearing and auditory scene understanding. Recent advances in machine learning, as well as in computational models of the human auditory system, have contributed to advances in this increasingly popular research field. Robust sound event classification, the ability to recognise sounds under real-world noisy conditions, is an especially challenging task. Classification methods translated from the speech recognition domain, using features such as mel-frequency cepstral coefficients, have been shown to perform reasonably well for the sound event classification task, although spectrogram-based or auditory image analysis techniques reportedly achieve superior performance in noise. This paper outlines a sound event classification framework that compares auditory image front end features with spectrogram image-based front end features, using support vector machine and deep neural network classifiers. Performance is evaluated on a standard robust classification task in different levels of corrupting noise, and with several system enhancements, and shown to compare very well with current state-of-the-art classification techniques.",2015,Y. Shi; W. Zeng; J. Deng; W. Nie; Y. Zhang,540,552,13,128,10.1109/TASLP.2015.2389618,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7003973,IEEE Journals,IEEE
Classification-Based Record Linkage With Pseudonymized Data for Epidemiological Cancer Registries,Cancer registries;healthcare;machine learning;registry integration;record linkage,"Cancer is one of the widest spread diseases in human society. Therefore, the need has grown to monitor, evaluate, and predict its development. Cancer registries address this problem by collecting data on cancer cases, striving for high quality, accuracy, and completeness. One of the basic challenges in this context is the linkage of data from multiple sources. In order to link new cancer records with existing ones, the cancer registries typically use an algorithm referred to as record linkage. Although the algorithm has automated a significant amount of the linking process, there still is a certain percentage of records that cannot be linked automatically. This study addresses the problem of reducing the need of manually matching records with machine learning methods. The particular challenge is caused by pseudonymization of the data. The main contribution is thus finding ways to encode the-pseudonymized-data, i.e., feature extraction so that it can be interpreted by a classifier. Three classifiers (neural network, support vector machines, decision tree) manage to achieve at least 93% classification rate on a dataset of 73 000 cancer records extracted from the inventory of a cancer registry. In addition, ensemble techniques boost the performance further to over 95%. We present an in-depth discussion of the experimental results from a perspective of applying the classification-based record linkage in real practice. Two scenarios of translating to practice will be outlined with a potential of reducing the human workload by an order of magnitude of hundreds of hours.",2016,Y. Zhou; I. Ioannou; S. Wijewickrema; J. Bailey; P. Piromchai; G. Kennedy; S. OLeary,1929,1941,13,5,10.1109/TMM.2016.2598482,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536193,IEEE Journals,IEEE
The Hardware and Algorithm Co-Design for Energy-Efficient DNN Processor on Edge/Mobile Devices,Application specific integrated circuit (ASIC);co-design;deep learning (DL);deep neural network (DNN);energy efficient hardware;hardware friendly algorithm;machine learning (ML),"Deep neural network (DNN) has been widely studied due to its high performance and usability for various applications such as image classification, detection, segmentation, translation, and action recognition. Thanks to the universal applications and high performance of DNN algorithm, DNN is adopted for various AI platforms, including edge/mobile devices as well as cloud servers. However, high-performance DNN requires a large amount of computation and memory access, making it challenging to implement DNN operation on edge/mobile. There have been several ways to solve these problems, including algorithms as well as hardware for DNN. Algorithms that help accelerate DNN in hardware enable much more efficient operation of high-performance AI. This article aims to provide an overview of the recent hardware and algorithm co-design schemes enabling efficient processing of DNNs. Specifically, it will provide algorithm optimization methods for DNN structure, neurons, synapses, and data types. This paper also introduces optimization methods for hardware architectures, PE array, data-path control, and microarchitecture of PE. And we will also show examples of DNN algorithm and hardware co-designed ASICs.",2020,Yi-Dong Chen; Xiao-Dong Shi; Chang-Le Zhou; Qing-Yang Hong,3458,3470,13,1,10.1109/TCSI.2020.3021397,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189797,IEEE Journals,IEEE
Framework to Support Scenario Development for Human-Centered Alerting System Evaluation,Air traffic control;alarm systems;alerting systems;decision support systems;man machine systems,"The purpose of the framework introduced here is to support the development of evaluation scenarios that are capable of assessing system level performance while considering the system, the humans that interact with it, and the environment. The following five step framework is presented and applied to a pilot self separation task: 1) identify entities critical to system design, development, and operation and define their goals and properties as they relate to the system being studied; 2) define a subset of functionality for evaluation (define an execution sequence); 3) map entity properties to the execution sequence to identify independent variables; 4) translate entity goals into a set of system goals that can be used to identify dependent measures; and 5) iterate through each step to ensure the models produced are internally consistent.",2013,Z. Liu; K. Zhao,595,607,13,5,10.1109/THMS.2013.2283399,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6636042,IEEE Journals,IEEE
On Learning From Game Annotations,Computer Chess;machine learning in games;preference learning,"Most of the research in the area of evaluation function learning is focused on self-play. However in many domains, like Chess, expert feedback is amply available in the form of annotated games. This feedback usually comes in the form of qualitative information because human annotators find it hard to determine precise utility values for game states. The goal of this work is to investigate inasmuch it is possible to leverage this qualitative feedback for learning an evaluation function for the game. To this end, we show how the game annotations can be translated into preference statements over moves and game states, which in turn can be used for learning a utility function that respects these preference constraints. We evaluate the resulting function by creating multiple heuristics based upon different sized subsets of the training data and compare them in a tournament scenario. The results showed that learning from game annotations is possible, but, on the other hand, our learned functions did not quite reach the performance of the original, manually tuned function of the Chess program. The reason for this failure seems to lie in the fact that human annotators only annotate â€œinterestingâ€? positions, so that it is hard to learn basic information, such as material advantage from game annotations alone.",2015,Z. Wang; X. Zhu; Z. Lu,304,316,13,1,10.1109/TCIAIG.2014.2332442,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6861960,IEEE Journals,IEEE
Integration of Speech Recognition and Machine Translation in Computer-Assisted Translation,Computer-assisted translation (CAT);speech recognition;statistical machine translation (MT),"Parallel integration of automatic speech recognition (ASR) models and statistical machine translation (MT) models is an unexplored research area in comparison to the large amount of works done on integrating them in series, i.e., speech-to-speech translation. Parallel integration of these models is possible when we have access to the speech of a target language text and to its corresponding source language text, like a computer-assisted translation system. To our knowledge, only a few methods for integrating ASR models with MT models in parallel have been studied. In this paper, we systematically study a number of different translation models in the context of the N-best list rescoring. As an alternative to the N -best list rescoring, we use ASR word graphs in order to arrive at a tighter integration of ASR and MT models. The experiments are carried out on two tasks: English-to-German with an ASR vocabulary size of 17 K words, and Spanish-to-English with an ASR vocabulary of 58 K words. For the best method, the MT models reduce the ASR word error rate by a relative of 18% and 29% on the 17 K and the 58 K tasks, respectively.",2008,A. M. Saif; M. J. A. Aziz,1551,1564,14,16,10.1109/TASL.2008.2004301,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4648933,IEEE Journals,IEEE
Arabicâ€“Chinese Neural Machine Translation: Romanized Arabic as Subword Unit for Arabic-sourced Translation,Arabic morphology;Arabic romanization;BPE;data filtering;linguistic feature;morphological segmentation;neural machine translation,"Morphologically rich and complex languages such as Arabic, pose a major challenge to neural machine translation (NMT) due to the large number of rare words and the inability of NMT to translate them. Unknown word (UNK) symbols are used to represent out-of-vocabulary words because NMT typically operates with a fixed vocabulary size. These rare words can be effectively encoded as sequences of subword units by using algorithms, such as byte pair encoding (BPE), to tackle the UNK problem. However, for languages with highly inflected and morphological variations, such as Arabic, the aforementioned method has its own limitations that make it not effective enough for translation quality. To alleviate the UNK problem and address the inconvenient behavior of BPE when translating the Arabic language, we propose to utilize a romanization system that converts Arabic scripts to subword units. We investigate the effect of our approach on NMT performance under various segmentation scenarios and compare the results with systems trained on original Arabic form. In addition, we integrate Romanized Arabic as an input factor for Arabic-sourced NMT compared with well-known factors, namely, lemma, part-of-speech tags, and morph features. Extensive experiments on Arabic-Chinese translation demonstrate that the proposed approaches can effectively tackle the UNK problem and significantly improve the translation quality for Arabic-sourced translation. Additional experiments in this study focus on developing the NMT system on Chinese-Arabic translation. Before implementing our experiments, we first propose standard criteria for the data filtering of a parallel corpus, which helps in filtering out its noise.",2019,B. BerrÃº-Novoa; R. GonzÃ¡lez-Valenzuela; P. Shiguihara-JuÃ¡rez,133122,133135,14,1,10.1109/ACCESS.2019.2941161,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835016,IEEE Journals,IEEE
End-to-End Speech Translation With Transcoding by Multi-Task Learning for Distant Language Pairs,End-to-end speech-to-text translation;automatic speech recognition;machine translation (MT);multi-task learning,"Directly translating spoken utterances from a source language to a target language is challenging because it requires a fundamental transformation in both linguistic and para/non-linguistic features. Traditional speech-to-speech translation approaches concatenate automatic speech recognition (ASR), text-to-text machine translation (MT), and text-to-speech synthesizer (TTS) by text information. The current state-of-the-art models for ASR, MT, and TTS have mainly been built using deep neural networks, in particular, an attention-based encoder-decoder neural network with an attention mechanism. Recently, several works have constructed end-to-end direct speech-to-text translation by combining ASR and MT into a single model. However, the usefulness of these models has only been investigated on language pairs of similar syntax and word order (e.g., English-French or English-Spanish). For syntactically distant language pairs (e.g., English-Japanese), speech translation requires distant word reordering. Furthermore, parallel texts with corresponding speech utterances that are suitable for training end-to-end speech translation are generally unavailable. Collecting such corpora is usually time-consuming and expensive. This article proposes the first attempt to build an end-to-end direct speech-to-text translation system on syntactically distant language pairs that suffer from long-distance reordering. We train the model on English (subject-verb-object (SVO) word order) and Japanese (SOV word order) language pairs. To guide the attention-based encoder-decoder model on this difficult problem, we construct end-to-end speech translation with transcoding and utilize curriculum learning (CL) strategies that gradually train the network for end-to-end speech translation tasks by adapting the decoder or encoder parts. We use TTS for data augmentation to generate corresponding speech utterances from the existing parallel text data. Our experiment results show that the proposed approach provides significant improvements compared with conventional cascade models and the direct speech translation approach that uses a single model without transcoding and CL strategies.",2020,C. M. Files; M. A. Perkowski,1342,1355,14,2,10.1109/TASLP.2020.2986886,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072502,IEEE Journals,IEEE
Linguistic Knowledge-Aware Neural Machine Translation,Attention gate;knowledge block;knowledge gate;neural machine translation (NMT),"Recently, researchers have shown an increasing interest in incorporating linguistic knowledge into neural machine translation (NMT). To this end, previous works choose either to alter the architecture of NMT encoder to incorporate syntactic information into the translation model, or to generalize the embedding layer of the encoder to encode additional linguistic features. The former approach mainly focuses on injecting the syntactic structure of the source sentence into the encoding process, leading to a complicated model that lacks the flexibility to incorporate other types of knowledge. The latter extends word embeddings by considering additional linguistic knowledge as features to enrich the word representation. It thus does not explicitly balance the contribution from word embeddings and the contribution from additional linguistic knowledge. To address these limitations, this paper proposes a knowledge-aware NMT approach that models additional linguistic features in parallel to the word feature. The core idea is that we propose modeling a series of linguistic features at the word level (knowledge block) using a recurrent neural network (RNN). And in sentence level, those word-corresponding feature blocks are further encoded using a RNN encoder. In decoding, we propose a knowledge gate and an attention gate to dynamically control the proportions of information contributing to the generation of target words from different sources. Extensive experiments show that our approach is capable of better accounting for importance of additional linguistic, and we observe significant improvements from 1.0 to 2.3 BLEU points on Chinese$\leftrightarrow$ English and English$\rightarrow$German translation tasks.",2018,C. O. Mawalim; D. P. Lestari; A. Purwarianti,2341,2354,14,3,10.1109/TASLP.2018.2864648,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430540,IEEE Journals,IEEE
HMM Word and Phrase Alignment for Statistical Machine Translation,Hidden Markov model;phrase alignment;statistical machine translation;word alignment,"Estimation and alignment procedures for word and phrase alignment hidden Markov models (HMMs) are developed for the alignment of parallel text. The development of these models is motivated by an analysis of the desirable features of IBM Model 4, one of the original and most effective models for word alignment. These models are formulated to capture the desirable aspects of Model 4 in an HMM alignment formalism. Alignment behavior is analyzed and compared to human-generated reference alignments, and the ability of these models to capture different types of alignment phenomena is evaluated. In analyzing alignment performance, Chinese-English word alignments are shown to be comparable to those of IBM Model 4 even when models are trained over large parallel texts. In translation performance, phrase-based statistical machine translation systems based on these HMM alignments can equal and exceed systems based on Model 4 alignments, and this is shown in Arabic-English and Chinese-English translation. These alignment models can also be used to generate posterior statistics over collections of parallel text, and this is used to refine and extend phrase translation tables with a resulting improvement in translation quality.",2008,Eugene Seo; Il-Sun Song; Su-Kyung Kim; Ho-Jin Choi,494,507,14,16,10.1109/TASL.2008.916056,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4443885,IEEE Journals,IEEE
Disambiguating Discourse Connectives for Statistical Machine Translation,Discourse connectives;machine translation (MT),"This paper shows that the automatic labeling of discourse connectives with the relations they signal, prior to machine translation (MT), can be used by phrase-based statistical MT systems to improve their translations. This improvement is demonstrated here when translating from English to four target languages-French, German, Italian and Arabic-using several test sets from recent MT evaluation campaigns. Using automatically labeled data for training, tuning and testing MT systems is beneficial on condition that labels are sufficiently accurate, typically above 70%. To reach such an accuracy, a large array of features for discourse connective labeling (morpho-syntactic, semantic and discursive) are extracted using state-of-the-art tools and exploited in factored MT models. The translation of connectives is improved significantly, between 0.7% and 10% as measured with the dedicated ACT metric. The improvements depend mainly on the level of ambiguity of the connectives in the test sets.",2015,G. Deshpande; V. S. Viraraghavan; M. Duggirala; R. R. Vempada; S. Patel,1184,1197,14,2,10.1109/TASLP.2015.2422576,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7084603,IEEE Journals,IEEE
Machine Learning at Facebook: Understanding Inference at the Edge,Machine learning;Edge Inference,"At Facebook, machine learning provides a wide range of capabilities that drive many aspects of user experience including ranking posts, content understanding, object detection and tracking for augmented and virtual reality, speech and text translations. While machine learning models are currently trained on customized data-center infrastructure, Facebook is working to bring machine learning inference to the edge. By doing so, user experience is improved with reduced latency (inference time) and becomes less dependent on network connectivity. Furthermore, this also enables many more applications of deep learning with important features only made available at the edge. This paper takes a data-driven approach to present the opportunities and design challenges faced by Facebook in order to enable machine learning inference locally on smart phones and other edge platforms.",2019,L. RodrÃ­guez; A. Reddy; R. Rose,331,344,14,53,10.1109/HPCA.2019.00048,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675201,IEEE Conferences,IEEE
Syntactically Lexicalized Phrase-Based SMT,Combinatory categorical grammar (CCG);lexical syntax;lexicalized tree adjoining grammar (LTAG);statistical machine translation (SMT);syntax-based machine translation,"Until quite recently, extending phrase-based statistical machine translation (PBSMT) with syntactic knowledge caused system performance to deteriorate. The most recent successful enrichments of PBSMT with hierarchical structure either employ nonlinguistically motivated syntax for capturing hierarchical reordering phenomena, or extend the phrase translation table with redundantly ambiguous syntactic structures over phrase pairs. In this paper, we present an extended, harmonized account of our previous work which showed that incorporating linguistically motivated lexical syntactic descriptions, called supertags, can yield significantly better PBSMT systems at insignificant extra computational cost. We describe a novel PBSMT model that integrates supertags into the target language model and the target side of the translation model. Two kinds of supertags are employed: those from lexicalized tree-adjoining grammar and combinatory categorial grammar. Despite the differences between the two sets of supertags, they give similar improvements. In addition to integrating the Markov supertagging approach in PBSMT, we explore the utility of a new surface grammaticality measure based on combinatory operators. We perform various experiments on the Arabic-to-English NIST 2005 test set addressing the issues of sparseness, scalability, and the utility of system subcomponents. We show that even when the parallel training data grows very large, the supertagged system retains a relatively stable absolute performance advantage over the unadorned PBSMT system. Arguably, this hints at a performance gap that cannot be bridged by acquiring more phrase pairs. Our best result shows a relative improvement of 6.1% over a state-of-the-art PBSMT model, which compares favorably with the leading systems on the NIST 2005 task. We also demonstrate that the advantages of a supertag-based system carry over to German-English, where improvements of up to 8.9% relative to the baseline system are observed.",2008,M. Day; C. Tsai,1260,1273,14,7,10.1109/TASL.2008.925870,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4599248,IEEE Journals,IEEE
Robust SAR Automatic Target Recognition Via Adversarial Learning,Adversarial learning;automatic target recognition (ATR);generative adversarial networks (GAN);noise robust;semisupervised learning;synthetic aperture radar (SAR),"The traditional denoising methods in noise robust synthetic aperture radar (SAR) automatic target recognition research are independent of the recognition model, which limits the robust recognition performance. In this article, we present a robust SAR automatic target recognition method via adversarial learning, which could integrate data denoising, feature extraction, and classification into a unified framework for joint learning. Different from the common recognition methods of directly inputting the SAR data into the classifiers, we add a dual-generative-adversarial-network (GAN) model between the SAR data and the classifier for data translation from a noise-polluted style to a relatively clean style to reduce the noise from SAR data. In order to ensure the target information in the SAR data can be retained during the data style translation, reconstruction constraint and label constraint are also used in the dual-GAN model. Then, the more reliable transferred SAR data are fed into the classifier. The parameters of the dual-GAN and classifier are learned through joint optimization in our method. Thus, the data separability is guaranteed in the process of denoising and feature extraction, which greatly improves the recognition performance of the method. In addition, our method can be easily extended to a semisupervised method by using different objective functions for labeled and unlabeled training data, which is more suitable for practical application. Experimental results on MSTAR dataset and Gotcha dataset show that our method can get the encouraging performance in the case of low signal-to-noise ratio and small labeled data size.",2021,M. K. Nyein; K. Mar Soe,716,729,14,,10.1109/JSTARS.2020.3039235,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264634,IEEE Journals,IEEE
Multimodal Word Discovery and Retrieval With Spoken Descriptions and Visual Concepts,Unsupervised word discovery;language acquisition;machine translation;multimodal learning,"In the absence of dictionaries, translators, or grammars, it is still possible to learn some of the words of a new language by listening to spoken descriptions of images. If several images, each containing a particular visually salient object, each co-occur with a particular sequence of speech sounds, we can infer that those speech sounds are a word whose definition is the visible object. A multimodal word discovery system accepts, as input, a database of spoken descriptions of images (or a set of corresponding phone transcriptions) and learns a mapping from waveform segments (or phone strings) to their associated image concepts. In this article, four multimodal word discovery systems are demonstrated: three models based on statistical machine translation (SMT) and one based on neural machine translation (NMT). The systems are trained with phonetic transcriptions, MFCC and multilingual bottleneck features (MBN). On the phone-level, the SMT outperforms the NMT model, achieving a 61.6% F1 score in the phone-level word discovery task on Flickr30k. On the audio-level, we compared our models with the existing ES-KMeans algorithm for word discovery and present some of the challenges in multimodal spoken word discovery.",2020,M. W. Ahmad; S. M. Shovan; M. E. Arafat; M. H. Rahman Sifat; M. A. Mehedi Hasan; S. Shatabda,1560,1573,14,,10.1109/TASLP.2020.2996082,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097433,IEEE Journals,IEEE
The Google Similarity Distance,Accuracy comparison with WordNet categories;automatic classification and clustering;automatic meaning discovery using Google;automatic relative semantics;automatic translation;dissimilarity semantic distance;Google search;Google distribution via page hit counts;Google code;Kolmogorov complexity;normalized compression distance (ncd);normalized information distance (nid);normalized Google distance (ngd);meaning of words and phrases extracted from the Web;parameter-free data mining;universal similarity metric.,"Words and phrases acquire meaning from the way they are used in society, from their relative semantics to other words and phrases. For computers, the equivalent of ""society"" is ""database,"" and the equivalent of ""use"" is ""a way to search the database"". We present a new theory of similarity between words and phrases based on information distance and Kolmogorov complexity. To fix thoughts, we use the World Wide Web (WWW) as the database, and Google as the search engine. The method is also applicable to other search engines and databases. This theory is then applied to construct a method to automatically extract similarity, the Google similarity distance, of words and phrases from the WWW using Google page counts. The WWW is the largest database on earth, and the context information entered by millions of independent users averages out to provide automatic semantics of useful quality. We give applications in hierarchical clustering, classification, and language translation. We give examples to distinguish between colors and numbers, cluster names of paintings by 17th century Dutch masters and names of books by English novelists, the ability to understand emergencies and primes, and we demonstrate the ability to do a simple automatic English-Spanish translation. Finally, we use the WordNet database as an objective baseline against which to judge the performance of our method. We conduct a massive randomized trial in binary classification using support vector machines to learn categories based on our Google distance, resulting in an a mean agreement of 87 percent with the expert crafted WordNet categories",2007,O. Levkovskyi; W. Li,370,383,14,903,10.1109/TKDE.2007.48,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4072748,IEEE Journals,IEEE
Intelligent Biofeedback Augmented Content Comprehension (TellBack),Biomedical measurement;cognitive load;content comprehension;eye-tracking;heart rate variability;machine learning,"Assessing comprehension difficulties requires the ability to assess cognitive load. Changes in cognitive load induced by comprehension difficulties could be detected with an adequate time resolution using different biofeedback measures (e.g., changes in the pupil diameter). However, identifying the Spatio-temporal sources of content comprehension difficulties (i.e., when, and where exactly the difficulty occurs in content regions) with a fine granularity is a big challenge that has not been explicitly addressed in the state-of-the-art. This paper proposes and evaluates an innovative approach named Intelligent BiofeedbackAugmented Content Comprehension (TellBack) to explicitly address this challenge. The goal is to autonomously identify regions of digital content that cause user's comprehension difficulty, opening the possibility to provide real-time comprehension support to users. TellBack is based on assessing the cognitive load associated with content comprehension through non-intrusive cheap biofeedback devices that acquire measures such as pupil response or Heart Rate Variability (HRV). To identify when exactly the difficulty in comprehension occurs, physiological manifestations of the Autonomic Nervous System (ANS) such as the pupil diameter variability and the modulation of HRV are exploited, whereas the fine spatial resolution (i.e., the region of content where the user is looking at) is provided by eye-tracking. The evaluation results of this approach show an accuracy of 83.00% Â± 0.75 in classifying regions of content as difficult or not difficult using Support Vector Machine (SVM), and precision, recall, and micro F1-score of 0.89, 0.79, and 0.83, respectively. Results obtained with 4 other classifiers, namely Random Forest, k-nearest neighbor, Decision Tree, and Gaussian Naive Bayes, showed a slightly lower precision. TellBack outperforms the state-of-the-art in precision & recall by 23% and 17% respectively.",2021,Q. Liu; Z. Liu; H. Zhu; H. Fan; B. Du; Y. Qian,28393,28406,14,,10.1109/ACCESS.2021.3058664,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352725,IEEE Journals,IEEE
Multi-Instrument Automatic Music Transcription With Self-Attention-Based Instance Segmentation,Automatic music transcription;deep learning;multi-pitch estimation;multi-pitch streaming;self-attention,"Multi-instrument automatic music transcription (AMT) is a critical but less investigated problem in the field of music information retrieval (MIR). With all the difficulties faced by traditional AMT research, multi-instrument AMT needs further investigation on high-level music semantic modeling, efficient training methods for multiple attributes, and a clear problem scenario for system performance evaluation. In this article, we propose a multi-instrument AMT method, with signal processing techniques specifying pitch saliency, novel deep learning techniques, and concepts partly inspired by multi-object recognition, instance segmentation, and image-to-image translation in computer vision. The proposed method is flexible for all the sub-tasks in multi-instrument AMT, including multi-instrument note tracking, a task that has rarely been investigated before. State-of-the-art performance is also reported in the sub-task of multi-pitch streaming.",2020,S. Dieleman; B. Schrauwen,2796,2809,14,,10.1109/TASLP.2020.3030482,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222310,IEEE Journals,IEEE
HAIRIS: A Method for Automatic Image Registration Through Histogram-Based Image Segmentation,Histogram;image registration;image segmentation;matching;Wiener filtering,"Automatic image registration is still an actual challenge in several fields. Although several methods for automatic image registration have been proposed in the last few years, it is still far from a broad use in several applications, such as in remote sensing. In this paper, a method for automatic image registration through histogram-based image segmentation (HAIRIS) is proposed. This new approach mainly consists in combining several segmentations of the pair of images to be registered, according to a relaxation parameter on the histogram modes delineation (which itself is a new approach), followed by a consistent characterization of the extracted objects-through the objects area, ratio between the axis of the adjust ellipse, perimeter and fractal dimension-and a robust statistical based procedure for objects matching. The application of the proposed methodology is illustrated to simulated rotation and translation. The first dataset consists in a photograph and a rotated and shifted version of the same photograph, with different levels of added noise. It was also applied to a pair of satellite images with different spectral content and simulated translation, and to real remote sensing examples comprising different viewing angles, different acquisition dates and different sensors. An accuracy below 1Â° for rotation and at the subpixel level for translation were obtained, for the most part of the considered situations. HAIRIS allows for the registration of pairs of images (multitemporal and multisensor) with differences in rotation and translation, with small differences in the spectral content, leading to a subpixel accuracy.",2011,S. Gogineni; G. Suryanarayana; S. K. Surendran,776,789,14,47,10.1109/TIP.2010.2076298,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5570999,IEEE Journals,IEEE
Optimal Margin Distribution Machine,Margin;margin distribution;minimum margin;classification,"Support Vector Machine (SVM) has always been one of the most successful learning algorithms, with the central idea of maximizing the minimum margin, i.e., the smallest distance from the instances to the classification boundary. However, recent theoretical results disclosed that maximizing the minimum margin does not necessarily lead to better generalization performance, and instead, the margin distribution has been proven to be more crucial. Based on this idea, we propose the Optimal margin Distribution Machine (ODM), which can achieve a better generalization performance by optimizing the margin distribution explicitly. We characterize the margin distribution by the first- and second-order statistics, i.e., the margin mean and variance. The proposed method is a general learning approach which can be applied in any place where SVMs are used, and its superiority is verified both theoretically and empirically in this paper.",2020,T. Meyer; N. Hajlaoui; A. Popescu-Belis,1143,1156,14,5,10.1109/TKDE.2019.2897662,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8638559,IEEE Journals,IEEE
Full Parameter Time Complexity (FPTC): A Method to Evaluate the Running Time of Machine Learning Classifiers for Land Use/Land Cover Classification,Algorithm running time;full parameter time complexity (FPTC);land use/land cover (LULC) classification;Sentinel-2a;traditional time complexity (TTC),"In emergency responses to natural disasters, actionable information provided by remote sensing images is crucial to help emergency managers become aware of the situation and assess the magnitude of the damage. Without the accurate prediction of time consumption, choosing an algorithm for land use/land cover (LULC) classification under these emergency circumstances could be blind and subjective. Here, we proposed a full parameter time complexity (FPTC) analysis and the corresponding coefficient Ï‰ to estimate the actual running time of the LULC classification without actually running the code. The FPTC of five general algorithms is derived in this article. After derivation, the FPTC of k-nearest neighbors (kNN) is F(nv + nlog2 u), the FPTC of logistic regression (LR) is F(Qm2vn), the FPTC of classification and regression tree (CART) is F((m + 1)nvlog2n), the FPTC of random forest (RF) is F(s(m + 1)nvlog2n), and the FPTC of support vector machine (SVM) is F(m2Qv (n + k)). The results show a strong linear relationship between the actual running time and FPTC [R-squared: kNN (0.991), LR (0.997), CART (0.999), RF (1.000), and SVM (0.999)], with different data size. The average root-mean-squared error between the real running time and the estimated running time is 3.34 s, which demonstrates the effectiveness of FPTC. Combining FPTC with the corresponding coefficient Ï‰, the running time of the classification can be precisely predicted, which will help emergency managers quickly choose algorithms in response to natural disasters with available remote sensing data and limited time.",2021,T. N. Diep Do; D. B. Nguyen; D. K. Mac; D. Dat Tran,2222,2235,14,,10.1109/JSTARS.2021.3050166,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317826,IEEE Journals,IEEE
3D Human Pose Machines with Self-Supervised Learning,Human pose estimation;convolutional neural networks;spatio-temporal modeling;self-supervised learning;geometric deep learning,"Driven by recent computer vision and robotic applications, recovering 3D human poses has become increasingly important and attracted growing interests. In fact, completing this task is quite challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric ambiguities inside monocular images. Most of the existing methods focus on designing some elaborate priors /constraints to directly regress 3D human poses based on the corresponding 2D human pose-aware features or 2D pose predictions. However, due to the insufficient 3D pose data for training and the domain gap between 2D space and 3D space, these methods have limited scalabilities for all practical scenarios (e.g., outdoor scene). Attempt to address this issue, this paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images. Specifically, the proposed mechanism involves two dual learning tasks, i.e., the 2D-to-3D pose transformation and 3D-to-2D pose projection, to serve as a bridge between 3D and 2D human poses in a type of â€œfreeâ€? self-supervision for accurate 3D human pose estimation. The 2D-to-3D pose implies to sequentially regress intermediate 3D poses by transforming the pose representation from the 2D domain to the 3D domain under the sequence-dependent temporal context, while the 3D-to-2D pose projection contributes to refining the intermediate 3D poses by maintaining geometric consistency between the 2D projections of 3D poses and the estimated 2D poses. Therefore, these two dual learning tasks enable our model to adaptively learn from 3D human pose data and external large-scale 2D human pose data. We further apply our self-supervised correction mechanism to develop a 3D human pose machine, which jointly integrates the 2D spatial relationship, temporal smoothness of predictions and 3D geometric knowledge. Extensive evaluations on the Human3.6M and HumanEva-I benchmarks demonstrate the superior performance and efficiency of our framework over all the compared competing methods.",2020,T. N. T. Zakaria; M. J. A. Aziz; T. N. Rizan; T. M. Maasum,1069,1082,14,4,10.1109/TPAMI.2019.2892452,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611195,IEEE Journals,IEEE
A New Method for Automatic Sleep Stage Classification,Convolutional neural network;electroencephalography;feature extraction;fisher criterion;sleep stage,"Traditionally, automatic sleep stage classification is quite a challenging task because of the difficulty in translating open-textured standards to mathematical models and the limitations of handcrafted features. In this paper, a new system for automatic sleep stage classification is presented. Compared with existing sleep stage methods, our method can capture the sleep information hidden inside electroencephalography (EEG) signals and automatically extract features from raw data. To translate open sleep stage standards into machine rules recognized by computers, a new model named fast discriminative complex-valued convolutional neural network (FDCCNN) is proposed to extract features from raw EEG data and classify sleep stages. The new model combines complex-valued backpropagation and the Fisher criterion. It can learn discriminative features and overcome the negative effect of imbalance dataset. More importantly, the orthogonal decision boundaries for the real and imaginary parts of a complex-valued convolutional neuron are proven. A speed-up algorithm is proposed to reduce computational workload and yield improvements of over an order of magnitude compared to the normal convolution algorithm. The classification performances of handcrafted features and different convolutional neural networks are compared with that of the FDCCNN. The total accuracy and kappa coefficient of the proposed method are 92% and 0.84, respectively. Experiment results demonstrated that the performance of our system is comparable to those of human experts.",2017,T. Sakai,1097,1110,14,12,10.1109/TBCAS.2017.2719631,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010320,IEEE Journals,IEEE
Linguistic Descriptions for Automatic Generation of Textual Short-Term Weather Forecasts on Real Prediction Data,Computing with perceptions (CWPs);linguistic descriptions of data (LDD);natural language generation (NLG);open data,"We present in this paper an application that automatically generates textual short-term weather forecasts for every municipality in Galicia (NW Spain), using the real data provided by the Galician Meteorology Agency (MeteoGalicia). This solution combines in an innovative way computing with perceptions techniques and strategies for linguistic description of data, together with a natural language generation (NLG) system. The application, which is named GALiWeather, extracts relevant information from weather forecast input data and encodes it into intermediate descriptions using linguistic variables and temporal references. These descriptions are later translated into natural language texts by the NLG system. The obtained forecast results have been thoroughly validated by an expert meteorologist from MeteoGalicia using a quality assessment methodology, which covers two key dimensions of a text: the accuracy of its content and the correctness of its form. Following this validation, GALiWeather will be released as a real service, offering custom forecasts for a wide public.",2015,W. Hongbin; H. Hongxu; W. Jing; L. Jinting; F. Wenting,44,57,14,38,10.1109/TFUZZ.2014.2328011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824839,IEEE Journals,IEEE
A Visual Analytic in Deep Learning Approach to Eye Movement for Human-Machine Interaction Based on Inertia Measurement,Accelerometer;gyroscope;complementary filter;deep learning approach;Fitts???s law,"This paper proposes a hand free human-machine interaction (HMI) system to establish a novel way for communication between humans and computers. A regular interaction system based on the computer mouse puts the user's hand for too long in a pronation posture that increases inflammation in the wrist and hand. Additionally, the need for hand obstructs the use of computers for handicap people. In this paper, we develop a new pointing device for differently able people based on open and closed human eyes with inertia measurement that restrict to deal with carpal tunnel syndrome (CTS) for regular people and enables a novel way to interact with computers for the handicap people. The proposed system carries the human head gesture and eyes to perform the movement and clicking event of the mouse cursor. A combined three-axis accelerometer and gyroscope is used to detect the head gesture and translate it into the position of the mouse cursor on the computer monitor. To perform the left and right-clicking event, the user needs to shut down the left and right eye for a moment while opening another eye. This paper is also carried out the design of a deep learning approach to classify the individual openness and closeness of both human eyes with quite a high accuracy of 95.36% that ensures the comprehensive control over the clicking performance. The use of complementary filter removes the noise and drift from the obtained performance and confirms the smooth and accurate operation of the proposed device. An experimental validation is added to show the effectiveness of the proposed HMI system. The experimental details along with the performance evaluation prove that the proposed HMI system has extensive control over its performance for differently able people.",2020,X. Yan,45924,45937,14,8,10.1109/ACCESS.2020.2978028,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022935,IEEE Journals,IEEE
Using Emulation to Engineer and Understand Simulations of Biological Systems,Emulation;ensemble;mechanistic modeling;sensitivity analysis;multi-objective optimization;approximate Bayesian computation;machine learning,"Modeling and simulation techniques have demonstrated success in studying biological systems. As the drive to better capture biological complexity leads to more sophisticated simulators, it becomes challenging to perform statistical analyses that help translate predictions into increased understanding. These analyses may require repeated executions and extensive sampling of high-dimensional parameter spaces: analyses that may become intractable due to time and resource limitations. Significant reduction in these requirements can be obtained using surrogate models, or emulators, that can rapidly and accurately predict the output of an existing simulator. We apply emulation to evaluate and enrich understanding of a previously published agent-based simulator of lymphoid tissue organogenesis, showing an ensemble of machine learning techniques can reproduce results obtained using a suite of statistical analyses within seconds. This performance improvement permits incorporation of previously intractable analyses, including multi-objective optimization to obtain parameter sets that yield a desired response, and Approximate Bayesian Computation to assess parametric uncertainty. To facilitate exploitation of emulation in simulation-focused studies, we extend our open source statistical package, spartan, to provide a suite of tools for emulator development, validation, and application. Overcoming resource limitations permits enriched evaluation and refinement, easing translation of simulator insights into increased biological understanding.",2020,Y. Li; Y. Zhuang,302,315,14,,10.1109/TCBB.2018.2843339,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374844,IEEE Journals,IEEE
A Neural Approach to Source Dependence Based Context Model for Statistical Machine Translation,Source dependence;context representation;neural network;translation prediction;statistical machine translation,"In statistical machine translation, translation prediction considers not only the aligned source word itself but also its source contextual information. Learning context representation is a promising method for improving translation results, particularly through neural networks. Most of the existing methods process context words sequentially and neglect source long-distance dependencies. In this paper, we propose a novel neural approach to source dependence-based context representation for translation prediction. The proposed model is capable of not only encoding source long-distance dependencies but also capturing functional similarities to better predict translations (i.e., word form translations and ambiguous word translations). To verify our method, the proposed mode is incorporated into phrase-based and hierarchical phrase-based translation models, respectively. Experiments on large-scale Chinese-to-English and English-to-German translation tasks show that the proposed approach achieves significant improvement over the baseline systems and outperforms several existing context-enhanced methods.",2018,A. A. Yadav; I. Garg; D. P. Mathur,266,280,15,15,10.1109/TASLP.2017.2772846,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8105847,IEEE Journals,IEEE
Neural Machine Translation With Sentence-Level Topic Context,Sentence-level Context;Latent Topic Representation;Convolutional Neural Network;Neural Machine Translation,"Traditional neural machine translation (NMT) methods use the word-level context to predict target language translation while neglecting the sentence-level context, which has been shown to be beneficial for translation prediction in statistical machine translation. This paper represents the sentence-level context as latent topic representations by using a convolution neural network, and designs a topic attention to integrate source sentence-level topic context information into both attention-based and Transformer-based NMT. In particular, our method can improve the performance of NMT by modeling source topics and translations jointly. Experiments on the large-scale LDC Chinese-to-English translation tasks and WMT'14 English-to-German translation tasks show that the proposed approach can achieve significant improvements compared with baseline systems.",2019,A. Caliskan; R. Greenstadt,1970,1984,15,2,10.1109/TASLP.2019.2937190,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811589,IEEE Journals,IEEE
Sentence Selection and Weighting for Neural Machine Translation Domain Adaptation,Neural machine translation;domain adaptation,"Neural machine translation (NMT) has been prominent in many machine translation tasks. However, in some domain-specific tasks, only the corpora from similar domains can improve translation performance. If out-of-domain corpora are directly added into the in-domain corpus, the translation performance may even degrade. Therefore, domain adaptation techniques are essential to solve the NMT domain problem. Most existing methods for domain adaptation are designed for the conventional phrase-based machine translation. For NMT domain adaptation, there have been only a few studies on topics such as fine tuning, domain tags, and domain features. In this paper, we have four goals for sentence level NMT domain adaptation. First, the NMT's internal sentence embedding is exploited and the sentence embedding similarity is used to select out-of-domain sentences that are close to the in-domain corpus. Second, we propose three sentence weighting methods, i.e., sentence weighting, domain weighting, and batch weighting, to balance the data distribution during NMT training. Third, in addition, we propose dynamic training methods to adjust the sentence selection and weighting during NMT training. Fourth, to solve the multidomain problem in a real-world NMT scenario where the domain distributions of training and testing data often mismatch, we proposed a multidomain sentence weighting method to balance the domain distributions of training data and match the domain distributions of training and testing data. The proposed methods are evaluated in international workshop on spoken language translation (IWSLT) English-to-French/German tasks and a multidomain English-to-French task. Empirical results show that the sentence selection and weighting methods can significantly improve the NMT performance, outperforming the existing baselines.",2018,A. Dogra; A. Kaul; R. Sharma,1727,1741,15,7,10.1109/TASLP.2018.2837223,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360031,IEEE Journals,IEEE
Korean-Vietnamese Neural Machine Translation System With Korean Morphological Analysis and Word Sense Disambiguation,Korean-Vietnamese machine translation;korean-Vietnamese parallel corpus;lexical semantic network;morphological analysis;neural machine translation;word sense disambiguation,"Although deep neural networks have recently led to great achievements in machine translation (MT), various challenges are still encountered during the development of Korean-Vietnamese MT systems. Because Korean is a morphologically rich language and Vietnamese is an analytic language, neither have clear word boundaries. The high rate of homographs in Korean causes word ambiguities, which causes problems in neural MT (NMT). In addition, as a low-resource language pair, there is no freely available, adequate Korean-Vietnamese parallel corpus that can be used to train translation models. In this paper, we manually established a lexical semantic network for the special characteristics of Korean as a knowledge base that was used for developing our Korean morphological analysis and word-sense disambiguation system: UTagger. We also constructed a large Korean-Vietnamese parallel corpus, in which we applied the state-of-the-art Vietnamese word segmentation method RDRsegmenter to Vietnamese texts and UTagger to Korean texts. Finally, we built a bi-directional Korean-Vietnamese NMT system based on the attention-based encoder-decoder architecture. The experimental results indicated that UTagger and RDRsegmenter could significantly improve the performance of the Korean-Vietnamese NMT system, achieving remarkable results by 27.79 BLEU points and 58.77 TER points in Korean-to-Vietnamese direction and 25.44 BLEU points and 58.72 TER points in the reverse direction.",2019,D. D. Kalamkar; K. Banerjee; S. Srinivasan; S. Sridharan; E. Georganas; M. E. Smorkalov; C. Xu; A. Heinecke,32602,32616,15,2,10.1109/ACCESS.2019.2902270,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8660625,IEEE Journals,IEEE
A Loss-Augmented Approach to Training Syntactic Machine Translation Systems,Loss-augmented training;machine translation;syntax-based model,"Current syntactic machine translation (MT) systems implicitly use beam-width unlimited search in learning model parameters (e.g., feature values for each translation rule). However, a limited beam-width has to be adopted in decoding new sentences, and the MT output is in general evaluated by various metrics, such as BLEU and TER. In this paper, we address: 1) the mismatch of adopted beam-widths between training and decoding; and 2) the mismatch of training criteria and MT evaluation metrics. Unlike previous work, we model the two problems in a single training paradigm simultaneously. We design a loss-augmented approach that explicitly considers the limited beam-width and evaluation metric in training, and present a simple but effective method to learn the model. By using beam search and BLEU-related losses, our approach improves a state-of-the-art syntactic MT system by +1.0 BLEU on Chinese-to-English and English-to-Chinese translation tasks. It even outperforms seven previous training approaches over 0.8 BLEU points. More interestingly, promising improvements are observed when our approach works with TER.",2016,E. BiÃ§ici; D. Yuret,2069,2083,15,4,10.1109/TASLP.2016.2594383,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523295,IEEE Journals,IEEE
Grounded Sequence to Sequence Transduction,Grounding;multimodal machine learning;speech recognition;machine translation;representation learning;summarization,"Speech recognition and machine translation have made major progress over the past decades, providing practical systems to map one language sequence to another. Although multiple modalities such as sound and video are becoming increasingly available, the state-of-the-art systems are inherently unimodal, in the sense that they take a single modality - either speech or text - as input. Evidence from human learning suggests that additional modalities can provide disambiguating signals crucial for many language tasks. In this article, we describe the How2 dataset , a large, open-domain collection of videos with transcriptions and their translations. We then show how this single dataset can be used to develop systems for a variety of language tasks and present a number of models meant as starting points. Across tasks, we find that building multimodal architectures that perform better than their unimodal counterpart remains a challenge. This leaves plenty of room for the exploration of more advanced solutions that fully exploit the multimodal nature of the How2 dataset , and the general direction of multimodal learning with other datasets as well.",2020,M. Yasuoka; P. Bjorn,577,591,15,,10.1109/JSTSP.2020.2998415,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103248,IEEE Journals,IEEE
Cross-View Action Recognition Based on a Statistical Translation Framework,Cross-view action recognition;expectation-maximization algorithm;log-likelihood-ratio tests;statistical machine translation;transfer probabilities,"Actions captured under view changes pose serious challenges to modern action recognition methods. In this paper, we propose an effective approach for cross-view action recognition based on a statistical translation framework, which boils down to estimation of visual word transfer probabilities across views. Specifically, local features are extracted from action video frames and form bags of words based on k-means clustering. Though the appearance of an action may vary due to view changes, the underlying transfer tendency between visual words across views can be exploited. We propose two methods to measure the visual-word-based transfer relationship that are eventually based on frequency counts of word pairs. In the first method, word transfer probabilities are estimated by maximizing the likelihood of a shared action set with the EM algorithm. In the second method, word transfer probabilities are estimated by using likelihood-ratio tests. The two methods achieve comparable results and perform better when they are combined. For cross-view action classification, we compute action transfer probabilities based on the estimated word transfer probabilities and then implement a K-NN-like classification based on action video transfer probabilities. We verified our method on the public multiview IXMAS dataset and the WVU dataset. Promising results are obtained compared with state-of-the-art methods.",2016,N. Srinivasa; M. Jouaneh,1461,1475,15,9,10.1109/TCSVT.2014.2382984,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6990544,IEEE Journals,IEEE
Extreme Learning Machine With Affine Transformation Inputs in an Activation Function,Affine transformation (AT) activation function;classification;extreme learning machine (ELM);maximum entropy;regression,"The extreme learning machine (ELM) has attracted much attention over the past decade due to its fast learning speed and convincing generalization performance. However, there still remains a practical issue to be approached when applying the ELM: the randomly generated hidden node parameters without tuning can lead to the hidden node outputs being nonuniformly distributed, thus giving rise to poor generalization performance. To address this deficiency, a novel activation function with an affine transformation (AT) on its input is introduced into the ELM, which leads to an improved ELM algorithm that is referred to as an AT-ELM in this paper. The scaling and translation parameters of the AT activation function are computed based on the maximum entropy principle in such a way that the hidden layer outputs approximately obey a uniform distribution. Application of the AT-ELM algorithm in nonlinear function regression shows its robustness to the range scaling of the network inputs. Experiments on nonlinear function regression, real-world data set classification, and benchmark image recognition demonstrate better performance for the AT-ELM compared with the original ELM, the regularized ELM, and the kernel ELM. Recognition results on benchmark image data sets also reveal that the AT-ELM outperforms several other state-of-the-art algorithms in general.",2019,P. Tennage; A. Herath; M. Thilakarathne; P. Sandaruwan; S. Ranathunga,2093,2107,15,22,10.1109/TNNLS.2018.2877468,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8533625,IEEE Journals,IEEE
Road-Sign Detection and Recognition Based on Support Vector Machines,Classification;detection;hue;hue saturation intensity (HSI);road sign;support vector machines (SVMs),"This paper presents an automatic road-sign detection and recognition system based on support vector machines (SVMs). In automatic traffic-sign maintenance and in a visual driver-assistance system, road-sign detection and recognition are two of the most important functions. Our system is able to detect and recognize circular, rectangular, triangular, and octagonal signs and, hence, covers all existing Spanish traffic-sign shapes. Road signs provide drivers important information and help them to drive more safely and more easily by guiding and warning them and thus regulating their actions. The proposed recognition system is based on the generalization properties of SVMs. The system consists of three stages: 1) segmentation according to the color of the pixel; 2) traffic-sign detection by shape classification using linear SVMs; and 3) content recognition based on Gaussian-kernel SVMs. Because of the used segmentation stage by red, blue, yellow, white, or combinations of these colors, all traffic signs can be detected, and some of them can be detected by several colors. Results show a high success rate and a very low amount of false positives in the final recognition stage. From these results, we can conclude that the proposed algorithm is invariant to translation, rotation, scale, and, in many situations, even to partial occlusions",2007,S. Narzary; M. Brahma; B. Singha; R. Brahma; B. Dibragede; S. Barman; S. Nandi; B. Som,264,278,15,418,10.1109/TITS.2007.895311,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4220659,IEEE Journals,IEEE
Using Machine Learning to Optimize Web Interactions on Heterogeneous Mobile Systems,Interactive mobile web browsing;machine learning;energy optimization,"The web has become a ubiquitous application development platform for mobile systems. Yet, web access on mobile devices remains an energy-hungry activity. Prior work in the field mainly focuses on the initial page loading stage, but fails to exploit the opportunities for energy-efficiency optimization while the user is interacting with a loaded page. This paper presents a novel approach for performing energy optimization for interactive mobile web browsing. At the heart of our approach is a set of machine learning models, which estimate at runtime the frames per second for a given user interaction input by running the computation-intensive web render engine on a specific processor core under a given clock speed. We use the learned predictive models as a utility function to quickly search for the optimal processor setting to carefully trade responsive time for reduced energy consumption. We integrate our techniques to the open-source Chromium browser and apply it to two representative mobile user events: scrolling and pinching (i.e., zoom in and out). We evaluate the developed system on the landing pages of the top-100 hottest websites and two big.LITTLE heterogeneous mobile platforms. Our extensive experiments show that the proposed approach reduces the system-wide energy consumption by over 36% on average and up to 70%. This translates to an over 17% improvement on energy-efficiency over a state-of-the-art event-based web browser scheduler, but with significantly fewer violations on the quality of service.",2019,S. P. Singh; H. Darbari; A. Kumar; S. Jain; A. Lohan,139394,139408,15,2,10.1109/ACCESS.2019.2936620,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8808911,IEEE Journals,IEEE
Electrothermal Microactuators With Peg Drive Improve Performance for Brain Implant Applications,Biomedical devices;BioMEMS;brainâ€“machine interface;electrothermal microactuators;in vivo microelectrodes;neural prosthesis;robots,"This paper presents a new actuation scheme for in-plane bidirectional translation of polysilicon microelectrodes. The new Chevron-peg actuation scheme uses micro-electromechanical systems (MEMS) based electrothermal microactuators to move microelectrodes for brain implant applications. The design changes were motivated by specific needs identified by the in vivo testing of an earlier generation of MEMS microelectrodes that were actuated by the Chevron-latch type of mechanism. The microelectrodes actuated by the Chevron-peg mechanism discussed here show improved performance in the following key areas: higher force generation capability (111 Î¼N per heat strip compared to 50 Î¼N), reduced power consumption (91 mW compared to 360 mW), and reliable performance with consistent forward and backward movements of microelectrodes. Failure analysis of the Chevron-latch and the Chevron-peg type of actuation schemes showed that the latter is more robust to wear over four million cycles of operation. The parameters for the activation waveforms for Chevron-peg actuators were optimized using statistical analysis. Waveforms with a 1-ms time period and a 1-Hz frequency of operation showed minimal error between the expected and the actual movement of the microelectrodes. The new generation of Chevron-peg actuators and microelectrodes are therefore expected to enhance the longevity and performance of implanted microelectrodes in the brain.",2012,V. Zakharov; A. Khoroshilov; A. Khoroshilov,1172,1186,15,18,10.1109/JMEMS.2012.2203789,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239549,IEEE Journals,IEEE
Learning Nonnegative Factors From Tensor Data: Probabilistic Modeling and Inference Algorithm,Tensor decomposition;nonnegative factors;variational inference;automatic rank determination,"Tensor canonical polyadic decomposition (CPD) with nonnegative factor matrices, which extracts useful latent information from multidimensional data, has found wide-spread applications in various big data analytic tasks. Currently, the implementation of most existing algorithms needs the knowledge of tensor rank. However, this information is practically unknown and difficult to acquire. To address this issue, a probabilistic approach is taken in this paper. Different from previous works, this paper firstly introduces a sparsity-promoting nonnegative Gaussian-gamma prior, based on which a novel probabilistic model for the CPD problem with nonnegative and continuous factors is established. This probabilistic model further enables the derivation of an efficient inference algorithm that accurately learns the nonnegative factors from the tensor data, along with an integrated feature of automatic rank determination. Numerical results using synthetic data and real-world applications are presented to show the remarkable performance of the proposed algorithm.",2020,Wenpeng Lu; Ruojuan Xue,1792,1806,15,3,10.1109/TSP.2020.2975353,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006902,IEEE Journals,IEEE
Progressive Transfer Learning and Adversarial Domain Adaptation for Cross-Domain Skin Disease Classification,Automatic melanoma detection;dermoscopy image;cycle-GAN;deep learning;transfer learning;domain adaptation,"Deep learning has been used to analyze and diagnose various skin diseases through medical imaging. However, recent researches show that a well-trained deep learning model may not generalize well to data from different cohorts due to domain shift. Simple data fusion techniques such as combining disease samples from different data sources are not effective to solve this problem. In this paper, we present two methods for a novel task of cross-domain skin disease recognition. Starting from a fully supervised deep convolutional neural network classifier pre-trained on ImageNet, we explore a two-step progressive transfer learning technique by fine-tuning the network on two skin disease datasets. We then propose to adopt adversarial learning as a domain adaptation technique to perform invariant attribute translation from source to target domain in order to improve the recognition performance. In order to evaluate these two methods, we analyze generalization capability of the trained model on melanoma detection, cancer detection, and cross-modality learning tasks on two skin image datasets collected from different clinical settings and cohorts with different disease distributions. The experiments prove the effectiveness of our method in solving the domain shift problem.",2020,Y. M. ShweSin; K. M. Soe; K. Y. Htwe,1379,1393,15,3,10.1109/JBHI.2019.2942429,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846038,IEEE Journals,IEEE
System Combination for Machine Translation of Spoken and Written Language,machine translation;natural languages;speech processing;text processing,"This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation (MT) systems. The consensus translation is computed by weighted majority voting on a confusion network, similarly to the well-established ROVER approach of Fiscus for combining speech recognition hypotheses. To create the confusion network, pairwise word alignments of the original MT hypotheses are learned using an enhanced statistical alignment algorithm that explicitly models word reordering. The context of a whole corpus of automatic translations rather than a single sentence is taken into account in order to achieve high alignment quality. The confusion network is rescored with a special language model, and the consensus translation is extracted as the best path. The proposed system combination approach was evaluated in the framework of the TC-STAR speech translation project. Up to six state-of-the-art statistical phrase-based translation systems from different project partners were combined in the experiments. Significant improvements in translation quality from Spanish to English and from English to Spanish in comparison with the best of the individual MT systems were achieved under official evaluation conditions.",2008,D. Han; T. Ito; T. Furugori,1222,1237,16,18,10.1109/TASL.2008.914970,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4599393,IEEE Journals,IEEE
Applications of Statistical Machine Translation Approaches to Spoken Language Understanding,Combined approach;machine translation;maximum entropy;minimum error rate training;speech recognition;spoken language understanding,"In this paper, we investigate two statistical methods for spoken language understanding based on statistical machine translation. The first approach employs the source-channel paradigm, whereas the other uses the maximum entropy framework. Starting with an annotated corpus, we describe the problem of natural language understanding as a translation from a source sentence to a formal language target sentence. We analyze the quality of different alignment models and feature functions and show that the direct maximum entropy approach outperforms the source channel-based method. Furthermore, we investigate how both methods perform if the input sentences contain speech recognition errors. Finally, we investigate a new approach to combine speech recognition and spoken language understanding. For this purpose, we employ minimum error rate training which directly optimizes the final evaluation criterion. By combining all knowledge sources in a log-linear way, we show that we can decrease both the word error rate and the slot error rate. Experiments were carried out on two German inhouse corpora for spoken dialogue systems.",2009,G. Tiwari; A. Sharma; A. Sahotra; R. Kapoor,803,818,16,11,10.1109/TASL.2009.2014262,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806285,IEEE Journals,IEEE
Kernel Association for Classification and Prediction: A Survey,Kernel methods;Mercer kernels;neural network (NN);principal component analysis (PCA);support vector machine (SVM).;Kernel methods;Mercer kernels;neural network (NN);principal component analysis (PCA);support vector machine (SVM),"Kernel association (KA) in statistical pattern recognition used for classification and prediction have recently emerged in a machine learning and signal processing context. This survey outlines the latest trends and innovations of a kernel framework for big data analysis. KA topics include offline learning, distributed database, online learning, and its prediction. The structural presentation and the comprehensive list of references are geared to provide a useful overview of this evolving field for both specialists and relevant scholars.",2015,S. Jusoh; H. M. Alfawareh,208,223,16,27,10.1109/TNNLS.2014.2333664,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6851930,IEEE Journals,IEEE
RMVP: A Real-Time Method to Monitor Random Processes of Virtual Machine,Virtual machine;real-time monitoring;process detection;rootkit;memory mapping,"Out-of-box methods can provide strict isolation between the security tool and the target virtual machine (TVM), so they have strong anti-jamming abilities. Current monitoring methods are mostly based on memory snapshots at a time point or a fixed period. Due to the randomness of processes and the discontinuity of monitoring methods, methods based on time point or fixed period snapshots that security tools used to monitor processes may result in a high leakage rate. The real-time monitoring method can be used to resolve this problem. However, all current real-time monitoring methods require a ready monitoring set, and their monitoring range is strictly limited. They are only effective for the inherent objects within the ready set and ineffective for the random processes. This paper presents real-time monitoring of virtual machine processes (RMVP), a real-time monitoring method to monitor a random process in the TVM. First, the RMVP monitors process switch by capturing the switch of kernel stack base addresses outside the TVM in real time. Then, it extracts raw memory of the current process through the memory mapping technology that adopts caching mechanism and multi-task concurrent execution strategy. Finally, the RMVP translates raw memory into high-level semantics according to a semantic knowledge base constructed offline. The RMVP can monitor random processes in real time and overcome the challenge of process randomness. The experimental results show that the capture rate of the random process is over 95% and the capture delay is in the range of 2.3~3.3 ms. In addition, the RMVP is especially effective for detecting the processes hidden by rootkits.",2019,S. Ninomiya; Tran Than Thi Ngan Hoa; Y. Mori; T. Takasaki; T. Ishida; Donghui Lin; T. Kameoka; A. Takezaki; A. Tanaka; K. Yamamoto; K. Nishioka; R. Ikeda,15845,15860,16,,10.1109/ACCESS.2019.2893627,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618390,IEEE Journals,IEEE
Weakly Supervised Training of a Sign Language Recognition System Using Multiple Instance Learning Density Matrices,HMM;multiple instance learning (MIL);sign language recognition;size function;support vector machine (SVM);weakly supervised learning,"A system for automatically training and spotting signs from continuous sign language sentences is presented. We propose a novel multiple instance learning density matrix algorithm which automatically extracts isolated signs from full sentences using the weak and noisy supervision of text translations. The automatically extracted isolated samples are then utilized to train our spatiotemporal gesture and hand posture classifiers. The experiments were carried out to evaluate the performance of the automatic sign extraction, hand posture classification, and spatiotemporal gesture spotting systems. We then carry out a full evaluation of our overall sign spotting system which was automatically trained on 30 different signs.",2011,V. Goyal; G. S. Lehal,526,541,16,29,10.1109/TSMCB.2010.2065802,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582311,IEEE Journals,IEEE
Effective Deep Learning Models for Automatic Diacritization of Arabic Text,Arabic language;Tacotron;diacritization;deep learning;text-to-speech,"While building a text-to-speech system for the Arabic language, we found that the system synthesized speeches with many pronunciation errors. The primary source of these errors is the lack of diacritics in modern standard Arabic writing. These diacritics are small strokes that appear above or below each letter to provide pronunciation and grammatical information. We propose three deep learning models to recover Arabic text diacritics based on our work in a text-to-speech synthesis system using deep learning. The first model is a baseline model used to test how a simple deep learning model performs on the corpora. The second model is based on an encoder-decoder architecture, which resembles our text-to-speech synthesis model with many modifications to suit this problem. The last model is based on the encoder part of the text-to-speech model, which achieves state-of-the-art performances in both word error rate and diacritic error rate metrics. These models will benefit a wide range of natural language processing applications such as text-to-speech, part-of-speech tagging, and machine translation.",2021,W. Winiwarter,273,288,16,,10.1109/ACCESS.2020.3041676,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274427,IEEE Journals,IEEE
Robust Pol-ISAR Target Recognition Based on ST-MC-DCNN,Automatic target recognition (ATR);deep convolutional neural network (DCNN);image deformation;inverse synthetic aperture radar (ISAR),"Although the deep convolutional neural network (DCNN) has been successfully applied to automatic target recognition (ATR) of ground vehicles based on synthetic aperture radar (SAR), most of the available techniques are not suitable for inverse synthetic aperture radar (ISAR) because they cannot tackle the inherent unknown deformation (e.g., translation, scaling, and rotation) among the training and test samples. To achieve robust polarimetric-ISAR (Pol-ISAR) ATR, this paper proposes the spatial transformer-multi-channel-deep convolutional neural network, i.e., ST-MC-DCNN. In this structure, we adopt the double-layer spatial transformer network (STN) module to adjust the image deformation of each polarimetric channel and then perform a robust hierarchical feature extraction by MC-DCNN. Finally, we carry out feature fusion in the concatenation layer and output the recognition result by the softmax classifier. The proposed network is end-to-end trainable and could learn the optimal deformation parameters automatically from training samples. For the fully Pol-ISAR image database generated from electromagnetic (EM) echoes of four satellites, the proposed structure achieves higher recognition accuracy than traditional DCNN and MC-DCNN. Additionally, it has shown robustness to image scaling, rotation, and combined deformation.",2019,Y. Nishimura; K. Sudoh; G. Neubig; S. Nakamura,9912,9927,16,4,10.1109/TGRS.2019.2930112,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804365,IEEE Journals,IEEE
Disaggregating County-Level Census Data for Population Mapping Using Residential Geo-Objects With Multisource Geo-Spatial Data,Census data;machine-learning (ML) algorithms;multisource geospatial data;population mapping;residential geo-objects;spatialization,"Accurate spatialization of socioeconomic data is conducive to understand the spatial and temporal distribution of human social development status and, thus, effectively support future scientific decision-making. This study focuses on population mapping, which is a classical spatialization of macroeconomic data of the social economy. Traditional population mapping based on rough grids or administrative divisions such as townships often has deficiencies in the accuracy of spatial pattern and prediction. In this article, hence, we employ residential geo-objects as basic mapping units and formalize the problem as a spatial prediction process using machine-learning (ML) methods with high-spatial-resolution (HSR) satellite remote sensing images and multisource geospatial data. The indicators of population spatial density, including residential geo-objects' area, building existence index, terrain slope, night light intensity, density of point of interest (POI) and road network from Internet electronic maps, and locational factors such as the distances from road and river, are jointly applied to establish the relationship between these multivariable factors and quantitative index of population density using ML algorithms such as Random Forests and XGBoost. The predicated values of population density from the mined nonlinear regression relation are further used to calculate the weights of disaggregation of each unit, and then the population quantity distribution at the scale of residential geo-objects is obtained under the control of the total amount of population statistics. Experiments with a county area show that the methodology has the ability to achieve better results than the traditional deterministic methods by reproducing a more accurate and finer geographic population distribution pattern. Meanwhile, it is found that the optimization of mapping results may benefit from the multisources geospatial data, and thus the methodological framework can be recommended to be extended to other spatialization areas of socioeconomic data.",2020,Y. Gokcen; V. A. Foroushani; A. N. Z. Heywood,1189,1205,17,,10.1109/JSTARS.2020.2974896,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042311,IEEE Journals,IEEE
ByRDiE: Byzantine-Resilient Distributed Coordinate Descent for Decentralized Learning,Byzantine failure;consensus;coordinate descent;decentralized learning;distributed optimization;empirical risk minimization;machine learning,"Distributed machine learning algorithms enable learning of models from datasets that are distributed over a network without gathering the data at a centralized location. While efficient distributed algorithms have been developed under the assumption of faultless networks, failures that can render these algorithms nonfunctional occur frequently in the real world. This paper focuses on the problem of Byzantine failures, which are the hardest to safeguard against in distributed algorithms. While Byzantine fault tolerance has a rich history, existing work does not translate into efficient and practical algorithms for high-dimensional learning in fully distributed (also known as decentralized) settings. In this paper, an algorithm termed Byzantine-resilient distributed coordinate descent is developed and analyzed that enables distributed learning in the presence of Byzantine failures. Theoretical analysis (convex settings) and numerical experiments (convex and nonconvex settings) highlight its usefulness for high-dimensional distributed learning in the presence of Byzantine failures.",2019,Y. Zhang,611,627,17,7,10.1109/TSIPN.2019.2928176,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759887,IEEE Journals,IEEE
Brainâ€“Computer Evolutionary Multiobjective Optimization: A Genetic Algorithm Adapting to the Decision Maker,Interactive decision making;machine learning;reactive search optimization;support vector ranking,"The centrality of the decision maker (DM) is widely recognized in the multiple criteria decision-making community. This translates into emphasis on seamless human-computer interaction, and adaptation of the solution technique to the knowledge which is progressively acquired from the DM. This paper adopts the methodology of reactive search optimization (RSO) for evolutionary interactive multiobjective optimization. RSO follows to the paradigm of â€œlearning while optimizing,â€? through the use of online machine learning techniques as an integral part of a self-tuning optimization scheme. User judgments of couples of solutions are used to build robust incremental models of the user utility function, with the objective to reduce the cognitive burden required from the DM to identify a satisficing solution. The technique of support vector ranking is used together with a k-fold cross-validation procedure to select the best kernel for the problem at hand, during the utility function training procedure. Experimental results are presented for a series of benchmark problems.",2010,Z. El Maazouzi; B. E. El Mohajir; M. A. Achhab; A. Souri,671,687,17,59,10.1109/TEVC.2010.2058118,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560789,IEEE Journals,IEEE
Cognitive Training and Stress Detection in MCI Frail Older People Through Wearable Sensors and Machine Learning,Cognitive training;m-health;physiological data analysis;stress detection;wearable sensors;decision support system;machine learning,"Personalised training of motor and cognitive abilities is fundamental to help older people maintain a good quality of life, especially in case of frailty conditions. However, the training activity can increase the stress level, especially in persons affected by a chronic stress condition. Wearable technologies and m-health solutions can support the person, the medical specialist, and long-term care facilities to efficiently implement personalised therapy solutions by monitoring the stress level of each subject during the motor and cognitive training. In this paper we present a comprehensive work on this topic, starting from a pilot study involving a group of frail older adults suffering from Mild Cognitive Impairment (MCI) who actively participated in cognitive and motor rehabilitation sessions equipped with wearable physiological sensors and a mobile application for physiological monitoring. We analyse the collected data to investigate the stress response of frail older subjects during the therapy, and how the cognitive training is positively affected by physical exercise. Then, we evaluated a stress detection system based on several machine learning algorithms in order to highlight their performances on the real dataset we collected. However, stress detection algorithms generally provide only the identification of a stressful/non stressful event, which is not sufficient to personalise the therapy. Therefore, we propose a mobile system architecture for online stress monitoring able to infer the stress level during a session. The obtained result is then used as input for a Decision Support System (DSS) in order to support the medical user in the definition of a personalised therapy for frail older adults.",2020,N. S. T. Hirata,65573,65590,18,3,10.1109/ACCESS.2020.2985301,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9055213,IEEE Journals,IEEE
Deep Learning for Health Informatics,Bioinformatics;deep learning;health informatics;machine learning;medical imaging;public health;wearable devices,"With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. This article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.",2017,V. Nikulin; N. Rogovschi; N. Grozavu,4,21,18,557,10.1109/JBHI.2016.2636665,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801947,IEEE Journals,IEEE
A Machine Learning-Based Recommender System for Improving Students Learning Experiences,Outcome-based education;educational data mining;recommender systems;students learning experiences;teaching strategies,"Outcome-based education (OBE) is a well-proven teaching strategy based upon a predefined set of expected outcomes. The components of OBE are Program Educational Objectives (PEOs), Program Outcomes (POs), and Course Outcomes (COs). These latter are assessed at the end of each course and several recommended actions can be proposed by faculty members' to enhance the quality of courses and therefore the overall educational program. Considering a large number of courses and the faculty members' devotion, bad actions could be recommended and therefore undesirable and inappropriate decisions may occur. In this paper, a recommender system, using different machine learning algorithms, is proposed for predicting suitable actions based on course specifications, academic records, and course learning outcomes' assessments. We formulated the problem as a multi-label multi-class binary classification problem and the dataset was translated into different problem transformation and adaptive methods such as one-vs.-all, binary relevance, label powerset, classifier chain, and ML-KNN adaptive classifier. As a case study, the proposed recommender system is applied to the college of Computer and Information Sciences, Jouf University, Kingdom of Saudi Arabia (KSA) for helping academic staff improving the quality of teaching strategies. The obtained results showed that the proposed recommender system presents more recommended actions for improving students' learning experiences.",2020,X. Bai; X. Zhou; F. Zhang; L. Wang; R. Xue; F. Zhou,201218,201235,18,,10.1109/ACCESS.2020.3036336,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9249379,IEEE Journals,IEEE
Predicting Chronic Disease Hospitalizations from Electronic Health Records: An Interpretable Classification Approach,Diabetes;electronic health records (EHRs);heart disease;machine learning;predictive analytics;smart city;smart health,"Urban living in modern large cities has significant adverse effects on health, increasing the risk of several chronic diseases. We focus on the two leading clusters of chronic diseases, heart disease and diabetes, and develop data-driven methods to predict hospitalizations due to these conditions. We base these predictions on the patients' medical history, recent and more distant, as described in their Electronic Health Records (EHRs). We formulate the prediction problem as a binary classification problem and consider a variety of machine learning methods, including kernelized and sparse Support Vector Machines (SVMs), sparse logistic regression, and random forests. To strike a balance between accuracy and interpretability of the prediction, which is important in a medical setting, we propose two novel methods: K -LRT, a likelihood ratio test-based method, and a Joint Clustering and Classification (JCC) method which identifies hidden patient clusters and adapts classifiers to each cluster. We develop theoretical out-of-sample guarantees for the latter method. We validate our algorithms on large data sets from the Boston Medical Center, the largest safety-net hospital system in New England.",2018,Y. K. Thu; A. Finch; E. Sumita; Y. Sagisaka,690,707,18,6,10.1109/JPROC.2017.2789319,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283520,IEEE Journals,IEEE
Part of Speech Tagging in Urdu: Comparison of Machine and Deep Learning Approaches,Urdu;part of speech (POS);conditional random field (CRF);support vector machine (SVM);recurrent neural network (RNN);hidden Markov model (HMM),"In Urdu, part of speech (POS) tagging is a challenging task as it is both inflectionally and derivationally rich morphological language. Verbs are generally conceived a highly inflected object in Urdu comparatively to nouns. POS tagging is used as a preliminary linguistic text analysis in diverse natural language processing domains such as speech processing, information extraction, machine translation, and others. It is a task that first identifies appropriate syntactic categories for each word in running text and second assigns the predicted syntactic tag to all concerned words. The current work is the extension of our previous work. Previously, we presented conditional random field (CRF)-based POS tagger with both language dependent and independent feature set. However, in the current study, we offer: 1) the implementation of both machine and deep learning models for Urdu POS tagging task with well-balanced language-independent feature set and 2) to highlight diverse challenges which cause Urdu POS task a challenging one. In this research, we demonstrated the effectiveness of machine learning and deep learning models for Urdu POS task. Empirically, we have evaluated the performance of all models on two benchmark datasets. The core models evaluated in this study are CRF, support vector machine (SVM), two variants of the deep recurrent neural network (DRNN), and a variant of n-gram Markov model the bigram hidden Markov model (HMM). The two variants of DRRN models evaluated include forward long short-term memory (LSTM)-RNN and LSTM-RNN with CRF output.",2019,P. Y. Mundkur; U. B. Desai,38918,38936,19,6,10.1109/ACCESS.2019.2897327,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636191,IEEE Journals,IEEE
Optimizing Streaming Parallelism on Heterogeneous Many-Core Architectures,Heterogeneous computing;parallelism;performance tuning;machine learning,"As many-core accelerators keep integrating more processing units, it becomes increasingly more difficult for a parallel application to make effective use of all available resources. An effective way of improving hardware utilization is to exploit spatial and temporal sharing of the heterogeneous processing units by multiplexing computation and communication tasks - a strategy known as heterogeneous streaming. Achieving effective heterogeneous streaming requires carefully partitioning hardware among tasks, and matching the granularity of task parallelism to the resource partition. However, finding the right resource partitioning and task granularity is extremely challenging, because there is a large number of possible solutions and the optimal solution varies across programs and datasets. This article presents an automatic approach to quickly derive a good solution for hardware resource partition and task granularity for task-based parallel applications on heterogeneous many-core architectures. Our approach employs a performance model to estimate the resulting performance of the target application under a given resource partition and task granularity configuration. The model is used as a utility to quickly search for a good configuration at runtime. Instead of hand-crafting an analytical model that requires expert insights into low-level hardware details, we employ machine learning techniques to automatically learn it. We achieve this by first learning a predictive model offline using training programs. The learned model can then be used to predict the performance of any unseen program at runtime. We apply our approach to 39 representative parallel applications and evaluate it on two representative heterogeneous many-core platforms: a CPU-XeonPhi platform and a CPU-GPU platform. Compared to the single-stream version, our approach achieves, on average, a 1.6x and 1.1x speedup on the XeonPhi and the GPU platform, respectively. These results translate to over 93 percent of the performance delivered by a theoretically perfect predictor.",2020,Wenbin Hao; Qunzhan Li; Xueyuan Zhang; Yongkang Zheng,1878,1896,19,,10.1109/TPDS.2020.2978045,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022909,IEEE Journals,IEEE
Towards a Context-Free Machine Universal Grammar (CF-MUG) in Natural Language Processing,Semantic document exchange;natural language processing;universal grammar,"In natural language processing, semantic document exchange ensures unambiguity and shares the same meaning for documents sender and receiver cross different natural languages (e.g., English to Chinese), this difference makes the translation between natural languages becomes complex and inaccurate. This paper proposed a novel framework of Context-Free Machine Universal Grammar which consists of local mode (sender and receiver) and mediation mode (Machine Universal Language) based on the concept of collaboration, the framework improves semantic unambiguity and accuracy in crossing language document, meanwhile makes document computer-readable through unique ID for each word or phrase. More importantly, inspired by grammatical case in linguistics, a novel Machine Universal Grammar provides a universal grammar that accepts all coming languages and improves semantic accuracy in natural language processing.",2020,X. Jiang; K. Xu; X. Liu; C. Dai; D. A. Clifton; E. A. Clancy; M. Akay; W. Chen,165111,165129,19,,10.1109/ACCESS.2020.3022674,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187784,IEEE Journals,IEEE
Multimodal Machine Learning: A Survey and Taxonomy,Multimodal;machine learning;introductory;survey,"Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.",2019,S. N. Patankar; M. M. Phadke; S. R. Devane,423,443,21,119,10.1109/TPAMI.2018.2798607,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269806,IEEE Journals,IEEE
Deep Learning for Proactive Network Monitoring and Security Protection,Deep learning;proactive forecasting;network monitoring;cyber security;anomaly detection;neural machine translation,"The work presented in this paper deals with a proactive network monitoring for security and protection of computing infrastructures. We provide an exploitation of an intelligent module, in the form of a as a machine learning application using deep learning modeling, in order to enhance functionality of intrusion detection system supervising network traffic flows. Currently, intrusion detection systems work well for network monitoring in near real-time and they effectively deal with threats in a reactive way. Deep learning is the emerging generation of artificial intelligence techniques and one of the most promising candidates for intelligence integration into traditional solutions leading to quality improvement of the original solutions. The work presented in this paper faces the challenge of cooperation between deep learning techniques and large-scale data processing. The outcomes obtained from extensive and careful experiments show the applicability and feasibility of simultaneously modelled multiple monitoring channels using deep learning techniques. The proper joining of deep learning modelling with scalable data preprocessing ensures high quality and stability of model performance in dynamic and fast-changing environments such as network traffic flow monitoring.",2020,T. W. Rogers; N. Jaccard; E. D. Protonotarios; J. Ollier; E. J. Morton; L. D. Griffin,19696,19716,21,4,10.1109/ACCESS.2020.2968718,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966259,IEEE Journals,IEEE
AI in Medical Imaging Informatics: Current Challenges and Future Directions,Medical Imaging;Image Analysis;Image Classification;Image Processing;Image Segmentation;Image Visualization;Integrative Analytics;Machine Learning;Deep Learning;Big Data,"This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine.",2020,V. Y. Meltsov; V. A. Lesnikov; M. L. Dolzhenkova,1837,1857,21,8,10.1109/JBHI.2020.2991043,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103969,IEEE Journals,IEEE
A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction,Machine learning;deep convolutional neural networks;scattering networks;feature extraction;frame theory,"Deep convolutional neural networks (DCNNs) have led to breakthrough results in numerous practical machine learning tasks, such as classification of images in the ImageNet data set, control-policy-learning to play Atari games or the board game Go, and image captioning. Many of these applications first perform feature extraction and then feed the results thereof into a classifier. The mathematical analysis of DCNNs for feature extraction was initiated by Mallat, 2012. Specifically, Mallat considered so-called scattering networks based on a wavelet transform followed by the modulus non-linearity in each network layer, and proved translation invariance (asymptotically in the wavelet scale parameter) and deformation stability of the corresponding feature extractor. This paper complements Mallat's results by developing a theory that encompasses general convolutional transforms, or in more technical parlance, general semi-discrete frames (including Weyl-Heisenberg filters, curvelets, shearlets, ridgelets, wavelets, and learned filters), general Lipschitz-continuous non-linearities (e.g., rectified linear units, shifted logistic sigmoids, hyperbolic tangents, and modulus functions), and general Lipschitz-continuous pooling operators emulating, e.g., sub-sampling and averaging. In addition, all of these elements can be different in different network layers. For the resulting feature extractor, we prove a translation invariance result of vertical nature in the sense of the features becoming progressively more translation-invariant with increasing network depth, and we establish deformation sensitivity bounds that apply to signal classes such as, e.g., band-limited functions, cartoon functions, and Lipschitz functions.",2018,T. Meier; K. N. Ngan,1845,1866,22,27,10.1109/TIT.2017.2776228,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8116648,IEEE Journals,IEEE
A Deformation Robust ISAR Image Satellite Target Recognition Method Based on PT-CCNN,Automatic target recognition (ATR);inverse synthetic aperture radar (ISAR);deep convolutional neural network (DCNN);image deformation;log-polar transformation,"To tackle the inherent unknown deformation (e.g., translation, rotation and scaling) of the inverse synthetic aperture radar (ISAR) images, a deep polar transformer-circular convolutional neural network, i.e., PT-CCNN, is proposed to achieve deformation robust ISAR image automatic target recognition (ATR) in this article. Inspired by human visual system and canonical coordinate of Lie-groups, we adopt a polar transformer module to transform the deformation ISAR images to the log-polar representations, before which a conventional convolutional neural network (CNN) is utilized to predict the origin of log-polar transformation. The above techniques make the proposed network invariant to translation, and equivariant to rotation and scaling. On this basis, for the log-polar representations with wrap-around structure, a circular convolutional neural network (CCNN) is further applied to extract more effective and highly discriminative features and improve recognition accuracy. The proposed network is end-to-end trainable with a classification loss, and could extract deformation-robust and essential features automatically. For multiple practical ISAR image datasets of six satellites, the performance testing and comparison experiments demonstrate that the techniques utilized in PT-CCNN are effective, and our proposed network achieve higher recognition accuracy than those previous common methods based on deep learning. For instance, our proposed PT-CCNN beats traditional CNN on rotation, scaling and practical deformation datasets by 24.5-49.3%, 9.0-40.8% and 22.3-26.7%. And it also outperforms the polar CNN without using the above techniques on rotation, scaling and practical deformation datasets by 9.2-53.7%, 5.2-54.6% and 9.0-49.9%. Additionally, the presented visualization results show the abilities and advantages of our method in terms of handling image deformation and extracting effective features.",2021,Y. Kim; H. Kim,23432,23453,22,,10.1109/ACCESS.2021.3056671,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345674,IEEE Journals,IEEE
"Statistical Machine Translation for Speech: A Perspective on Structures, Learning, and Decoding",Discriminative training;finite-state transducer (FST);graph;hypergraph;speech translation (ST);statistical machine translation (SMT);synchronous context-free grammar (SCFG);Viterbi search,"In this paper, we survey and analyze state-of-the-art statistical machine translation (SMT) techniques for speech translation (ST). We review key learning problems, and investigate essential model structures in SMT, taking a unified perspective to reveal both connections and contrasts between automatic speech recognition (ASR) and SMT. We show that phrase-based SMT can be viewed as a sequence of finite-state transducer (FST) operations, similar in spirit to ASR. We further inspect the synchronous context-free grammar (SCFG)-based formalism that includes hierarchical phrase-based and many linguistically syntax-based models. Decoding for ASR, FST-based, and SCFG-based translation is also presented from a unified perspective as different realizations of the generic Viterbi algorithm on graphs or hypergraphs. These consolidated perspectives are helpful to catalyze tighter integrations for improved ST, and we discuss joint decoding and modeling toward coupling ASR and SMT.",2013,D. H. Sanders,1180,1202,23,4,10.1109/JPROC.2013.2249491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6497459,IEEE Journals,IEEE
A Multi-Anatomical Retinal Structure Segmentation System for Automatic Eye Screening Using Morphological Adaptive Fuzzy Thresholding,Retina screening;retinopathy;retinal vessels segmentation;optic disc segmentation;retinal exudate segmentation;fuzzy systems;fuzzy C-means;adaptive local thresholding;morphological operations,"Eye exam can be as efficacious as physical one in determining health concerns. Retina screening can be the very first clue for detecting a variety of hidden health issues including pre-diabetes and diabetes. Through the process of clinical diagnosis and prognosis; ophthalmologists rely heavily on the binary segmented version of retina fundus image; where the accuracy of segmented vessels, optic disc, and abnormal lesions extremely affects the diagnosis accuracy which in turn affect the subsequent clinical treatment steps. This paper proposes an automated retinal fundus image segmentation system composed of three segmentation subsystems follow same core segmentation algorithm. Despite of broad difference in features and characteristics; retinal vessels, optic disc, and exudate lesions are extracted by each subsystem without the need for texture analysis or synthesis. For sake of compact diagnosis and complete clinical insight, our proposed system can detect these anatomical structures in one session with high accuracy even in pathological retina images. The proposed system uses a robust hybrid segmentation algorithm combines adaptive fuzzy thresholding and mathematical morphology. The proposed system is validated using four benchmark datasets: DRIVE and STARE (vessels), DRISHTI-GS (optic disc), and DIARETDB1 (exudates lesions). Competitive segmentation performance is achieved, outperforming a variety of up-to-date systems and demonstrating the capacity to deal with other heterogeneous anatomical structures.",2018,S. A. Khalek; S. Khurshid,1,23,23,,10.1109/JTEHM.2018.2835315,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360472,IEEE Journals,IEEE
Software Vulnerability Detection Using Deep Neural Networks: A Survey,Cybersecurity;deep neural network (DNN);machine learning (ML);representation learning;software vulnerability,"The constantly increasing number of disclosed security vulnerabilities have become an important concern in the software industry and in the field of cybersecurity, suggesting that the current approaches for vulnerability detection demand further improvement. The booming of the open-source software community has made vast amounts of software code available, which allows machine learning and data mining techniques to exploit abundant patterns within software code. Particularly, the recent breakthrough application of deep learning to speech recognition and machine translation has demonstrated the great potential of neural models' capability of understanding natural languages. This has motivated researchers in the software engineering and cybersecurity communities to apply deep learning for learning and understanding vulnerable code patterns and semantics indicative of the characteristics of vulnerable code. In this survey, we review the current literature adopting deep-learning-/neural-network-based approaches for detecting software vulnerabilities, aiming at investigating how the state-of-the-art research leverages neural techniques for learning and understanding code semantics to facilitate vulnerability discovery. We also identify the challenges in this new field and share our views of potential research directions.",2020,S. Bakhshaei; S. Khadivi; N. Riahi,1825,1848,24,6,10.1109/JPROC.2020.2993293,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108283,IEEE Journals,IEEE
"On the Future of Information: Reunification, Computability, Adaptation, Cybersecurity, Semantics",Informatics;Machine Intelligence;National Security;Automation;Emergent Phenomena;Adaptive Systems;Informatics;mamchine intelligence;national security;automation;emergent phenomena;adaptive systems,"The vulnerability of software and the Internet and the accumulation of unprocessed information in big data are serious problems in informatics. Both are human-related. The former was traced to flaws caused by human interventions in development. In the latter case, humans also intervene to connect the dots, find meaningful patterns, and make sense of the information. The proposed solutions are based on more human interventions, which tend to aggravate the problems rather than solving them. I propose the complete elimination of human interventions in both cases. This goal is conceptually easy to achieve. The approach, however, is radical and theoretical. It considers the causal set, a mathematical object, as the universal language underlying all information in nature and, hence, also all computation. This assumption is recognized as the fundamental principle of causality, that effects follow their causes. The new theory is based solely on the causal set, its metric, and its vast array of algebraic properties. The consequences are unexpected, fascinating, and totally new. Since translations between causal sets and programming languages are easy, I also propose to confine the use of programming languages to the human interface, and create an inner layer of mathematical code expressed as a causal set. Machines talk only to mathematically verified, bug-free, secure code. Included in this paper are experimental and computational verifications of the theory, proposed applications to Internet vulnerability, science and technology, machine learning, computer intelligence, and details for building a first prototype.",2016,Y. Yuan; B. Babych; S. Sharoff,1117,1140,24,,10.1109/ACCESS.2016.2524403,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7397819,IEEE Journals,IEEE
Diversity in Machine Learning,Diversity;training data;model learning;inference;supervised learning;active learning;unsupervised learning;posterior regularization,"Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a totally good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though diversity plays an important role in the machine learning process, there is no systematical analysis of the diversification in the machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work. Our analysis provides a deeper understanding of the diversity technology in machine learning tasks and hence can help design and learn more effective models for real-world applications.",2019,R. Fatmi; S. Rashad; R. Integlia,64323,64350,28,5,10.1109/ACCESS.2019.2917620,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717641,IEEE Journals,IEEE
