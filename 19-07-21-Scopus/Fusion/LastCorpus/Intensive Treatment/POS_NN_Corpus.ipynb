{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6ab09b-4f70-4610-9abe-bc27b46106fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine translation errors: English and Iraqi Arabic Arabic; English; Error analysis; Evaluation; Statistical machine translation Errors in machine translations of English-Iraqi Arabic dialogues were analyzed using the methods developed for the Human Translation Error Rate measure (HTER). Human annotations were used to refine the Translation Error Rate (TER) annotations. The analyses were performed on approximately 100 translations into each language from four translation systems. Results include high frequencies of pronoun errors and errors involving the copula in translations to English. High frequencies of errors in subject/person inflection and closed-word classes characterized translations to Iraqi Arabic. There were similar frequencies of word order errors in both translation directions and low frequencies of polarity errors. The problems associated with many errors can be predicted from structural differences between the two languages. Also problematic is the need to insert lexemes not present in the source or vice versa. Some problems associated with deictic elements like pronouns will require knowledge of the discourse context to resolve. '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "\n",
    "#from gensim.models import Phrases\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "# NLTK Stop words\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','a','about', 'above', 'across'])\n",
    "\n",
    "NewCorpus = pd.read_excel('CorpusBeta.xlsx',header=0)\n",
    "\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Title'] +' '+ NewCorpus['Author Keywords'] +' '+ NewCorpus['Abstract'].str.split('Â©').str[0] #+' '+ NewCorpus['Year'].astype(str)\n",
    "NewCorpus['Titles & Keywords'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e094ab3-31a4-4882-ba77-c79bc08d88d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1166"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NewCorpus['Titles & Keywords'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6278916d-06dd-49c8-99d6-a1d63906d522",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'corenlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14620/2681994258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#from pycorenlp import *\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcorenlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStanfordCoreNLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Simple usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from stanfordcorenlp import StanfordCoreNLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'corenlp'"
     ]
    }
   ],
   "source": [
    "#from pycorenlp import *\n",
    "from corenlp import StanfordCoreNLP\n",
    "# Simple usage\n",
    "#from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp=StanfordCoreNLP(\"http://localhost:8811/\")\n",
    "\n",
    "def get_Nouns_sent(text):\n",
    "    try:\n",
    "        parser = nlp.annotate(text, properties={\"annotators\":\"parse\",\"outputFormat\": \"json\"})\n",
    "        t = nltk.tree.ParentedTree.fromstring(parser[\"sentences\"][0][\"parse\"])\n",
    "    except:\n",
    "        exception = []\n",
    "        print('something wrong at this sent : '+text+' in this article : ' )\n",
    "        #exception.append(sent)\n",
    "    verb_phrases = []\n",
    "    num_children = len(t)\n",
    "    num_VP = sum(1 if (t[i].label() == \"NN\" or t[i].label() == \"NNS\" or t[i].label() == \"NNP\") else 0 for i in range(0, num_children))\n",
    "\n",
    "    if (t.label() != \"NN\" and t.label() != \"NNS\" and t.label() != \"NNP\"):\n",
    "        for i in range(0, num_children):\n",
    "            if t[i].height() > 2:\n",
    "                verb_phrases.extend(get_verb_sent(t[i]))\n",
    "    elif (t.label() == \"NN\" or t.label() == \"NNS\" or t.label() == \"NNP\") and num_VP > 1:\n",
    "        for i in range(0, num_children):\n",
    "            if (t[i].label() == \"NN\" or t[i].label() == \"NNS\" or t[i].label() == \"NNP\"):\n",
    "                if t[i].height() > 2:\n",
    "                    verb_phrases.extend(get_verb_sent(t[i]))\n",
    "    else:\n",
    "        verb_phrases.append(' '.join(t.leaves()))\n",
    "\n",
    "    return verb_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dffd1e-57ed-415c-be66-2a72b1f72439",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewCoprus['Titles & Keywords'].apply(get_Nouns_sent)\n",
    "NewCoprus['Titles & Keywords'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad5eb6-d6e6-4bd3-b183-30cf5fb57000",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(NewCoprus['Titles & Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586826c-c0b9-4c84-92c9-445faa848d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
