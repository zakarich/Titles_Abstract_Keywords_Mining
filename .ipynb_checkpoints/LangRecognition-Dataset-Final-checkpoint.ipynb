{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "Corpus = pd.read_csv('19-07-21-Scopus/Fusion/Dataset-IEEE-Scopus-Snowball-vf.csv',header=0, engine='python', warn_bad_lines=True, error_bad_lines=False)\n",
    "\n",
    "#Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus.dropna(subset = [\"Author Keywords\"], inplace=True)\n",
    "Corpus.dropna(subset = [\"Title\"], inplace=True)\n",
    "Corpus.dropna(subset = [\"Abstract\"], inplace=True)\n",
    "\n",
    "Corpus.reset_index(drop=True, inplace=True)\n",
    "#Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Patterns that the program can recognize :50\n",
      "the program is running .....  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Cited by</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>Page count</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creating a multimodal translation tool and tes...</td>\n",
       "      <td>Commercial software tools for translation have...</td>\n",
       "      <td>Agile development; Computer-aided translation;...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.3390/informatics6010013</td>\n",
       "      <td>Teixeira C.S.C., Moorkens J., Turner D., Vreek...</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[voice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A structure-based model for Chinese organizati...</td>\n",
       "      <td>Named entity (NE) translation is a fundamental...</td>\n",
       "      <td>Alignment; Chunk; Hierarchical derivation; Mac...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/1330291.1330292</td>\n",
       "      <td>Chen Y., Zong C.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ancient-modern Chinese translation with a new ...</td>\n",
       "      <td>Ancient Chinese brings the wisdom and spirit c...</td>\n",
       "      <td>Ancient-Modern Chinese parallel corpus; Biling...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/3325887</td>\n",
       "      <td>Dayiheng L.I.U., Yang K., Qu Q., Jiancheng L.V.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matching graph, a method for extracting parall...</td>\n",
       "      <td>Comparable corpora are valuable alternatives f...</td>\n",
       "      <td>And Arabic languages; Comparable corpora; Engl...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/3329713</td>\n",
       "      <td>Bakhshaei S., Safabakhsh R., Khadivi S.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modeling monolingual character alignment for a...</td>\n",
       "      <td>Automatic evaluation of machine translations i...</td>\n",
       "      <td>And Phrases: Automatic evaluation; Chinese cha...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/2815619</td>\n",
       "      <td>Li M., Wang M., Li H., Xu F.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Creating a multimodal translation tool and tes...   \n",
       "1  A structure-based model for Chinese organizati...   \n",
       "2  Ancient-modern Chinese translation with a new ...   \n",
       "3  Matching graph, a method for extracting parall...   \n",
       "4  Modeling monolingual character alignment for a...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Commercial software tools for translation have...   \n",
       "1  Named entity (NE) translation is a fundamental...   \n",
       "2  Ancient Chinese brings the wisdom and spirit c...   \n",
       "3  Comparable corpora are valuable alternatives f...   \n",
       "4  Automatic evaluation of machine translations i...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Agile development; Computer-aided translation;...   \n",
       "1  Alignment; Chunk; Hierarchical derivation; Mac...   \n",
       "2  Ancient-Modern Chinese parallel corpus; Biling...   \n",
       "3  And Arabic languages; Comparable corpora; Engl...   \n",
       "4  And Phrases: Automatic evaluation; Chinese cha...   \n",
       "\n",
       "                                                Link  Year  Cited by  \\\n",
       "0  https://www.scopus.com/inward/record.uri?eid=2...  2019       2.0   \n",
       "1  https://www.scopus.com/inward/record.uri?eid=2...  2008       9.0   \n",
       "2  https://www.scopus.com/inward/record.uri?eid=2...  2019       NaN   \n",
       "3  https://www.scopus.com/inward/record.uri?eid=2...  2019       NaN   \n",
       "4  https://www.scopus.com/inward/record.uri?eid=2...  2016       4.0   \n",
       "\n",
       "  Page start Page end Page count                         DOI  \\\n",
       "0        NaN      NaN          1  10.3390/informatics6010013   \n",
       "1        NaN      NaN          1     10.1145/1330291.1330292   \n",
       "2        NaN      NaN          1             10.1145/3325887   \n",
       "3        NaN      NaN          1             10.1145/3329713   \n",
       "4        NaN      NaN          1             10.1145/2815619   \n",
       "\n",
       "                                             Authors Document Type  Source  \\\n",
       "0  Teixeira C.S.C., Moorkens J., Turner D., Vreek...       Article  Scopus   \n",
       "1                                   Chen Y., Zong C.       Article  Scopus   \n",
       "2    Dayiheng L.I.U., Yang K., Qu Q., Jiancheng L.V.       Article  Scopus   \n",
       "3            Bakhshaei S., Safabakhsh R., Khadivi S.       Article  Scopus   \n",
       "4                       Li M., Wang M., Li H., Xu F.       Article  Scopus   \n",
       "\n",
       "  Patterns  \n",
       "0  [voice]  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PatternsInn = []\n",
    "#Remove All words that could mess our classification\n",
    "Patterns = ['post translational','translation initiation','translational science','braille','binary translation',\n",
    "            'kinematic','unstructured data','voice','3D','2D','twitter','facebook','comment','tweet','image','transliteration',\n",
    "            'speech','uml','social media','spoken','signal','video','optical character','ORC','sign language','sign languages',\n",
    "            'programming languages','programming language','implementation language','implementation languages','dialect',\n",
    "            'compiler','compilers','compiling','decompiling','decompiled','decompilation','automatic code translation',\n",
    "            'machine code translation','music','musical','source code','caption','tv','multimedia','orc','2d','3d','social network',\n",
    "            'social networking']\n",
    "\n",
    "#Lang = [word.lower() for word in Languages]\n",
    "# Recognition for IEEE\n",
    "for i in range(len(Corpus[\"Title\"])): \n",
    "    #res = re.sub(r'[^\\w\\s]', ' ', df.astype(str)[\"Document Title\"][i]+df.astype(str)[\"Abstract\"][i]+df.astype(str)[\"Author Keywords\"][i])\n",
    "    #res = re.sub(r'[^\\w\\s]', ' ', str(csv_fileIEEE[\"Titles & Keywords\"][i]))\n",
    "    #texto = res.lower().split()\n",
    "    PatternsIn = []\n",
    "    Title_AuthKey = str(Corpus[\"Title\"][i].lower()+' '+Corpus[\"Author Keywords\"][i].lower())\n",
    "    for j in range(len(Patterns)):\n",
    "        a = re.sub(r'[^\\w\\s]', ' ', Title_AuthKey)\n",
    "        b = r'\\b' + r'\\b.*\\b'.join(re.escape(word) for word in Patterns[j].split(' ')) + r'\\b'\n",
    "        c = bool(re.search(b,a))\n",
    "        if c == True:\n",
    "            PatternsIn.append(Patterns[j])\n",
    "    PatternsInn.append(PatternsIn)\n",
    "    \n",
    "Corpus[\"Patterns\"] = PatternsInn\n",
    "print(\"The number of Patterns that the program can recognize :\"+str(len(Patterns)))\n",
    "print('the program is running .....  ')\n",
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus.to_excel(\"19-07-21-Scopus\\Fusion\\PatternsTestAll1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(Corpus['Patterns'][0])\n",
    "#Corpus = Corpus.loc[(Corpus['Patterns'] == [])]\n",
    "Corpus = Corpus.loc[Corpus.astype(str)['Patterns'] == '[]']\n",
    "Corpus.reset_index(drop=True, inplace=True)\n",
    "#Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of languages that our Program can recognize is :334\n",
      "the lenght of the corpus after removing all patterns and indentifying all languages : 2064\n"
     ]
    }
   ],
   "source": [
    "Languages_Translation = []\n",
    "Languages = [\"mandarin\",\"chinese\",\"spanish\",\"Jalaa\",\"Maori\",\"Ryukyuan\",\"Maroon\",\"Mayan\",\"Sranan\",\"Nahuatl\",\"mam\",\n",
    "             \"Patois\",\"Xinca\",\"Quiche\",\"Kekchi\",\"Cakchiquel\",\"Nahua\",\"Carib\",\"Amerindian\",\"Garifuna\",\"Mesrop\",\n",
    "             \"Khenkha\",\"Tshanglakha\",\"Lhotsamkha\",\"Nepalese\",\"Waray\",\"Pampango\",\"Pangasinense\",\"Bicol\",\"Aramaic\",\n",
    "             \"Circassian\",\"Tajik\",\"Baluchi\",\"Khalkha\",\"mongol\",\"Dhivehi\",\"Maldivian\",\"Altaic\",\"Kyrgyz\",\"Bahasa\",\n",
    "             \"Hangungmal\",\"Qazaq\",\"Turcoman\",\"Assyrian\",\"Yiddish\",\"Judeo\",\"Ladino\",\"Tuvaluan\",\"Kejia\",\"Tibetan\",\n",
    "             \"Tibet\",\"Mongolian\",\"Bhutanese\",\"Darussalam\",\"Dzongkha\",\"Farsi\",\"Turkic\",\"Azeri\",\"Bislama\",\"Bichelama\",\n",
    "             \"Ulithian\",\"Pitcairnese\",\"Pisin\",\"Motu\",\"Sonsoralese\",\"Angaur\",\"Carolinian\",\"Niuean\",\"Tongan\",\n",
    "             \"Polynesian\",\"Melanesian\",\"Kapingamarangi\",\"Tahitian\",\"Nukuoro\",\"Woleaian\",\"Trukese\",\"Pohnpeian\",\n",
    "             \"Kosrean\",\"Yapese\",\"Kiribati\",\"Chamorro\",\"Ibibio\",\"Fijian\",\"Welsh\",\"gaelic\",\"Samoan \",\"Nordic\",\n",
    "             \"Monegasque\",\"Gagauz\",\"Lahnda\",\"Llanito \",\"Sami\",\"Castilian\",\"Zande\",\"Chadic\",\"Sena\",\"Volta\",\"twi\",\n",
    "             \"Wolof\",\"Umbundu\",\"Tsoa\",\"Tshivenda\",\"Tshiluba\",\"Tshwa\",\"kua\",\"Tonga\",\"Swazi\",\"Seychellois\",\n",
    "             \"Mauritian\",\"Noon\",\"Nambya\",\"Ndau\",\"Kimbundu\",\"Sotho\",\"Luganda\",\"Lingala\",\"Kituba\",\"Kongo\",\"fon\",\n",
    "             \"Fulani\",\"Kikongo\",\"Verdean\",\"Abron\",\"Afar\",\"Dangme\",\"Berber\",\"Khoekhoe\",\"Seychelles\",\"Comorian\",\n",
    "             \"Sesotho\",\"Ndebele\",\"Sepedi\",\"Setswana\",\"Tswana\",\"Sindebele\",\"Tigrinya\",\"Swati\",\"Swahili\",\"Tsonga\",\n",
    "             \"Venda\",\"Soranî\",\"Mimi\",\"Ga\",\"Yeni\",\"Shabo\",\"Weyto\",\"Wutana\",\"Mpra\",\"Oropom\",\"Ongota\",\"Oblo\",\"Bangi\",\n",
    "             \"Meyobe\",\"Mawa\",\"Luo\",\"Kujarge\",\"Lufu\",\"Laal\",\"Lezgi\",\"Hadza\",\"Irimba\",\"Gumuz\",\"Gomba\",\"Bayot\",\"Ega\",\n",
    "             \"Dompo\",\"Ingush\",\"Kabardian\",\"Tatar\",\"Esperanto\",\"Chechen\",\"Chuvash\",\"Dargwa\",\"Bashkir\",\"Riksmål\",\n",
    "             \"Latin\",\"Riksmal\",\"Galician\",\"Catalan\",\"Tamazight\",\"Sorani\",\"Slovene\",\"Afrikaans\",\"Armenian\",\"Slovak\",\n",
    "             \"Danish\",\"Norwegian\",\"Icelandic\",\"Finnish\",\"Dhundhari\",\"Fuzhou\",\"Balochi\",\"Xhosa\",\"Belarusian\",\"Mossi\",\n",
    "             \"Ilocano\",\"Shona\",\"Hiligaynon\",\"Ilonggo\",\"Hmong\",\"Swedish\",\"Quechua\",\"Kirundi\",\"Haitian\",\"Creole\",\n",
    "             \"Zhuang\",\"Akan\",\"Chewa\",\"Haryanvi\",\"Marwari\",\"Madurese\",\"Turkmen\",\"Serbo\",\"Sinhala\",\"Malagasy\",\n",
    "             \"Croatian\",\"Fula\",\"Gan\",\"Visayan\",\"Awadhi\",\"Oromo\",\"Sundanese\",\"Teochew\",\"Min\",\"Cantonese\",\"Hokkien\",\n",
    "             \"Shanghainese\",\"english\",\"Bodo\",\"Filipino\",\"Dogri\",\"Santhali\",\"Oriya\",\"Sanskrit\",\"hindi\",\"Manipuri\",\n",
    "             \"Konkani\",\"Kashmiri\",\"hindustani\",\"bengali\",\"portuguese\",\"russian\",\"japanese\",\"western\",\"punjabi\",\n",
    "             \"marathi\",\"Telugu\",\"Wu\",\"Turkish\",\"Korean\",\"French\",\"German\",\"Vietnamese\",\"Tamil\",\"Yue\",\"Urdu\",\n",
    "             \"Javanese\",\"Italian\",\"Egyptian\",\"Arabic\",\"Gujarati\",\"Iranian\",\"Persian\",\"Bhojpuri\",\"Minnan\",\"nan\",\n",
    "             \"banlam\",\"Hakka\",\"Jin\",\"Hausa\",\"Kannada\",\"Indonesian\",\"Malay\",\"Polish\",\"Yoruba\",\"Xiang\",\"Malayalam\",\n",
    "             \"Odia\",\"Maithili\",\"Burmese\",\"Sunda\",\"Sudanese\",\"Algerian\",\"Moroccan\",\"Ukrainian\",\"Igbo\",\"Uzbek\",\n",
    "             \"Sindhi\",\"Romanian\",\"Tagalog\",\"Dutch\",\"Amharic\",\"Putonghua\",\"Pashto\",\"Magahi\",\"Thai\",\"Saraiki\",\n",
    "             \"Khmer\",\"Chhattisgarhi\",\"Somali\",\"Malaysian\",\"Malay\",\"Cebuano\",\"Nepali\",\"Mesopotamian\",\"Avar\",\n",
    "             \"Assamese\",\"Sinhalese\",\"Kurdish\",\"Hejazi\",\"Nigerian\",\"Fulfulde\",\"Bavarian\",\"Azerbaijani\",\"Greek\",\n",
    "             \"Chittagonian\",\"Kazakh\",\"Deccan\",\"Hungarian\",\"Kinyarwanda\",\"Zulu\",\"Levantine\",\"Tunisian\",\"Sanaani\",\n",
    "             \"MinBei\",\"Bei\",\"Rundi\",\"Czech\",\"Taʽizzi-Adeni\",\"Uyghur\",\"MinDong\",\"Dong\",\"Sylheti\",\"Hinglish\"]\n",
    "Lang = [word.lower() for word in Languages]\n",
    "# Recognition for IEEE\n",
    "for i in range(len(Corpus[\"Title\"])): \n",
    "    #res = re.sub(r'[^\\w\\s]', ' ', df.astype(str)[\"Document Title\"][i]+df.astype(str)[\"Abstract\"][i]+df.astype(str)[\"Author Keywords\"][i])\n",
    "    res = re.sub(r'[^\\w\\s]', ' ', str(Corpus[\"Title\"][i]+' '+ Corpus[\"Abstract\"][i]+' '+Corpus[\"Author Keywords\"][i]))\n",
    "    Title = res.lower().split() \n",
    "    Languages_Translation.append(list(set(Title) & set(Lang)))\n",
    "Corpus[\"From-->Too\"] = Languages_Translation \n",
    "print(\"The number of languages that our Program can recognize is :\"+str(len(Lang)))\n",
    "Corpus.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\AllCorpus.xlsx\", index=False)\n",
    "print('the lenght of the corpus after removing all patterns and indentifying all languages : '+str(len(Corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of artciles that describ machine translation of human language to another language :1287\n",
      "the number of articles that describ machine translation generally:777\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Corpus Lang identification\n",
    "Corpus_NoLang = Corpus[Corpus.astype(str)[\"From-->Too\"] == '[]']\n",
    "Corpus_Lang = Corpus[Corpus.astype(str)[\"From-->Too\"] != '[]']\n",
    "Corpus_NoLang.reset_index(drop=True, inplace=True)\n",
    "Corpus_Lang.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Corpus_Lang.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\CorpusLang.xlsx\", index=False)\n",
    "Corpus_NoLang.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\CorpusNoLang.xlsx\", index=False)\n",
    "#Corpus_Lang\n",
    "\n",
    "print('the number of artciles that describ machine translation of human language to another language :'+str(len(Corpus_Lang)))\n",
    "print('the number of articles that describ machine translation generally:'+str(len(Corpus_NoLang)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "the totale number of articles that talks about Machine Translation (From --> to) : 1287\n",
      "################################################################################\n",
      "\n",
      " \n",
      "\n",
      "################################################################################\n",
      "the number of articles that talks about Arabic Machine Translation : 110\n",
      "\n",
      "\n",
      "the number of articles that talks about English Machine Translation : 947\n",
      "\n",
      "\n",
      "the number of articles that talks about French Machine Translation : 103\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "from re import search\n",
    "#df[df.astype(str)[\"From --> Too\"] != '[]']\n",
    "#df_ar = dfof[dfof[\"From-->Too\"].str.contains(r\"arabic\")]\n",
    "#f_ar = dfof[pd.DataFrame(dfof[\"From-->Too\"].tolist()).isin(['arabic']).any(1).values]\n",
    "#f_en = dfof[pd.DataFrame(dfof[\"From-->Too\"].tolist()).isin(['english']).any(1).values]\n",
    "#f_fr = dfof[pd.DataFrame(dfof[\"From-->Too\"].tolist()).isin(['french']).any(1).values]\n",
    "\n",
    "#IEEE\n",
    "Corpus_ar = Corpus_Lang[pd.DataFrame(Corpus_Lang[\"From-->Too\"].tolist()).isin(['arabic']).any(1).values]\n",
    "Corpus_ar.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\Corpus_ar.xlsx\", index=False)\n",
    "\n",
    "Corpus_en = Corpus_Lang[pd.DataFrame(Corpus_Lang[\"From-->Too\"].tolist()).isin(['english']).any(1).values]\n",
    "Corpus_en.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\Corpus_en.xlsx\", index=False)\n",
    "\n",
    "Corpus_fr = Corpus_Lang[pd.DataFrame(Corpus_Lang[\"From-->Too\"].tolist()).isin(['french']).any(1).values]\n",
    "Corpus_fr.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\Corpusfr.xlsx\", index=False)\n",
    "\n",
    "print(\"################################################################################\")\n",
    "print(\"the totale number of articles that talks about Machine Translation (From --> to) : \"+str(len(Corpus_Lang)))\n",
    "print(\"################################################################################\")\n",
    "print('\\n \\n')\n",
    "print(\"################################################################################\")\n",
    "print(\"the number of articles that talks about Arabic Machine Translation : \"+str(len(Corpus_ar)))\n",
    "print('\\n')\n",
    "print(\"the number of articles that talks about English Machine Translation : \"+str(len(Corpus_en)))\n",
    "print('\\n')\n",
    "print(\"the number of articles that talks about French Machine Translation : \"+str(len(Corpus_fr)))\n",
    "print(\"################################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd section: Methods recognition & LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Cited by</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>Page count</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Patterns</th>\n",
       "      <th>From--&gt;Too</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A structure-based model for Chinese organizati...</td>\n",
       "      <td>Named entity (NE) translation is a fundamental...</td>\n",
       "      <td>Alignment; Chunk; Hierarchical derivation; Mac...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/1330291.1330292</td>\n",
       "      <td>Chen Y., Zong C.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chinese', 'english']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ancient-modern Chinese translation with a new ...</td>\n",
       "      <td>Ancient Chinese brings the wisdom and spirit c...</td>\n",
       "      <td>Ancient-Modern Chinese parallel corpus; Biling...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/3325887</td>\n",
       "      <td>Dayiheng L.I.U., Yang K., Qu Q., Jiancheng L.V.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chinese']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matching graph, a method for extracting parall...</td>\n",
       "      <td>Comparable corpora are valuable alternatives f...</td>\n",
       "      <td>And Arabic languages; Comparable corpora; Engl...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/3329713</td>\n",
       "      <td>Bakhshaei S., Safabakhsh R., Khadivi S.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['persian', 'english', 'arabic']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modeling monolingual character alignment for a...</td>\n",
       "      <td>Automatic evaluation of machine translations i...</td>\n",
       "      <td>And Phrases: Automatic evaluation; Chinese cha...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/2815619</td>\n",
       "      <td>Li M., Wang M., Li H., Xu F.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chinese', 'english']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Using sublexical translations to handle the OO...</td>\n",
       "      <td>We introduce a method for learning to translat...</td>\n",
       "      <td>And sublexical translation; Language model; Ma...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/2002980.2002986</td>\n",
       "      <td>Huang C.-C., Yen H.-C., Yang P.-C., Huang S.-T...</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A structure-based model for Chinese organizati...   \n",
       "1  Ancient-modern Chinese translation with a new ...   \n",
       "2  Matching graph, a method for extracting parall...   \n",
       "3  Modeling monolingual character alignment for a...   \n",
       "4  Using sublexical translations to handle the OO...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Named entity (NE) translation is a fundamental...   \n",
       "1  Ancient Chinese brings the wisdom and spirit c...   \n",
       "2  Comparable corpora are valuable alternatives f...   \n",
       "3  Automatic evaluation of machine translations i...   \n",
       "4  We introduce a method for learning to translat...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Alignment; Chunk; Hierarchical derivation; Mac...   \n",
       "1  Ancient-Modern Chinese parallel corpus; Biling...   \n",
       "2  And Arabic languages; Comparable corpora; Engl...   \n",
       "3  And Phrases: Automatic evaluation; Chinese cha...   \n",
       "4  And sublexical translation; Language model; Ma...   \n",
       "\n",
       "                                                Link  Year  Cited by  \\\n",
       "0  https://www.scopus.com/inward/record.uri?eid=2...  2008       9.0   \n",
       "1  https://www.scopus.com/inward/record.uri?eid=2...  2019       NaN   \n",
       "2  https://www.scopus.com/inward/record.uri?eid=2...  2019       NaN   \n",
       "3  https://www.scopus.com/inward/record.uri?eid=2...  2016       4.0   \n",
       "4  https://www.scopus.com/inward/record.uri?eid=2...  2011      10.0   \n",
       "\n",
       "  Page start Page end Page count                      DOI  \\\n",
       "0        NaN      NaN          1  10.1145/1330291.1330292   \n",
       "1        NaN      NaN          1          10.1145/3325887   \n",
       "2        NaN      NaN          1          10.1145/3329713   \n",
       "3        NaN      NaN          1          10.1145/2815619   \n",
       "4        NaN      NaN          1  10.1145/2002980.2002986   \n",
       "\n",
       "                                             Authors Document Type  Source  \\\n",
       "0                                   Chen Y., Zong C.       Article  Scopus   \n",
       "1    Dayiheng L.I.U., Yang K., Qu Q., Jiancheng L.V.       Article  Scopus   \n",
       "2            Bakhshaei S., Safabakhsh R., Khadivi S.       Article  Scopus   \n",
       "3                       Li M., Wang M., Li H., Xu F.       Article  Scopus   \n",
       "4  Huang C.-C., Yen H.-C., Yang P.-C., Huang S.-T...       Article  Scopus   \n",
       "\n",
       "  Patterns                        From-->Too  \n",
       "0       []            ['chinese', 'english']  \n",
       "1       []                       ['chinese']  \n",
       "2       []  ['persian', 'english', 'arabic']  \n",
       "3       []            ['chinese', 'english']  \n",
       "4       []                                []  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "NewCorpus = pd.read_excel('19-07-21-Scopus\\Fusion\\LastCorpus\\AllCorpus.xlsx',header=0)\n",
    "NewCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a structure based model chinese organization named entity ne fundamental task multilingual natural language processing the performance depends heavily precise inclusive ne furthermore organization on complex ne ne in article structure formulation ons investigated hierarchical structure based on model chinese english presented first model performs on chunking word chunk process chunk reordering achieved synchronous context free grammar cfg the cfg rule extracted bilingual on pair training program the main contribution article defining appropriate chunk unit analyzing internal structure chinese ons making chunk based on feasible flexible hierarchical cfg derivation proposing training architecture automatically learn synchronous cfg constructing ons chunk unit aligned bilingual on pair the experiment proposed approach translates chinese ons english accuracy significantly improves performance baseline statistical statistical'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewCorpus['Titles & Keywords'] = NewCorpus['Title'] +' '+ NewCorpus['Abstract'] +' '+ NewCorpus['Author Keywords'] +' '+ NewCorpus['Year'].astype(str)\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "import string\n",
    "\n",
    "#Words not must be included in the analysis\n",
    "removed = ['machine','translation','automatic','mt']\n",
    "#Define the function to remove the punctuation\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = str(text).replace(punctuation, ' ')\n",
    "    return text\n",
    "\n",
    "#Lemmatizaion of the keywords\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(str(text))]\n",
    "\n",
    "#merge ords of a list into string \n",
    "def ListToString(lista):\n",
    "    text = ''\n",
    "    for word in lista:\n",
    "        text += ' '+word\n",
    "    return text\n",
    "\n",
    "#Replace Abbreviation\n",
    "def replace_Abbreviation(text):\n",
    "    text = str(text).replace('smt', 'statistical')\n",
    "    text = str(text).replace('nmt', 'neural')\n",
    "    text = str(text).replace('rbmt','rule based')\n",
    "    text = str(text).replace('hmt','Hybrid based')\n",
    "    text = str(text).replace('dmt','direct based')\n",
    "    text = str(text).replace('tbmt','transfer based')\n",
    "    text = str(text).replace('cbmt','corpus based')\n",
    "    text = str(text).replace('ebmt','example based')\n",
    "    return text\n",
    "\n",
    "#Apply Remove Punctuations\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(remove_punctuations)\n",
    "#Remove Stop words:\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))\n",
    "#Lowercase Author Keywords\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.lower()\n",
    "#Remove All words that could mess our classification\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in removed))\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(replace_Abbreviation)\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.split('©').str[0]\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.replace('\\d+', '')\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.replace('  ', ' ')\n",
    "#Apply the function lemmatization\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(lemmatize_text)\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(ListToString)\n",
    "NewCorpus['Titles & Keywords'][0]\n",
    "#print(lemmatize_text('mt evaluations metrics evaluation slavic languages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of methods that the program can recognize :10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Cited by</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>Page count</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Patterns</th>\n",
       "      <th>From--&gt;Too</th>\n",
       "      <th>Titles &amp; Keywords</th>\n",
       "      <th>Method Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A structure-based model for Chinese organizati...</td>\n",
       "      <td>Named entity (NE) translation is a fundamental...</td>\n",
       "      <td>Alignment; Chunk; Hierarchical derivation; Mac...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/1330291.1330292</td>\n",
       "      <td>Chen Y., Zong C.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chinese', 'english']</td>\n",
       "      <td>a structure based model chinese organization ...</td>\n",
       "      <td>[statistical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ancient-modern Chinese translation with a new ...</td>\n",
       "      <td>Ancient Chinese brings the wisdom and spirit c...</td>\n",
       "      <td>Ancient-Modern Chinese parallel corpus; Biling...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/3325887</td>\n",
       "      <td>Dayiheng L.I.U., Yang K., Qu Q., Jiancheng L.V.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chinese']</td>\n",
       "      <td>ancient modern chinese new large training dat...</td>\n",
       "      <td>[neural, statistical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matching graph, a method for extracting parall...</td>\n",
       "      <td>Comparable corpora are valuable alternatives f...</td>\n",
       "      <td>And Arabic languages; Comparable corpora; Engl...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/3329713</td>\n",
       "      <td>Bakhshaei S., Safabakhsh R., Khadivi S.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['persian', 'english', 'arabic']</td>\n",
       "      <td>matching graph method extracting parallel inf...</td>\n",
       "      <td>[statistical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modeling monolingual character alignment for a...</td>\n",
       "      <td>Automatic evaluation of machine translations i...</td>\n",
       "      <td>And Phrases: Automatic evaluation; Chinese cha...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/2815619</td>\n",
       "      <td>Li M., Wang M., Li H., Xu F.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chinese', 'english']</td>\n",
       "      <td>modeling monolingual character alignment eval...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Using sublexical translations to handle the OO...</td>\n",
       "      <td>We introduce a method for learning to translat...</td>\n",
       "      <td>And sublexical translation; Language model; Ma...</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1145/2002980.2002986</td>\n",
       "      <td>Huang C.-C., Yen H.-C., Yang P.-C., Huang S.-T...</td>\n",
       "      <td>Article</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>using sublexical translation handle oov probl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A structure-based model for Chinese organizati...   \n",
       "1  Ancient-modern Chinese translation with a new ...   \n",
       "2  Matching graph, a method for extracting parall...   \n",
       "3  Modeling monolingual character alignment for a...   \n",
       "4  Using sublexical translations to handle the OO...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Named entity (NE) translation is a fundamental...   \n",
       "1  Ancient Chinese brings the wisdom and spirit c...   \n",
       "2  Comparable corpora are valuable alternatives f...   \n",
       "3  Automatic evaluation of machine translations i...   \n",
       "4  We introduce a method for learning to translat...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Alignment; Chunk; Hierarchical derivation; Mac...   \n",
       "1  Ancient-Modern Chinese parallel corpus; Biling...   \n",
       "2  And Arabic languages; Comparable corpora; Engl...   \n",
       "3  And Phrases: Automatic evaluation; Chinese cha...   \n",
       "4  And sublexical translation; Language model; Ma...   \n",
       "\n",
       "                                                Link  Year  Cited by  \\\n",
       "0  https://www.scopus.com/inward/record.uri?eid=2...  2008       9.0   \n",
       "1  https://www.scopus.com/inward/record.uri?eid=2...  2019       NaN   \n",
       "2  https://www.scopus.com/inward/record.uri?eid=2...  2019       NaN   \n",
       "3  https://www.scopus.com/inward/record.uri?eid=2...  2016       4.0   \n",
       "4  https://www.scopus.com/inward/record.uri?eid=2...  2011      10.0   \n",
       "\n",
       "  Page start Page end Page count                      DOI  \\\n",
       "0        NaN      NaN          1  10.1145/1330291.1330292   \n",
       "1        NaN      NaN          1          10.1145/3325887   \n",
       "2        NaN      NaN          1          10.1145/3329713   \n",
       "3        NaN      NaN          1          10.1145/2815619   \n",
       "4        NaN      NaN          1  10.1145/2002980.2002986   \n",
       "\n",
       "                                             Authors Document Type  Source  \\\n",
       "0                                   Chen Y., Zong C.       Article  Scopus   \n",
       "1    Dayiheng L.I.U., Yang K., Qu Q., Jiancheng L.V.       Article  Scopus   \n",
       "2            Bakhshaei S., Safabakhsh R., Khadivi S.       Article  Scopus   \n",
       "3                       Li M., Wang M., Li H., Xu F.       Article  Scopus   \n",
       "4  Huang C.-C., Yen H.-C., Yang P.-C., Huang S.-T...       Article  Scopus   \n",
       "\n",
       "  Patterns                        From-->Too  \\\n",
       "0       []            ['chinese', 'english']   \n",
       "1       []                       ['chinese']   \n",
       "2       []  ['persian', 'english', 'arabic']   \n",
       "3       []            ['chinese', 'english']   \n",
       "4       []                                []   \n",
       "\n",
       "                                   Titles & Keywords            Method Used  \n",
       "0   a structure based model chinese organization ...          [statistical]  \n",
       "1   ancient modern chinese new large training dat...  [neural, statistical]  \n",
       "2   matching graph method extracting parallel inf...          [statistical]  \n",
       "3   modeling monolingual character alignment eval...                     []  \n",
       "4   using sublexical translation handle oov probl...                     []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Method_Found = []\n",
    "#Remove All words that could mess our classification\n",
    "Methods = ['neural','statistical','hybrid based','rule based','direct based','transfer based','interlingual','corpus based','example based','']\n",
    "#Lang = [word.lower() for word in Languages]\n",
    "# Recognition for IEEE\n",
    "for i in range(len(NewCorpus[\"Titles & Keywords\"])): \n",
    "    #res = re.sub(r'[^\\w\\s]', ' ', df.astype(str)[\"Document Title\"][i]+df.astype(str)[\"Abstract\"][i]+df.astype(str)[\"Author Keywords\"][i])\n",
    "    res = re.sub(r'[^\\w\\s]', ' ', str(NewCorpus[\"Titles & Keywords\"][i]))\n",
    "    Title = res.lower().split() \n",
    "    Method_Found.append(list(set(Title) & set(Methods)))\n",
    "NewCorpus[\"Method Used\"] = Method_Found \n",
    "print(\"The number of methods that the program can recognize :\"+str(len(Methods)))\n",
    "NewCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy influence retrieval result this report present novel methodology evaluating performance popular line multilingual search engine altavista we study crucial aspect natural language usually disrupt process extend influence retrieval result having prepared test set analyze phenomenon english french language pair relation strategy browsing web document feature specified query using natural language processing technique test performance order improve quality turn impact result information retrieval language query language\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy influence retrieval result this report present novel methodology evaluating performance popular line multilingual search engine altavista we study crucial aspect natural language usually disrupt process extend having prepared test set analyze phenomenon english french pair relation strategy browsing web document feature specified query using processing technique order improve quality turn impact information'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "#remove all duplicated words. we aimed removing it till now just bcz we didn't want to reshape the structure of the text before extracting all methods names  \n",
    "\n",
    "#' '.join(dict.fromkeys(string.split()))\n",
    "print(NewCorpus['Titles & Keywords'][330])\n",
    "print('\\n')\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.split().apply(lambda x: OrderedDict.fromkeys(x).keys()).str.join(' ')\n",
    "NewCorpus['Titles & Keywords'][330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvns = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvns.fit_transform(NewCorpus['Titles & Keywords'])\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvns.get_feature_names())\n",
    "\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "id2wordn = dict((v, k) for k, v in cvns.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"machine\" + 0.013*\"korean\" + 0.011*\"turn\" + 0.010*\"preliminary\" + 0.010*\"manually\" + 0.010*\"applied\" + 0.010*\"content\" + 0.010*\"produced\" + 0.010*\"element\" + 0.009*\"writing\"'),\n",
       " (1,\n",
       "  '0.014*\"method\" + 0.014*\"based\" + 0.013*\"language\" + 0.013*\"result\" + 0.012*\"model\" + 0.011*\"corpus\" + 0.011*\"paper\" + 0.008*\"task\" + 0.008*\"statistical\" + 0.008*\"source\"'),\n",
       " (2,\n",
       "  '0.022*\"decrease\" + 0.022*\"total\" + 0.021*\"change\" + 0.020*\"substitution\" + 0.018*\"likely\" + 0.018*\"distribution\" + 0.017*\"edit\" + 0.017*\"deletion\" + 0.017*\"insertion\" + 0.017*\"suggest\"'),\n",
       " (3,\n",
       "  '0.009*\"information\" + 0.008*\"user\" + 0.008*\"research\" + 0.008*\"language\" + 0.008*\"approach\" + 0.007*\"translate\" + 0.007*\"based\" + 0.006*\"neural\" + 0.006*\"paper\" + 0.006*\"state\"'),\n",
       " (4,\n",
       "  '0.014*\"english\" + 0.014*\"text\" + 0.013*\"paper\" + 0.013*\"language\" + 0.013*\"based\" + 0.011*\"word\" + 0.010*\"result\" + 0.010*\"analysis\" + 0.009*\"data\" + 0.009*\"different\"'),\n",
       " (5,\n",
       "  '0.014*\"prototype\" + 0.013*\"relation\" + 0.013*\"resourced\" + 0.013*\"context\" + 0.012*\"relevance\" + 0.012*\"constructing\" + 0.012*\"linguistic\" + 0.012*\"performed\" + 0.012*\"form\" + 0.012*\"computational\"'),\n",
       " (6,\n",
       "  '0.012*\"based\" + 0.012*\"statistical\" + 0.010*\"translator\" + 0.010*\"language\" + 0.009*\"corpus\" + 0.008*\"english\" + 0.008*\"text\" + 0.008*\"available\" + 0.008*\"analysis\" + 0.007*\"pair\"'),\n",
       " (7,\n",
       "  '0.017*\"proposed\" + 0.014*\"representation\" + 0.014*\"en\" + 0.013*\"based\" + 0.012*\"meaning\" + 0.012*\"translated\" + 0.011*\"target\" + 0.011*\"knowledge\" + 0.011*\"sentence\" + 0.011*\"encodes\"'),\n",
       " (8,\n",
       "  '0.010*\"result\" + 0.009*\"language\" + 0.009*\"model\" + 0.008*\"state\" + 0.008*\"paper\" + 0.008*\"art\" + 0.008*\"quality\" + 0.008*\"task\" + 0.008*\"analysis\" + 0.008*\"statistical\"'),\n",
       " (9,\n",
       "  '0.012*\"time\" + 0.012*\"translator\" + 0.012*\"study\" + 0.012*\"term\" + 0.012*\"post\" + 0.011*\"editing\" + 0.011*\"text\" + 0.010*\"edited\" + 0.010*\"quality\" + 0.009*\"using\"'),\n",
       " (10,\n",
       "  '0.016*\"based\" + 0.013*\"model\" + 0.013*\"statistical\" + 0.012*\"english\" + 0.011*\"phrase\" + 0.009*\"language\" + 0.009*\"bleu\" + 0.008*\"word\" + 0.008*\"result\" + 0.008*\"using\"'),\n",
       " (11,\n",
       "  '0.015*\"paper\" + 0.013*\"used\" + 0.013*\"problem\" + 0.012*\"english\" + 0.011*\"language\" + 0.008*\"different\" + 0.008*\"various\" + 0.008*\"presented\" + 0.007*\"construction\" + 0.006*\"example\"'),\n",
       " (12,\n",
       "  '0.017*\"share\" + 0.016*\"numerous\" + 0.014*\"suitability\" + 0.014*\"comparative\" + 0.013*\"applying\" + 0.013*\"thai\" + 0.013*\"common\" + 0.013*\"goal\" + 0.012*\"set\" + 0.012*\"question\"'),\n",
       " (13,\n",
       "  '0.004*\"possibly\" + 0.002*\"integer\" + 0.002*\"register\" + 0.002*\"iot\" + 0.002*\"moment\" + 0.002*\"compilation\" + 0.002*\"desirable\" + 0.002*\"lattice\" + 0.002*\"bytecode\" + 0.002*\"cold\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try  8 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=14, id2word=id2wordn, passes=100)\n",
    "ldan.print_topics() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ldan.show_topics(14)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of topics is14\n"
     ]
    }
   ],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='black',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=8,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = ldan.show_topics(14,formatted=False)\n",
    "print('the number of topics is : '+str(len(topics)))\n",
    "fig, axes = plt.subplots(7, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "corpus_transformed_s = ldan[corpusn]\n",
    "#corpus_transformed = ldan[0][corpusn[0]]\n",
    "#len(corpus_transformed)\n",
    "corpos = []\n",
    "corpo = []\n",
    "for corp in corpus_transformed_s:\n",
    "    if len(corp) > 1:\n",
    "        corpo.append([max(corp, key=itemgetter(1))])\n",
    "    else:\n",
    "        corpo.append(corp)\n",
    "NewCorpus['Topic'] = corpo\n",
    "#display the results for the IEEE database\n",
    "NewCorpus.to_excel(\"19-07-21-Scopus\\Fusion\\LastCorpus\\AllCorpusTopics.xlsx\", index=False)\n",
    "NewCorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Section : Topic Modeling with HDP-LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2064"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "\n",
    "#from gensim.models import Phrases\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "# NLTK Stop words\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','a','about', 'above', 'across'])\n",
    "\n",
    "NewCorpus = pd.read_excel('19-07-21-Scopus\\Fusion\\LastCorpus\\AllCorpus.xlsx',header=0)\n",
    "\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Title'] +' '+ NewCorpus['Author Keywords'] +' '+ NewCorpus['Abstract'] #+' '+ NewCorpus['Year'].astype(str)\n",
    "len(NewCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a structure based model chinese organization alignment chunk hierarchical derivation named entity organization rule extraction structural analysis synchronous context free grammar named entity ne fundamental task multilingual natural language processing the performance depends heavily precise inclusive ne furthermore organization on complex ne ne in article structure formulation ons investigated hierarchical structure based on model chinese english presented first model performs on chunking word chunk process chunk reordering achieved synchronous context free grammar cfg the cfg rule extracted bilingual on pair training program the main contribution article defining appropriate chunk unit analyzing internal structure chinese ons making chunk based on feasible flexible hierarchical cfg derivation proposing training architecture automatically learn synchronous cfg constructing ons chunk unit aligned bilingual on pair the experiment proposed approach translates chinese ons english accuracy  significantly improves performance baseline statistical statistical '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction import text\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "import string\n",
    "\n",
    "#Words not must be included in the analysis\n",
    "removed = ['machine','translation','automatic','mt']\n",
    "#Define the function to remove the punctuation\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = str(text).replace(punctuation, ' ')\n",
    "    return text\n",
    "\n",
    "#Lemmatizaion of the keywords\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(str(text))]\n",
    "\n",
    "#merge ords of a list into string \n",
    "def ListToString(lista):\n",
    "    text = ''\n",
    "    for word in lista:\n",
    "        text += ' '+word\n",
    "    return text\n",
    "\n",
    "#Replace Abbreviation\n",
    "def replace_Abbreviation(text):\n",
    "    text = str(text).replace('smt', 'statistical')\n",
    "    text = str(text).replace('nmt', 'neural')\n",
    "    text = str(text).replace('rbmt','rule based')\n",
    "    text = str(text).replace('hmt','Hybrid based')\n",
    "    text = str(text).replace('dmt','direct based')\n",
    "    text = str(text).replace('tbmt','transfer based')\n",
    "    text = str(text).replace('cbmt','corpus based')\n",
    "    text = str(text).replace('ebmt','example based')\n",
    "    return text\n",
    "\n",
    "#Apply Remove Punctuations\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(remove_punctuations)\n",
    "#Remove Stop words:\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))\n",
    "#Lowercase Author Keywords\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.lower()\n",
    "#Remove All words that could mess our classification\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in removed))\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(replace_Abbreviation)\n",
    "#Apply the function lemmatization\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(lemmatize_text)\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].apply(ListToString)\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.replace('\\d+', '')\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.replace('  ', ' ')\n",
    "NewCorpus['Titles & Keywords'] = NewCorpus['Titles & Keywords'].str.split('©').str[0]\n",
    "NewCorpus['Titles & Keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' a structure based model chinese organization alignment chunk hierarchical derivation named entity organization rule extraction structural analysis synchronous context free grammar named entity ne fundamental task multilingual natural language processing the performance depends heavily precise inclusive ne furthermore organization on complex ne ne in article structure formulation ons investigated hierarchical structure based on model chinese english presented first model performs on chunking word chunk process chunk reordering achieved synchronous context free grammar cfg the cfg rule extracted bilingual on pair training program the main contribution article defining appropriate chunk unit analyzing internal structure chinese ons making chunk based on feasible flexible hierarchical cfg derivation proposing training architecture automatically learn synchronous cfg constructing ons chunk unit aligned bilingual on pair the experiment proposed approach translates chinese ons english accuracy significantly improves performance baseline statistical statistical ']\n",
      "[' a structure based model chinese organization alignment chunk hierarchical derivation named entity organization rule extraction structural analysis synchronous context free grammar named entity ne fundamental task multilingual natural language processing the performance depends heavily precise inclusive ne furthermore organization on complex ne ne in article structure formulation ons investigated hierarchical structure based on model chinese english presented first model performs on chunking word chunk process chunk reordering achieved synchronous context free grammar cfg the cfg rule extracted bilingual on pair training program the main contribution article defining appropriate chunk unit analyzing internal structure chinese ons making chunk based on feasible flexible hierarchical cfg derivation proposing training architecture automatically learn synchronous cfg constructing ons chunk unit aligned bilingual on pair the experiment proposed approach translates chinese ons english accuracy significantly improves performance baseline statistical statistical ', ' ancient modern chinese new large training dataset ancient modern chinese parallel corpus bilingual text alignment neural ancient chinese brings wisdom spirit culture chinese nation ancient chinese modern chinese help inherit carry forward quintessence ancient however lack large scale parallel corpus limit study ancient modern chinese in article propose ancient modern chinese clause alignment approach based characteristic language this method combine lexical based information statistical based information achieves f score manual annotation test set we use method create new large scale ancient modern chinese parallel corpus contains m bilingual pair to best knowledge large high quality ancient modern chinese dataset furthermore analyzed compared performance statistical various neural model dataset provided strong baseline task ']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "df = NewCorpus['Titles & Keywords'].values.tolist()\n",
    "\n",
    "df = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in df]\n",
    "\n",
    "# Remove new line characters\n",
    "df = [re.sub('\\s+', ' ', sent) for sent in df]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "df = [re.sub(\"\\'\", \"\", sent) for sent in df]\n",
    "\n",
    "print(df[:1])\n",
    "\n",
    "df = [re.sub(\"-\", \" \", sent) for sent in df]\n",
    "df = [re.sub(\":\", \"\", sent) for sent in df]\n",
    "\n",
    "print(df[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2064"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "df_words = list(sent_to_words(df))\n",
    "len(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(df_words, min_count=5, threshold=10)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "\n",
    "data_words_nostops = remove_stopwords(df_words)\n",
    "\n",
    "# Form Bigrams\n",
    "\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "#_core_web_sm\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel, HdpModel\n",
    "hdpmodel = HdpModel(corpus=corpus, id2word=id2word)\n",
    "hdptopics = hdpmodel.show_topics(formatted=False)\n",
    "print(str(len(hdptopics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdptopics[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords;\n",
    "import nltk;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', max_features=5000, stop_words='english', lowercase=True, \n",
    "                             token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}');\n",
    "x_counts = vectorizer.fit_transform(NewCorpus['Titles & Keywords']);\n",
    "print( \"Created %d X %d document-term matrix\" % (x_counts.shape[0], x_counts.shape[1]) )\n",
    "transformer = TfidfTransformer(smooth_idf=False);\n",
    "x_tfidf = transformer.fit_transform(x_counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['come','order','try','go','get','make','drink','plate','dish','restaurant','place',\n",
    "                  'would','really','like','great','service','came','got'])\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "    \n",
    "def get_corpus(df):\n",
    "    df['text'] = strip_newline(df.text)\n",
    "    words = list(sent_to_words(df.text))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[review] for review in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    return corpus, id2word, bigram\n",
    "\n",
    "train_corpus, train_id2word, bigram_train = get_corpus(rev_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim.models.wrappers.ldamallet as ldamallet\n",
    "#from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "import os\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "os.environ['MALLET_HOME'] = \"C:\\\\Users\\\\HP\\\\Desktop\\\\Equipe-ILC\\\\Automatisation\\\\LdaMallet\\\\mallet-2.0.8\"\n",
    "\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = \"C:\\\\Users\\\\HP\\\\Desktop\\\\Equipe-ILC\\\\Automatisation\\\\LdaMallet\\\\mallet-2.0.8\\\\bin\\\\mallet\" # update this path\n",
    "#ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=20, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2p0lEQVR4nO3dd3xV9f3H8dcni0CAAEmYCQRI2IRh2DgY4hYV66gDt7YO1Kq149fa2lpna2tVarECarWI0qK4EBBkExDChhACBAKEIIGQkPn5/XFPMIYAN5Cbc2/yeT4eeZB7zrn3viEkn3zH+X5FVTHGGGMqC3I7gDHGGP9kBcIYY0yVrEAYY4ypkhUIY4wxVbICYYwxpkohbgeoSdHR0RofH+92DGOMCRgrV648oKoxVZ2rUwUiPj6elJQUt2MYY0zAEJEdJztnXUzGGGOqZAXCGGNMlaxAGGOMqVKdGoMwxhi3FBcXk5mZybFjx9yOUqXw8HBiY2MJDQ31+jlWIIwxpgZkZmbSpEkT4uPjERG34/yAqpKTk0NmZiYdO3b0+nnWxWSMMTXg2LFjREVF+V1xABARoqKiqt26sQJhjDE1xB+LQ7kzyWYFwhjjV9bsOsQ7S3ewLTsP247AXTYGYYzxG2VlyoT3vyUjJx+AtpHhDEuIZnhiNEM7RxPTpIHLCesXKxDGGL8xf0s2GTn5/Pqy7jQMC2ZR2gG+3LCPD1ZmAtCtdROGJ0QzLDGaQR1b0CjMfoT5kv3rGmP8xuTFGbRs0oDxQ+MJDQ7ipkEdKC1T1u/JZWHaARZuPcDUJTuYtHA7ocFC//bNjxeMpHaRhATX717zqVOn8uKLLyIiJCUl8fbbb5/V61mBMMb4hfTsPOZvyeaR0V0IrfCDPjhISIptRlJsM356QQIFRaWk7DjIwq0HWJh2gJdmb+Gl2VtoEh7CkE5RDE+MZnhCNB2jI1wbNP7dx+vZsOdwjb5mj7ZN+e0VPU96fv369fzxj39k0aJFREdHc/DgwbN+TysQxhi/MHXJDkKDhRsHxZ3yuoZhwZybGMO5iZ4FSHPyClmSnsPCrQf4ZqunSwrq3/jF3Llzufbaa4mOjgagRYsWZ/2aViCMMa7LKyxh+spMLuvdhpZNwqv13KjGDbg8qS2XJ7VFVdl5MJ9vth446fjF8MRoBvp4/OJUv+n7iqrWeIvJCoQxxnUfrcokr7CE8UPjz+p1RIQOURF0iIrg5sGe8Yt1uz3jF4vSqh6/GJ4YTe86MH4xatQorr76ah555BGioqI4ePDgWbcirEAYY1xVVqZMWZxBn9hI+rVvXqOvHRwk9IlrRp+4Ztw/wjN+sSLjIIvSqh6/ODcxmmEuj1+cqZ49e/KrX/2K888/n+DgYPr168fkyZPP6jWtQBhjXLUw7QDbso/y5+v6+Py9GoYFc16XGM7r8v34xeJtOSxKO/n4xbCEaKIbB8b4xfjx4xk/fnyNvZ4VCGOMq6YsziC6cRiXJbWp9feOatyAK/q05Yo+nvGLHTn5x7ujvli/9wfjF+cmRjO2bzt6tYus9ZxusQJhjHHNzpx85m7ezwMjEmgQEuxqFhEhPjqC+OgTxy8Wbj3AlMU7eGfpTr54+DzaRzVyNWttCexRGWNMQJu6JINgEW4a1MHtKCcoH7+4f0QC790zmHmPX0BIkPD49DWUlVW9RpQ/rx11JtmsQBjjQ2n7j/DKnK185fRtm+/lF5UwLWUXF/VqTevI6k1tdUO7Zg35v8t7sGz7QaYuyTjhfHh4ODk5OX5ZJMr3gwgPr96/s3UxGVPD0rPzmJWaxSepWWzedwSApuEhLHxyJE3Dvd/Nq66b8e1uDh8r4baznNpam36UHMun67J47vPNXNC1JfHREcfPxcbGkpmZSXZ2tosJT658R7nq8GmBEJGLgb8CwcAkVX220vmxwNNAGVACPKyqC51zE4C7AQH+qaov+zKrMWdjR85RPknNYlZqFhuyPEssJHdozlNX9KBDdAS3v7WCyYsyeGhUostJ/YOqZ2prz7ZNSe5Qs1NbfUlE+NM1vRnzlwU8Pn0N/7lnCEFBnumwoaGh1dqtLRD4rECISDDwKnAhkAmsEJGZqrqhwmVzgJmqqiKSBEwDuolILzzFYSBQBHwuIrNUdauv8hpTXbsO5vPpWk9LYe3uXAD6tW/Gry/rzmVJbWgT2fD4taO7t+LNhdu5bVi8tSKAJek5bNmXx/PXJgXc/QZtIhvy2yt68tgHa3hrcQZ3Dq9bRaEiX7YgBgJpqpoOICLvA2OB4wVCVfMqXB8BlHfedQeWqmq+89z5wNXA8z7Ma8xp7TlUcLworN51CICk2Eh+eWk3Lu3dhtjmVc9umTAqkSv+vpApizJ40FoRTFmcQfNGoVzZp63bUc7IuP7t+HRtFi98sYkRXWPoFNPY7Ug+4csC0Q7YVeFxJjCo8kUicjXwJ6AlcJlzeB3wRxGJAgqAS4GUqt5ERO4B7gFo3759TWU35rh9h48dLword3wHQM+2TXni4q5c3rutV1Mee8dGMrp7SyY5rYgm9bgVkfldPrM37OPe8zsTHuru1NYzVd7VdOGf5/P49FSm3TuE4KDAagl5w5cFoqp/rROG91V1BjBDRM7DMx4xWlU3ishzwGwgD1iDZ4zixBdUfQN4AyA5Odn/pg+YgJR9pJDP12XxcWoWKzIOouq5WeqxMV24tHebM/qNccKoLp5WxOIMHhhZf1sR7yzdCcDNg/1vamt1tGoazlNX9uTRaWt4a9F27jq3k9uRapwvC0QmUHHd3lhgz8kuVtUFItJZRKJV9YCqvgm8CSAizzivZ4zP5OQV8vn6vXyyJotl23MoU0ho2ZgJoxK5PKkNCS2bnNXr946NZFQ3Tyti/ND62Yo4VlzK+yt2MqZHa9o1a3j6J/i5q/u149O1e3nhC8+spoSWdauryZcFYgWQKCIdgd3ADcCPK14gIgnANmeQuj8QBuQ451qq6n4RaQ9cAwzxYVZTTx3KL+LzdXuZtTaLxdtyKC1TOkVH8MCIBC5LakvX1mdXFCqbMDqRK/++iKlLdnD/iIQafe1AMHP1Hg7lF5/1qq3+QkR45ppex2c1Tb9vaJ3qavJZgVDVEhF5APgCzzTXf6nqehG5zzk/ERgH3CoixXjGGq7X7+8y+dAZgygG7lfV73yV1dQvuQXFfLneUxQWbj1ASZnSIaoR953fict6t6V7myY+m1mTFNuMkd1a8s9v0hk/NJ7GDerPrUiqyuTFGXRt1YTBnc5+Mxt/0bJJOL+7sicT3l/NpG/Suff8zm5HqjE+/d+pqp8Cn1Y6NrHC588Bz53kuef6MpupX44cK+arjfv4ZE0WC7ZmU1yqxDZvyJ3nduSKpLb0bNu01qZbThiVyNhXFzFlcUa9akWk7PiODVmHeebq3gE3tfV0ruzTlk/XZvHS7C2M6t7yrLsj/UX9+fXF1DtHC0v4auM+ZqVm8fWWbIpKymgbGc5tQ+O5LKktfWIjXflB1SeuGSO6xjCpnrUiJi/KoGl4CFf1C8ypraciIvzhqt6M+ct8fvZBKh/eNyTgNyACKxCmjskvKmHepmw+Sd3D3E37KSwpo1XTBtw0qD2XJ7WlX1yz43e+umnC6C5c9eoipi7J4KcX1P1WRFZuAZ+v38sdw+J9utWnm2KaNOD3Y3vx4Hvf8sY36XXi61o3v1KmXvrL7C28sSCdguJSohs34IYBcVyW1JbkDs39oihU1DeuGRd0jeGfC9IZPySeiDreinh36U7KVLllcLzbUXzq8qQ2fLYui5dnb2VUt1Y1PsmhtgV+G8gYYP2eXP46ZyvDEqJ47+7BLPvlKH43thcDO7bwu+JQbsKoRL7LL2bqkh1uR/GpY8WlvLd8J6O6tazz+yiICE+P7UWT8BAe+2ANxaVlbkc6K1YgTJ3w5y+30DQ8hJeu68uQzlEBMdWwX/vmnN8lhn9+k87RwirvA60TZqVmkXO0qM5MbT2dqMYNePqqXqzdncs/5m9zO85ZsQJhAt7KHd8xZ9N+7j2/M5ENA+vmswmjEzl4tIi3l9bNVoSqMmVJBgktGzM8IdrtOLXm0t5tuDypDX+ds5WNzuq+gcgKhAl4L36xmejGYdw+LN7tKNXWv31zzusSwxsL0skvqnutiG93HSI1M5fxQzrUuamtp/P7sb2IbBga0F1NViBMQFuUdoAl6TncPyIhYGfHTBjltCLq4FjElMUZNGkQwjX9q7dRTV3QIiKMP1zVm/V7DvPavMDsarICYQKWqvLCF5tpGxnOjwcF7kq+53RozrmJ0XWuFbH/iGcV3GuTY+v8LK2TubhXa8b2bcsrc7eyfk+u23GqzQqECVhzNu5n9a5DPDQqkQYhgblsdLmHRyeSc7SId+rQWMS/l+2kuFS5dUi821Fc9dQVPWnWKIzHPkilqCSwupqsQJiAVFamvPjlZuKjGjHunMDvvjinQ4s61YooKinj3WU7uaBrDB0r7NtcHzWPCOOZq3uxMeswf5+X5nacarECYQLSJ2uz2LT3CI9c2IXQOrCkAXjGIg7kFfGus19CIPtsXRbZRwrrzdTW0xnTszXX9GvHa/PSWLc7cLqa6sZ3lqlXSkrLeHn2Frq2asIVSXVnXZ/k+BYMT4jmHwu2UVBU6nacszJlcQYdoyM4PzHG7Sh+47dX9KRFRBiPfbAmYLqarECYgPPRqt2kHzjKo2O6+O1d0mdqwminFbEscMci1mbmsmrnIW4Z3KHOfX3ORmSjUP50TW827T3CK3O3uh3HK1YgTEApLCnlr3O20ic2kjE9Wrkdp8YNiG/BsIQoJs5PD9hWxOTFGTQKC+ba5MAfG6ppo7q3Ylz/WF77ehupmYfcjnNaViBMQHl/+S52HyrgsYu61tkbryaM6sKBvMKAbEUcyCvk4zV7GNc/lqb1cEtVb/zmih5EN/Z0NRWW+PcvAVYgTMDILyrhlblpDOrYok4v2zCwYwuGdo7iHwvSOVbs3z9AKnt/+U6KSssYP7SD21H8VmTDUJ4dl8SWfXn89Sv/7mqyAmECxpTFOziQV8jjdbj1UG7CqESyjxTy7rLAmdFUXFrGO0t3Mjwhus7sqOYrI7q25LrkWCbO38bqXYfcjnNSViBMQDh8rJiJ87dxQdcYkuPrzn7GJzOoUxRDOkUxcf62gGlFfLl+H3sPH7OprV769eU9aNU0nJ9NW+23X2MrECYgTPpmO7kFxTw2pqvbUWrNhNGeVsS/A6QVMWVxBnEtGjKyW0u3owSEpuGhPDcuiW3ZR/nLV1vcjlMlnxYIEblYRDaLSJqIPFnF+bEikioiq0UkRUSGVzj3iIisF5F1IvKeiIT7MqvxXwePFvHmN+lc0qs1vdpFuh2n1gzuFMXgTi0CohWxYc9hlmcc5NbB8QGxF4e/OK9LDDcOjOOfC9JZtfM7t+OcwGcFQkSCgVeBS4AewI0i0qPSZXOAPqraF7gDmOQ8tx3wEJCsqr2AYOAGX2U1/m3i/G0UFJfy6IVd3I5S6yaM6sL+I4W8t9y/WxFTFmfQMDSY65Lj3I4ScH55aXfaRDbksQ/W+N0vAr5sQQwE0lQ1XVWLgPeBsRUvUNU8VVXnYQSgFU6HAA1FJARoBOzxYVbjp/YdPsaUxRlc1a8dia3q38DnkM5RDOrYgte/9t9WxHdHi/jv6t1c1a8dkY1samt1NXG6mtKzj/LSl5vdjvMDviwQ7YBdFR5nOsd+QESuFpFNwCw8rQhUdTfwIrATyAJyVfXLqt5ERO5xuqdSsrOza/ivYNz2ytytlJYpD4+qf62HchNGJ7L/SCHv+2kr4j8puygssamtZ2N4YjQ3DWrPpIXbSck46Hac43xZIKrqiNQTDqjOUNVuwFXA0wAi0hxPa6Mj0BaIEJGbq3oTVX1DVZNVNTkmxtZ9qUt2Hczn/eW7uH5AXJ3f7P5UhnSKYmDHFrzuh2MRpWXK20t2MLhTC7q1bup2nID2i0u7065ZQx6fnuo3d9H7skBkAhU7JGM5RTeRqi4AOotINDAa2K6q2apaDHwEDPVhVuOHXv5qK8FBwoMjE92O4ioR4eFRiew7XMh/Vuw6/RNq0Vcb97H7UAG32dTWs9a4QQjPX5vE9gNHeeEL/+hq8mWBWAEkikhHEQnDM8g8s+IFIpIgzh1PItIfCANy8HQtDRaRRs75UcBGH2Y1fiZt/xFmfJvJLYM70DrSJrAN6RzFwHj/G4uYsjiDtpHhjO5e99bFcsPQztHcOqQDby3ezvLt7nc1+axAqGoJ8ADwBZ4f7tNUdb2I3Cci9zmXjQPWichqPDOerlePZcB0YBWw1sn5hq+yGv/zl9lbaRgazE8u6Ox2FL8gIkwYncjew8eYluIfrYgt+46weFsONw/pQEgd2ZPDH/z84m7ENW/E49PXuL55lE+/qqr6qap2UdXOqvpH59hEVZ3ofP6cqvZU1b6qOkRVF1Z47m9VtZuq9lLVW1S10JdZjf9YtzuXWWuzuHN4R6IaN3A7jt8Y2jmK5A7NeW3eNr9Y5G3K4gzCQoK4YUDg7gfujyKcrqYdOfk8/7m7XU1W9o3f+fPsLUQ2DOWu8zq5HcWviAgPj+7iaUW4PBaRW1DMR6t2M7ZPW1pEhLmapS4a3CmK24bGM3lxBkvTc1zLYQXC+JWVOw4yd9N+7j2/ky0XXYVhCVGc06E5r33tbivig5RdFBSX2rpLPvTExV2Jj/J0NR0tdKeryQqE8RuqygtfbCa6cQObFXMSnlZEIlm5x5iWkulKhtIyZeqSHSR3aF6vlj6pbY3CQnjhR33I/K6AZz/b5EoGKxDGbyxKy2Fp+kHuH9GZRmEhbsfxW8MTounfvhmvz0tzpRXx9eb97DyYb62HWjAgvgV3DOvI20t3sDjtQK2/vxUI4xdUlRe+3EzbyHB+PMgGPU+lfCxiT+4xPnChFTF5cQatmjbg4l6ta/2966PHxnSlY3QEj09PJa+Wu5qsQBi/8NXG/azZdYgJoxNpEBLsdhy/d25iNP3aN+O1eWkUlZTV2vtuy87jm60HuHlQB0JtamutaBgWzIs/SmJPbgF/+rR2bwezr7BxXVmZ8tKXm+kYHcG4/rbRvTd+0IpYWXszmqYuziAsOIgbrZVXq87p0IK7z+3Eu8t28s3W2ltzzgqEcd3HqXvYtPcID49OtBuuquG8xGj6xjXjtXnbaqUVceRYMdNXZnJ5Uhui7f6UWvfohV3oFBPBz6encuRYca2852m/G53lLv5PRP7pPE4Ukct9H83UByWlZbz81Va6tW7CFUlt3Y4TUMpnNO0+VMD0lb4fi/hwZSZHi2xqq1vCQ4N58Ud92Hv4GM/UUleTN7+uvQUUAkOcx5nAH3yWyNQrH67KZPuBozx6YReCbCeyaju/Swx94prxqo/HIsqcqa1945rRJ66Zz97HnFr/9s2557zOvLd8F/O3+L6ryZsC0VlVnweKAVS1gKqX8jamWgpLSvnbnDT6xDXjwh622NuZqNiK+HCV71oR36QdIP3AUbs/xQ88PDqRxJaNefLDVA77uKvJmwJRJCINcfZyEJHOeFoUxpyV95btZPehAh4b0wVnUV9zBi7oEkOf2EiftiKmLM4gunEDLu3dxievb7xX3tW0/0ghf/hkg0/fy5sC8VvgcyBORN7Fs4/0Ez5NZeq8/KIS/j5vG4M7tWB4QrTbcQJa+YymzO8K+MgHrYgdOUeZt3k/Px7UnrAQm0TgD/rENePe8zoxLSWTeZv2++x9TvnVFpEgoDlwDXAb8B6QrKpf+yyRqRcmL87gQF4hj1/U1VoPNeCCrjEkxUby93lpFJfWbCti6pIdBItwk01t9SsTRifSpVVjnvwoldx833Q1nbJAqGoZ8ICq5qjqLFX9RFVr/35vU6fkFhTzj/npjOgawzkdWrgdp04oH4uo6VbE0cISpqXs4pLebWjV1DZu8icNQoJ56Ud9OZBXxO991NXkTXtxtog8JiJxItKi/MMnaUy98OY36eQWFPOzMV3djlKnjOjassZbETO+3c2RYyXcNrRDjbyeqVm9YyP56QWd2bzvsE82F/KmQNwB3A8sAFY6Hyk1nsTUCzl5hby5cDuX9m5tK4HWMBFhwqhEdh0sYMaq3Wf9eqrKlMUZ9GrXlP7tm9dAQuMLD45MZMZPh/lkgcvTFghV7VjFh+3kYs7IxPnbKCgu5dELu7gdpU4a2a0lvdvVTCti8bYctu7PY/yQeBsn8mNhIUE+WxfLmzupQ0XkIRGZ7nw8ICK2k4uptr25x5i6ZAdX9WtHQssmbsepk8pbETsP5vPfb8+uFTF5cQYtIsK4oo/d4V5feVN2XgfOAV5zPs5xjhlTLa/M3UqZKo+MttaDL43q3pJe7Zry93lplJxhK2LXwXzmbNzHjQPjCA+11XXrK28KxABVHa+qc52P24EB3ry4iFwsIptFJE1Enqzi/FgRSRWR1SKSIiLDneNdnWPlH4dF5OFq/c2MX9mZk89/Vuzi+gFxxLVo5HacOs3TiujCjpx8/rt6zxm9xjtLdyAi3DzYBqfrM28KRKlz9zQAItIJOO02ViISDLwKXAL0AG4UkR6VLpsD9FHVvngGwycBqOpmVe3rHD8HyAdmeJHV+KmX52whOEh4cGSi21HqhdHdW9KzbVNembu12q2IgqJS3l+xi4t6tqJNZEMfJTSBwJsC8TgwT0S+FpH5wFzgZ148byCQpqrpqloEvA+MrXiBquapqjoPI3CW86hkFLBNVXd48Z7GD6XtP8J/v93NrUM62Fz6WlI+FrEjJ5//VbMV8b/Vu8ktKGb8kHjfhDMB47TzolR1jogkAl3xLNK3SVW9WYupHVBxJ5NMYFDli0TkauBPQEvgsipe5wY8d3BXSUTuAe4BaN/e7vT0R3+evYWGocH85IIEt6PUKxf2aEWPNp5WxNi+bb3aa0NVmbw4g26tmzCwo93uVN95M4vpfqChqqaq6hqgkYj81IvXrmpe3AktBFWdoardgKuApyu9dxhwJfDByd5EVd9Q1WRVTY6JifEilqlN63bn8unavdw5vCMtIsLcjlOviAgTRieSkZPPzDXetSKWbz/Ipr1HuG2oTW013nUx3a2qh8ofqOp3wN1ePC8TiKvwOBY46f9SVV0AdBaRiiu3XQKsUtV9Xryf8UMvfrmZyIah3HWe3TrjhjE9WtG9TVNemevdjKYpSzKIbBjK2L7taiGd8XfeFIggqfCrhDP47M2vgiuARBHp6LQEbgBmVrxARBLKX1tE+juvm1Phkhs5RfeS8W8pGQf5enM2953fmabhduuMG8rHIrYfOMrHqaduRew5VMAX6/dxw4A4GobZ1FbjXYH4ApgmIqNEZCSeH9ifn+5JqloCPOA8fyMwTVXXi8h9InKfc9k4YJ2IrMYz4+n68kFrEWkEXAh8VM2/k/EDqsoLX2wmunEDxts6Pq4a06MV3Vo34ZU5aZSWVTUPxOPdZTtQVZvaao7zZvGOn+MZBP4JnnGFL3Gmo56Oqn4KfFrp2MQKnz8HPHeS5+YDUd68j/E/C9MOsGz7QZ66oodP1ogx3gsK8qz0et87q/h4zR6u6ndi99Gx4lLeW76LUd1b2X0q5jhv1mIqU9WJqnotnrGHJap62vsgTP2lqrz4xWbaNWvIjbaHgF8Y06M13Vo34W9zt1bZivgkNYuDR4tsS1HzA97MYvpaRJo6S3yvBt4SkT/7PJkJWLM37GNNZi4PjUqgQYj1ZfuDoCDPWER69lE+qTQWUb5qa2LLxgztbI128z1vxiAiVfUwnl3l3lLVc4DRvo1lAlVZmfLSl1voGB3BuP6xbscxFVzUszVdWzXhr3N+2IpYtfMQa3fncqtNbTWVeFMgQkSkDXAd8ImP85gA93HqHjbvO8LDoxO9ujHL1J6gIM99EZVbEZMXZ9AkPIRrqhibMPWbN9/Bv8czEylNVVc4azFt9W0sE4iKS8v4y+wtdGvdhCuSbIlof3Sx04r4m9OK2Hf4GJ+tzeK65DgiGthkAvND3gxSf6CqSar6U+dxuqqO8300E2g+XJlJRk4+PxvTlaAg66rwR0FBwoOjEtiWfZRZa7N4d9lOSlW5dYhNbTUnsl8ZTI0oLCnlb3O20ieuGaO7t3Q7jjmFS3u1IbHlVv761RZyC0oY0bUlHaIi3I5l/JB1Epsa8e9lO9mTe4zHx3S1gU4/FxQkPDQqkW3ZRzmQV8h4m9pqTsIKhDlr+UUlvDovjcGdWjAswaZJBoJLe7ehS6vGdI6J4NyE6NM/wdRLp+1iEpFWwDNAW1W9xNn0Z4iqvunzdCYgvLUogwN5RfzjFms9BIrgIOGduwahio0XmZPypgUxGc8spvJpKVuAh32UxwSY3IJi/jF/GyO6xnBOB9s/IJC0bBJuGziZU/KmQESr6jSgDI4vwmdLbRgAJn2TzuFjJfxsTFe3oxhjapg3BeKoiEThbPYjIoOBXJ+mMgEhJ6+Qfy3czmW929CrXaTbcYwxNcybaa6P4tnHobOILAJigGt9msoEhNe/3kZBcSmPXNjF7SjGGB/wZk/qVSJyPt/vSb1ZVYt9nsz4tazcAqYu3cHV/WJJaNnY7TjGGB/wdk/qxqq6XlXXAY293JPa1GGvzE1DVXl4dKLbUYwxPuLLPalNHbUzJ59pK3Zx/YA421zGmDrMl3tSmzpIVXnxy80EBwkPjrTWgzF1mTeD1OV7Uk/EM5PpPrzYk9rUTa/OS2Pmmj08NDLB5tAbU8d5uyf1vZzBntSmbnl7SQYvfrmFq/u14+HRNnPJmLrOm1lMZcDrzoepp/63eje/mbme0d1b8vy1SbY8gzH1gDezmIaJyGwR2SIi6SKyXUTSvXlxEblYRDaLSJqIPFnF+bEikioiq0UkRUSGVzjXTESmi8gmEdkoIkOq91czNWXOxn08Om0Ngzq24O8/7k+o7RRnTL3gTRfTm8AjwEqqscSGM5j9KnAhkAmsEJGZqrqhwmVzgJmqqiKSBEwDujnn/gp8rqrXikgYYNNlXLA0PYefvruKnm2b8s9bkwkPDXY7kjGmlnhTIHJV9bMzeO2BeLYpTQcQkfeBscDxAqGqeRWuj+D75TyaAucBtznXFQFFZ5DBnIW1mbncNSWF2OYNmXz7QJqEh7odyRhTi7zpK5gnIi+IyBAR6V/+4cXz2gG7KjzOdI79gIhcLSKbgFnAHc7hTkA28JaIfCsik0Skyi2vROQep3sqJTs724tYxhtp+/MY/9ZyIhuG8s5dg2gRYTObjalvvCkQg4BkPHtCvOR8vOjF86oaxdQTDqjOUNVuwFXA087hEKA/8Lqq9gOOAieMYTjPf0NVk1U1OSYmxotY5nQyv8vnljeXESSePQPaRDZ0O5IxxgXezGIacYavnQnEVXgcC+w5xfssEJHOIhLtPDdTVZc5p6dzkgJhalb2kUJueXM5eYUl/OeeIXSMtr2KjamvvJnF1EpE3hSRz5zHPUTkTi9eewWQKCIdnUHmG/CsClvxtRPK79J2uq3CgBxV3QvsEpHyTQZGUWHswvhGbkEx4/+1nKzcAt66bQA92jZ1O5IxxkU+21HO2VjoAee5G4FpqrpeRO4Tkfucy8YB60RkNZ4ZT9erank31IPAuyKSCvTF08VlfKSgqJS7pqxg6/4j/OOWZJLjbXc4Y+o7+f7n8UkuEFmhqgNE5FtnPAARWa2qfWsjYHUkJydrSkqK2zECTlFJGfe8ncL8Ldm8cmM/Lk9qe/onGWPqBBFZqarJVZ2zHeXqudIy5dFpq/l6czbPXN3bioMx5jjbUa4eU1X+73/r+CQ1i19c0o0bB7Z3O5Ixxo+cskA4d0Of73zYjnJ1zPNfbObfy3bykws6c+/5nd2OY4zxM6fsYlLVUmCsqpaU7yhnxaFumDh/G69/vY0fD2rPExd1Pf0TjDH1jjddTItE5O/Af/DcsAZ49qr2WSrjU+8t38mzn23i8qQ2PD22FxX2gzLGmOO8KRBDnT9/X+GYAiNrPo7xtU9S9/DLGWu5oGsMf76uL8G2bLcx5iR8eSe18TNfb97PI/9ZTXKH5rx+0zmEhdiy3caYk/PlndTGj6RkHOS+d1aS2LIJk8YPoGGYLdttjDk1n91JbfzHhj2HuX3yCtpGNmTqnQOJbGjLdhtjTs+bAhGtqtOAMji+hIbXGwcZd20/cJRb/7WMxg1CePuuQUQ3buB2JGNMgLA7qeuwrNwCbp60jDKFt+8cRLtmtmy3McZ7did1HXXwaBE3T1pGbkEx7909mISWjd2OZIwJMN7MYlolInYndQA5csyzbHfmdwVMvWMgvWMj3Y5kjAlA3rQgwLO/dLxzfX8RQVWn+iyVOWPHiku5a0oKG7MO88at5zCoU5TbkYwxAeq0BUJE3gY6A6v5fnBaASsQfqa4tIwH/r2K5RkHefn6vozs1srtSMaYAOZNCyIZ6KGn2zjCuKqsTHlieipfbdzP01f1Ymzfdm5HMsYEOG9mMa0DWvs6iDlzqsrvPl7PjG9389iYLtwyuIPbkYwxdcBJWxAi8jGerqQmwAYRWQ4Ulp9X1St9H8944y+ztzBlyQ7uPrcj949IcDuOMaaOOFUX04u1lsKcsUnfpPO3uWlcnxzHLy/tbiuzGmNqzEkLhKrOL/9cRFoBA5yHy1V1v6+DmdOblrKLP8zayCW9WvPMNb2tOBhjapQ3i/VdBywHfgRcBywTEa9ulBORi0Vks4ikiciTVZwfKyKpIrJaRFJEZHiFcxkisrb8nPd/pfrh83V7efLDVM5NjOblG2zZbmNMzfNmFtOvgAHlrQYRiQG+Aqaf6knOdqWvAhcCmcAKEZmpqhsqXDYHmKmqKiJJwDSgW4XzI1T1gNd/m3pi4dYDPPTet/SJa8bEm8+hQYitzGqMqXnezGIKqtSllOPl8wYCaaqarqpFwPvA2IoXqGpehemzETjrPZmTW7XzO+55O4VOMRFMvm0gEQ28vdfRGGOqx5sf9J+LyBcicpuI3AbMAj7z4nntgF0VHmc6x35ARK4WkU3O695R4ZQCX4rIShG552RvIiL3ON1TKdnZ2V7EClyb9x7h9rdWENOkAVPvGEhkI1u22xjjO6ctEKr6OPAPIAnoA7yhqk948dpVdYqf0EJQ1Rmq2g24Cni6wqlhqtofuAS4X0TOO0m+N1Q1WVWTY2JivIgVmHbm5HPLm8sIDw3inTsH0bJpuNuRjDF13EkLhIgkiMgwAFX9SFUfVdVHgBwR6ezFa2cCcRUexwJ7Tnaxqi7As2JstPN4j/PnfmAGni6remnf4WPc9OZSikrLePvOQcS1aOR2JGNMPXCqFsTLwJEqjuc7505nBZAoIh1FJAy4Ac+y4cc5RUicz/sDYXgKUISINHGORwBj8NzRXe8cyi/i1jeXczCviMm3D6RLqyZuRzLG1BOnGuGMV9XUygdVNUVE4k/3wqpaIiIP4NmuNBj4l6quF5H7nPMTgXHArSJSDBQA1zszmloBM5zaEQL8W1U/r+bfLeAdLSzhtrdWsP3AUSbfPoC+cc3cjmSMqUdOVSBO1cnt1dZkqvop8GmlYxMrfP4c8FwVz0vHM95Rb5WVKT95dxVrd+fy2k39GZoQ7XYkY0w9c6ouphUicnflgyJyJ7DSd5EMwLvLdrBgSzZPXdmTi3raWonGmNp3qhbEw3i6eW7i+4KQjGec4Gof56rXdh3M50+fbeLcxGhuHtTe7TjGmHrqVGsx7QOGisgIoJdzeJaqzq2VZPWUqvLLGWsR4E+2vpIxxkXe7Ek9D5hXC1kM8EFKJt9sPcDTY3sS29ymsxpj3OPNndSmluzNPcbTszYwqGMLbhpkm/4YY9xlBcJPqCq/mrGW4tIynhuXRJCtzmqMcZkVCD8xc80e5mzaz2NjuhIfHeF2HGOMsQLhD7KPFPLbmevp174Ztw/r6HYcY4wBrED4hadmrie/sJQXrk2yjX+MMX7DCoTLPlubxay1WUwYnUhCS1tnyRjjP6xAuOi7o0X83//W0atdU+45r5PbcYwx5gdsOzIX/f6TDRzKL2bqHYMIDbZabYzxL/ZTySVzNu5jxre7+emIBHq0bep2HGOMOYEVCBfkFhTzyxlr6dqqCQ+MSHA7jjHGVMm6mFzwp083kn2kkDduSSYsxGq0McY/2U+nWvbN1mzeX7GLu8/rRB/bAMgY48esQNSio4UlPPnhWjpFR/DI6C5uxzHGmFOyLqZa9Pznm9iTW8AH9w4hPDTY7TjGGHNK1oKoJcu3H2TKkh3cNjSe5PgWbscxxpjTsgJRCwqKSnli+hriWjTk8Yu6uh3HGGO84tMCISIXi8hmEUkTkSerOD9WRFJFZLWIpIjI8Erng0XkWxH5xJc5fe0vX20hIyef565JolGY9eoZYwKDzwqEiAQDrwKXAD2AG0WkR6XL5gB9VLUvcAcwqdL5CcBGX2WsDd/u/I5J36Tz40HtGZoQ7XYcY4zxmi9bEAOBNFVNV9Ui4H1gbMULVDVPVdV5GAGUf46IxAKXcWLRCBiFJaU8MT2VVk3D+cUl3dyOY4wx1eLLAtEO2FXhcaZz7AdE5GoR2QTMwtOKKPcy8ARQdqo3EZF7nO6plOzs7LMOXZP+PjeNrfvzeOaa3jQJD3U7jjHGVIsvC0RVGxvoCQdUZ6hqN+Aq4GkAEbkc2K+qK0/3Jqr6hqomq2pyTEzMWUauOet25/La19sY1z+WEV1buh3HGGOqzZcFIhOIq/A4FthzsotVdQHQWUSigWHAlSKSgadraqSIvOPDrDWquLSMJ6an0iIijP+7vLvbcYwx5oz4skCsABJFpKOIhAE3ADMrXiAiCSIizuf9gTAgR1V/oaqxqhrvPG+uqt7sw6w16h/zt7Eh6zB/uKoXzRqFuR3HGGPOiM/mXKpqiYg8AHwBBAP/UtX1InKfc34iMA64VUSKgQLg+gqD1gFpy74j/G1OGpcnteGinq3djmOMMWdMAvzn8Q8kJydrSkqKa+9fUlrGuNcXs+u7AmY/ch5RjRu4lsUYY7whIitVNbmqc3bXVg3616LtrMnM5W839rPiYIwJeLbURg1Jz87jpS+3cGGPVlyR1MbtOMYYc9asQNSAsjLl5x+m0iAkiD9e1Qtn3N0YYwKaFYga8PbSHazI+I7fXNGTlk3D3Y5jjDE1wgrEWdp1MJ/nPt/E+V1iGNf/hBvFjTEmYFmBOAuqypMfpRIkwjPX9LauJWNMnWIF4iz8Z8UuFqXl8ItLu9GuWUO34xhjTI2yAnGGsnIL+OOsjQzpFMWNA9q7HccYY2qcFYgzoKr88qO1lJQpz47rTVCQdS0ZY+oeKxBn4L+rdzNvczaPX9SVDlERbscxxhifsAJRTfuPHOOpmRs4p0Nzxg+NdzuOMcb4jBWIavrt/9ZTUFzKc+OSCLauJWNMHWYFoho+XZvFZ+v28sjoLiS0bOx2HGOM8SkrEF46eLSI3/xvHb3bRXL3uR3djmOMMT5nq7l66fcfrye3oJh37hpESLDVVWNM3Wc/6bzw1YZ9/Hf1Hu4fkUC31k3djmOMMbXCCsRp5BYU86v/rqVb6yb89IIEt+MYY0ytsS6m0/jjrA0cyCti0q0DCAuxemqMqT/sJ94pLNiSzbSUTO49rxO9YyPdjmOMMbXKCsRJ5BWW8IuP1tI5JoKHRiW6HccYY2qddTGdxHOfbWJPbgHT7xtKeGiw23GMMabW+bQFISIXi8hmEUkTkSerOD9WRFJFZLWIpIjIcOd4uIgsF5E1IrJeRH7ny5yVLU3P4e2lO7hjWEfO6dC8Nt/aGGP8hs9aECISDLwKXAhkAitEZKaqbqhw2RxgpqqqiCQB04BuQCEwUlXzRCQUWCgin6nqUl/lLVdQVMrPP0ylQ1QjHhvT1ddvZ4wxfsuXLYiBQJqqpqtqEfA+MLbiBaqap6rqPIwA1DmuqprnHA91PpRa8NKXm9mRk8+z1yTRMMy6lowx9ZcvC0Q7YFeFx5nOsR8QkatFZBMwC7ijwvFgEVkN7Admq+qyqt5ERO5xuqdSsrOzzyrwqp3f8eai7dw8uD1DOked1WsZY0yg82WBqGqp0xNaAao6Q1W7AVcBT1c4XqqqfYFYYKCI9KrqTVT1DVVNVtXkmJiYMw57rLiUJ6an0jayIU9e0v2MX8cYY+oKXxaITCCuwuNYYM/JLlbVBUBnEYmudPwQ8DVwcc1H/N4rc7eStj+PZ67pTeMGNrnLGGN8WSBWAIki0lFEwoAbgJkVLxCRBBER5/P+QBiQIyIxItLMOd4QGA1s8lXQdbtzmTg/nR+dE8v5Xc68FWKMMXWJz35VVtUSEXkA+AIIBv6lqutF5D7n/ERgHHCriBQDBcD1zoymNsAUZyZUEDBNVT/xRc6ikjIe+2ANURFh/PqyHr54C2OMCUg+7UtR1U+BTysdm1jh8+eA56p4XirQz5fZyhWXltGrXSRjerQislFobbylMcYEhHrf2R7RIIQXf9TH7RjGGON3bC0mY4wxVbICYYwxpkpWIIwxxlTJCoQxxpgqWYEwxhhTJSsQxhhjqmQFwhhjTJWsQBhjjKmSfL8dQ+ATkWxgxxk+PRo4UINxaorlqh7LVT2Wq3rqYq4OqlrlInR1qkCcDRFJUdVkt3NUZrmqx3JVj+WqnvqWy7qYjDHGVMkKhDHGmCpZgfjeG24HOAnLVT2Wq3osV/XUq1w2BmGMMaZK1oIwxhhTJSsQxhhjqlSvC4SIxInIPBHZKCLrRWSC25kqEpFgEflWRHyy3eqZEJFmIjJdRDY5/25D3M4EICKPOF/DdSLynoiEu5jlXyKyX0TWVTjWQkRmi8hW58/mfpLrBedrmSoiM8r3gnc7V4Vzj4mIiki0v+QSkQdFZLPz/+15f8glIn1FZKmIrBaRFBEZWBPvVa8LBFAC/ExVuwODgftFxJ82pp4AbHQ7RCV/BT5X1W5AH/wgn4i0Ax4CklW1F5490G9wMdJk4OJKx54E5qhqIjDHeVzbJnNirtlAL1VNArYAv6jtUFSdCxGJAy4EdtZ2IMdkKuUSkRHAWCBJVXsCL/pDLuB54Heq2hf4jfP4rNXrAqGqWaq6yvn8CJ4fdu3cTeUhIrHAZcAkt7OUE5GmwHnAmwCqWqSqh1wN9b0QoKGIhACNgD1uBVHVBcDBSofHAlOcz6cAV9VmJqg6l6p+qaolzsOlQKw/5HL8BXgCcGUmzUly/QR4VlULnWv2+0kuBZo6n0dSQ///63WBqEhE4oF+wDKXo5R7Gc83R5nLOSrqBGQDbzldX5NEJMLtUKq6G89vcjuBLCBXVb90N9UJWqlqFnh+MQFaupynKncAn7kdAkBErgR2q+oat7NU0gU4V0SWich8ERngdiDHw8ALIrILz/dCjbQErUAAItIY+BB4WFUP+0Gey4H9qrrS7SyVhAD9gddVtR9wFHe6Sn7A6c8fC3QE2gIRInKzu6kCi4j8Ck+X67t+kKUR8Cs8XSX+JgRojqdL+nFgmoiIu5EAT8vmEVWNAx7BaeWfrXpfIEQkFE9xeFdVP3I7j2MYcKWIZADvAyNF5B13IwGQCWSqankrazqeguG20cB2Vc1W1WLgI2Coy5kq2ycibQCcP2u9a+JkRGQ8cDlwk/rHjVGd8RT7Nc73QCywSkRau5rKIxP4SD2W42nh1/oAehXG4/l/D/ABYIPUZ8up/G8CG1X1z27nKaeqv1DVWFWNxzPYOldVXf+NWFX3ArtEpKtzaBSwwcVI5XYCg0WkkfM1HYUfDJ5XMhPPNzHOn/9zMctxInIx8HPgSlXNdzsPgKquVdWWqhrvfA9kAv2d/39u+y8wEkBEugBh+MfqrnuA853PRwJba+RVVbXefgDD8QzupAKrnY9L3c5VKeMFwCdu56iQpy+Q4vyb/Rdo7nYmJ9fvgE3AOuBtoIGLWd7DMxZSjOeH251AFJ7ZS1udP1v4Sa40YFeF//8T/SFXpfMZQLQ/5MJTEN5x/p+tAkb6Sa7hwEpgDZ5x1HNq4r1sqQ1jjDFVqtddTMYYY07OCoQxxpgqWYEwxhhTJSsQxhhjqmQFwhhjTJWsQJh6y1kl9KUKjx8Tkadq+D1ud1bYXC0iRSKy1vn82Wq+zqdurLRq6jeb5mrqLRE5hmc++QBVPSAijwGNVfUpH71fBp4VZ/3hxipjTstaEKY+K8Gzl+8jlU+IyGQRubbC4zznzwucRdqmicgWEXlWRG4SkeVO66Dz6d5UPF5w9q5YKyLXV3jtBc6+DBtEZKKIBDnnMsr3RBCRW539G9aIyNvOsR85r7dGRBbUxD+OMSFuBzDGZa8CqdXc+KUP0B3PksvpwCRVHSieDacexLOy5qlcg+eO9D541vFZUeGH+kCgB7AD+Ny5dnr5E0WkJ56F7IY5rZ4WzqnfABep6m7rijI1xVoQpl5Tz+q9U/FsOOStFerZS6QQ2AaULy2+Foj34vnDgfdUtVRV9wHzgfJlo5erarqqluJZUmF4peeOBKaXd1Opavm+AIuAySJyN54Nk4w5a1YgjPHsvXEnUHFvixKc7w9nAcCwCucKK3xeVuFxGd61yk+1PHTlQcHKj6WKY6jqfcCvgThgtYhEeZHDmFOyAmHqPee38Gl4ikS5DOAc5/OxQGgNvuUC4Hrx7Dkeg2eXvuXOuYEi0tEZe7geWFjpuXOA68oLQHkXk4h0VtVlqvobPKuLxtVgXlNPWYEwxuMlfriu/z+B80VkOTAIz+ZINWUGntVw1wBzgSf0+6WslwDP4lktdLtz7XGquh74IzBfRNYA5cvUv+AMeK/DU4D8bSc2E4BsmqsxfkJELgAeU9XLXY5iDGAtCGOMMSdhLQhjjDFVshaEMcaYKlmBMMYYUyUrEMYYY6pkBcIYY0yVrEAYY4yp0v8DD3voWL2LIYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Show graph\n",
    "limit=20; start=2; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
